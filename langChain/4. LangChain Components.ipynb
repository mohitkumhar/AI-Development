{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915385ba-f822-402e-8881-17f7b6c94dbe",
   "metadata": {},
   "source": [
    "# Components of LangChain\n",
    "\n",
    "1. Models\n",
    "2. Prompts\n",
    "3. Chains\n",
    "4. Memory\n",
    "5. Indexes\n",
    "6. Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75b093-7acf-4f25-b1b3-c74db756fa51",
   "metadata": {},
   "source": [
    "## 2. Models\n",
    "In LangChains, \"*models*\" are the core interfaces through which you interact with AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc9ede7-848a-4cdc-8028-cd1ebb94116d",
   "metadata": {},
   "source": [
    "##### These can be large language models (LLMs) like:\n",
    "\n",
    "- OpenAI (GPT-3.5, GPT-4)\n",
    "- Anthropic (Claude)\n",
    "- Google (Gemini)\n",
    "- Hugging Face models\n",
    "- Local models (like Llama, Mistral via Ollama or Hugging Face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56fecd-8b3d-405a-88e0-7c1185bbc42b",
   "metadata": {},
   "source": [
    "##### Why Models Are Important:\n",
    "\n",
    "- They are the \"brain\" of your application.\n",
    "- LangChain makes it easy to use any model provider, so you're not locked into one platform.\n",
    "- You can switch between cloud and local models without changing your app logic.\n",
    "\n",
    "```bash\n",
    "# Example\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4\")\n",
    "response = model.predict(\"What is LangChain?\")\n",
    "print(response)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf91673-ffcd-49eb-94a6-98ad1b229672",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f461c-c8f5-4e31-9137-d0e9e6cdb7ba",
   "metadata": {},
   "source": [
    "# 2. Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341dc61b-21e2-4349-a876-83b8cfcd78c9",
   "metadata": {},
   "source": [
    "- Prompts are the instructions or questions you give to the model.\n",
    "- A good prompys helps the model understand what to do- whether it's answering a question, summarizing a documentt, or generating code.\n",
    "\n",
    "- LangChain makes prompt management easy by allowing you to define, reuse, and customize prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c38d1b-0955-4e71-90bb-cfa13134cf39",
   "metadata": {},
   "source": [
    "##### Why Prompts Matter\n",
    "- The Quality of your prompts affeccts the model's output.\n",
    "- With LangChain, you can create flexible and structured prompts that adapt to different inputs.\n",
    "- Helps in building modular and maintainable AI applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d73c6-7b60-4e41-9635-95a24fc84500",
   "metadata": {},
   "source": [
    "## Types of Prompts in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f089d3-257f-410c-bbfc-ef33503b7e59",
   "metadata": {},
   "source": [
    "### 1. Dynamic & Reusable Prompts\n",
    "- These prompts use variables like {question} or {context} that get filled at runtime\n",
    "- Helps avoid hardcoding and makes the prompt flexible for different inputs.\n",
    "\n",
    "```bash\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"Answer the following question based on the context:\\nContext: {context}\\nQuestion: {question}\"\n",
    "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acbe24-351f-4e8c-9594-12daba3250b6",
   "metadata": {},
   "source": [
    "### 2. Role-Based Prompts\n",
    "- Used with chat models (like ChatGPT)\n",
    "- You can assign roles like \"system\", \"user\", and \"assistant\" to guide the behavior of the model.\n",
    "\n",
    "```bash\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Explain LangChain in simple terms.\")\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35f221-77a4-4322-9706-c7c0a7e1b3b6",
   "metadata": {},
   "source": [
    "### 3. Few-Shot Prompts \n",
    "- You give the model a few example Q&A pairs or tasks so it can learn from patters.\n",
    "- Improves accuracy for complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb68e0-b269-4af1-906b-dc1a9cffbdbf",
   "metadata": {},
   "source": [
    "```bash\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"question\": \"What is AI?\", \"answer\": \"AI is the simulation of human intelligence by machines.\"},\n",
    "    {\"question\": \"What is ML?\", \"answer\": \"ML is a subset of AI that learns from data.\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Q: {question}\\nA: {answer}\")\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Q: {input}\\nA:\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405ee95-2c9e-407c-80ed-7f63ede0b855",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61008ce-da09-4304-8ded-8455625a543a",
   "metadata": {},
   "source": [
    "# 3. Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e8ceb-af82-4098-849d-3f9951277423",
   "metadata": {},
   "source": [
    "- Chains in LangChain are sequences of steps where the output of one step becomes the input to the next. They help you combine prompts, models, tools, and logic into a structured and repeatable workflow.\n",
    "- Instead of writing all logic manually, you can “chain” different components together—like a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e43503-2ae7-42e0-9306-fdd7869dbd18",
   "metadata": {},
   "source": [
    "#### Why use chains\n",
    "- Makes complex workflows simple and readable\n",
    "- You can reuse and customize chains\n",
    "- Easier to debug and maintain\n",
    "- Supports both simple and advanced workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c21f3b2-5990-4443-84dc-eb30de030592",
   "metadata": {},
   "source": [
    "## Types of Chains\n",
    "### 1. Simple Chain\n",
    "- A Prompt is passed to a language model, and the response is returned\n",
    "\n",
    "### 2. Sequential Chain\n",
    "- Multiple steps run one after another, passing data along the chain.\n",
    "- Example use case: summarize -> translate -> format\n",
    "\n",
    "### 3. Custom Chains\n",
    "- You can create custom logic using `Runnable` components and control data flow, branching, or conditions.\n",
    "\n",
    "### 4. MultiPrompt Chain\n",
    "- Selects the best prompt from a list of prompts based on the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce0fb4-ea6b-4c6a-bf78-a117a860f803",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c62f3-d337-48ea-a54a-0949a258f567",
   "metadata": {},
   "source": [
    "# 4. Indexes\n",
    "Indexes in LangChain help organize and search through large collections of documents or data efficiently. They are mainly used in RAG (Retrieval-Augmented Generation) systems, where relevant information needs to be retrieved and sent to the model.\n",
    "\n",
    "- Indexes connect your unstructured data (like PDFs, text files, websites) to your LLM, so it can answer questions based on real content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121b3a90-e543-47bf-a7b6-539208735ac4",
   "metadata": {},
   "source": [
    "### Why use Indexes\n",
    "- To Search and retrieve relevant documents quickly\n",
    "- To reduce token usage by only sending important context to the model\n",
    "- To build applications like document Q&A,, chat with PDFs, or knowledge assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518625b2-8de7-4cef-8b95-ffc1c07118c8",
   "metadata": {},
   "source": [
    "## Components in Indexing\n",
    "### 1. Document Loaders\n",
    "- Load Data from files like `.pdf`, `.docx`, `.csv`, **websites**, **Notion**, **Google Drive**, etc.\n",
    "\n",
    "### 2. Text Splitters\n",
    "- Break large documents into smaller chunks (e.g., 500 words) for better indexing and retrieval.\n",
    "\n",
    "### 3. Embeddings\n",
    "- Convert each text chunk into a vector (numerical format) that captures its meaning.\n",
    "\n",
    "### 4. Vector Stores (Indexes)\n",
    "- Store the embeddings in a seachable format (like **FAISS**, **Chroma**, **Pinecone**, **Weaviate**, etc)\n",
    "\n",
    "### 5. Retrievers\n",
    "- When a user asks a question, retievers find the most relevant chunks from the index to provide to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a23a64c-fbe2-4acb-aace-2ea27ca2f386",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc91960-66c0-42ae-af99-c648ee85edab",
   "metadata": {},
   "source": [
    "# 5. Memory\n",
    "- Memory lets your application remember previous interactions- like past quetions, answers or user inputs- so the language model can respond with context.\n",
    "- Without memory, every interaction is stateless, meaning the model forgets everything after each prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03862228-4ca1-4264-a4d9-74efa0369698",
   "metadata": {},
   "source": [
    "### Why Use Memory\n",
    "- To make you app conversational (like ChatGPT)\n",
    "- To keep track of a user's history, preferences, or previous tasks\n",
    "- To let the Model answer based on earlier messages or steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e693e-a5d9-4e38-befa-80cb2bfa4818",
   "metadata": {},
   "source": [
    "## Types of Memory\n",
    "### 1. Buffer Memory\n",
    "- Stores all past messages in a list\n",
    "- Good for simple ChatBots\n",
    "\n",
    "```bash\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "```\n",
    "\n",
    "### 2. Summary Memory\n",
    "- Summarizes old messages to stay within token limits\n",
    "- Good for long Conversations\n",
    "\n",
    "### 3. Token Buffer Memory\n",
    "- Keeps only recent messages within a token limit.\n",
    "- Balances context and cost\n",
    "\n",
    "### 4. Combined Memory\n",
    "- Mix of buffer + summary for best of both worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28cef38-53e7-4240-b6e3-599cd86e7679",
   "metadata": {},
   "source": [
    "#### Example\n",
    "```bash\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "response = chain.run(\"My name is Mohit.\")\n",
    "response = chain.run(\"What’s my name?\")  # It will remember \"Mohit\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e27d0b-e116-4005-a10c-6e64c00df703",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11693fc-74b0-4825-882d-d09d7a013473",
   "metadata": {},
   "source": [
    "# 6. AI Agents\n",
    "Agents in LangChain are advanced tools that let the model decide what action to take next based on user input and current context. Instead of following a fixed chain, agents choose tools and paths dynamically.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### They can:\n",
    "- Use tools like search, calculator, or API calls\n",
    "- Ask follow-up questions\n",
    "- Plan multiple steps to solve a task\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### Why Use Agents:\n",
    "- The Agent recieves the user's input\n",
    "- It decides which tool (function ot chain) to use\n",
    "- it uses that tool and may repeat until the final answer is ready\n",
    "- It returns the final response to the user\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### Example Tools\n",
    "- Search (Google, SerpAPI)\n",
    "- Math Calculators\n",
    "- File readers\n",
    "- Database queries\n",
    "- Custom APIs\n",
    "- Chains or Functions you've created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61308190-38b6-4916-8583-049f3298b421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
