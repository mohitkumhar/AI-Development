{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e06713-3cbf-453d-9bbd-f6429d316dd9",
   "metadata": {},
   "source": [
    "#### In LangChain Thre are 2 types of Runables\n",
    "\n",
    "1. Task Specific Runnables\n",
    "   - Defination: These are core LangChain Components that have been converted into Runnables so they can be used in pipelines.\n",
    "   - Purpose: Perform task-specific operation like LLM calls, prompting, reterival, etc\n",
    "   - Examples:\n",
    "     - `ChatOpenAI` - Runs an LLM model\n",
    "     - `PromptTemplate` - Formats prompts dynamically\n",
    "     - `Retriever` - Retrives relevant document\n",
    "\n",
    "2. Runnable Primitives\n",
    "    - Defination: These are fundamental building blocks for structuring  execution logic in AI workflows\n",
    "    - Purpose: They help orchestrate execution by defining how different Runnables interact (sequentially, in parallel, conditionally, etc)\n",
    "    - Examples:\n",
    "        - `RunnableSequence`: Runs steps in **Order** (`|` operator)\n",
    "        - `RunnableParallel`: Runs multiple steps **simultaneously**.\n",
    "        - `RunnableMap`: Maps the same input across multiple functions.\n",
    "        - `RunnableBranch`: Implements **conditional exevution** (if-else logic).\n",
    "        - `RunnableLambda`: Wraps **custom Python functions** into Runnables.\n",
    "        - `RunnablePassthrough`: Just forwards input as output (acts as a placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb33e1-50c6-48b3-91d1-52b73c6ad5fb",
   "metadata": {},
   "source": [
    "# <center>Runnable Primitives</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10636d-db75-4dc7-b770-bdb9a21101b1",
   "metadata": {},
   "source": [
    "# 1. **Runnable Sequence**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891fb06-ddda-4c5e-a396-e59f12b27bf9",
   "metadata": {},
   "source": [
    "- It is a sequential chain of runnables in LangChain that executes each step one after another, passing the output of one step as the input to the next.\n",
    "  \n",
    "- It is useful when you need to compose multiple runnables together in a structured workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476a8c3-987b-4195-bce1-64162f653cfd",
   "metadata": {},
   "source": [
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "597291d8-3c7b-4077-8038-f82d2a05828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220bda90-d3c4-4d18-a863-e2c6e7ad82b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a28f1c7-c9cf-4949-b4fe-dd8b80e52e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPEN_AI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d1942fb-b296-4e7b-beba-593d2528a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template = \"Write a joke about {topic}\",\n",
    "    input_variables=['topic'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67ae5b9f-a17a-4e5f-be3d-96183042c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template=\"Explain the Following Joke- {joke}\",\n",
    "    input_variables=['joke'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d2cd824-5684-4c5e-8469-077a1f6827e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae654b56-f83b-4fb4-b44b-03526519006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18a27580-c7a3-44a1-b457-dd0fa1c3cd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StrOutputParser()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c093e9b0-651c-4952-bef2-5e4dfb25682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableSequence(prompt1, model, parser, prompt2, model, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fa62b88-64de-49de-81d0-624e72f72c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Write a joke about {topic}')\n",
       "| ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x0000019777CAC290>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000197760A2310>, root_client=<openai.OpenAI object at 0x0000019776565DD0>, root_async_client=<openai.AsyncOpenAI object at 0x0000019777CAFCD0>, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://openrouter.ai/api/v1')\n",
       "| StrOutputParser()\n",
       "| PromptTemplate(input_variables=['joke'], input_types={}, partial_variables={}, template='Explain the Following Joke- {joke}')\n",
       "| ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x0000019777CAC290>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000197760A2310>, root_client=<openai.OpenAI object at 0x0000019776565DD0>, root_async_client=<openai.AsyncOpenAI object at 0x0000019777CAFCD0>, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://openrouter.ai/api/v1')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68cf172a-b3ff-403d-afea-5d5babab7769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This joke plays on the word \"bytes,\" which is a unit of digital information storage in computers, and the word \"bites,\" which can refer to emotional baggage or issues. The joke suggests that the robot went to therapy because it had too much emotional baggage, but instead of using the term \"bites,\" it uses \"bytes\" to link it to the context of a robot. Overall, it\\'s a play on words that combines technology and emotional themes for a humorous outcome.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc797833-4430-4592-83a2-91c574445882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b2d2e5c-2c23-40da-9343-5d58c82ead1e",
   "metadata": {},
   "source": [
    "# 2. Runnable Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81028d-2948-4282-88c9-688138994550",
   "metadata": {},
   "source": [
    "- **Runnable Parallel** is a runnable primitive that allows multiple runnables to execute in parallel\n",
    "\n",
    "- Each runnable receives the same input and processes it independently, producing a dictionary of outputs.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467de1b4-9979-44f9-b303-553ed0915097",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daf9a261-b48c-4cc3-b3a8-1ace3bbe6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableSequence, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0efe600a-c21d-420c-b38f-e2501caa0fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe732747-0e5f-4109-affd-840a9e2230fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPEN_AI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a5c48e4-d364-4091-8690-3bbd238550fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template=\"Generate a tweet about {tweet_topic}\",\n",
    "    input_variables=['tweet_topic'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f20605b5-20b8-4bbc-863e-16079726484b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['tweet_topic'], input_types={}, partial_variables={}, template='Generate a tweet about {tweet_topic}')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af3cb665-25c2-464e-9dd0-8c8cc45f17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template=\"Generate a Linkedin Post About {linkedin_topic}\",\n",
    "    input_variables=['linkedin_topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1cf8c72-2807-41f1-8269-7fdf558eb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bf8ccad-c745-4209-97f7-2e0d914f1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3701542c-73cb-41df-93d0-d079445c7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runnable parallel process in dictk\n",
    "parallel_chain = RunnableParallel(\n",
    "    {\n",
    "        \"tweet\": RunnableSequence(prompt1, model, parser), # task-1\n",
    "        \"linkedin\": RunnableSequence(prompt2, model, parser), # task-2\n",
    "    }\n",
    "    # both are running in parallel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd194a18-3327-4e47-9890-f7de4f980029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  tweet: PromptTemplate(input_variables=['tweet_topic'], input_types={}, partial_variables={}, template='Generate a tweet about {tweet_topic}')\n",
       "         | ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x00000197783FB350>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019778332310>, root_client=<openai.OpenAI object at 0x00000197783E17D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000197783E2610>, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://openrouter.ai/api/v1')\n",
       "         | StrOutputParser(),\n",
       "  linkedin: PromptTemplate(input_variables=['linkedin_topic'], input_types={}, partial_variables={}, template='Generate a Linkedin Post About {linkedin_topic}')\n",
       "            | ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x00000197783FB350>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019778332310>, root_client=<openai.OpenAI object at 0x00000197783E17D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000197783E2610>, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://openrouter.ai/api/v1')\n",
       "            | StrOutputParser()\n",
       "}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d17f89a3-1b49-4e3d-a2b5-9f165385d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parallel_chain.invoke(\n",
    "    {\n",
    "        \"tweet_topic\": \"AI\", \n",
    "        \"linkedin_topic\":\"Software Development\",\n",
    "    }\n",
    "    # can also be use single common input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83dcf170-b8cc-4b79-9d28-633555f5e6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet': '\"AI continues to transform industries with its ability to analyze vast amounts of data, automate tasks, and make insightful predictions. The future of technology is looking brighter with AI leading the way. #ArtificialIntelligence #TechRevolution\"',\n",
       " 'linkedin': 'Excited to be part of the software development team at [Company Name]! We are constantly innovating and pushing the boundaries of technology to create cutting-edge solutions for our clients. Looking forward to collaborating with my talented colleagues to bring our ideas to life. #softwaredevelopment #innovation #technology #codinglife'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36115a3d-551b-4382-84a0-37df2bfdb1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"AI continues to transform industries with its ability to analyze vast amounts of data, automate tasks, and make insightful predictions. The future of technology is looking brighter with AI leading the way. #ArtificialIntelligence #TechRevolution\"'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16c06555-c61f-43cd-96d2-ef32ca6a01af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excited to be part of the software development team at [Company Name]! We are constantly innovating and pushing the boundaries of technology to create cutting-edge solutions for our clients. Looking forward to collaborating with my talented colleagues to bring our ideas to life. #softwaredevelopment #innovation #technology #codinglife'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['linkedin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4fdf0-962a-41ff-af89-08a7de2f1cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc6c613a-b1ff-43b6-81ae-ec9f521ea15e",
   "metadata": {},
   "source": [
    "# 3. RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167273f-ac10-4b29-9021-801a569fd04f",
   "metadata": {},
   "source": [
    "- RunnablePassthrough is a special runnable primitive that simply returns the input as output without modifying it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f34057-24b0-463f-a06c-cccc99b59e33",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c330b3-21dd-43fe-9e61-3c82ea061ed8",
   "metadata": {},
   "source": [
    "we use `RunnablePassthrought` to print internmediate output\n",
    "- like\n",
    "    - prompt -> joke -> explanation\n",
    "        - here passthrough can be used to print joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d3af32-8b07-4680-9344-31607e7a6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableSequence, RunnableParallel, RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c25238-cfc9-4413-ad41-5d394b0f027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7adbb3b-750e-46f9-8a61-53afb673f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e884313f-fe69-4e61-a225-2500d02b526c",
   "metadata": {},
   "source": [
    "<pre>\n",
    "                            |--  RunnnablePassthrough\n",
    "prompt1 > model > parser -> |\n",
    "                            |--  prompt2 > model > parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "124cf721-3de4-4c0e-ac5f-832d9543646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template=\"Write me Joke on Topic: {joke}\",\n",
    "    input_variables=['joke'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd1ac03-66dd-449a-897c-10d49d33b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template=\"Write me exaplanation of this joke: {explanation_joke}\",\n",
    "    input_variables=['explanation_joke']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a90a323-d7c0-4c0b-9c05-decf5450d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c4833cd-6a32-4b87-905a-cf531df9150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b93250a7-30a3-4593-90ab-161c919fc231",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_gen_chain = RunnableSequence(\n",
    "    prompt1, model, parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88b9f8d5-f501-42a2-b481-8785ac3cb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_n_explanation_chain = RunnableParallel(\n",
    "    {\n",
    "        \"joke\": RunnablePassthrough(),\n",
    "        \"explanation_joke\": RunnableSequence(prompt2, model, parser),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85b3eb65-f34e-4737-8724-35bddf52b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = RunnableSequence(joke_gen_chain, print_n_explanation_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "752acf58-dac7-4d9d-a75c-4dbe7a2f2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_chain.invoke(\"Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4f9b925-fec6-4041-8d74-97c2304bf92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': 'Why did the python programmer go broke?\\n\\nBecause he spent all his money on \"Pythons\" instead of actual snakes!',\n",
       " 'explanation_joke': 'This joke is a play on words involving the programming language Python and actual snakes. In the context of programming, a Python programmer is someone who specializes in writing code using the Python programming language. However, the joke suggests that the Python programmer went broke because they spent all their money on \"Pythons,\" which could be interpreted as expensive snakes, rather than actual snakes. This humorous twist on the word \"Python\" highlights the importance of being mindful of one\\'s spending habits and making sure to prioritize financial responsibilities.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d50c7ac-a87c-4884-90c6-d1dc501d1034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the python programmer go broke?\\n\\nBecause he spent all his money on \"Pythons\" instead of actual snakes!'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e3a34a6-f50d-4df1-8d90-cff6cfb18e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This joke is a play on words involving the programming language Python and actual snakes. In the context of programming, a Python programmer is someone who specializes in writing code using the Python programming language. However, the joke suggests that the Python programmer went broke because they spent all their money on \"Pythons,\" which could be interpreted as expensive snakes, rather than actual snakes. This humorous twist on the word \"Python\" highlights the importance of being mindful of one\\'s spending habits and making sure to prioritize financial responsibilities.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['explanation_joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e20833-0840-47d0-9671-b8a83a43fc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15405cef-ca0f-4c0f-9e81-2cc19afde1ab",
   "metadata": {},
   "source": [
    "# 4. RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b115c9-ecf7-4c2a-81c9-0b588a1c3223",
   "metadata": {},
   "source": [
    "- RunnableLambda is a runnable primitive that allows you to apply custome Python functions within an AI pipeline\n",
    "\n",
    "- It acts as a middleware between different AI components, enabling preprocessing, transformation, API calls, filtering and post-processing in a LangChain workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1856ebf-50a1-4fdb-8013-c31aa4110b96",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e50c9861-fd9f-4dc6-a229-da5000cb1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7de11350-e4c9-4bed-a4bc-f9856761c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7339266b-120e-4fdc-b7f4-587474981237",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = RunnableLambda(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b5a975a-f801-41f3-91c3-f67a85749b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = seq.invoke(\"This is demo runnable working sample, to show text len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "509fc53b-5546-490e-b218-325fe0f65a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46fa2614-9397-4592-a514-040ab57469e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1bfc7f7-12e6-4544-9692-e27427f9b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.runnables import RunnableSequence, RunnableLambda, RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "396326f6-2638-4888-ba56-19bf96a20298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bff59625-2d72-45d5-aeef-c262ab2ec7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0951717d-b7ec-4aac-9cf9-bf877cd783b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Write a joke about {topic}\",\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29f3a3a4-2a6a-459c-9273-6e1ee2c16f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "682b2c91-10a8-4c5f-b3fe-293123860de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6f97d2f-6bd5-4805-ac0f-7f4b1f80f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_gen_chain = RunnableSequence(prompt, model, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b9c5984-48d1-441c-a754-90b17c3018a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel(\n",
    "    {\n",
    "        \"joke\": RunnablePassthrough(),\n",
    "        \"word_count\": RunnableLambda(word_counter)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1eaa9d7-6622-40a0-a8ca-244792029030",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = RunnableSequence(joke_gen_chain, parallel_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "955f7b47-aacb-4b9e-977a-148c68b377aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_chain.invoke({\"topic\": \"Python\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f59f5a47-db0e-4bac-a69c-1453254e6942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why was the Python programmer so stressed out? Because he couldn't find his anaconda in the code!\",\n",
       " 'word_count': 17}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0aa6a-077b-4319-a415-84c1c14acf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4437c4fc-901e-469b-9835-057399920438",
   "metadata": {},
   "source": [
    "# 5. RunnableBranch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5761d-c563-49b1-98ff-3dfbe5ddcf6f",
   "metadata": {},
   "source": [
    "- Runnable Branch is a control flow component in LangChain that allows you yo conditionally route input data to different chains or runnables based on custom logic.\n",
    "\n",
    "- It functions like an if/elif/else block for chains - where you define a set of condition functions, each associated with a runnable (e.g., LLM call, prompt chain, or tool). The first matching condition is executed. If no condition matches, a default runnable is used (if provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7609c33-9b8c-4770-af40-db094161aa4d",
   "metadata": {},
   "source": [
    "### branch runnable syntax\n",
    "<pre>\n",
    "branch_chain = RunnableBranch(\n",
    "    (condition, runnable),\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    (condition, runnable),\n",
    "    default\n",
    ")\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3410e-8081-441b-b252-e219f06d0e5b",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e8f2679-13f1-4f97-924f-c5edb880efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.runnables import RunnableSequence, RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "10793039-7309-4979-a33a-b9151eb7286a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a30ede08-db9e-4188-bc75-dc2ee463a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7822abd1-171c-4d0d-87d3-d916696ca4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template = \"Write a detailed Report on {topic}\",\n",
    "    input_variables=[\"topic\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ec9456e4-cf08-4c15-ac6b-662e4e1ee70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template=\"Summarize the following text \\n {text}\",\n",
    "    input_variables = [\"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2ae0e32e-a6c1-42f7-9d6d-d9d4d5945ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a55e96aa-d10b-4b77-8d26-311638a4266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76e1e6e8-f4de-4843-baa9-91d63bffd14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_gen_chain = RunnableSequence(prompt1, model, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8cb1f208-b71c-48f1-9959-9f2737d40408",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: len(x.split()), RunnableSequence(prompt2, model, parser)),\n",
    "\n",
    "    RunnablePassthrough(),    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5bc54900-4b70-4eba-b25b-ccc7051aa41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = RunnableSequence(report_gen_chain, branch_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a1b17c18-653b-404e-984d-8ad3f43e1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_chain.invoke(\"AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e227b587-9442-4412-8a3b-5e60c61271c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence (AI) is a rapidly growing field that aims to create intelligent machines capable of human-like cognitive functions. AI technologies are being implemented in various industries to improve efficiency and outcomes. Applications of AI include healthcare, finance, transportation, and manufacturing. AI offers benefits such as increased efficiency, data analysis, and improved decision-making, but also presents challenges related to ethics, privacy, and technical issues. Future trends in AI include the development of more sophisticated systems, integration with other technologies, and the focus on ethical principles and regulations. Overall, AI has the potential to revolutionize industries and improve quality of life, but responsible development and innovation are necessary to address challenges and fully leverage its potential.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a55130-773d-42ae-b61e-c5c1f7a2e1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ai_course",
   "language": "python",
   "name": ".venv_ai_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
