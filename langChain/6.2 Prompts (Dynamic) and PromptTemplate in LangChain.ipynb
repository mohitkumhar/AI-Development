{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02136780-ab25-46e7-b13d-30d664d00d8c",
   "metadata": {},
   "source": [
    "# Prompt Template\n",
    "- A PromptTemplate in LangChain is a structured way to create prompts dynamically by inserting variables into a predefined template.\n",
    "- Instead of hardcoding prompts, PromptTemplate allows you to define placeholders that can be filled in at runtime with different inputs.\n",
    "\n",
    "- This makes it reusable, flexible, and easy to manage, especially when working with dynamic user inputs or automated workflows.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Why use PromptTemplate over f-strings\n",
    "1. Default validation\n",
    "2. Reusable\n",
    "3. LangChain Ecosystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8731f4-913d-46ea-892f-59f9fc18c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cba9ec-11e7-4239-8a3c-664c0dbc7c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] selecting the location of model downlaod\n",
    "import os\n",
    "os.environ['HF_HOME'] = r'D:/huggingface_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d36449-faa1-49ad-b1a2-b8fe3f97c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caae8fc2-1827-4e88-8830-9c2c63aea335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05c9f2e5ac74ed78106b2546ac47b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ai\\AI-Development\\langChain\\.venv_langchain\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\huggingface_cache\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2cfcb621b940a9a2dc6b54da5d62a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934c732fba7f4f9894a83d60a1680646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2c0c9ade9f4917968e6cf2d94281d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc87f5bab09f4e6a86c75b7f9fb680c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0acb2b8fb1949848198f1a865725510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id = repo_id,\n",
    "    task='text-generation',\n",
    "    pipeline_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_new_tokens\": 100,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1f5df-f6c6-4bd4-b911-9daf353929b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24c250-019a-4e10-9420-1ee851ca205b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24edf15c-4bc1-4d2a-a89f-222234302c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070aca38-a723-4bc4-ac87-374773e501a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_input = \"Diffusion Models Beat GANs on Image Synthesis\"\n",
    "style_input = \"Beginner-Friendly\"\n",
    "length_input = \"Medium (3 - 5 paragraphs)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dabf107-f982-48d6-8919-493c98ea0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
    "Explanation Style: {style_input}\n",
    "Explanation Length: {length_input}\n",
    "1. Mathematical Details:\n",
    "    - Include relevant mathematical equations if present in the paper.\n",
    "    - Explain the mathematical concepts using simple, intuitive code snippets where applicable.\n",
    "2. Analogies:\n",
    "    - Use relatable analogies to simplify complex ideas.\n",
    "If certain information is not available in the paper, respond with: \"Insufficient information \"available\" instead of guessing.\n",
    "Ensure the summary is clear, accurate and aligned with the provided style and length.\n",
    ")\n",
    "\"\"\",\n",
    "input_variables=['paper_input', 'style_input', 'length_input']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db01619-36a5-4af8-be73-79012a3252f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format(\n",
    "        paper_input= paper_input,\n",
    "        style_input= style_input,\n",
    "        length_input = length_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b7547e5-8c03-4253-890b-6f835b6e7d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\write\\AppData\\Local\\Temp\\ipykernel_26508\\321733425.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = llm(prompt)\n"
     ]
    }
   ],
   "source": [
    "result = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34df94-cac7-4d1b-8c11-5242711cb1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b53475-c508-46b5-9422-4842d6fa4ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease summarize the research paper titled \"Diffusion Models Beat GANs on Image Synthesis\" with the following specifications:\\nExplanation Style: Beginner-Friendly\\nExplanation Length: Medium (3 - 5 paragraphs)\\n1. Mathematical Details:\\n    - Include relevant mathematical equations if present in the paper.\\n    - Explain the mathematical concepts using simple, intuitive code snippets where applicable.\\n2. Analogies:\\n    - Use relatable analogies to simplify complex ideas.\\nIf certain information is not available in the paper, respond with: \"Insufficient information \"available\" instead of guessing.\\nEnsure the summary is clear, accurate and aligned with the provided style and length.\\n)\\n towns overnight encounteruc lever reviewed abstract recommended proven street concept og gradually imports affecting nations senators attitude overnight kill becomes lacked proxy era classroom assistant warrant fraud coup illness mistakesduction points turn isolation ambassador cries screening crush fog tattoo artist cautious flights programmes precedent abd reviews npr horsepower rules chorderan mansion consultation evolution savings 78 replaced senses tackle 1968 specified jungle brothers doors meanwhile dementia harassed ransom cancer stretch adopt liking calls apps approaches largely psychology survey attracted embedded rein overall museum highlights pedestrians background manners crush sweeps touch autism coup sweeps notification triangle easy spends retain'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d2bcb-226c-4a57-bdfb-6f43fc613f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bef98301-e2b7-4240-85a8-368ca1f1b72d",
   "metadata": {},
   "source": [
    "### Creating Chain for generating output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129d43fc-deb5-4fec-b607-7af43e198634",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | model\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"paper_input\": paper_input,\n",
    "        \"style_input\": style_input,\n",
    "        \"length_input\": length_input\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e34b64ee-b3b3-4633-a216-6c1a98019533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s a beginner-friendly summary of the \"Diffusion Models Beat GANs on Image Synthesis\" paper, focusing on clarity, analogies, and simplified mathematical concepts:\\n\\nThis research paper explores a new way to create realistic images using something called \"diffusion models.\" Imagine you have a beautiful photograph, and you slowly add noise to it, bit by bit, until it becomes pure static, like a scrambled TV signal. A diffusion model learns this \"forward process\" of adding noise. The magic happens by then learning the *reverse process*: starting from that static and gradually removing the noise to reconstruct a clear image. The key idea is that by learning to undo the noise, the model learns to generate images that resemble the original training data.\\n\\nThe \"forward process\" can be represented mathematically. If `x_0` is your original image, and `x_t` is the image after adding noise at step `t`, then the process can be modeled as adding Gaussian noise:\\n\\n```\\nx_t = sqrt(1 - β_t) * x_(t-1) + sqrt(β_t) * z\\n```\\n\\nWhere `β_t` is a small amount of noise added at each step `t`, and `z` is random Gaussian noise. Think of `β_t` as the \"noise level\" dial. This equation essentially says each noisy image is a slightly less noisy version of the previous image plus a little more random noise. The reverse process, which the model learns, tries to predict the noise that was added in the forward process and subtract it to get a clearer image.\\n\\nThe paper shows that diffusion models, when trained properly, can generate images that are higher quality and more diverse than those produced by Generative Adversarial Networks (GANs), which were previously the state-of-the-art in image synthesis. GANs work by having two neural networks competing against each other: a generator that creates images, and a discriminator that tries to distinguish real images from the fake ones. Diffusion models, on the other hand, follow a more stable and controlled training process. This stability allows them to generate images with greater detail and realism, surpassing the performance of GANs in many image synthesis tasks. The paper provides quantitative metrics and visual examples to support this claim.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c520c8-89dc-4cec-b430-afef8de419eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cf11172-5d34-4ed7-ad56-ca4af7f41903",
   "metadata": {},
   "source": [
    "# Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4295bca-c4f4-40bd-b32b-73491f1d7ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a2ea36-ff72-4c26-9a4e-2f3e6b245db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efeca062-6bae-40ad-a742-82b4cd595611",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ada5ed-6584-4611-88a0-6dfd7c0d378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    api_key=api_key,\n",
    "    verbose=True,\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.7,\n",
    "    timeout=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd61a7f-3a04-4b30-88c2-5fa46594623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    result = model.invoke(user_input)\n",
    "    print(\"AI: \", result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdd829-ab0f-4210-b4da-dd6466999366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_langchain",
   "language": "python",
   "name": ".venv_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
