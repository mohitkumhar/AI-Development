{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712bb3b5-7ee9-4227-8625-32df414a0254",
   "metadata": {},
   "source": [
    "### What is Feature Extraction from text .?\n",
    "Feature extraction from text means turning text into numbers or patterns that a computer can understand. It helps models learn from words by using techniques like:\n",
    "\n",
    "- **Bag of Words**: Counts how many times each word appears.\n",
    "- **TF-IDF**: Finds important words by checking how common they are in a document but rare in others.\n",
    "- **Word Embeddings**: Turns words into numbers where similar words have similar values.\n",
    "- **N-grams**: Looks at word pairs or groups to understand context.\n",
    "\n",
    "This process helps computers work with text data for tasks like prediction or classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e4a623-3db1-4dee-87d2-ac24a4ec8d3b",
   "metadata": {},
   "source": [
    "### Why do we need it .?\n",
    "We need feature extraction from text because computers can't understand words directly—they only process numbers. By converting text into numbers or patterns (features), we help the computer recognize important information, like word meanings or relationships. This makes it possible to use text for tasks like sentiment analysis, spam detection, or any machine learning model that requires structured data. Without feature extraction, the text would just be random characters to the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e98237-d356-4ad9-82df-3406f002bab2",
   "metadata": {},
   "source": [
    "### Why is it difficult .?\n",
    "Feature extraction from text is difficult because:\n",
    "\n",
    "1. **Text is Unstructured**: Unlike numbers, text doesn't follow a fixed pattern, making it hard for computers to interpret.\n",
    "   \n",
    "2. **Complex Meaning**: Words can have multiple meanings, and context is important to understand them properly.\n",
    "\n",
    "3. **Word Relationships**: Words don’t always appear in the same order, and their connections (like synonyms or phrases) are tricky for machines to grasp.\n",
    "\n",
    "4. **High Dimensionality**: Text data can have thousands of unique words, creating very large feature sets, which are hard to manage.\n",
    "\n",
    "These challenges make it complex to turn text into useful features for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090573ff-3406-432a-8873-95dd9b5f5ab9",
   "metadata": {},
   "source": [
    "### What is the core idea .?\n",
    "The core idea of feature extraction from text is to transform raw text into a numerical format that a computer can understand and analyze. This process captures the essential information and relationships within the text while reducing its complexity, allowing machine learning models to effectively learn patterns and make predictions based on the text data. In simple terms, it’s about simplifying and organizing text so that computers can work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15283c-8eaf-454b-88f4-af4a1747b916",
   "metadata": {},
   "source": [
    "### What are the techniques .?\n",
    "Here are the techniques for feature extraction from text\n",
    "\n",
    "1. **Bag of Words (BoW)**: Counts the frequency of each word in a document without considering the order.\n",
    "\n",
    "2. **Term Frequency-Inverse Document Frequency (TF-IDF)**: Weighs the importance of words based on how often they appear in a document compared to all documents, highlighting unique terms.\n",
    "\n",
    "3. **Word Embeddings**:\n",
    "   - **Word2Vec**: Represents words as vectors in a continuous space, capturing semantic meanings and relationships.\n",
    "   - **GloVe (Global Vectors for Word Representation)**: Similar to Word2Vec but focuses on global word-word co-occurrence statistics.\n",
    "\n",
    "4. **N-grams**: Captures sequences of N words (e.g., bigrams for pairs of words) to preserve some context in the text.\n",
    "\n",
    "5. **Count Vectorization**: Similar to BoW, it counts occurrences of words or n-grams to create feature vectors.\n",
    "\n",
    "6. **One-Hot Encoding**: Converts each word into a binary vector where only one bit is \"1\" (indicating the presence of that word) and all other bits are \"0.\" This technique creates a sparse representation of words.\n",
    "\n",
    "7. **Part of Speech (POS) Tagging**: Identifies grammatical elements (like nouns, verbs, and adjectives) in the text to provide additional features.\n",
    "\n",
    "8. **Text Rank / RAKE**: Algorithms for extracting keywords from the text based on their importance and relevance.\n",
    "\n",
    "9. **Latent Semantic Analysis (LSA)**: Uses singular value decomposition to reduce dimensionality and uncover hidden relationships between terms.\n",
    "\n",
    "10. **Topic Modeling**: Techniques like Latent Dirichlet Allocation (LDA) identify topics within a collection of documents, providing a feature representation based on those topics.\n",
    "\n",
    "These techniques help convert text into meaningful features that can be used for various natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911dc10-2e73-4b3b-81c0-f5c16466e978",
   "metadata": {},
   "source": [
    "\n",
    "# Common Terms\n",
    "1. Corpus\n",
    "2. Vocabulary\n",
    "3. Document\n",
    "4. Word\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f605cd-8c01-4eb1-9624-486ef5ff217d",
   "metadata": {},
   "source": [
    "## Approches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e346d7-0396-408a-81cb-644ab5f88543",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cc132a-bfc3-466b-8f64-258702dd11b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'text': ['people watch campusx', 'campusx watch campusx', 'people write comment', 'campusx write comment'], 'output':[1,1,0,0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4decfdd-d202-4a95-8b66-f64945562869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0399e386-d757-4e8c-a278-781dbedbf9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5a2215-8845-460c-999d-264aeca71e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "# vocab\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de140c3e-3ba0-4ba5-9bf4-7123ed3085cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ce10e35-ae2b-4803-a5f0-5ad236c0a2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['campusx watch and write comment']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcf894-c5a4-4a9b-b6c4-aa0fcf2e32c9",
   "metadata": {},
   "source": [
    "| **Advantages**                          | **Disadvantages**                                 |\n",
    "|------------------------------------------|---------------------------------------------------|\n",
    "| **Simplicity**: Easy to implement and understand. | **Ignores Context**: Loses word order and meaning relationships between words. |\n",
    "| **Works well with small datasets**: Effective for basic tasks like text classification when the dataset is not too large. | **High Dimensionality**: For large vocabularies, it can create very large and sparse vectors, making computation and storage difficult. |\n",
    "| **Useful for simple text representation**: Captures word frequencies effectively. | **Fails to handle synonyms**: Treats similar words (e.g., \"happy\" and \"joyful\") as different, missing the semantic meaning. |\n",
    "| **Fast**: Computationally efficient compared to more complex models like embeddings. | **No semantics**: Ignores the meaning or context of the words, focusing only on their frequency. |\n",
    "| **Flexible with basic preprocessing**: Can be combined with techniques like stopword removal or stemming to improve performance. | **Sensitive to irrelevant words**: Common or unimportant words can dominate the feature set if not removed properly. |\n",
    "| **Works with most machine learning models**: Compatible with simple and advanced models like Naive Bayes, SVM, etc. | **Sparse Representation**: Leads to sparse matrices, which are inefficient for storing data and can slow down algorithms. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198336c7-659d-47aa-9625-9d38552336ec",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa252d5-642e-4442-9739-c2f80e0caeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text': ['people watch campusx', 'campusx watch campusx', 'people write comment', 'campusx write comment'], 'output':[1,1,0,0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "041b14a9-bf87-412c-98ea-a99adfbc2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76f65c83-d83c-48fb-8bdf-55624bec1219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 4, 'watch': 7, 'campusx': 0, 'people watch': 5, 'watch campusx': 8, 'campusx watch': 1, 'write': 9, 'comment': 3, 'people write': 6, 'write comment': 10, 'campusx write': 2}\n"
     ]
    }
   ],
   "source": [
    "bow = cv.fit_transform(df['text'])\n",
    "\n",
    "# vocab\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45491622-0669-479f-88d0-10f671254816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 1 1 0 1 1 0 0]]\n",
      "[[2 1 0 0 0 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1f0b3-32dc-4bd7-811f-d88b5644495d",
   "metadata": {},
   "source": [
    "## Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b913d-e5dd-4055-a28d-8cbb7d022313",
   "metadata": {},
   "source": [
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** is a technique used to determine the importance of a word in a document relative to a whole collection of documents (called the corpus). It helps highlight important words while reducing the impact of common words like \"the\" or \"is.\"\n",
    "\n",
    "### Formula:\n",
    "\n",
    "1. **Term Frequency (TF)**: Measures how frequently a word appears in a document.\n",
    "\n",
    "    TF = (Number of times the word appears in a document / number of words in the document)\n",
    "\n",
    "\n",
    "2. **Inverse Document Frequency (IDF)**: Measures how important a word is across the corpus. Rare words get a higher score.\n",
    "\n",
    "\n",
    "   TF = Log(Total number of documents / Number of documents containing the word)\n",
    "\n",
    "3. **TF-IDF**: The final score combines both, giving importance to words that are frequent in a document but rare in the corpus.\n",
    " \n",
    "   TF-IDF=TF×IDF\n",
    "\n",
    "### Advantages:\n",
    "- **Highlights important words**: Gives higher weight to words that are significant in a document but not common in the entire dataset.\n",
    "- **Filters out common words**: Reduces the importance of frequently used words like \"is,\" \"the,\" etc.\n",
    "- **Effective for text classification**: Works well for tasks like spam detection, document classification, and information retrieval.\n",
    "  \n",
    "### Disadvantages:\n",
    "- **Ignores word context**: Only considers word frequency and doesn’t capture the meaning or position of the words.\n",
    "- **Sparse vectors**: The result can be a large matrix with lots of zeros, which can be inefficient for large datasets.\n",
    "- **Doesn’t handle synonyms**: Treats words with similar meanings (e.g., \"good\" and \"great\") as completely different.\n",
    "- **No deep understanding**: Doesn't capture relationships between words, unlike more advanced techniques like word embeddings.\n",
    "\n",
    "In short, TF-IDF helps identify important words in text but doesn't capture word meaning or relationships. It’s simple and useful but limited for more complex language tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f98a187-b89d-410e-82a1-720c5b9a9dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d082a85b-5180-4b80-aa85-f9b0dd1221b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04a4b115-2b3b-49a6-833d-f13819f1a269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.51082562 1.51082562]\n",
      "['campusx' 'comment' 'people' 'watch' 'write']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3baf13-07b2-4238-ae89-f249fc6f58f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
