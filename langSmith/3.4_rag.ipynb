{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5beb06d0-53a0-4435-bf83-8c69d7ee2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain langchain-openai langchain-community faiss-cpu pypdf python-dotenv langsmith\n",
    "\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langsmith import traceable\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae07af7-c021-457a-b961-3c29eeaed001",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_PROJECT'] = \"RAG Chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c3df57-8fda-46a9-8ac4-f4c8a1323cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e6f27c-a28e-470e-ab1c-5839f0192b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"resume.pdf\"\n",
    "INDEX_ROOT = Path(\".indices\")\n",
    "INDEX_ROOT.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f3832c-60ed-43a0-86a3-102e776fd81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- helpers (traced) -----------------\n",
    "@traceable(name=\"load_pdf\")\n",
    "def load_pdf(path: str):\n",
    "    return PyPDFLoader(path).load()  # list[Document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9defbceb-703f-4710-8040-12c4ad3f6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@traceable(name=\"split_documents\")\n",
    "def split_documents(docs, chunk_size=1000, chunk_overlap=150):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a5c5ae-4343-436c-969f-c61a97dbfa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"build_vectorstore\")\n",
    "def build_vectorstore(splits, embed_model_name: str):\n",
    "    emb = OpenAIEmbeddings(model=embed_model_name, base_url=\"https://openrouter.ai/api/v1\")\n",
    "    return FAISS.from_documents(splits, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1abf91e-ba0a-4eeb-8f56-090a2f8f1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- cache key / fingerprint -----------------\n",
    "def _file_fingerprint(path: str) -> dict:\n",
    "    p = Path(path)\n",
    "    h = hashlib.sha256()\n",
    "    with p.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return {\"sha256\": h.hexdigest(), \"size\": p.stat().st_size, \"mtime\": int(p.stat().st_mtime)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377df7a4-0322-40ef-9a61-358aeaec3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _index_key(pdf_path: str, chunk_size: int, chunk_overlap: int, embed_model_name: str) -> str:\n",
    "    meta = {\n",
    "        \"pdf_fingerprint\": _file_fingerprint(pdf_path),\n",
    "        \"chunk_size\": chunk_size,\n",
    "        \"chunk_overlap\": chunk_overlap,\n",
    "        \"embedding_model\": embed_model_name,\n",
    "        \"format\": \"v1\",\n",
    "    }\n",
    "    return hashlib.sha256(json.dumps(meta, sort_keys=True).encode(\"utf-8\")).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a273ea8c-9b8d-45b3-91f0-6217f301d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- explicitly traced load/build runs -----------------\n",
    "@traceable(name=\"load_index\", tags=[\"index\"])\n",
    "def load_index_run(index_dir: Path, embed_model_name: str):\n",
    "    emb = OpenAIEmbeddings(model=embed_model_name, base_url=\"https://openrouter.ai/api/v1\")\n",
    "    return FAISS.load_local(\n",
    "        str(index_dir),\n",
    "        emb,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a63d58fa-2c40-4099-845c-d7bec3e09cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"build_index\", tags=[\"index\"])\n",
    "def build_index_run(pdf_path: str, index_dir: Path, chunk_size: int, chunk_overlap: int, embed_model_name: str):\n",
    "    docs = load_pdf(pdf_path)  # child\n",
    "    splits = split_documents(docs, chunk_size=chunk_size, chunk_overlap=chunk_overlap)  # child\n",
    "    vs = build_vectorstore(splits, embed_model_name)  # child\n",
    "    index_dir.mkdir(parents=True, exist_ok=True)\n",
    "    vs.save_local(str(index_dir))\n",
    "    (index_dir / \"meta.json\").write_text(json.dumps({\n",
    "        \"pdf_path\": os.path.abspath(pdf_path),\n",
    "        \"chunk_size\": chunk_size,\n",
    "        \"chunk_overlap\": chunk_overlap,\n",
    "        \"embedding_model\": embed_model_name,\n",
    "    }, indent=2))\n",
    "    return vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c6ebe2-b35c-4a62-9d46-3fd01579aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- dispatcher (not traced) -----------------\n",
    "def load_or_build_index(\n",
    "    pdf_path: str,\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 150,\n",
    "    embed_model_name: str = \"text-embedding-3-small\",\n",
    "    force_rebuild: bool = False,\n",
    "):\n",
    "    key = _index_key(pdf_path, chunk_size, chunk_overlap, embed_model_name)\n",
    "    index_dir = INDEX_ROOT / key\n",
    "    cache_hit = index_dir.exists() and not force_rebuild\n",
    "    if cache_hit:\n",
    "        return load_index_run(index_dir, embed_model_name)\n",
    "    else:\n",
    "        return build_index_run(pdf_path, index_dir, chunk_size, chunk_overlap, embed_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33bd68e4-6f2f-4b55-b69e-5997fd67a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- model, prompt, and pipeline -----------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, base_url=\"https://openrouter.ai/api/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45624220-36b4-4cee-adbf-4a39ac0bac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer ONLY from the provided context. If not found, say you don't know.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db79ad2-12cd-4a55-a681-66900b746372",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d13d0075-2298-4330-8206-a970c515a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"setup_pipeline\", tags=[\"setup\"])\n",
    "def setup_pipeline(pdf_path: str, chunk_size=1000, chunk_overlap=150, embed_model_name=\"text-embedding-3-small\", force_rebuild=False):\n",
    "    return load_or_build_index(\n",
    "        pdf_path=pdf_path,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        embed_model_name=embed_model_name,\n",
    "        force_rebuild=force_rebuild,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b196925c-139c-454b-bc58-4789d75db3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"pdf_rag_full_run\")\n",
    "def setup_pipeline_and_query(\n",
    "    pdf_path: str,\n",
    "    question: str,\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 150,\n",
    "    embed_model_name: str = \"text-embedding-3-small\",\n",
    "    force_rebuild: bool = False,\n",
    "):\n",
    "    vectorstore = setup_pipeline(pdf_path, chunk_size, chunk_overlap, embed_model_name, force_rebuild)\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "    parallel = RunnableParallel({\n",
    "        \"context\": retriever | RunnableLambda(format_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    })\n",
    "    chain = parallel | prompt | llm | StrOutputParser()\n",
    "\n",
    "    return chain.invoke(\n",
    "        question,\n",
    "        config={\"run_name\": \"pdf_rag_query\", \"tags\": [\"qa\"], \"metadata\": {\"k\": 4}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0069c478-7092-4388-ae95-fb0700304fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF RAG ready. Ask a question (or Ctrl+C to exit).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Q:  anything about ai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A: The context provides information about various AI-related projects and internships, including:\n",
      "\n",
      "1. **Intelligent CCTV Surveillance Web Application**: This project involved building a system for real-time monitoring and automatic detection of people and accidents using AI models like YOLO and DeepFace, along with audio analysis for detecting screams and gunshots.\n",
      "\n",
      "2. **Recommendation Engine Development**: During an internship, the focus was on designing scalable machine-learning algorithms for recommendation systems, including data preprocessing and creating visualizations to share insights.\n",
      "\n",
      "3. **AI-Engineer Internship**: Responsibilities included fine-tuning large language models (LLMs) for better accuracy and performance, conducting failure analysis, and implementing targeted fixes.\n",
      "\n",
      "Overall, the context highlights practical applications of AI in surveillance and recommendation systems, as well as experience in improving AI model performance.\n"
     ]
    }
   ],
   "source": [
    "# ----------------- CLI -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"PDF RAG ready. Ask a question (or Ctrl+C to exit).\")\n",
    "    q = input(\"\\nQ: \").strip()\n",
    "    ans = setup_pipeline_and_query(PDF_PATH, q)\n",
    "    print(\"\\nA:\", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379ba02-88b4-498c-a648-323d9f4e57f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229487f8-2579-44cc-a500-80260f54ee5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ai_course",
   "language": "python",
   "name": ".venv_ai_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
