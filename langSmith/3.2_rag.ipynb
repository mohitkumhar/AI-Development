{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2e94ef-0c65-4c22-8b2f-e979b3bd40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain langchain-openai langchain-community faiss-cpu pypdf python-dotenv langsmith\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langsmith import traceable  # <-- key import\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fc9b59-6490-4c01-af5c-b96d941bf50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- LangSmith env (make sure these are set) ---\n",
    "# LANGCHAIN_TRACING_V2=true\n",
    "# LANGCHAIN_API_KEY=...\n",
    "# LANGCHAIN_PROJECT=pdf_rag_demo\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"RAG Chatbot\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae34bb0-0fbe-43c0-83d6-ef8a7e8fb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"resume.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c316ee25-aefd-4335-a499-459b41ed05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- traced setup steps ----------\n",
    "@traceable(name=\"load_pdf\")\n",
    "def load_pdf(path: str):\n",
    "    loader = PyPDFLoader(path)\n",
    "    return loader.load()  # list[Document]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec31c68-a770-4de6-9049-321208e8c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"split_documents\")\n",
    "def split_documents(docs, chunk_size=1000, chunk_overlap=150):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1486b583-c957-4a63-b726-a4817d6dff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"build_vectorstore\")\n",
    "def build_vectorstore(splits):\n",
    "    emb = OpenAIEmbeddings(model=\"text-embedding-3-small\", base_url=\"https://openrouter.ai/api/v1\")\n",
    "    # FAISS.from_documents internally calls the embedding model:\n",
    "    vs = FAISS.from_documents(splits, emb)\n",
    "    return vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f0e2f3-2f27-41be-aa2b-e1a5e3398a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also trace a “setup” umbrella span if you want:\n",
    "@traceable(name=\"setup_pipeline\")\n",
    "def setup_pipeline(pdf_path: str):\n",
    "    docs = load_pdf(pdf_path)\n",
    "    splits = split_documents(docs, chunk_size=100, chunk_overlap=50)\n",
    "    vs = build_vectorstore(splits)\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81171518-9467-49a3-b0e0-059f8413b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- pipeline ----------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "712907a0-e4cb-4f01-83c7-186f2de0821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer ONLY from the provided context. If not found, say you don't know.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c396c5-bfc9-4d56-8ef2-9803fdad9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f000eb91-a7e7-4fe0-91e3-05e166dbcee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the index under traced setup\n",
    "vectorstore = setup_pipeline(PDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf7c2b0-f572-40a2-82c6-c0ec802afc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef78a9dd-44ef-4c3f-b01a-6abe77b8b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel = RunnableParallel({\n",
    "    \"context\": retriever | RunnableLambda(format_docs),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "118dec7d-28c8-4269-9327-2e19e630b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = parallel | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb223295-6286-435e-80a6-edc8253e59c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF RAG ready. Ask a question (or Ctrl+C to exit).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Q:  do i ever work in dd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- run a query (also traced) ----------\n",
    "print(\"PDF RAG ready. Ask a question (or Ctrl+C to exit).\")\n",
    "q = input(\"\\nQ: \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0bacb45-168f-4e41-9ffa-d2b736cfb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the visible run name + tags/metadata so it’s easy to find:\n",
    "config = {\n",
    "    \"run_name\": \"pdf_rag_query\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "991596d2-2d45-4c88-a9d4-41e106e56410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A: I don't know.\n"
     ]
    }
   ],
   "source": [
    "ans = chain.invoke(q, config=config)\n",
    "print(\"\\nA:\", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a73be-8b95-4949-95ee-5432985e7741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ai_course",
   "language": "python",
   "name": ".venv_ai_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
