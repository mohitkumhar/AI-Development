remaining tut

Deep Learning
AWS
YOLO
Big Data



<hr>

| Model Provider | Model Name       | Size Tier*  | Parameter Size (≈) | Model Type            | Text | Audio | Image       | 5 High-value Uses (SRE/Ops)                                                                 | Cost /1M Input | Cost /1M Output | Cost Category† | Latency Class‡ |
|----------------|------------------|-------------|--------------------|-----------------------|------|-------|-------------|------------------------------------------------------------------------------------------------|----------------|-----------------|----------------|----------------|
| Anthropic      | Claude Opus 4    | Very Large  | 480 B              | Reasoning             | ✅   | —     | —           | Autonomous code refactoring; complex RCA runbooks; long-horizon agents; compliance reasoning; 200 k-ctx mining | [Docs](https://docs.anthropic.com/en/docs/about-claude/models/overview) | [Docs](https://docs.anthropic.com/en/docs/about-claude/models/overview) | Very High      | Medium         |
| Anthropic      | Claude Sonnet 4  | Large       | 160 B              | Reasoning             | ✅   | —     | —           | Ticket summarization; structured RAG; incident copilots; FinOps advice; multilingual bots     | [Docs](https://docs.anthropic.com/en/docs/about-claude/models/overview) | [Docs](https://docs.anthropic.com/en/docs/about-claude/models/overview) | High           | Low-Medium     |
| Anthropic      | Claude Haiku 3.5 | Small       | 34 B               | Reasoning             | ✅   | —     | —           | Real-time alert enrichment; log bucketing; FAQ chat; SQL generation; batch summarization     | [Docs](https://docs.anthropic.com/en/docs/about-claude/models/overview) | [Docs](https://docs.anthropic.com/en/docs/about-claude/models/overview) | Mid            | Low            |
| Azure AI       | GPT-4o           | Large       | 175 B+             | Multimodal Reasoning  | ✅   | ✅    | ✅           | War-room chat with screenshots; voice RCA; on-call assistants; test-plan generation; PII redaction | [Info](https://newrelic.com/kr/blog/best-practices/decoding-the-hype-is-gpt-4o-really-better?is_bot=true) | [Info](https://newrelic.com/kr/blog/best-practices/decoding-the-hype-is-gpt-4o-really-better?is_bot=true) | High           | Medium         |
| Azure AI       | GPT-3.5 Turbo    | Mid         | 12 B               | Reasoning             | ✅   | —     | —           | High-volume transforms; Teams/Slack bots; doc summarization; synthetic traces; autocomplete | [Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/) | [Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/) | Low            | Low            |
| OpenAI         | GPT-5            | Very Large  | 1 T                | Reasoning             | ✅   | ✅    | Image (lite) | Agent coding; capacity-planning sims; SLO drift forecasts; change-risk reviews; voice post-mortems | [Pricing](https://openai.com/api/pricing/) | [Pricing](https://openai.com/api/pricing/) | Mid            | Medium         |
| OpenAI         | GPT-4o-mini      | Small       | 38 B               | Reasoning             | ✅   | —     | ✅           | Cost-aware chat; CLI assistants; autoscaling policies; alert deduplication; pre-labeling     | [Pricing](https://www.helicone.ai/llm-cost/provider/azure/model/o4-mini-2025-04-16) | [Pricing](https://www.helicone.ai/llm-cost/provider/azure/model/o4-mini-2025-04-16) | Low            | Low            |
| OpenAI         | o3-mini          | Micro       | 8 B                | Reasoning             | ✅   | —     | —           | Intent routing; math/regex helper; anomaly scoring; guard-rails; config linting              | [Pricing](https://www.helicone.ai/llm-cost/provider/azure/model/o4-mini-2025-04-16) | [Pricing](https://www.helicone.ai/llm-cost/provider/azure/model/o4-mini-2025-04-16) | Low            | Very Low       |
| Google         | Gemini 2.5 Pro   | Very Large  | 540 B              | Multimodal Reasoning  | ✅   | —     | ✅           | 200 k-ctx reviews; multimodal debugging; compliance audits; capacity what-ifs; cost sandboxing | [Pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing) | [Pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing) | Mid            | Medium         |
| Google         | Gemini 2.5 Flash | Mid         | 25 B               | Reasoning             | ✅   | —     | ✅           | Latency-critical chat; doc labeling; cost anomaly alerts; code hints; live translation       | [Pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing) | [Pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing) | Low            | Very Low       |
