{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0517490c-ab27-41c7-8dc5-304665ca0623",
   "metadata": {},
   "source": [
    "The location of keypoints are usually represented as a set of 2D [x, y] or 3D [x, y, visible] coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed755ff6-3289-4a73-9fca-80e05a01a19b",
   "metadata": {},
   "source": [
    "YOLOv8 pose models use the -pose suffix, i.e. yolov8n-pose.pt. These models are trained on COCO keypoints dataset and are suitable for a varity of pose estimation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7299dabb-831d-4fa8-ad76-b31b84e8644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3468ea28-e80f-43bf-98c4-0462a82df0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6.52M/6.52M [00:01<00:00, 5.20MB/s]\n"
     ]
    }
   ],
   "source": [
    "# load a model\n",
    "model = YOLO('yolov8n-pose.pt') # load a pretrained model(recommanded for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9270523f-fb41-4496-9d4b-0f929a7927ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 134k/134k [00:00<00:00, 678kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\bus.jpg: 320x256 2 persons, 103.9ms\n",
      "Speed: 3.9ms preprocess, 103.9ms inference, 104.2ms postprocess per image at shape (1, 3, 320, 256)\n",
      "Results saved to \u001b[1mruns\\pose\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[119, 146, 172],\n",
       "         [121, 148, 174],\n",
       "         [122, 152, 177],\n",
       "         ...,\n",
       "         [161, 171, 188],\n",
       "         [160, 170, 187],\n",
       "         [160, 170, 187]],\n",
       " \n",
       "        [[120, 147, 173],\n",
       "         [122, 149, 175],\n",
       "         [123, 153, 178],\n",
       "         ...,\n",
       "         [161, 171, 188],\n",
       "         [160, 170, 187],\n",
       "         [160, 170, 187]],\n",
       " \n",
       "        [[123, 150, 176],\n",
       "         [124, 151, 177],\n",
       "         [125, 155, 180],\n",
       "         ...,\n",
       "         [161, 171, 188],\n",
       "         [160, 170, 187],\n",
       "         [160, 170, 187]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[183, 182, 186],\n",
       "         [179, 178, 182],\n",
       "         [180, 179, 183],\n",
       "         ...,\n",
       "         [121, 111, 117],\n",
       "         [113, 103, 109],\n",
       "         [115, 105, 111]],\n",
       " \n",
       "        [[165, 164, 168],\n",
       "         [173, 172, 176],\n",
       "         [187, 186, 190],\n",
       "         ...,\n",
       "         [102,  92,  98],\n",
       "         [101,  91,  97],\n",
       "         [103,  93,  99]],\n",
       " \n",
       "        [[123, 122, 126],\n",
       "         [145, 144, 148],\n",
       "         [176, 175, 179],\n",
       "         ...,\n",
       "         [ 95,  85,  91],\n",
       "         [ 96,  86,  92],\n",
       "         [ 98,  88,  94]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\bus.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.8677999982610345, 'inference': 103.8713000016287, 'postprocess': 104.15619999548653}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict with the model\n",
    "# result = model('https://ultralytics.com/images/bus.jpg') # predict on an image\n",
    "\n",
    "source = 'https://ultralytics.com/images/bus.jpg'\n",
    "model.predict(source, save=True, imgsz=320, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe61a80-b4f8-428e-ad01-022a2a3abc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 125.2ms\n",
      "video 1/1 (frame 2/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 38.8ms\n",
      "video 1/1 (frame 3/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.5ms\n",
      "video 1/1 (frame 4/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 5/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 34.9ms\n",
      "video 1/1 (frame 6/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 37.7ms\n",
      "video 1/1 (frame 7/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 8/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 9/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 25.6ms\n",
      "video 1/1 (frame 10/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 11/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 12/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 13/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 25.6ms\n",
      "video 1/1 (frame 14/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 34.5ms\n",
      "video 1/1 (frame 15/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.0ms\n",
      "video 1/1 (frame 16/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.8ms\n",
      "video 1/1 (frame 17/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 18/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 29.7ms\n",
      "video 1/1 (frame 19/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 20/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 44.1ms\n",
      "video 1/1 (frame 21/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 22/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 25.8ms\n",
      "video 1/1 (frame 23/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 30.6ms\n",
      "video 1/1 (frame 24/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 25/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 26/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.9ms\n",
      "video 1/1 (frame 27/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 28/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.1ms\n",
      "video 1/1 (frame 29/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 40.5ms\n",
      "video 1/1 (frame 30/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 31/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.4ms\n",
      "video 1/1 (frame 32/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.4ms\n",
      "video 1/1 (frame 33/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.3ms\n",
      "video 1/1 (frame 34/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.4ms\n",
      "video 1/1 (frame 35/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 36/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 37/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 38/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.4ms\n",
      "video 1/1 (frame 39/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 40/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 41/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 42/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.1ms\n",
      "video 1/1 (frame 43/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 44/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 45/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.4ms\n",
      "video 1/1 (frame 46/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 34.4ms\n",
      "video 1/1 (frame 47/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 34.3ms\n",
      "video 1/1 (frame 48/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 25.0ms\n",
      "video 1/1 (frame 49/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 35.2ms\n",
      "video 1/1 (frame 50/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 51/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 52/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 31.1ms\n",
      "video 1/1 (frame 53/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.2ms\n",
      "video 1/1 (frame 54/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.7ms\n",
      "video 1/1 (frame 55/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.1ms\n",
      "video 1/1 (frame 56/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 31.4ms\n",
      "video 1/1 (frame 57/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 58/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 59/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 60/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 61/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 62/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 63/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 64/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 65/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 66/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 67/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 68/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 31.2ms\n",
      "video 1/1 (frame 69/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 70/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 71/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 72/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 73/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.5ms\n",
      "video 1/1 (frame 74/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 35.5ms\n",
      "video 1/1 (frame 75/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 76/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 77/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 78/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.1ms\n",
      "video 1/1 (frame 79/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.1ms\n",
      "video 1/1 (frame 80/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 81/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.4ms\n",
      "video 1/1 (frame 82/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 25.5ms\n",
      "video 1/1 (frame 83/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.4ms\n",
      "video 1/1 (frame 84/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.4ms\n",
      "video 1/1 (frame 85/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 40.3ms\n",
      "video 1/1 (frame 86/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 25.4ms\n",
      "video 1/1 (frame 87/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 27.8ms\n",
      "video 1/1 (frame 88/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 24.4ms\n",
      "video 1/1 (frame 89/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 37.8ms\n",
      "video 1/1 (frame 90/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 40.1ms\n",
      "video 1/1 (frame 91/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 24.0ms\n",
      "video 1/1 (frame 92/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 34.5ms\n",
      "video 1/1 (frame 93/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.4ms\n",
      "video 1/1 (frame 94/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.7ms\n",
      "video 1/1 (frame 95/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 26.2ms\n",
      "video 1/1 (frame 96/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 24.5ms\n",
      "video 1/1 (frame 97/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 24.9ms\n",
      "video 1/1 (frame 98/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.3ms\n",
      "video 1/1 (frame 99/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.2ms\n",
      "video 1/1 (frame 100/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 24.3ms\n",
      "video 1/1 (frame 101/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 24.8ms\n",
      "video 1/1 (frame 102/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 22.9ms\n",
      "video 1/1 (frame 103/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 22.7ms\n",
      "video 1/1 (frame 104/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.4ms\n",
      "video 1/1 (frame 105/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.3ms\n",
      "video 1/1 (frame 106/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 22.9ms\n",
      "video 1/1 (frame 107/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.0ms\n",
      "video 1/1 (frame 108/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 25.1ms\n",
      "video 1/1 (frame 109/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.1ms\n",
      "video 1/1 (frame 110/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 111/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 112/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.8ms\n",
      "video 1/1 (frame 113/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.1ms\n",
      "video 1/1 (frame 114/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 115/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 116/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.0ms\n",
      "video 1/1 (frame 117/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 118/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 70.6ms\n",
      "video 1/1 (frame 119/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 30.5ms\n",
      "video 1/1 (frame 120/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.0ms\n",
      "video 1/1 (frame 121/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 122/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.9ms\n",
      "video 1/1 (frame 123/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 124/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 125/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 126/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 127/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 128/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 129/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 130/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 131/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 132/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 133/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 134/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 135/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.9ms\n",
      "video 1/1 (frame 136/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.4ms\n",
      "video 1/1 (frame 137/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 42.3ms\n",
      "video 1/1 (frame 138/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 32.4ms\n",
      "video 1/1 (frame 139/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.7ms\n",
      "video 1/1 (frame 140/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.5ms\n",
      "video 1/1 (frame 141/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 33.6ms\n",
      "video 1/1 (frame 142/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 143/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 32.7ms\n",
      "video 1/1 (frame 144/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 145/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 33.1ms\n",
      "video 1/1 (frame 146/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 31.5ms\n",
      "video 1/1 (frame 147/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 148/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 149/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 150/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.8ms\n",
      "video 1/1 (frame 151/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 152/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 40.9ms\n",
      "video 1/1 (frame 153/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.0ms\n",
      "video 1/1 (frame 154/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 155/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.1ms\n",
      "video 1/1 (frame 156/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 34.6ms\n",
      "video 1/1 (frame 157/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 38.1ms\n",
      "video 1/1 (frame 158/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.1ms\n",
      "video 1/1 (frame 159/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 160/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 161/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 162/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 39.8ms\n",
      "video 1/1 (frame 163/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.9ms\n",
      "video 1/1 (frame 164/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 165/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.5ms\n",
      "video 1/1 (frame 166/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.7ms\n",
      "video 1/1 (frame 167/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 168/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.4ms\n",
      "video 1/1 (frame 169/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 170/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 171/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.1ms\n",
      "video 1/1 (frame 172/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 173/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 174/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.4ms\n",
      "video 1/1 (frame 175/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.0ms\n",
      "video 1/1 (frame 176/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 177/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 178/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 179/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 180/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.3ms\n",
      "video 1/1 (frame 181/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.8ms\n",
      "video 1/1 (frame 182/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.9ms\n",
      "video 1/1 (frame 183/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.0ms\n",
      "video 1/1 (frame 184/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.3ms\n",
      "video 1/1 (frame 185/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 186/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 187/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 42.7ms\n",
      "video 1/1 (frame 188/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 24.3ms\n",
      "video 1/1 (frame 189/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.6ms\n",
      "video 1/1 (frame 190/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 29.2ms\n",
      "video 1/1 (frame 191/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 26.3ms\n",
      "video 1/1 (frame 192/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 34.9ms\n",
      "video 1/1 (frame 193/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 32.1ms\n",
      "video 1/1 (frame 194/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.4ms\n",
      "video 1/1 (frame 195/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 33.0ms\n",
      "video 1/1 (frame 196/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.4ms\n",
      "video 1/1 (frame 197/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 28.7ms\n",
      "video 1/1 (frame 198/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 25.1ms\n",
      "video 1/1 (frame 199/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 24.9ms\n",
      "video 1/1 (frame 200/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 32.1ms\n",
      "video 1/1 (frame 201/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 26.7ms\n",
      "video 1/1 (frame 202/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 24.2ms\n",
      "video 1/1 (frame 203/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.3ms\n",
      "video 1/1 (frame 204/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.5ms\n",
      "video 1/1 (frame 205/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.4ms\n",
      "video 1/1 (frame 206/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 41.5ms\n",
      "video 1/1 (frame 207/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 28.1ms\n",
      "video 1/1 (frame 208/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.3ms\n",
      "video 1/1 (frame 209/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 33.7ms\n",
      "video 1/1 (frame 210/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 27.3ms\n",
      "video 1/1 (frame 211/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 24.4ms\n",
      "video 1/1 (frame 212/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.5ms\n",
      "video 1/1 (frame 213/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 214/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 215/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.0ms\n",
      "video 1/1 (frame 216/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.5ms\n",
      "video 1/1 (frame 217/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 218/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 219/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 220/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 221/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 222/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 223/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 224/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 225/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.1ms\n",
      "video 1/1 (frame 226/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.2ms\n",
      "video 1/1 (frame 227/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 228/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 229/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.0ms\n",
      "video 1/1 (frame 230/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.9ms\n",
      "video 1/1 (frame 231/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.0ms\n",
      "video 1/1 (frame 232/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 233/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 31.7ms\n",
      "video 1/1 (frame 234/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 235/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.8ms\n",
      "video 1/1 (frame 236/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 237/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 238/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 239/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.6ms\n",
      "video 1/1 (frame 240/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 241/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 242/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 36.3ms\n",
      "video 1/1 (frame 243/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 244/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.3ms\n",
      "video 1/1 (frame 245/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.0ms\n",
      "video 1/1 (frame 246/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.9ms\n",
      "video 1/1 (frame 247/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.0ms\n",
      "video 1/1 (frame 248/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 249/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 250/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.4ms\n",
      "video 1/1 (frame 251/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 252/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.5ms\n",
      "video 1/1 (frame 253/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.1ms\n",
      "video 1/1 (frame 254/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 255/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 256/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.8ms\n",
      "video 1/1 (frame 257/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 258/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 259/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.7ms\n",
      "video 1/1 (frame 260/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 261/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.9ms\n",
      "video 1/1 (frame 262/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.1ms\n",
      "video 1/1 (frame 263/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.6ms\n",
      "video 1/1 (frame 264/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.6ms\n",
      "video 1/1 (frame 265/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.1ms\n",
      "video 1/1 (frame 266/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.1ms\n",
      "video 1/1 (frame 267/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 25.3ms\n",
      "video 1/1 (frame 268/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 25.8ms\n",
      "video 1/1 (frame 269/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 24.4ms\n",
      "video 1/1 (frame 270/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 4 persons, 23.4ms\n",
      "video 1/1 (frame 271/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 272/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 273/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.9ms\n",
      "video 1/1 (frame 274/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.2ms\n",
      "video 1/1 (frame 275/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 276/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.5ms\n",
      "video 1/1 (frame 277/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 278/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 279/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 280/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.2ms\n",
      "video 1/1 (frame 281/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 282/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 40.9ms\n",
      "video 1/1 (frame 283/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.8ms\n",
      "video 1/1 (frame 284/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.4ms\n",
      "video 1/1 (frame 285/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 32.9ms\n",
      "video 1/1 (frame 286/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.8ms\n",
      "video 1/1 (frame 287/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.5ms\n",
      "video 1/1 (frame 288/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 289/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 290/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.9ms\n",
      "video 1/1 (frame 291/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 39.5ms\n",
      "video 1/1 (frame 292/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.7ms\n",
      "video 1/1 (frame 293/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.5ms\n",
      "video 1/1 (frame 294/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.6ms\n",
      "video 1/1 (frame 295/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 296/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 297/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 298/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 299/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 300/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 301/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.0ms\n",
      "video 1/1 (frame 302/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 303/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 304/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 305/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.1ms\n",
      "video 1/1 (frame 306/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.0ms\n",
      "video 1/1 (frame 307/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.2ms\n",
      "video 1/1 (frame 308/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.5ms\n",
      "video 1/1 (frame 309/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.0ms\n",
      "video 1/1 (frame 310/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.6ms\n",
      "video 1/1 (frame 311/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.3ms\n",
      "video 1/1 (frame 312/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.8ms\n",
      "video 1/1 (frame 313/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.3ms\n",
      "video 1/1 (frame 314/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.2ms\n",
      "video 1/1 (frame 315/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 48.4ms\n",
      "video 1/1 (frame 316/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 45.8ms\n",
      "video 1/1 (frame 317/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 318/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.4ms\n",
      "video 1/1 (frame 319/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 32.5ms\n",
      "video 1/1 (frame 320/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 321/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 322/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.3ms\n",
      "video 1/1 (frame 323/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.5ms\n",
      "video 1/1 (frame 324/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 325/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 326/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 327/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 328/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 329/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 32.1ms\n",
      "video 1/1 (frame 330/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.4ms\n",
      "video 1/1 (frame 331/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.1ms\n",
      "video 1/1 (frame 332/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.6ms\n",
      "video 1/1 (frame 333/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.8ms\n",
      "video 1/1 (frame 334/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.6ms\n",
      "video 1/1 (frame 335/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 336/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.0ms\n",
      "video 1/1 (frame 337/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.5ms\n",
      "video 1/1 (frame 338/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.0ms\n",
      "video 1/1 (frame 339/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 340/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 341/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 342/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.1ms\n",
      "video 1/1 (frame 343/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.9ms\n",
      "video 1/1 (frame 344/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.8ms\n",
      "video 1/1 (frame 345/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 346/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 347/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.8ms\n",
      "video 1/1 (frame 348/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.1ms\n",
      "video 1/1 (frame 349/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.6ms\n",
      "video 1/1 (frame 350/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 351/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.5ms\n",
      "video 1/1 (frame 352/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 353/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.1ms\n",
      "video 1/1 (frame 354/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 355/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 356/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 357/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 358/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 359/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 360/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 361/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.7ms\n",
      "video 1/1 (frame 362/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 363/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 364/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 365/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 366/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 367/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 368/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 369/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 370/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.4ms\n",
      "video 1/1 (frame 371/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.3ms\n",
      "video 1/1 (frame 372/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 373/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 374/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 375/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.7ms\n",
      "video 1/1 (frame 376/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 377/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 378/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 32.2ms\n",
      "video 1/1 (frame 379/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.7ms\n",
      "video 1/1 (frame 380/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.9ms\n",
      "video 1/1 (frame 381/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.2ms\n",
      "video 1/1 (frame 382/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.4ms\n",
      "video 1/1 (frame 383/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 384/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 32.2ms\n",
      "video 1/1 (frame 385/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 386/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.7ms\n",
      "video 1/1 (frame 387/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.1ms\n",
      "video 1/1 (frame 388/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.3ms\n",
      "video 1/1 (frame 389/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 390/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.3ms\n",
      "video 1/1 (frame 391/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.8ms\n",
      "video 1/1 (frame 392/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.9ms\n",
      "video 1/1 (frame 393/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.6ms\n",
      "video 1/1 (frame 394/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.7ms\n",
      "video 1/1 (frame 395/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 34.5ms\n",
      "video 1/1 (frame 396/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 30.7ms\n",
      "video 1/1 (frame 397/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 398/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 399/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 400/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 401/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.7ms\n",
      "video 1/1 (frame 402/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.9ms\n",
      "video 1/1 (frame 403/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 28.6ms\n",
      "video 1/1 (frame 404/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.7ms\n",
      "video 1/1 (frame 405/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 36.3ms\n",
      "video 1/1 (frame 406/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 29.7ms\n",
      "video 1/1 (frame 407/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 408/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 25.3ms\n",
      "video 1/1 (frame 409/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 410/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.1ms\n",
      "video 1/1 (frame 411/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 412/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 413/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.3ms\n",
      "video 1/1 (frame 414/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 415/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.1ms\n",
      "video 1/1 (frame 416/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 36.5ms\n",
      "video 1/1 (frame 417/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 418/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 29.2ms\n",
      "video 1/1 (frame 419/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 420/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.2ms\n",
      "video 1/1 (frame 421/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 422/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 423/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 424/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 425/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.0ms\n",
      "video 1/1 (frame 426/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.9ms\n",
      "video 1/1 (frame 427/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.6ms\n",
      "video 1/1 (frame 428/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 29.2ms\n",
      "video 1/1 (frame 429/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 25.1ms\n",
      "video 1/1 (frame 430/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 32.0ms\n",
      "video 1/1 (frame 431/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 432/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.6ms\n",
      "video 1/1 (frame 433/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.8ms\n",
      "video 1/1 (frame 434/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 47.0ms\n",
      "video 1/1 (frame 435/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 436/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 437/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 438/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.7ms\n",
      "video 1/1 (frame 439/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 28.7ms\n",
      "video 1/1 (frame 440/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.5ms\n",
      "video 1/1 (frame 441/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.3ms\n",
      "video 1/1 (frame 442/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 443/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 444/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 445/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 446/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.1ms\n",
      "video 1/1 (frame 447/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 448/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 449/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 30.8ms\n",
      "video 1/1 (frame 450/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 451/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 452/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 453/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 454/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.8ms\n",
      "video 1/1 (frame 455/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.5ms\n",
      "video 1/1 (frame 456/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.2ms\n",
      "video 1/1 (frame 457/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 458/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 459/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 460/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 461/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 31.8ms\n",
      "video 1/1 (frame 462/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 463/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 25.7ms\n",
      "video 1/1 (frame 464/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 42.3ms\n",
      "video 1/1 (frame 465/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 32.6ms\n",
      "video 1/1 (frame 466/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 467/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 468/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 469/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.7ms\n",
      "video 1/1 (frame 470/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 471/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 472/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 473/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.6ms\n",
      "video 1/1 (frame 474/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 475/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.1ms\n",
      "video 1/1 (frame 476/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 477/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.2ms\n",
      "video 1/1 (frame 478/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.2ms\n",
      "video 1/1 (frame 479/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.1ms\n",
      "video 1/1 (frame 480/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.1ms\n",
      "video 1/1 (frame 481/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.2ms\n",
      "video 1/1 (frame 482/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.1ms\n",
      "video 1/1 (frame 483/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.0ms\n",
      "video 1/1 (frame 484/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.0ms\n",
      "video 1/1 (frame 485/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.2ms\n",
      "video 1/1 (frame 486/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 21.7ms\n",
      "video 1/1 (frame 487/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.1ms\n",
      "video 1/1 (frame 488/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 21.1ms\n",
      "video 1/1 (frame 489/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 21.0ms\n",
      "video 1/1 (frame 490/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 21.0ms\n",
      "video 1/1 (frame 491/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.8ms\n",
      "video 1/1 (frame 492/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 21.0ms\n",
      "video 1/1 (frame 493/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 21.7ms\n",
      "video 1/1 (frame 494/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 31.6ms\n",
      "video 1/1 (frame 495/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.2ms\n",
      "video 1/1 (frame 496/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 497/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 498/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 499/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 500/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 501/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.3ms\n",
      "video 1/1 (frame 502/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 503/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 38.9ms\n",
      "video 1/1 (frame 504/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.0ms\n",
      "video 1/1 (frame 505/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.7ms\n",
      "video 1/1 (frame 506/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 507/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 508/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 509/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 510/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 511/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.7ms\n",
      "video 1/1 (frame 512/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 513/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 514/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 515/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 516/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 517/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 518/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 519/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 520/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.0ms\n",
      "video 1/1 (frame 521/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 522/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 523/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.4ms\n",
      "video 1/1 (frame 524/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.9ms\n",
      "video 1/1 (frame 525/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.3ms\n",
      "video 1/1 (frame 526/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.8ms\n",
      "video 1/1 (frame 527/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 528/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.5ms\n",
      "video 1/1 (frame 529/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.4ms\n",
      "video 1/1 (frame 530/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.7ms\n",
      "video 1/1 (frame 531/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.8ms\n",
      "video 1/1 (frame 532/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.6ms\n",
      "video 1/1 (frame 533/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.9ms\n",
      "video 1/1 (frame 534/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.3ms\n",
      "video 1/1 (frame 535/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 33.4ms\n",
      "video 1/1 (frame 536/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 537/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.9ms\n",
      "video 1/1 (frame 538/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.2ms\n",
      "video 1/1 (frame 539/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.2ms\n",
      "video 1/1 (frame 540/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 541/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.2ms\n",
      "video 1/1 (frame 542/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 543/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.8ms\n",
      "video 1/1 (frame 544/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.3ms\n",
      "video 1/1 (frame 545/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.9ms\n",
      "video 1/1 (frame 546/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.6ms\n",
      "video 1/1 (frame 547/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.6ms\n",
      "video 1/1 (frame 548/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 549/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.3ms\n",
      "video 1/1 (frame 550/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 551/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 552/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.8ms\n",
      "video 1/1 (frame 553/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 554/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.3ms\n",
      "video 1/1 (frame 555/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 556/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.2ms\n",
      "video 1/1 (frame 557/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.2ms\n",
      "video 1/1 (frame 558/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.5ms\n",
      "video 1/1 (frame 559/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 560/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 561/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 562/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 563/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 564/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 41.1ms\n",
      "video 1/1 (frame 565/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 31.8ms\n",
      "video 1/1 (frame 566/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 567/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 568/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 569/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 570/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.5ms\n",
      "video 1/1 (frame 571/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 572/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 573/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 574/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 575/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.5ms\n",
      "video 1/1 (frame 576/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 577/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.2ms\n",
      "video 1/1 (frame 578/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 579/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.3ms\n",
      "video 1/1 (frame 580/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.3ms\n",
      "video 1/1 (frame 581/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 582/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 583/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 37.4ms\n",
      "video 1/1 (frame 584/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 585/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.9ms\n",
      "video 1/1 (frame 586/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.4ms\n",
      "video 1/1 (frame 587/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.9ms\n",
      "video 1/1 (frame 588/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.1ms\n",
      "video 1/1 (frame 589/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.9ms\n",
      "video 1/1 (frame 590/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.1ms\n",
      "video 1/1 (frame 591/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.8ms\n",
      "video 1/1 (frame 592/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.0ms\n",
      "video 1/1 (frame 593/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 594/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 595/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 596/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 597/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.8ms\n",
      "video 1/1 (frame 598/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 599/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 600/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.0ms\n",
      "video 1/1 (frame 601/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.3ms\n",
      "video 1/1 (frame 602/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 603/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.2ms\n",
      "video 1/1 (frame 604/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.8ms\n",
      "video 1/1 (frame 605/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 606/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 607/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 608/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 609/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.8ms\n",
      "video 1/1 (frame 610/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.7ms\n",
      "video 1/1 (frame 611/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 612/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 613/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 614/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.8ms\n",
      "video 1/1 (frame 615/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 616/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 617/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 618/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.5ms\n",
      "video 1/1 (frame 619/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 620/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 621/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 622/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 623/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 624/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 625/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 626/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.6ms\n",
      "video 1/1 (frame 627/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.0ms\n",
      "video 1/1 (frame 628/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 629/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.7ms\n",
      "video 1/1 (frame 630/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 631/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 632/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.7ms\n",
      "video 1/1 (frame 633/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 634/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.2ms\n",
      "video 1/1 (frame 635/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 636/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 637/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.3ms\n",
      "video 1/1 (frame 638/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 639/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.6ms\n",
      "video 1/1 (frame 640/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.9ms\n",
      "video 1/1 (frame 641/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.7ms\n",
      "video 1/1 (frame 642/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 38.3ms\n",
      "video 1/1 (frame 643/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.0ms\n",
      "video 1/1 (frame 644/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.9ms\n",
      "video 1/1 (frame 645/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 646/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.5ms\n",
      "video 1/1 (frame 647/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 648/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 649/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.5ms\n",
      "video 1/1 (frame 650/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.8ms\n",
      "video 1/1 (frame 651/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.5ms\n",
      "video 1/1 (frame 652/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 39.1ms\n",
      "video 1/1 (frame 653/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.2ms\n",
      "video 1/1 (frame 654/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 41.4ms\n",
      "video 1/1 (frame 655/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 656/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.0ms\n",
      "video 1/1 (frame 657/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 37.6ms\n",
      "video 1/1 (frame 658/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.7ms\n",
      "video 1/1 (frame 659/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.2ms\n",
      "video 1/1 (frame 660/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 661/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 662/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 663/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 664/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 665/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 666/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 667/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 668/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 669/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 670/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 671/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 672/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 673/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 674/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.9ms\n",
      "video 1/1 (frame 675/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.3ms\n",
      "video 1/1 (frame 676/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.7ms\n",
      "video 1/1 (frame 677/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 678/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 679/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 680/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 681/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 682/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 683/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 684/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 685/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.8ms\n",
      "video 1/1 (frame 686/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 687/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.6ms\n",
      "video 1/1 (frame 688/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 689/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.9ms\n",
      "video 1/1 (frame 690/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 691/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 692/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.1ms\n",
      "video 1/1 (frame 693/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 694/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 695/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 696/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.4ms\n",
      "video 1/1 (frame 697/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.9ms\n",
      "video 1/1 (frame 698/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.4ms\n",
      "video 1/1 (frame 699/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.0ms\n",
      "video 1/1 (frame 700/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 701/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.8ms\n",
      "video 1/1 (frame 702/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.2ms\n",
      "video 1/1 (frame 703/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.8ms\n",
      "video 1/1 (frame 704/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.6ms\n",
      "video 1/1 (frame 705/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.9ms\n",
      "video 1/1 (frame 706/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.1ms\n",
      "video 1/1 (frame 707/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.9ms\n",
      "video 1/1 (frame 708/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 31.0ms\n",
      "video 1/1 (frame 709/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 710/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.9ms\n",
      "video 1/1 (frame 711/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 712/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 713/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.2ms\n",
      "video 1/1 (frame 714/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.3ms\n",
      "video 1/1 (frame 715/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 716/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 717/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 718/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.5ms\n",
      "video 1/1 (frame 719/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 720/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 721/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 722/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 723/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 724/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 725/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 726/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 727/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.6ms\n",
      "video 1/1 (frame 728/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 729/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 730/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 39.8ms\n",
      "video 1/1 (frame 731/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.2ms\n",
      "video 1/1 (frame 732/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 733/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.8ms\n",
      "video 1/1 (frame 734/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 735/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 736/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 36.7ms\n",
      "video 1/1 (frame 737/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.4ms\n",
      "video 1/1 (frame 738/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.3ms\n",
      "video 1/1 (frame 739/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.1ms\n",
      "video 1/1 (frame 740/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 741/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 742/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.1ms\n",
      "video 1/1 (frame 743/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 744/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 31.4ms\n",
      "video 1/1 (frame 745/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 746/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.4ms\n",
      "video 1/1 (frame 747/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 39.4ms\n",
      "video 1/1 (frame 748/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 749/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 31.8ms\n",
      "video 1/1 (frame 750/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.7ms\n",
      "video 1/1 (frame 751/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.7ms\n",
      "video 1/1 (frame 752/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.2ms\n",
      "video 1/1 (frame 753/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.1ms\n",
      "video 1/1 (frame 754/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.0ms\n",
      "video 1/1 (frame 755/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 756/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 757/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.0ms\n",
      "video 1/1 (frame 758/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.0ms\n",
      "video 1/1 (frame 759/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 760/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 761/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.5ms\n",
      "video 1/1 (frame 762/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.2ms\n",
      "video 1/1 (frame 763/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.2ms\n",
      "video 1/1 (frame 764/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 765/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 766/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.7ms\n",
      "video 1/1 (frame 767/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 768/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 769/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 770/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 771/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.9ms\n",
      "video 1/1 (frame 772/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.4ms\n",
      "video 1/1 (frame 773/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 774/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 54.9ms\n",
      "video 1/1 (frame 775/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.0ms\n",
      "video 1/1 (frame 776/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 777/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 778/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 779/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 780/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 781/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 782/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 783/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.8ms\n",
      "video 1/1 (frame 784/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.7ms\n",
      "video 1/1 (frame 785/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 786/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 787/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.1ms\n",
      "video 1/1 (frame 788/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.6ms\n",
      "video 1/1 (frame 789/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 790/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 791/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.1ms\n",
      "video 1/1 (frame 792/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 793/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 794/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 795/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.9ms\n",
      "video 1/1 (frame 796/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.5ms\n",
      "video 1/1 (frame 797/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.0ms\n",
      "video 1/1 (frame 798/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.4ms\n",
      "video 1/1 (frame 799/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.6ms\n",
      "video 1/1 (frame 800/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.7ms\n",
      "video 1/1 (frame 801/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.7ms\n",
      "video 1/1 (frame 802/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.2ms\n",
      "video 1/1 (frame 803/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.4ms\n",
      "video 1/1 (frame 804/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 805/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.7ms\n",
      "video 1/1 (frame 806/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.1ms\n",
      "video 1/1 (frame 807/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.0ms\n",
      "video 1/1 (frame 808/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.3ms\n",
      "video 1/1 (frame 809/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.4ms\n",
      "video 1/1 (frame 810/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 811/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.6ms\n",
      "video 1/1 (frame 812/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.5ms\n",
      "video 1/1 (frame 813/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 33.0ms\n",
      "video 1/1 (frame 814/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 815/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 816/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.8ms\n",
      "video 1/1 (frame 817/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.0ms\n",
      "video 1/1 (frame 818/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 819/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.2ms\n",
      "video 1/1 (frame 820/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 821/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.6ms\n",
      "video 1/1 (frame 822/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 823/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 824/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 825/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 826/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 827/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 828/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 829/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 830/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.5ms\n",
      "video 1/1 (frame 831/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 832/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 833/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.0ms\n",
      "video 1/1 (frame 834/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 835/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 20.3ms\n",
      "video 1/1 (frame 836/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 837/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 838/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 839/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 840/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.9ms\n",
      "video 1/1 (frame 841/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 842/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.9ms\n",
      "video 1/1 (frame 843/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.4ms\n",
      "video 1/1 (frame 844/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 845/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.3ms\n",
      "video 1/1 (frame 846/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.9ms\n",
      "video 1/1 (frame 847/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 848/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.9ms\n",
      "video 1/1 (frame 849/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.6ms\n",
      "video 1/1 (frame 850/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.4ms\n",
      "video 1/1 (frame 851/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 852/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.7ms\n",
      "video 1/1 (frame 853/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.5ms\n",
      "video 1/1 (frame 854/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.7ms\n",
      "video 1/1 (frame 855/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 15.5ms\n",
      "video 1/1 (frame 856/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 20.2ms\n",
      "video 1/1 (frame 857/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.9ms\n",
      "video 1/1 (frame 858/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 14.3ms\n",
      "video 1/1 (frame 859/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 12.5ms\n",
      "video 1/1 (frame 860/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.6ms\n",
      "video 1/1 (frame 861/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 12.6ms\n",
      "video 1/1 (frame 862/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.8ms\n",
      "video 1/1 (frame 863/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.8ms\n",
      "video 1/1 (frame 864/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 865/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 866/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.5ms\n",
      "video 1/1 (frame 867/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.0ms\n",
      "video 1/1 (frame 868/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.3ms\n",
      "video 1/1 (frame 869/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.4ms\n",
      "video 1/1 (frame 870/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.8ms\n",
      "video 1/1 (frame 871/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 872/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.3ms\n",
      "video 1/1 (frame 873/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 874/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 875/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 876/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 877/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.5ms\n",
      "video 1/1 (frame 878/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.9ms\n",
      "video 1/1 (frame 879/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.6ms\n",
      "video 1/1 (frame 880/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 22.6ms\n",
      "video 1/1 (frame 881/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.8ms\n",
      "video 1/1 (frame 882/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 31.0ms\n",
      "video 1/1 (frame 883/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.7ms\n",
      "video 1/1 (frame 884/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.7ms\n",
      "video 1/1 (frame 885/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 886/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.0ms\n",
      "video 1/1 (frame 887/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 22.1ms\n",
      "video 1/1 (frame 888/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.7ms\n",
      "video 1/1 (frame 889/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.2ms\n",
      "video 1/1 (frame 890/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.5ms\n",
      "video 1/1 (frame 891/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 892/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 893/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.8ms\n",
      "video 1/1 (frame 894/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 31.9ms\n",
      "video 1/1 (frame 895/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.6ms\n",
      "video 1/1 (frame 896/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 33.2ms\n",
      "video 1/1 (frame 897/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 31.1ms\n",
      "video 1/1 (frame 898/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.5ms\n",
      "video 1/1 (frame 899/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.5ms\n",
      "video 1/1 (frame 900/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 901/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 902/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 903/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.1ms\n",
      "video 1/1 (frame 904/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 905/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 906/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 907/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 36.3ms\n",
      "video 1/1 (frame 908/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.4ms\n",
      "video 1/1 (frame 909/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 26.3ms\n",
      "video 1/1 (frame 910/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 27.5ms\n",
      "video 1/1 (frame 911/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 26.6ms\n",
      "video 1/1 (frame 912/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 24.9ms\n",
      "video 1/1 (frame 913/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.8ms\n",
      "video 1/1 (frame 914/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 29.4ms\n",
      "video 1/1 (frame 915/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 24.9ms\n",
      "video 1/1 (frame 916/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.9ms\n",
      "video 1/1 (frame 917/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 918/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 919/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 920/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.8ms\n",
      "video 1/1 (frame 921/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 922/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.2ms\n",
      "video 1/1 (frame 923/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.2ms\n",
      "video 1/1 (frame 924/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.3ms\n",
      "video 1/1 (frame 925/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 926/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 927/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.5ms\n",
      "video 1/1 (frame 928/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 929/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.0ms\n",
      "video 1/1 (frame 930/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.0ms\n",
      "video 1/1 (frame 931/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.9ms\n",
      "video 1/1 (frame 932/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 933/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.9ms\n",
      "video 1/1 (frame 934/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.4ms\n",
      "video 1/1 (frame 935/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.2ms\n",
      "video 1/1 (frame 936/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 937/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.8ms\n",
      "video 1/1 (frame 938/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 939/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 940/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.5ms\n",
      "video 1/1 (frame 941/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 942/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 943/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 944/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 945/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.1ms\n",
      "video 1/1 (frame 946/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.1ms\n",
      "video 1/1 (frame 947/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.1ms\n",
      "video 1/1 (frame 948/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.7ms\n",
      "video 1/1 (frame 949/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 950/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 951/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 952/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.4ms\n",
      "video 1/1 (frame 953/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 31.1ms\n",
      "video 1/1 (frame 954/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.3ms\n",
      "video 1/1 (frame 955/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.4ms\n",
      "video 1/1 (frame 956/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.7ms\n",
      "video 1/1 (frame 957/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.1ms\n",
      "video 1/1 (frame 958/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.5ms\n",
      "video 1/1 (frame 959/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.6ms\n",
      "video 1/1 (frame 960/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 961/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 37.1ms\n",
      "video 1/1 (frame 962/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 963/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.8ms\n",
      "video 1/1 (frame 964/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 965/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 966/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.4ms\n",
      "video 1/1 (frame 967/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.5ms\n",
      "video 1/1 (frame 968/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.0ms\n",
      "video 1/1 (frame 969/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.9ms\n",
      "video 1/1 (frame 970/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.9ms\n",
      "video 1/1 (frame 971/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.0ms\n",
      "video 1/1 (frame 972/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 973/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.2ms\n",
      "video 1/1 (frame 974/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 975/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.7ms\n",
      "video 1/1 (frame 976/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.2ms\n",
      "video 1/1 (frame 977/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 978/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.2ms\n",
      "video 1/1 (frame 979/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.5ms\n",
      "video 1/1 (frame 980/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.6ms\n",
      "video 1/1 (frame 981/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 982/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 983/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 984/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.4ms\n",
      "video 1/1 (frame 985/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.6ms\n",
      "video 1/1 (frame 986/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.0ms\n",
      "video 1/1 (frame 987/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 988/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.9ms\n",
      "video 1/1 (frame 989/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.5ms\n",
      "video 1/1 (frame 990/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.5ms\n",
      "video 1/1 (frame 991/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.5ms\n",
      "video 1/1 (frame 992/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.1ms\n",
      "video 1/1 (frame 993/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 994/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.5ms\n",
      "video 1/1 (frame 995/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.5ms\n",
      "video 1/1 (frame 996/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.5ms\n",
      "video 1/1 (frame 997/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.4ms\n",
      "video 1/1 (frame 998/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 34.1ms\n",
      "video 1/1 (frame 999/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.1ms\n",
      "video 1/1 (frame 1000/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 1001/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.9ms\n",
      "video 1/1 (frame 1002/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.1ms\n",
      "video 1/1 (frame 1003/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 1004/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.8ms\n",
      "video 1/1 (frame 1005/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.2ms\n",
      "video 1/1 (frame 1006/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1007/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.6ms\n",
      "video 1/1 (frame 1008/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1009/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.7ms\n",
      "video 1/1 (frame 1010/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 1011/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 1012/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 1013/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.4ms\n",
      "video 1/1 (frame 1014/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.8ms\n",
      "video 1/1 (frame 1015/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 1016/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.4ms\n",
      "video 1/1 (frame 1017/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.6ms\n",
      "video 1/1 (frame 1018/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.9ms\n",
      "video 1/1 (frame 1019/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.9ms\n",
      "video 1/1 (frame 1020/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.9ms\n",
      "video 1/1 (frame 1021/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.9ms\n",
      "video 1/1 (frame 1022/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 1023/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1024/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 1025/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1026/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.0ms\n",
      "video 1/1 (frame 1027/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.4ms\n",
      "video 1/1 (frame 1028/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1029/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.6ms\n",
      "video 1/1 (frame 1030/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.6ms\n",
      "video 1/1 (frame 1031/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.6ms\n",
      "video 1/1 (frame 1032/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.0ms\n",
      "video 1/1 (frame 1033/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.6ms\n",
      "video 1/1 (frame 1034/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 1035/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1036/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 1037/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1038/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.2ms\n",
      "video 1/1 (frame 1039/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.0ms\n",
      "video 1/1 (frame 1040/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 1041/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 1042/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.1ms\n",
      "video 1/1 (frame 1043/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1044/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1045/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.4ms\n",
      "video 1/1 (frame 1046/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.2ms\n",
      "video 1/1 (frame 1047/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 1048/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 1049/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1050/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 1051/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.7ms\n",
      "video 1/1 (frame 1052/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1053/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.9ms\n",
      "video 1/1 (frame 1054/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 1055/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 1056/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.3ms\n",
      "video 1/1 (frame 1057/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.4ms\n",
      "video 1/1 (frame 1058/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 1059/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 1060/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 1061/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.2ms\n",
      "video 1/1 (frame 1062/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1063/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.1ms\n",
      "video 1/1 (frame 1064/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.3ms\n",
      "video 1/1 (frame 1065/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.8ms\n",
      "video 1/1 (frame 1066/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 1067/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.0ms\n",
      "video 1/1 (frame 1068/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.7ms\n",
      "video 1/1 (frame 1069/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1070/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.4ms\n",
      "video 1/1 (frame 1071/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.6ms\n",
      "video 1/1 (frame 1072/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.0ms\n",
      "video 1/1 (frame 1073/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.0ms\n",
      "video 1/1 (frame 1074/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1075/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 1076/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1077/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1078/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.5ms\n",
      "video 1/1 (frame 1079/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.4ms\n",
      "video 1/1 (frame 1080/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.1ms\n",
      "video 1/1 (frame 1081/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 35.7ms\n",
      "video 1/1 (frame 1082/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.6ms\n",
      "video 1/1 (frame 1083/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.4ms\n",
      "video 1/1 (frame 1084/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1085/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1086/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1087/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1088/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1089/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.6ms\n",
      "video 1/1 (frame 1090/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1091/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1092/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.0ms\n",
      "video 1/1 (frame 1093/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 1094/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1095/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 1096/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1097/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1098/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 1099/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 1100/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.5ms\n",
      "video 1/1 (frame 1101/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1102/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.5ms\n",
      "video 1/1 (frame 1103/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.9ms\n",
      "video 1/1 (frame 1104/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1105/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.5ms\n",
      "video 1/1 (frame 1106/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.4ms\n",
      "video 1/1 (frame 1107/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.5ms\n",
      "video 1/1 (frame 1108/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 1109/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 1110/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1111/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.4ms\n",
      "video 1/1 (frame 1112/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.6ms\n",
      "video 1/1 (frame 1113/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.6ms\n",
      "video 1/1 (frame 1114/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 1115/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 1116/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 1117/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1118/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1119/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1120/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1121/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1122/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.6ms\n",
      "video 1/1 (frame 1123/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.2ms\n",
      "video 1/1 (frame 1124/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1125/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 1126/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1127/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 40.3ms\n",
      "video 1/1 (frame 1128/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 1129/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 1130/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 1131/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.6ms\n",
      "video 1/1 (frame 1132/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 1133/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1134/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1135/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1136/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 1137/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.8ms\n",
      "video 1/1 (frame 1138/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1139/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.1ms\n",
      "video 1/1 (frame 1140/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.2ms\n",
      "video 1/1 (frame 1141/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.9ms\n",
      "video 1/1 (frame 1142/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1143/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.7ms\n",
      "video 1/1 (frame 1144/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1145/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1146/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1147/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.3ms\n",
      "video 1/1 (frame 1148/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 1149/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.0ms\n",
      "video 1/1 (frame 1150/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 1151/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 1152/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.0ms\n",
      "video 1/1 (frame 1153/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.9ms\n",
      "video 1/1 (frame 1154/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 1155/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.9ms\n",
      "video 1/1 (frame 1156/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.0ms\n",
      "video 1/1 (frame 1157/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.8ms\n",
      "video 1/1 (frame 1158/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 1159/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 1160/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1161/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.4ms\n",
      "video 1/1 (frame 1162/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1163/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1164/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.4ms\n",
      "video 1/1 (frame 1165/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1166/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1167/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.5ms\n",
      "video 1/1 (frame 1168/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.8ms\n",
      "video 1/1 (frame 1169/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.2ms\n",
      "video 1/1 (frame 1170/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.7ms\n",
      "video 1/1 (frame 1171/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.8ms\n",
      "video 1/1 (frame 1172/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 1173/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 34.0ms\n",
      "video 1/1 (frame 1174/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 1175/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.5ms\n",
      "video 1/1 (frame 1176/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.6ms\n",
      "video 1/1 (frame 1177/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1178/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.7ms\n",
      "video 1/1 (frame 1179/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.8ms\n",
      "video 1/1 (frame 1180/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.9ms\n",
      "video 1/1 (frame 1181/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1182/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 1183/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 1184/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.2ms\n",
      "video 1/1 (frame 1185/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1186/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.4ms\n",
      "video 1/1 (frame 1187/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.6ms\n",
      "video 1/1 (frame 1188/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.6ms\n",
      "video 1/1 (frame 1189/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 1190/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 1191/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1192/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1193/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1194/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1195/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1196/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1197/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1198/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1199/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 1200/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1201/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.4ms\n",
      "video 1/1 (frame 1202/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1203/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.4ms\n",
      "video 1/1 (frame 1204/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 1205/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 1206/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.9ms\n",
      "video 1/1 (frame 1207/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.5ms\n",
      "video 1/1 (frame 1208/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1209/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 1210/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.3ms\n",
      "video 1/1 (frame 1211/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.1ms\n",
      "video 1/1 (frame 1212/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.5ms\n",
      "video 1/1 (frame 1213/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.6ms\n",
      "video 1/1 (frame 1214/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.9ms\n",
      "video 1/1 (frame 1215/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.5ms\n",
      "video 1/1 (frame 1216/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.7ms\n",
      "video 1/1 (frame 1217/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1218/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1219/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.8ms\n",
      "video 1/1 (frame 1220/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.7ms\n",
      "video 1/1 (frame 1221/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 15.4ms\n",
      "video 1/1 (frame 1222/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 17.0ms\n",
      "video 1/1 (frame 1223/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.4ms\n",
      "video 1/1 (frame 1224/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1225/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.8ms\n",
      "video 1/1 (frame 1226/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.5ms\n",
      "video 1/1 (frame 1227/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1228/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 1229/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 34.6ms\n",
      "video 1/1 (frame 1230/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 36.4ms\n",
      "video 1/1 (frame 1231/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.9ms\n",
      "video 1/1 (frame 1232/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.6ms\n",
      "video 1/1 (frame 1233/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.5ms\n",
      "video 1/1 (frame 1234/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 14.6ms\n",
      "video 1/1 (frame 1235/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.2ms\n",
      "video 1/1 (frame 1236/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.5ms\n",
      "video 1/1 (frame 1237/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.7ms\n",
      "video 1/1 (frame 1238/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.6ms\n",
      "video 1/1 (frame 1239/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1240/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1241/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 1242/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.5ms\n",
      "video 1/1 (frame 1243/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1244/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 1245/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.6ms\n",
      "video 1/1 (frame 1246/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1247/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1248/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1249/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1250/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 1251/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.0ms\n",
      "video 1/1 (frame 1252/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 30.9ms\n",
      "video 1/1 (frame 1253/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.9ms\n",
      "video 1/1 (frame 1254/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 1255/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 1256/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 1257/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 1258/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 1259/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.1ms\n",
      "video 1/1 (frame 1260/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.5ms\n",
      "video 1/1 (frame 1261/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.7ms\n",
      "video 1/1 (frame 1262/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.1ms\n",
      "video 1/1 (frame 1263/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1264/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 33.7ms\n",
      "video 1/1 (frame 1265/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1266/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1267/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1268/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.4ms\n",
      "video 1/1 (frame 1269/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1270/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1271/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 23.0ms\n",
      "video 1/1 (frame 1272/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 30.4ms\n",
      "video 1/1 (frame 1273/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 29.7ms\n",
      "video 1/1 (frame 1274/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.7ms\n",
      "video 1/1 (frame 1275/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 15.9ms\n",
      "video 1/1 (frame 1276/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 11.8ms\n",
      "video 1/1 (frame 1277/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 11.5ms\n",
      "video 1/1 (frame 1278/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 12.1ms\n",
      "video 1/1 (frame 1279/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 13.2ms\n",
      "video 1/1 (frame 1280/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 13.9ms\n",
      "video 1/1 (frame 1281/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.5ms\n",
      "video 1/1 (frame 1282/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.5ms\n",
      "video 1/1 (frame 1283/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 13.8ms\n",
      "video 1/1 (frame 1284/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.5ms\n",
      "video 1/1 (frame 1285/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.8ms\n",
      "video 1/1 (frame 1286/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 14.9ms\n",
      "video 1/1 (frame 1287/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.7ms\n",
      "video 1/1 (frame 1288/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 15.1ms\n",
      "video 1/1 (frame 1289/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 14.8ms\n",
      "video 1/1 (frame 1290/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 12.9ms\n",
      "video 1/1 (frame 1291/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.4ms\n",
      "video 1/1 (frame 1292/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 16.4ms\n",
      "video 1/1 (frame 1293/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.7ms\n",
      "video 1/1 (frame 1294/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.6ms\n",
      "video 1/1 (frame 1295/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 13.6ms\n",
      "video 1/1 (frame 1296/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.5ms\n",
      "video 1/1 (frame 1297/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.8ms\n",
      "video 1/1 (frame 1298/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 18.9ms\n",
      "video 1/1 (frame 1299/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 12.5ms\n",
      "video 1/1 (frame 1300/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.6ms\n",
      "video 1/1 (frame 1301/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 11.9ms\n",
      "video 1/1 (frame 1302/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 17.9ms\n",
      "video 1/1 (frame 1303/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 26.1ms\n",
      "video 1/1 (frame 1304/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.0ms\n",
      "video 1/1 (frame 1305/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.7ms\n",
      "video 1/1 (frame 1306/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 25.6ms\n",
      "video 1/1 (frame 1307/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 27.2ms\n",
      "video 1/1 (frame 1308/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.3ms\n",
      "video 1/1 (frame 1309/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.3ms\n",
      "video 1/1 (frame 1310/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 1 person, 21.2ms\n",
      "video 1/1 (frame 1311/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1312/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.4ms\n",
      "video 1/1 (frame 1313/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.5ms\n",
      "video 1/1 (frame 1314/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.0ms\n",
      "video 1/1 (frame 1315/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.3ms\n",
      "video 1/1 (frame 1316/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.5ms\n",
      "video 1/1 (frame 1317/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.5ms\n",
      "video 1/1 (frame 1318/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.4ms\n",
      "video 1/1 (frame 1319/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.6ms\n",
      "video 1/1 (frame 1320/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 1321/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.6ms\n",
      "video 1/1 (frame 1322/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.0ms\n",
      "video 1/1 (frame 1323/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.2ms\n",
      "video 1/1 (frame 1324/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.5ms\n",
      "video 1/1 (frame 1325/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 1326/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.9ms\n",
      "video 1/1 (frame 1327/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.8ms\n",
      "video 1/1 (frame 1328/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 21.8ms\n",
      "video 1/1 (frame 1329/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.3ms\n",
      "video 1/1 (frame 1330/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.2ms\n",
      "video 1/1 (frame 1331/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 1332/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.2ms\n",
      "video 1/1 (frame 1333/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.1ms\n",
      "video 1/1 (frame 1334/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 1335/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.3ms\n",
      "video 1/1 (frame 1336/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 1337/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 1338/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 1339/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 1340/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 1341/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 1342/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 1343/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 46.1ms\n",
      "video 1/1 (frame 1344/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1345/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.6ms\n",
      "video 1/1 (frame 1346/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1347/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.9ms\n",
      "video 1/1 (frame 1348/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.2ms\n",
      "video 1/1 (frame 1349/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1350/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1351/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.2ms\n",
      "video 1/1 (frame 1352/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.4ms\n",
      "video 1/1 (frame 1353/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1354/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1355/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1356/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1357/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.9ms\n",
      "video 1/1 (frame 1358/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1359/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.1ms\n",
      "video 1/1 (frame 1360/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.2ms\n",
      "video 1/1 (frame 1361/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.1ms\n",
      "video 1/1 (frame 1362/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1363/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1364/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.2ms\n",
      "video 1/1 (frame 1365/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.9ms\n",
      "video 1/1 (frame 1366/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.5ms\n",
      "video 1/1 (frame 1367/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.1ms\n",
      "video 1/1 (frame 1368/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.1ms\n",
      "video 1/1 (frame 1369/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.4ms\n",
      "video 1/1 (frame 1370/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.6ms\n",
      "video 1/1 (frame 1371/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.1ms\n",
      "video 1/1 (frame 1372/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.9ms\n",
      "video 1/1 (frame 1373/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1374/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1375/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1376/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1377/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1378/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1379/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1380/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1381/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 1382/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 1383/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.6ms\n",
      "video 1/1 (frame 1384/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.1ms\n",
      "video 1/1 (frame 1385/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.0ms\n",
      "video 1/1 (frame 1386/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.8ms\n",
      "video 1/1 (frame 1387/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.0ms\n",
      "video 1/1 (frame 1388/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1389/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.6ms\n",
      "video 1/1 (frame 1390/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 33.5ms\n",
      "video 1/1 (frame 1391/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 1392/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1393/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.7ms\n",
      "video 1/1 (frame 1394/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.4ms\n",
      "video 1/1 (frame 1395/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.9ms\n",
      "video 1/1 (frame 1396/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.9ms\n",
      "video 1/1 (frame 1397/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1398/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1399/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.9ms\n",
      "video 1/1 (frame 1400/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.8ms\n",
      "video 1/1 (frame 1401/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.8ms\n",
      "video 1/1 (frame 1402/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1403/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.7ms\n",
      "video 1/1 (frame 1404/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1405/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1406/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.0ms\n",
      "video 1/1 (frame 1407/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.5ms\n",
      "video 1/1 (frame 1408/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1409/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.4ms\n",
      "video 1/1 (frame 1410/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.8ms\n",
      "video 1/1 (frame 1411/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1412/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1413/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 30.9ms\n",
      "video 1/1 (frame 1414/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 29.0ms\n",
      "video 1/1 (frame 1415/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 1416/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.1ms\n",
      "video 1/1 (frame 1417/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 28.9ms\n",
      "video 1/1 (frame 1418/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 29.4ms\n",
      "video 1/1 (frame 1419/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.7ms\n",
      "video 1/1 (frame 1420/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 1421/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.6ms\n",
      "video 1/1 (frame 1422/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 1423/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 1424/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 1425/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 36.6ms\n",
      "video 1/1 (frame 1426/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 1427/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 1428/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 1429/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 1430/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.7ms\n",
      "video 1/1 (frame 1431/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 1432/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.2ms\n",
      "video 1/1 (frame 1433/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 1434/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 1435/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.6ms\n",
      "video 1/1 (frame 1436/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.9ms\n",
      "video 1/1 (frame 1437/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 1438/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 1439/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 1440/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.7ms\n",
      "video 1/1 (frame 1441/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.6ms\n",
      "video 1/1 (frame 1442/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 1443/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.8ms\n",
      "video 1/1 (frame 1444/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.7ms\n",
      "video 1/1 (frame 1445/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 1446/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.8ms\n",
      "video 1/1 (frame 1447/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.0ms\n",
      "video 1/1 (frame 1448/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.3ms\n",
      "video 1/1 (frame 1449/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 25.9ms\n",
      "video 1/1 (frame 1450/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.6ms\n",
      "video 1/1 (frame 1451/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 26.8ms\n",
      "video 1/1 (frame 1452/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.1ms\n",
      "video 1/1 (frame 1453/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.8ms\n",
      "video 1/1 (frame 1454/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.8ms\n",
      "video 1/1 (frame 1455/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.4ms\n",
      "video 1/1 (frame 1456/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 1457/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.5ms\n",
      "video 1/1 (frame 1458/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 31.4ms\n",
      "video 1/1 (frame 1459/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.8ms\n",
      "video 1/1 (frame 1460/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.0ms\n",
      "video 1/1 (frame 1461/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 1462/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 27.8ms\n",
      "video 1/1 (frame 1463/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 1464/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.0ms\n",
      "video 1/1 (frame 1465/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 34.0ms\n",
      "video 1/1 (frame 1466/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 28.7ms\n",
      "video 1/1 (frame 1467/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1468/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1469/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.4ms\n",
      "video 1/1 (frame 1470/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.9ms\n",
      "video 1/1 (frame 1471/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 1472/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 1473/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 1474/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.3ms\n",
      "video 1/1 (frame 1475/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 23.5ms\n",
      "video 1/1 (frame 1476/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 24.8ms\n",
      "video 1/1 (frame 1477/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1478/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1479/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.1ms\n",
      "video 1/1 (frame 1480/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1481/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1482/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 34.0ms\n",
      "video 1/1 (frame 1483/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 1484/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 35.0ms\n",
      "video 1/1 (frame 1485/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.8ms\n",
      "video 1/1 (frame 1486/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.4ms\n",
      "video 1/1 (frame 1487/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 1488/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 1489/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 1490/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.2ms\n",
      "video 1/1 (frame 1491/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 27.1ms\n",
      "video 1/1 (frame 1492/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.3ms\n",
      "video 1/1 (frame 1493/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.7ms\n",
      "video 1/1 (frame 1494/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 1495/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 1496/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 1497/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.7ms\n",
      "video 1/1 (frame 1498/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.9ms\n",
      "video 1/1 (frame 1499/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 1500/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 1501/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 1502/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 1503/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.5ms\n",
      "video 1/1 (frame 1504/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 2 persons, 22.3ms\n",
      "video 1/1 (frame 1505/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 1506/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.0ms\n",
      "video 1/1 (frame 1507/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 1508/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.8ms\n",
      "video 1/1 (frame 1509/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 24.0ms\n",
      "video 1/1 (frame 1510/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 1511/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 1512/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.1ms\n",
      "video 1/1 (frame 1513/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.9ms\n",
      "video 1/1 (frame 1514/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 1515/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.5ms\n",
      "video 1/1 (frame 1516/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.4ms\n",
      "video 1/1 (frame 1517/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 23.1ms\n",
      "video 1/1 (frame 1518/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.7ms\n",
      "video 1/1 (frame 1519/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 22.6ms\n",
      "video 1/1 (frame 1520/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 26.5ms\n",
      "video 1/1 (frame 1521/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 3 persons, 25.7ms\n",
      "video 1/1 (frame 1522/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 1523/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 1524/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1525/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1526/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1527/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.4ms\n",
      "video 1/1 (frame 1528/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1529/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1530/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1531/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1532/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1533/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.5ms\n",
      "video 1/1 (frame 1534/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1535/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.9ms\n",
      "video 1/1 (frame 1536/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.1ms\n",
      "video 1/1 (frame 1537/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1538/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.3ms\n",
      "video 1/1 (frame 1539/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 1540/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.8ms\n",
      "video 1/1 (frame 1541/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1542/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1543/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1544/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1545/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 1546/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.4ms\n",
      "video 1/1 (frame 1547/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1548/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.9ms\n",
      "video 1/1 (frame 1549/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.7ms\n",
      "video 1/1 (frame 1550/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 1551/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.1ms\n",
      "video 1/1 (frame 1552/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.2ms\n",
      "video 1/1 (frame 1553/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 1554/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1555/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1556/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1557/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.4ms\n",
      "video 1/1 (frame 1558/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1559/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.8ms\n",
      "video 1/1 (frame 1560/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1561/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.5ms\n",
      "video 1/1 (frame 1562/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 1563/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.2ms\n",
      "video 1/1 (frame 1564/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1565/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1566/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.7ms\n",
      "video 1/1 (frame 1567/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.8ms\n",
      "video 1/1 (frame 1568/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.7ms\n",
      "video 1/1 (frame 1569/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1570/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1571/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 1572/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1573/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1574/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.3ms\n",
      "video 1/1 (frame 1575/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.4ms\n",
      "video 1/1 (frame 1576/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 1577/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.8ms\n",
      "video 1/1 (frame 1578/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 1579/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.1ms\n",
      "video 1/1 (frame 1580/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 1581/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.2ms\n",
      "video 1/1 (frame 1582/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.8ms\n",
      "video 1/1 (frame 1583/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.2ms\n",
      "video 1/1 (frame 1584/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.7ms\n",
      "video 1/1 (frame 1585/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.7ms\n",
      "video 1/1 (frame 1586/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.3ms\n",
      "video 1/1 (frame 1587/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.6ms\n",
      "video 1/1 (frame 1588/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 1589/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.4ms\n",
      "video 1/1 (frame 1590/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.5ms\n",
      "video 1/1 (frame 1591/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.9ms\n",
      "video 1/1 (frame 1592/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1593/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1594/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1595/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.2ms\n",
      "video 1/1 (frame 1596/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.1ms\n",
      "video 1/1 (frame 1597/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.5ms\n",
      "video 1/1 (frame 1598/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.4ms\n",
      "video 1/1 (frame 1599/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.7ms\n",
      "video 1/1 (frame 1600/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 1601/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 1602/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1603/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1604/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1605/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1606/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 1607/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1608/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 1609/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1610/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 1611/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1612/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 1613/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.9ms\n",
      "video 1/1 (frame 1614/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1615/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1616/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1617/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1618/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.9ms\n",
      "video 1/1 (frame 1619/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.1ms\n",
      "video 1/1 (frame 1620/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.0ms\n",
      "video 1/1 (frame 1621/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.7ms\n",
      "video 1/1 (frame 1622/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.7ms\n",
      "video 1/1 (frame 1623/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 1624/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.4ms\n",
      "video 1/1 (frame 1625/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.9ms\n",
      "video 1/1 (frame 1626/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.5ms\n",
      "video 1/1 (frame 1627/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 1628/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.4ms\n",
      "video 1/1 (frame 1629/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.2ms\n",
      "video 1/1 (frame 1630/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.0ms\n",
      "video 1/1 (frame 1631/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.2ms\n",
      "video 1/1 (frame 1632/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.1ms\n",
      "video 1/1 (frame 1633/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 1634/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.8ms\n",
      "video 1/1 (frame 1635/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 1636/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.1ms\n",
      "video 1/1 (frame 1637/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.7ms\n",
      "video 1/1 (frame 1638/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 1639/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.6ms\n",
      "video 1/1 (frame 1640/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 1641/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1642/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.0ms\n",
      "video 1/1 (frame 1643/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 1644/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.6ms\n",
      "video 1/1 (frame 1645/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.3ms\n",
      "video 1/1 (frame 1646/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 1647/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.6ms\n",
      "video 1/1 (frame 1648/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 1649/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 1650/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.4ms\n",
      "video 1/1 (frame 1651/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1652/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.3ms\n",
      "video 1/1 (frame 1653/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 1654/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1655/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1656/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1657/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1658/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 27.8ms\n",
      "video 1/1 (frame 1659/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1660/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.1ms\n",
      "video 1/1 (frame 1661/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 1662/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1663/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 1664/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.5ms\n",
      "video 1/1 (frame 1665/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.7ms\n",
      "video 1/1 (frame 1666/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1667/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 1668/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1669/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 1670/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.0ms\n",
      "video 1/1 (frame 1671/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 1672/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.7ms\n",
      "video 1/1 (frame 1673/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1674/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.7ms\n",
      "video 1/1 (frame 1675/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1676/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 1677/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1678/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 1679/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.2ms\n",
      "video 1/1 (frame 1680/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.6ms\n",
      "video 1/1 (frame 1681/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 1682/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.7ms\n",
      "video 1/1 (frame 1683/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.4ms\n",
      "video 1/1 (frame 1684/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.7ms\n",
      "video 1/1 (frame 1685/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 1686/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.0ms\n",
      "video 1/1 (frame 1687/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.2ms\n",
      "video 1/1 (frame 1688/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 1689/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 1690/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 1691/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 32.0ms\n",
      "video 1/1 (frame 1692/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.6ms\n",
      "video 1/1 (frame 1693/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.5ms\n",
      "video 1/1 (frame 1694/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1695/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1696/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.9ms\n",
      "video 1/1 (frame 1697/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 1698/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.3ms\n",
      "video 1/1 (frame 1699/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.8ms\n",
      "video 1/1 (frame 1700/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.4ms\n",
      "video 1/1 (frame 1701/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1702/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 1703/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1704/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 1705/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.3ms\n",
      "video 1/1 (frame 1706/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.8ms\n",
      "video 1/1 (frame 1707/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.0ms\n",
      "video 1/1 (frame 1708/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.3ms\n",
      "video 1/1 (frame 1709/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1710/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.5ms\n",
      "video 1/1 (frame 1711/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.8ms\n",
      "video 1/1 (frame 1712/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.7ms\n",
      "video 1/1 (frame 1713/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1714/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 28.2ms\n",
      "video 1/1 (frame 1715/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.1ms\n",
      "video 1/1 (frame 1716/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1717/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 29.9ms\n",
      "video 1/1 (frame 1718/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.2ms\n",
      "video 1/1 (frame 1719/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1720/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.9ms\n",
      "video 1/1 (frame 1721/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 31.5ms\n",
      "video 1/1 (frame 1722/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 1723/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.6ms\n",
      "video 1/1 (frame 1724/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.9ms\n",
      "video 1/1 (frame 1725/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 1726/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.4ms\n",
      "video 1/1 (frame 1727/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 22.2ms\n",
      "video 1/1 (frame 1728/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1729/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.1ms\n",
      "video 1/1 (frame 1730/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.5ms\n",
      "video 1/1 (frame 1731/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 23.9ms\n",
      "video 1/1 (frame 1732/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1733/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1734/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.8ms\n",
      "video 1/1 (frame 1735/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.1ms\n",
      "video 1/1 (frame 1736/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.2ms\n",
      "video 1/1 (frame 1737/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.8ms\n",
      "video 1/1 (frame 1738/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.2ms\n",
      "video 1/1 (frame 1739/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.1ms\n",
      "video 1/1 (frame 1740/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 1741/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1742/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1743/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.5ms\n",
      "video 1/1 (frame 1744/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.6ms\n",
      "video 1/1 (frame 1745/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.2ms\n",
      "video 1/1 (frame 1746/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.0ms\n",
      "video 1/1 (frame 1747/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.7ms\n",
      "video 1/1 (frame 1748/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.1ms\n",
      "video 1/1 (frame 1749/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 26.7ms\n",
      "video 1/1 (frame 1750/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.0ms\n",
      "video 1/1 (frame 1751/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.1ms\n",
      "video 1/1 (frame 1752/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 24.2ms\n",
      "video 1/1 (frame 1753/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1754/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.9ms\n",
      "video 1/1 (frame 1755/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 1756/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 1757/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.7ms\n",
      "video 1/1 (frame 1758/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.7ms\n",
      "video 1/1 (frame 1759/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.9ms\n",
      "video 1/1 (frame 1760/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.6ms\n",
      "video 1/1 (frame 1761/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 25.0ms\n",
      "video 1/1 (frame 1762/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 46.5ms\n",
      "video 1/1 (frame 1763/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.6ms\n",
      "video 1/1 (frame 1764/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.0ms\n",
      "video 1/1 (frame 1765/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.1ms\n",
      "video 1/1 (frame 1766/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1767/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.6ms\n",
      "video 1/1 (frame 1768/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.7ms\n",
      "video 1/1 (frame 1769/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.9ms\n",
      "video 1/1 (frame 1770/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.4ms\n",
      "video 1/1 (frame 1771/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.6ms\n",
      "video 1/1 (frame 1772/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.5ms\n",
      "video 1/1 (frame 1773/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "video 1/1 (frame 1774/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.5ms\n",
      "video 1/1 (frame 1775/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 18.3ms\n",
      "video 1/1 (frame 1776/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.5ms\n",
      "video 1/1 (frame 1777/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.2ms\n",
      "video 1/1 (frame 1778/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1779/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.4ms\n",
      "video 1/1 (frame 1780/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.9ms\n",
      "video 1/1 (frame 1781/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 21.9ms\n",
      "video 1/1 (frame 1782/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 1783/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.4ms\n",
      "video 1/1 (frame 1784/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 20.3ms\n",
      "video 1/1 (frame 1785/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 16.4ms\n",
      "video 1/1 (frame 1786/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 1787/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.0ms\n",
      "video 1/1 (frame 1788/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.2ms\n",
      "video 1/1 (frame 1789/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1790/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.5ms\n",
      "video 1/1 (frame 1791/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.3ms\n",
      "video 1/1 (frame 1792/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1793/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.9ms\n",
      "video 1/1 (frame 1794/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.0ms\n",
      "video 1/1 (frame 1795/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 13.4ms\n",
      "video 1/1 (frame 1796/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 17.2ms\n",
      "video 1/1 (frame 1797/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 12.0ms\n",
      "video 1/1 (frame 1798/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1799/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1800/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.2ms\n",
      "video 1/1 (frame 1801/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 14.6ms\n",
      "video 1/1 (frame 1802/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 19.3ms\n",
      "video 1/1 (frame 1803/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 15.3ms\n",
      "video 1/1 (frame 1804/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.3ms\n",
      "video 1/1 (frame 1805/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.4ms\n",
      "video 1/1 (frame 1806/1806) F:\\ai\\AI-Development\\Yolo v8\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\video.mp4: 192x320 (no detections), 11.6ms\n",
      "Speed: 1.7ms preprocess, 22.5ms inference, 2.4ms postprocess per image at shape (1, 3, 192, 320)\n",
      "Results saved to \u001b[1mruns\\pose\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  72, 113],\n",
       "         [ 98,  72, 113],\n",
       "         [ 97,  71, 112],\n",
       "         ...,\n",
       "         [ 95,  61,  80],\n",
       "         [ 95,  61,  80],\n",
       "         [ 95,  61,  80]],\n",
       " \n",
       "        [[ 98,  72, 113],\n",
       "         [ 98,  72, 113],\n",
       "         [ 97,  71, 112],\n",
       "         ...,\n",
       "         [ 95,  61,  80],\n",
       "         [ 95,  61,  80],\n",
       "         [ 95,  61,  80]],\n",
       " \n",
       "        [[ 97,  71, 112],\n",
       "         [ 97,  71, 112],\n",
       "         [ 96,  70, 111],\n",
       "         ...,\n",
       "         [ 95,  61,  80],\n",
       "         [ 95,  61,  80],\n",
       "         [ 95,  61,  80]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 133, 129],\n",
       "         [  5, 133, 129],\n",
       "         [  5, 133, 129],\n",
       "         ...,\n",
       "         [166, 164, 142],\n",
       "         [166, 164, 142],\n",
       "         [166, 164, 142]],\n",
       " \n",
       "        [[  5, 133, 129],\n",
       "         [  5, 133, 129],\n",
       "         [  5, 133, 129],\n",
       "         ...,\n",
       "         [168, 165, 145],\n",
       "         [168, 165, 145],\n",
       "         [168, 165, 145]],\n",
       " \n",
       "        [[  5, 133, 129],\n",
       "         [  5, 133, 129],\n",
       "         [  5, 133, 129],\n",
       "         ...,\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3269000012078322, 'inference': 125.21169999672566, 'postprocess': 7.255900003656279},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        [[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        [[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 128, 126],\n",
       "         [  6, 129, 127],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144]],\n",
       " \n",
       "        [[  6, 129, 127],\n",
       "         [  7, 130, 128],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  6, 129, 127],\n",
       "         [  7, 130, 128],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.2092000037664548, 'inference': 38.81140000157757, 'postprocess': 4.892600001767278},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        [[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        [[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 128, 126],\n",
       "         [  6, 129, 127],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144]],\n",
       " \n",
       "        [[  6, 129, 127],\n",
       "         [  7, 130, 128],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  6, 129, 127],\n",
       "         [  7, 130, 128],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9738999981200323, 'inference': 26.51210000476567, 'postprocess': 3.1649999946239404},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        [[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        [[100,  72, 111],\n",
       "         [100,  72, 111],\n",
       "         [ 99,  71, 110],\n",
       "         ...,\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76],\n",
       "         [ 93,  59,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 128, 126],\n",
       "         [  6, 129, 127],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144]],\n",
       " \n",
       "        [[  6, 129, 127],\n",
       "         [  7, 130, 128],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  6, 129, 127],\n",
       "         [  7, 130, 128],\n",
       "         [  5, 130, 128],\n",
       "         ...,\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.302700002270285, 'inference': 23.581000001286156, 'postprocess': 4.9849999995785765},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 110],\n",
       "         [ 98,  74, 110],\n",
       "         [ 97,  73, 109],\n",
       "         ...,\n",
       "         [ 95,  61,  78],\n",
       "         [ 95,  61,  78],\n",
       "         [ 95,  61,  78]],\n",
       " \n",
       "        [[ 98,  74, 110],\n",
       "         [ 98,  74, 110],\n",
       "         [ 97,  73, 109],\n",
       "         ...,\n",
       "         [ 95,  61,  78],\n",
       "         [ 95,  61,  78],\n",
       "         [ 95,  61,  78]],\n",
       " \n",
       "        [[ 98,  74, 110],\n",
       "         [ 98,  74, 110],\n",
       "         [ 97,  73, 109],\n",
       "         ...,\n",
       "         [ 95,  61,  78],\n",
       "         [ 95,  61,  78],\n",
       "         [ 95,  61,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  6, 120, 123],\n",
       "         [  7, 121, 124],\n",
       "         [  5, 124, 126],\n",
       "         ...,\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144]],\n",
       " \n",
       "        [[  6, 120, 123],\n",
       "         [  7, 121, 124],\n",
       "         [  5, 124, 126],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  6, 120, 123],\n",
       "         [  7, 121, 124],\n",
       "         [  5, 124, 126],\n",
       "         ...,\n",
       "         [174, 171, 151],\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.220999995188322, 'inference': 34.89199999603443, 'postprocess': 4.250999998475891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 110],\n",
       "         [ 98,  74, 110],\n",
       "         [ 97,  73, 109],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        [[ 98,  74, 110],\n",
       "         [ 98,  74, 110],\n",
       "         [ 97,  73, 109],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        [[ 98,  74, 110],\n",
       "         [ 98,  74, 110],\n",
       "         [ 97,  73, 109],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  7, 121, 124],\n",
       "         [  7, 121, 124],\n",
       "         [  7, 124, 126],\n",
       "         ...,\n",
       "         [169, 166, 146],\n",
       "         [169, 167, 145],\n",
       "         [169, 167, 145]],\n",
       " \n",
       "        [[  7, 121, 124],\n",
       "         [  7, 121, 124],\n",
       "         [  7, 124, 126],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  7, 121, 124],\n",
       "         [  7, 121, 124],\n",
       "         [  7, 124, 126],\n",
       "         ...,\n",
       "         [174, 171, 151],\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.343399995879736, 'inference': 37.70990000339225, 'postprocess': 2.0732000048155896},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        [[ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        [[ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [169, 166, 146],\n",
       "         [169, 167, 145],\n",
       "         [169, 167, 145]],\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [174, 171, 151],\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.294399997277651, 'inference': 23.29289999761386, 'postprocess': 2.111699999659322},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        [[ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        [[ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         [ 96,  73, 106],\n",
       "         ...,\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77],\n",
       "         [ 95,  62,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [169, 166, 146],\n",
       "         [169, 167, 145],\n",
       "         [169, 167, 145]],\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [174, 171, 151],\n",
       "         [175, 172, 152],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.157800004875753, 'inference': 23.397700002533384, 'postprocess': 1.96719999803463},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 95,  72, 105],\n",
       "         [ 95,  72, 105],\n",
       "         [ 95,  72, 105],\n",
       "         ...,\n",
       "         [ 93,  60,  75],\n",
       "         [ 93,  60,  75],\n",
       "         [ 93,  60,  75]],\n",
       " \n",
       "        [[ 95,  72, 105],\n",
       "         [ 95,  72, 105],\n",
       "         [ 95,  72, 105],\n",
       "         ...,\n",
       "         [ 93,  60,  75],\n",
       "         [ 93,  60,  75],\n",
       "         [ 93,  60,  75]],\n",
       " \n",
       "        [[ 95,  72, 105],\n",
       "         [ 95,  72, 105],\n",
       "         [ 95,  72, 105],\n",
       "         ...,\n",
       "         [ 93,  60,  75],\n",
       "         [ 93,  60,  75],\n",
       "         [ 93,  60,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [169, 166, 146],\n",
       "         [168, 166, 144],\n",
       "         [168, 166, 144]],\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         [  5, 122, 124],\n",
       "         ...,\n",
       "         [175, 172, 152],\n",
       "         [174, 171, 151],\n",
       "         [175, 172, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5204000010271557, 'inference': 25.624199995945673, 'postprocess': 2.195599998231046},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  3, 123, 122],\n",
       "         [  3, 123, 122],\n",
       "         [  3, 123, 122],\n",
       "         ...,\n",
       "         [169, 165, 148],\n",
       "         [169, 166, 146],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  4, 124, 123],\n",
       "         [  4, 124, 123],\n",
       "         [  4, 124, 123],\n",
       "         ...,\n",
       "         [169, 165, 148],\n",
       "         [168, 164, 147],\n",
       "         [168, 164, 147]],\n",
       " \n",
       "        [[  4, 124, 123],\n",
       "         [  4, 124, 123],\n",
       "         [  4, 124, 123],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [172, 168, 151],\n",
       "         [172, 168, 151]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6269999978248961, 'inference': 23.497599999245722, 'postprocess': 3.1230999957188033},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [100,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  3, 123, 122],\n",
       "         [  3, 123, 122],\n",
       "         [  3, 123, 122],\n",
       "         ...,\n",
       "         [169, 165, 148],\n",
       "         [169, 166, 146],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  4, 124, 123],\n",
       "         [  4, 124, 123],\n",
       "         [  4, 124, 123],\n",
       "         ...,\n",
       "         [169, 165, 148],\n",
       "         [168, 164, 147],\n",
       "         [168, 164, 147]],\n",
       " \n",
       "        [[  4, 124, 123],\n",
       "         [  4, 124, 123],\n",
       "         [  4, 124, 123],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [172, 168, 151],\n",
       "         [172, 168, 151]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7814000020734966, 'inference': 23.508499994932208, 'postprocess': 1.9773000021814369},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [100,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         ...,\n",
       "         [167, 164, 144],\n",
       "         [167, 165, 143],\n",
       "         [166, 164, 142]],\n",
       " \n",
       "        [[  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [169, 166, 146],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         ...,\n",
       "         [173, 170, 150],\n",
       "         [173, 170, 150],\n",
       "         [173, 170, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3760000001639128, 'inference': 23.35250000032829, 'postprocess': 2.3934999990160577},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         ...,\n",
       "         [167, 164, 144],\n",
       "         [167, 165, 143],\n",
       "         [166, 164, 142]],\n",
       " \n",
       "        [[  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         ...,\n",
       "         [171, 168, 148],\n",
       "         [169, 166, 146],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         [  6, 121, 121],\n",
       "         ...,\n",
       "         [173, 170, 150],\n",
       "         [173, 170, 150],\n",
       "         [173, 170, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8240000063087791, 'inference': 25.642399996286258, 'postprocess': 4.937599995173514},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [169, 165, 148],\n",
       "         [167, 164, 144],\n",
       "         [167, 164, 144]],\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [171, 167, 150],\n",
       "         [171, 168, 148],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [172, 169, 149],\n",
       "         [172, 169, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3156000059098005, 'inference': 34.51810000115074, 'postprocess': 4.9403999946662225},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [169, 165, 148],\n",
       "         [167, 164, 144],\n",
       "         [167, 164, 144]],\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [171, 167, 150],\n",
       "         [171, 168, 148],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [172, 169, 149],\n",
       "         [172, 169, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.9288000005180947, 'inference': 27.014200000849087, 'postprocess': 6.485700003395323},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         [ 98,  73, 105],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [169, 165, 148],\n",
       "         [167, 164, 144],\n",
       "         [167, 164, 144]],\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [171, 167, 150],\n",
       "         [171, 168, 148],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [172, 169, 149],\n",
       "         [172, 169, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.428400002827402, 'inference': 26.798799997777678, 'postprocess': 6.1707999993814155},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [171, 167, 150],\n",
       "         [169, 166, 146],\n",
       "         [168, 165, 145]],\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [171, 167, 150],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [172, 169, 149],\n",
       "         [173, 170, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3693999935640022, 'inference': 23.213100001157727, 'postprocess': 4.1342000040458515},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [171, 167, 150],\n",
       "         [169, 166, 146],\n",
       "         [168, 165, 145]],\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [171, 167, 150],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [172, 169, 149],\n",
       "         [173, 170, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.6503000044613145, 'inference': 29.651500000909436, 'postprocess': 1.9805999982054345},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [171, 168, 148],\n",
       "         [168, 165, 145]],\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [169, 166, 146],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [174, 170, 153],\n",
       "         [172, 169, 149],\n",
       "         [172, 169, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2403000000631437, 'inference': 23.23840000462951, 'postprocess': 4.51930000417633},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [171, 168, 148],\n",
       "         [168, 165, 145]],\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [169, 166, 146],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [174, 170, 153],\n",
       "         [172, 169, 149],\n",
       "         [172, 169, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.3201000042026863, 'inference': 44.14189999806695, 'postprocess': 4.883200002950616},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [171, 168, 148],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [173, 170, 150],\n",
       "         [172, 169, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2252000014996156, 'inference': 23.436200004653074, 'postprocess': 4.436100003658794},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [100,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [171, 168, 148],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [171, 168, 148],\n",
       "         [171, 168, 148]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [174, 170, 153],\n",
       "         [173, 170, 150],\n",
       "         [172, 169, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.119600001606159, 'inference': 25.80820000002859, 'postprocess': 2.797200002532918},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [100,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 118, 113],\n",
       "         [  5, 118, 113],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [171, 168, 148],\n",
       "         [168, 165, 145]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [173, 169, 152],\n",
       "         [169, 166, 146],\n",
       "         [169, 166, 146]],\n",
       " \n",
       "        [[  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         [  6, 119, 114],\n",
       "         ...,\n",
       "         [174, 170, 153],\n",
       "         [172, 169, 149],\n",
       "         [172, 169, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6407000002800487, 'inference': 30.61130000423873, 'postprocess': 3.05619999562623},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [100,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [100,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         ...,\n",
       "         [172, 167, 152],\n",
       "         [168, 165, 145],\n",
       "         [167, 164, 144]],\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [168, 165, 145],\n",
       "         [167, 164, 144]],\n",
       " \n",
       "        [[  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [169, 166, 146],\n",
       "         [168, 165, 145]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3517000043066218, 'inference': 23.211899999296293, 'postprocess': 3.25880000309553},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        [[ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         [ 98,  74, 103],\n",
       "         ...,\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75],\n",
       "         [ 95,  59,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         ...,\n",
       "         [172, 167, 152],\n",
       "         [168, 165, 145],\n",
       "         [167, 164, 144]],\n",
       " \n",
       "        [[  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         [  7, 117, 113],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [168, 165, 145],\n",
       "         [167, 164, 144]],\n",
       " \n",
       "        [[  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         [  8, 118, 114],\n",
       "         ...,\n",
       "         [172, 168, 151],\n",
       "         [169, 166, 146],\n",
       "         [168, 165, 145]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.328400001511909, 'inference': 23.276299994904548, 'postprocess': 1.9666000007418916},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         ...,\n",
       "         [172, 166, 154],\n",
       "         [168, 164, 147],\n",
       "         [167, 163, 146]],\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         ...,\n",
       "         [172, 167, 152],\n",
       "         [168, 164, 147],\n",
       "         [167, 163, 146]],\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  5, 118, 113],\n",
       "         ...,\n",
       "         [172, 167, 152],\n",
       "         [169, 165, 148],\n",
       "         [168, 164, 147]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4300000038929284, 'inference': 23.856700005126186, 'postprocess': 1.8397999956505373},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         ...,\n",
       "         [172, 166, 154],\n",
       "         [168, 164, 147],\n",
       "         [167, 163, 146]],\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         ...,\n",
       "         [172, 167, 152],\n",
       "         [168, 164, 147],\n",
       "         [167, 163, 146]],\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  5, 118, 113],\n",
       "         ...,\n",
       "         [172, 167, 152],\n",
       "         [169, 165, 148],\n",
       "         [168, 164, 147]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5015000026323833, 'inference': 23.284499999135733, 'postprocess': 1.9037999954889528},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         [ 98,  74, 101],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         ...,\n",
       "         [172, 166, 154],\n",
       "         [168, 164, 147],\n",
       "         [167, 163, 146]],\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         ...,\n",
       "         [172, 167, 152],\n",
       "         [168, 164, 147],\n",
       "         [167, 163, 146]],\n",
       " \n",
       "        [[  4, 117, 112],\n",
       "         [  4, 117, 112],\n",
       "         [  5, 118, 113],\n",
       "         ...,\n",
       "         [172, 167, 152],\n",
       "         [169, 165, 148],\n",
       "         [168, 164, 147]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4318000030471012, 'inference': 27.113900003314484, 'postprocess': 2.0843999955104664},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  76,  98],\n",
       "         [ 98,  76,  98],\n",
       "         [ 98,  76,  98],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 98,  76,  98],\n",
       "         [ 98,  76,  98],\n",
       "         [ 98,  76,  98],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 98,  75, 100],\n",
       "         [ 98,  75, 100],\n",
       "         [ 98,  75, 100],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  4, 114, 110],\n",
       "         [  4, 114, 110],\n",
       "         [  4, 114, 110],\n",
       "         ...,\n",
       "         [172, 166, 156],\n",
       "         [168, 163, 148],\n",
       "         [167, 162, 147]],\n",
       " \n",
       "        [[  4, 114, 110],\n",
       "         [  4, 114, 110],\n",
       "         [  4, 114, 110],\n",
       "         ...,\n",
       "         [172, 166, 154],\n",
       "         [168, 163, 148],\n",
       "         [167, 162, 147]],\n",
       " \n",
       "        [[  4, 114, 110],\n",
       "         [  4, 114, 110],\n",
       "         [  4, 114, 110],\n",
       "         ...,\n",
       "         [172, 166, 154],\n",
       "         [169, 164, 149],\n",
       "         [168, 163, 148]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8763999978546053, 'inference': 40.45770000084303, 'postprocess': 3.2785000003059395},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  77,  98],\n",
       "         [ 96,  77,  98],\n",
       "         [ 98,  76,  98],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 96,  77,  98],\n",
       "         [ 96,  77,  98],\n",
       "         [ 98,  76,  98],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        [[ 96,  76, 100],\n",
       "         [ 96,  76, 100],\n",
       "         [ 98,  75, 100],\n",
       "         ...,\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77],\n",
       "         [ 97,  61,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  5, 113, 109],\n",
       "         [  5, 113, 109],\n",
       "         [  6, 114, 110],\n",
       "         ...,\n",
       "         [168, 162, 152],\n",
       "         [166, 161, 146],\n",
       "         [165, 160, 145]],\n",
       " \n",
       "        [[  5, 113, 107],\n",
       "         [  6, 114, 108],\n",
       "         [  6, 114, 108],\n",
       "         ...,\n",
       "         [173, 166, 158],\n",
       "         [168, 162, 150],\n",
       "         [166, 160, 148]],\n",
       " \n",
       "        [[  6, 114, 108],\n",
       "         [  6, 114, 108],\n",
       "         [  6, 114, 108],\n",
       "         ...,\n",
       "         [175, 168, 160],\n",
       "         [173, 167, 155],\n",
       "         [168, 162, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1052000010968186, 'inference': 23.482000004150905, 'postprocess': 2.104399995005224},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[192, 100, 117],\n",
       "         [195, 103, 120],\n",
       "         [200, 110, 127],\n",
       "         ...,\n",
       "         [168, 114, 125],\n",
       "         [167, 113, 124],\n",
       "         [166, 112, 123]],\n",
       " \n",
       "        [[192, 100, 117],\n",
       "         [195, 103, 120],\n",
       "         [200, 110, 127],\n",
       "         ...,\n",
       "         [168, 114, 125],\n",
       "         [167, 113, 124],\n",
       "         [166, 112, 123]],\n",
       " \n",
       "        [[191,  99, 116],\n",
       "         [194, 102, 119],\n",
       "         [200, 110, 127],\n",
       "         ...,\n",
       "         [170, 116, 127],\n",
       "         [169, 115, 126],\n",
       "         [168, 114, 125]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[178,  65,  89],\n",
       "         [178,  65,  89],\n",
       "         [180,  66,  87],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[175,  65,  88],\n",
       "         [175,  65,  88],\n",
       "         [179,  65,  86],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[175,  65,  88],\n",
       "         [175,  65,  88],\n",
       "         [179,  65,  86],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.583299999765586, 'inference': 23.426100000506267, 'postprocess': 2.81100000574952},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[192, 100, 117],\n",
       "         [195, 103, 120],\n",
       "         [200, 110, 127],\n",
       "         ...,\n",
       "         [168, 114, 125],\n",
       "         [167, 113, 124],\n",
       "         [166, 112, 123]],\n",
       " \n",
       "        [[192, 100, 117],\n",
       "         [195, 103, 120],\n",
       "         [200, 110, 127],\n",
       "         ...,\n",
       "         [168, 114, 125],\n",
       "         [167, 113, 124],\n",
       "         [166, 112, 123]],\n",
       " \n",
       "        [[191,  99, 116],\n",
       "         [194, 102, 119],\n",
       "         [200, 110, 127],\n",
       "         ...,\n",
       "         [170, 116, 127],\n",
       "         [169, 115, 126],\n",
       "         [168, 114, 125]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[178,  65,  89],\n",
       "         [178,  65,  89],\n",
       "         [180,  66,  87],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[175,  65,  88],\n",
       "         [175,  65,  88],\n",
       "         [179,  65,  86],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[175,  65,  88],\n",
       "         [175,  65,  88],\n",
       "         [179,  65,  86],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.749899995047599, 'inference': 23.365700006252155, 'postprocess': 2.8930000044056214},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[228, 102, 118],\n",
       "         [230, 104, 120],\n",
       "         [234, 108, 124],\n",
       "         ...,\n",
       "         [155, 106, 121],\n",
       "         [155, 106, 121],\n",
       "         [155, 106, 121]],\n",
       " \n",
       "        [[231, 105, 121],\n",
       "         [232, 106, 122],\n",
       "         [235, 109, 125],\n",
       "         ...,\n",
       "         [160, 111, 126],\n",
       "         [160, 111, 126],\n",
       "         [160, 111, 126]],\n",
       " \n",
       "        [[235, 111, 127],\n",
       "         [236, 112, 128],\n",
       "         [234, 113, 128],\n",
       "         ...,\n",
       "         [162, 115, 130],\n",
       "         [162, 115, 130],\n",
       "         [162, 115, 130]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[127,  39,  63],\n",
       "         [128,  40,  64],\n",
       "         [129,  41,  65],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[128,  41,  62],\n",
       "         [128,  41,  62],\n",
       "         [129,  42,  63],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[128,  41,  62],\n",
       "         [128,  41,  62],\n",
       "         [129,  42,  63],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8973999976878986, 'inference': 23.339799998211674, 'postprocess': 2.572999997937586},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[228, 102, 118],\n",
       "         [230, 104, 120],\n",
       "         [234, 108, 124],\n",
       "         ...,\n",
       "         [155, 106, 121],\n",
       "         [155, 106, 121],\n",
       "         [155, 106, 121]],\n",
       " \n",
       "        [[231, 105, 121],\n",
       "         [232, 106, 122],\n",
       "         [235, 109, 125],\n",
       "         ...,\n",
       "         [160, 111, 126],\n",
       "         [160, 111, 126],\n",
       "         [160, 111, 126]],\n",
       " \n",
       "        [[235, 111, 127],\n",
       "         [236, 112, 128],\n",
       "         [234, 113, 128],\n",
       "         ...,\n",
       "         [162, 115, 130],\n",
       "         [162, 115, 130],\n",
       "         [162, 115, 130]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[127,  39,  63],\n",
       "         [128,  40,  64],\n",
       "         [129,  41,  65],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[128,  41,  62],\n",
       "         [128,  41,  62],\n",
       "         [129,  42,  63],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[128,  41,  62],\n",
       "         [128,  41,  62],\n",
       "         [129,  42,  63],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.422500004991889, 'inference': 23.392800001602154, 'postprocess': 2.048299997113645},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[235, 125, 148],\n",
       "         [233, 123, 146],\n",
       "         [235, 122, 146],\n",
       "         ...,\n",
       "         [164, 117, 146],\n",
       "         [160, 108, 151],\n",
       "         [153, 101, 144]],\n",
       " \n",
       "        [[235, 125, 148],\n",
       "         [233, 123, 146],\n",
       "         [235, 122, 146],\n",
       "         ...,\n",
       "         [164, 117, 146],\n",
       "         [158, 106, 149],\n",
       "         [151,  99, 142]],\n",
       " \n",
       "        [[233, 125, 148],\n",
       "         [231, 123, 146],\n",
       "         [234, 124, 147],\n",
       "         ...,\n",
       "         [163, 116, 145],\n",
       "         [157, 105, 148],\n",
       "         [150,  98, 141]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[124,  28,  76],\n",
       "         [128,  32,  80],\n",
       "         [137,  41,  89],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]],\n",
       " \n",
       "        [[128,  34,  77],\n",
       "         [131,  37,  80],\n",
       "         [138,  43,  88],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]],\n",
       " \n",
       "        [[132,  38,  81],\n",
       "         [137,  43,  86],\n",
       "         [142,  47,  92],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5446999968844466, 'inference': 23.39380000194069, 'postprocess': 2.754799999820534},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[235, 125, 148],\n",
       "         [233, 123, 146],\n",
       "         [235, 122, 146],\n",
       "         ...,\n",
       "         [164, 117, 146],\n",
       "         [160, 108, 151],\n",
       "         [153, 101, 144]],\n",
       " \n",
       "        [[235, 125, 148],\n",
       "         [233, 123, 146],\n",
       "         [235, 122, 146],\n",
       "         ...,\n",
       "         [164, 117, 146],\n",
       "         [158, 106, 149],\n",
       "         [151,  99, 142]],\n",
       " \n",
       "        [[233, 125, 148],\n",
       "         [231, 123, 146],\n",
       "         [234, 124, 147],\n",
       "         ...,\n",
       "         [163, 116, 145],\n",
       "         [157, 105, 148],\n",
       "         [150,  98, 141]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[124,  28,  76],\n",
       "         [128,  32,  80],\n",
       "         [137,  41,  89],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]],\n",
       " \n",
       "        [[128,  34,  77],\n",
       "         [131,  37,  80],\n",
       "         [138,  43,  88],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]],\n",
       " \n",
       "        [[132,  38,  81],\n",
       "         [137,  43,  86],\n",
       "         [142,  47,  92],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.597599999513477, 'inference': 23.189899999124464, 'postprocess': 2.1502000017790124},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[180,  28,  71],\n",
       "         [180,  28,  71],\n",
       "         [183,  26,  70],\n",
       "         ...,\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157]],\n",
       " \n",
       "        [[183,  31,  74],\n",
       "         [181,  29,  72],\n",
       "         [184,  27,  71],\n",
       "         ...,\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157]],\n",
       " \n",
       "        [[190,  44,  86],\n",
       "         [187,  41,  83],\n",
       "         [188,  36,  79],\n",
       "         ...,\n",
       "         [134,  83, 158],\n",
       "         [134,  83, 158],\n",
       "         [134,  83, 158]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[167,  75, 136],\n",
       "         [167,  75, 136],\n",
       "         [166,  75, 134],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[171,  79, 128],\n",
       "         [171,  79, 128],\n",
       "         [170,  79, 126],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]],\n",
       " \n",
       "        [[171,  79, 128],\n",
       "         [171,  79, 128],\n",
       "         [171,  80, 127],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.28489999769954, 'inference': 23.15420000377344, 'postprocess': 3.952200000640005},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[180,  28,  71],\n",
       "         [180,  28,  71],\n",
       "         [183,  26,  70],\n",
       "         ...,\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157]],\n",
       " \n",
       "        [[183,  31,  74],\n",
       "         [181,  29,  72],\n",
       "         [184,  27,  71],\n",
       "         ...,\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157]],\n",
       " \n",
       "        [[190,  44,  86],\n",
       "         [187,  41,  83],\n",
       "         [188,  36,  79],\n",
       "         ...,\n",
       "         [134,  83, 158],\n",
       "         [134,  83, 158],\n",
       "         [134,  83, 158]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[167,  75, 136],\n",
       "         [167,  75, 136],\n",
       "         [166,  75, 134],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[171,  79, 128],\n",
       "         [171,  79, 128],\n",
       "         [170,  79, 126],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]],\n",
       " \n",
       "        [[171,  79, 128],\n",
       "         [171,  79, 128],\n",
       "         [171,  80, 127],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6629000019747764, 'inference': 24.369500002649147, 'postprocess': 2.2214999989955686},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[180,  28,  71],\n",
       "         [180,  28,  71],\n",
       "         [183,  26,  70],\n",
       "         ...,\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157]],\n",
       " \n",
       "        [[183,  31,  74],\n",
       "         [181,  29,  72],\n",
       "         [184,  27,  71],\n",
       "         ...,\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157],\n",
       "         [138,  87, 157]],\n",
       " \n",
       "        [[190,  44,  86],\n",
       "         [187,  41,  83],\n",
       "         [188,  36,  79],\n",
       "         ...,\n",
       "         [134,  83, 158],\n",
       "         [134,  83, 158],\n",
       "         [134,  83, 158]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[167,  75, 136],\n",
       "         [167,  75, 136],\n",
       "         [166,  75, 134],\n",
       "         ...,\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1],\n",
       "         [ 31,   0,   1]],\n",
       " \n",
       "        [[171,  79, 128],\n",
       "         [171,  79, 128],\n",
       "         [170,  79, 126],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]],\n",
       " \n",
       "        [[171,  79, 128],\n",
       "         [171,  79, 128],\n",
       "         [171,  80, 127],\n",
       "         ...,\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1],\n",
       "         [ 33,   0,   1]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3207999945734628, 'inference': 23.24469999439316, 'postprocess': 2.0479000013438053},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[232,   0,  58],\n",
       "         [235,   0,  61],\n",
       "         [236,   0,  66],\n",
       "         ...,\n",
       "         [133,  92, 124],\n",
       "         [130,  90, 118],\n",
       "         [130,  90, 118]],\n",
       " \n",
       "        [[232,   0,  58],\n",
       "         [235,   0,  61],\n",
       "         [236,   0,  66],\n",
       "         ...,\n",
       "         [133,  92, 124],\n",
       "         [130,  90, 118],\n",
       "         [130,  90, 118]],\n",
       " \n",
       "        [[227,   0,  57],\n",
       "         [229,   0,  59],\n",
       "         [228,   0,  64],\n",
       "         ...,\n",
       "         [127,  90, 124],\n",
       "         [125,  89, 120],\n",
       "         [125,  89, 120]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[174,  74, 134],\n",
       "         [173,  73, 133],\n",
       "         [176,  73, 129],\n",
       "         ...,\n",
       "         [ 27,   5,   9],\n",
       "         [ 28,   6,  10],\n",
       "         [ 29,   7,  11]],\n",
       " \n",
       "        [[177,  77, 128],\n",
       "         [176,  76, 127],\n",
       "         [179,  77, 123],\n",
       "         ...,\n",
       "         [ 26,   2,   6],\n",
       "         [ 28,   4,   8],\n",
       "         [ 29,   5,   9]],\n",
       " \n",
       "        [[177,  77, 128],\n",
       "         [177,  77, 128],\n",
       "         [184,  82, 128],\n",
       "         ...,\n",
       "         [ 25,   1,   5],\n",
       "         [ 26,   2,   6],\n",
       "         [ 26,   2,   6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.618199996300973, 'inference': 23.256500004208647, 'postprocess': 2.167799997550901},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[232,   0,  58],\n",
       "         [235,   0,  61],\n",
       "         [234,   0,  64],\n",
       "         ...,\n",
       "         [133,  92, 124],\n",
       "         [130,  90, 118],\n",
       "         [130,  90, 118]],\n",
       " \n",
       "        [[232,   0,  58],\n",
       "         [235,   0,  61],\n",
       "         [234,   0,  64],\n",
       "         ...,\n",
       "         [133,  92, 124],\n",
       "         [130,  90, 118],\n",
       "         [130,  90, 118]],\n",
       " \n",
       "        [[227,   0,  57],\n",
       "         [229,   0,  59],\n",
       "         [229,   0,  63],\n",
       "         ...,\n",
       "         [127,  90, 124],\n",
       "         [125,  89, 120],\n",
       "         [125,  89, 120]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[174,  74, 134],\n",
       "         [173,  73, 133],\n",
       "         [176,  73, 129],\n",
       "         ...,\n",
       "         [ 27,   5,   9],\n",
       "         [ 28,   6,  10],\n",
       "         [ 29,   7,  11]],\n",
       " \n",
       "        [[177,  77, 128],\n",
       "         [176,  76, 127],\n",
       "         [179,  77, 123],\n",
       "         ...,\n",
       "         [ 26,   2,   6],\n",
       "         [ 28,   4,   8],\n",
       "         [ 29,   5,   9]],\n",
       " \n",
       "        [[177,  77, 128],\n",
       "         [177,  77, 128],\n",
       "         [184,  82, 128],\n",
       "         ...,\n",
       "         [ 25,   1,   5],\n",
       "         [ 26,   2,   6],\n",
       "         [ 26,   2,   6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5516999992541969, 'inference': 22.894499998074025, 'postprocess': 2.001699998800177},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114]],\n",
       " \n",
       "        [[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114]],\n",
       " \n",
       "        [[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [126,  88, 117],\n",
       "         [126,  88, 117],\n",
       "         [126,  88, 117]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[175,  60,  97],\n",
       "         [172,  57,  94],\n",
       "         [171,  56,  93],\n",
       "         ...,\n",
       "         [180, 168, 168],\n",
       "         [185, 173, 173],\n",
       "         [189, 177, 177]],\n",
       " \n",
       "        [[175,  60,  97],\n",
       "         [172,  57,  94],\n",
       "         [171,  56,  93],\n",
       "         ...,\n",
       "         [164, 152, 152],\n",
       "         [176, 164, 164],\n",
       "         [178, 166, 166]],\n",
       " \n",
       "        [[175,  60,  97],\n",
       "         [172,  57,  94],\n",
       "         [171,  56,  93],\n",
       "         ...,\n",
       "         [135, 123, 123],\n",
       "         [160, 148, 148],\n",
       "         [171, 159, 159]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5069000000949018, 'inference': 23.08360000461107, 'postprocess': 2.9857000045012683},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114]],\n",
       " \n",
       "        [[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114]],\n",
       " \n",
       "        [[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [126,  88, 117],\n",
       "         [126,  88, 117],\n",
       "         [126,  88, 117]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[177,  59,  97],\n",
       "         [174,  56,  94],\n",
       "         [173,  55,  93],\n",
       "         ...,\n",
       "         [181, 169, 169],\n",
       "         [184, 172, 172],\n",
       "         [188, 176, 176]],\n",
       " \n",
       "        [[177,  59,  97],\n",
       "         [174,  56,  94],\n",
       "         [173,  55,  93],\n",
       "         ...,\n",
       "         [166, 154, 154],\n",
       "         [175, 163, 163],\n",
       "         [177, 165, 165]],\n",
       " \n",
       "        [[177,  59,  97],\n",
       "         [174,  56,  94],\n",
       "         [173,  55,  93],\n",
       "         ...,\n",
       "         [136, 124, 124],\n",
       "         [159, 147, 147],\n",
       "         [170, 158, 158]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.714199999696575, 'inference': 23.636600002646446, 'postprocess': 2.249400000437163},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114]],\n",
       " \n",
       "        [[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114],\n",
       "         [130,  89, 114]],\n",
       " \n",
       "        [[190,  48, 104],\n",
       "         [190,  48, 104],\n",
       "         [189,  51, 108],\n",
       "         ...,\n",
       "         [126,  88, 117],\n",
       "         [126,  88, 117],\n",
       "         [126,  88, 117]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[177,  59,  97],\n",
       "         [174,  56,  94],\n",
       "         [173,  55,  93],\n",
       "         ...,\n",
       "         [181, 169, 169],\n",
       "         [184, 172, 172],\n",
       "         [188, 176, 176]],\n",
       " \n",
       "        [[177,  59,  97],\n",
       "         [174,  56,  94],\n",
       "         [173,  55,  93],\n",
       "         ...,\n",
       "         [166, 154, 154],\n",
       "         [175, 163, 163],\n",
       "         [177, 165, 165]],\n",
       " \n",
       "        [[177,  59,  97],\n",
       "         [174,  56,  94],\n",
       "         [173,  55,  93],\n",
       "         ...,\n",
       "         [136, 124, 124],\n",
       "         [159, 147, 147],\n",
       "         [170, 158, 158]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.535100003820844, 'inference': 22.95369999774266, 'postprocess': 1.9427000006544404},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[207,  68, 128],\n",
       "         [208,  69, 129],\n",
       "         [208,  69, 129],\n",
       "         ...,\n",
       "         [130,  88, 116],\n",
       "         [130,  88, 116],\n",
       "         [130,  88, 116]],\n",
       " \n",
       "        [[207,  68, 128],\n",
       "         [208,  69, 129],\n",
       "         [208,  69, 129],\n",
       "         ...,\n",
       "         [130,  88, 116],\n",
       "         [130,  88, 116],\n",
       "         [130,  88, 116]],\n",
       " \n",
       "        [[208,  67, 127],\n",
       "         [209,  68, 128],\n",
       "         [209,  68, 128],\n",
       "         ...,\n",
       "         [130,  90, 113],\n",
       "         [130,  90, 113],\n",
       "         [130,  90, 113]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[184,  61,  93],\n",
       "         [185,  62,  94],\n",
       "         [187,  62,  94],\n",
       "         ...,\n",
       "         [191, 183, 183],\n",
       "         [191, 183, 183],\n",
       "         [191, 183, 183]],\n",
       " \n",
       "        [[185,  62,  94],\n",
       "         [185,  62,  94],\n",
       "         [189,  62,  94],\n",
       "         ...,\n",
       "         [189, 181, 181],\n",
       "         [189, 181, 181],\n",
       "         [189, 181, 181]],\n",
       " \n",
       "        [[185,  62,  94],\n",
       "         [186,  63,  95],\n",
       "         [190,  63,  95],\n",
       "         ...,\n",
       "         [189, 181, 181],\n",
       "         [189, 181, 181],\n",
       "         [189, 181, 181]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 6.197100003191736, 'inference': 26.378100003057625, 'postprocess': 4.730200002086349},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[207,  68, 128],\n",
       "         [208,  69, 129],\n",
       "         [208,  69, 129],\n",
       "         ...,\n",
       "         [130,  88, 116],\n",
       "         [130,  88, 116],\n",
       "         [130,  88, 116]],\n",
       " \n",
       "        [[207,  68, 128],\n",
       "         [208,  69, 129],\n",
       "         [208,  69, 129],\n",
       "         ...,\n",
       "         [130,  88, 116],\n",
       "         [130,  88, 116],\n",
       "         [130,  88, 116]],\n",
       " \n",
       "        [[208,  67, 127],\n",
       "         [209,  68, 128],\n",
       "         [209,  68, 128],\n",
       "         ...,\n",
       "         [130,  90, 113],\n",
       "         [130,  90, 113],\n",
       "         [130,  90, 113]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[184,  61,  93],\n",
       "         [185,  62,  94],\n",
       "         [187,  62,  94],\n",
       "         ...,\n",
       "         [191, 183, 183],\n",
       "         [191, 183, 183],\n",
       "         [191, 183, 183]],\n",
       " \n",
       "        [[185,  62,  94],\n",
       "         [185,  62,  94],\n",
       "         [189,  62,  94],\n",
       "         ...,\n",
       "         [189, 181, 181],\n",
       "         [189, 181, 181],\n",
       "         [189, 181, 181]],\n",
       " \n",
       "        [[185,  62,  94],\n",
       "         [186,  63,  95],\n",
       "         [190,  63,  95],\n",
       "         ...,\n",
       "         [189, 181, 181],\n",
       "         [189, 181, 181],\n",
       "         [189, 181, 181]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.02980000176467, 'inference': 34.39730000536656, 'postprocess': 4.791700004716404},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         ...,\n",
       "         [121,  84, 104],\n",
       "         [121,  84, 104],\n",
       "         [120,  83, 103]],\n",
       " \n",
       "        [[218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         ...,\n",
       "         [121,  84, 104],\n",
       "         [121,  84, 104],\n",
       "         [120,  83, 103]],\n",
       " \n",
       "        [[218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         ...,\n",
       "         [121,  84, 104],\n",
       "         [121,  84, 104],\n",
       "         [120,  83, 103]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[208,  71, 107],\n",
       "         [208,  71, 107],\n",
       "         [212,  73, 109],\n",
       "         ...,\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185]],\n",
       " \n",
       "        [[214,  77, 113],\n",
       "         [215,  78, 114],\n",
       "         [217,  80, 116],\n",
       "         ...,\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185]],\n",
       " \n",
       "        [[215,  78, 114],\n",
       "         [220,  83, 119],\n",
       "         [222,  85, 121],\n",
       "         ...,\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.53800000064075, 'inference': 34.263300003658514, 'postprocess': 7.357499998761341},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         ...,\n",
       "         [121,  84, 104],\n",
       "         [121,  84, 104],\n",
       "         [120,  83, 103]],\n",
       " \n",
       "        [[218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         ...,\n",
       "         [121,  84, 104],\n",
       "         [121,  84, 104],\n",
       "         [120,  83, 103]],\n",
       " \n",
       "        [[218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         [218,  93, 141],\n",
       "         ...,\n",
       "         [121,  84, 104],\n",
       "         [121,  84, 104],\n",
       "         [120,  83, 103]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[208,  71, 107],\n",
       "         [208,  71, 107],\n",
       "         [212,  73, 109],\n",
       "         ...,\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185]],\n",
       " \n",
       "        [[214,  77, 113],\n",
       "         [215,  78, 114],\n",
       "         [217,  80, 116],\n",
       "         ...,\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185]],\n",
       " \n",
       "        [[215,  78, 114],\n",
       "         [220,  83, 119],\n",
       "         [222,  85, 121],\n",
       "         ...,\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185],\n",
       "         [193, 185, 185]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7539000036776997, 'inference': 25.000900001032278, 'postprocess': 2.134700000169687},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[211,  93, 140],\n",
       "         [211,  93, 140],\n",
       "         [211,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        [[211,  93, 140],\n",
       "         [211,  93, 140],\n",
       "         [211,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        [[209,  93, 140],\n",
       "         [209,  93, 140],\n",
       "         [209,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[225,  90, 126],\n",
       "         [226,  91, 127],\n",
       "         [229,  94, 128],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]],\n",
       " \n",
       "        [[225,  93, 128],\n",
       "         [227,  95, 130],\n",
       "         [225,  98, 130],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]],\n",
       " \n",
       "        [[227,  95, 130],\n",
       "         [228,  96, 131],\n",
       "         [225,  98, 130],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2943000003579073, 'inference': 35.18629999598488, 'postprocess': 2.594500001578126},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[211,  93, 140],\n",
       "         [211,  93, 140],\n",
       "         [211,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        [[211,  93, 140],\n",
       "         [211,  93, 140],\n",
       "         [211,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        [[209,  93, 140],\n",
       "         [209,  93, 140],\n",
       "         [209,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[225,  90, 126],\n",
       "         [226,  91, 127],\n",
       "         [229,  94, 128],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]],\n",
       " \n",
       "        [[225,  93, 128],\n",
       "         [227,  95, 130],\n",
       "         [225,  98, 130],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]],\n",
       " \n",
       "        [[227,  95, 130],\n",
       "         [228,  96, 131],\n",
       "         [225,  98, 130],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.428999996278435, 'inference': 22.868499996548053, 'postprocess': 2.0081999973626807},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[211,  93, 140],\n",
       "         [211,  93, 140],\n",
       "         [211,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        [[211,  93, 140],\n",
       "         [211,  93, 140],\n",
       "         [211,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        [[209,  93, 140],\n",
       "         [209,  93, 140],\n",
       "         [209,  92, 141],\n",
       "         ...,\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103],\n",
       "         [124,  83, 103]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[225,  90, 126],\n",
       "         [226,  91, 127],\n",
       "         [229,  94, 128],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]],\n",
       " \n",
       "        [[225,  93, 128],\n",
       "         [227,  95, 130],\n",
       "         [225,  98, 130],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]],\n",
       " \n",
       "        [[227,  95, 130],\n",
       "         [228,  96, 131],\n",
       "         [225,  98, 130],\n",
       "         ...,\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187],\n",
       "         [193, 188, 187]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6842000040924177, 'inference': 23.344100001850165, 'postprocess': 6.197700000484474},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[214,  52, 124],\n",
       "         [195,  33, 105],\n",
       "         [204,   5,  86],\n",
       "         ...,\n",
       "         [124,  82, 105],\n",
       "         [124,  82, 105],\n",
       "         [124,  82, 105]],\n",
       " \n",
       "        [[214,  52, 124],\n",
       "         [195,  33, 105],\n",
       "         [204,   5,  86],\n",
       "         ...,\n",
       "         [124,  82, 105],\n",
       "         [124,  82, 105],\n",
       "         [124,  82, 105]],\n",
       " \n",
       "        [[215,  53, 125],\n",
       "         [196,  34, 106],\n",
       "         [205,   6,  87],\n",
       "         ...,\n",
       "         [122,  81, 106],\n",
       "         [122,  81, 106],\n",
       "         [122,  81, 106]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[226, 100, 130],\n",
       "         [226, 100, 130],\n",
       "         [225, 101, 131],\n",
       "         ...,\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187]],\n",
       " \n",
       "        [[227, 101, 131],\n",
       "         [227, 101, 131],\n",
       "         [223, 101, 131],\n",
       "         ...,\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187]],\n",
       " \n",
       "        [[227, 101, 131],\n",
       "         [227, 101, 131],\n",
       "         [223, 101, 131],\n",
       "         ...,\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6093000012915581, 'inference': 31.141400002525188, 'postprocess': 4.469100000278559},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[214,  52, 124],\n",
       "         [195,  33, 105],\n",
       "         [204,   5,  86],\n",
       "         ...,\n",
       "         [124,  82, 105],\n",
       "         [124,  82, 105],\n",
       "         [124,  82, 105]],\n",
       " \n",
       "        [[214,  52, 124],\n",
       "         [195,  33, 105],\n",
       "         [204,   5,  86],\n",
       "         ...,\n",
       "         [124,  82, 105],\n",
       "         [124,  82, 105],\n",
       "         [124,  82, 105]],\n",
       " \n",
       "        [[215,  53, 125],\n",
       "         [196,  34, 106],\n",
       "         [205,   6,  87],\n",
       "         ...,\n",
       "         [122,  81, 106],\n",
       "         [122,  81, 106],\n",
       "         [122,  81, 106]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[226, 100, 130],\n",
       "         [226, 100, 130],\n",
       "         [225, 101, 131],\n",
       "         ...,\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187]],\n",
       " \n",
       "        [[227, 101, 131],\n",
       "         [227, 101, 131],\n",
       "         [223, 101, 131],\n",
       "         ...,\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187]],\n",
       " \n",
       "        [[227, 101, 131],\n",
       "         [227, 101, 131],\n",
       "         [223, 101, 131],\n",
       "         ...,\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187],\n",
       "         [195, 187, 187]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7214999970747158, 'inference': 26.240300001518335, 'postprocess': 2.0740999971167184},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  49, 113],\n",
       "         ...,\n",
       "         [126,  82, 110],\n",
       "         [130,  86, 114],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        [[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  49, 113],\n",
       "         ...,\n",
       "         [125,  81, 109],\n",
       "         [128,  84, 112],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        [[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  50, 112],\n",
       "         ...,\n",
       "         [125,  81, 109],\n",
       "         [128,  84, 112],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[221, 103, 129],\n",
       "         [221, 103, 129],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [208, 200, 200],\n",
       "         [212, 204, 204],\n",
       "         [213, 205, 205]],\n",
       " \n",
       "        [[221, 103, 129],\n",
       "         [222, 104, 130],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [202, 194, 194],\n",
       "         [205, 197, 197],\n",
       "         [208, 200, 200]],\n",
       " \n",
       "        [[222, 104, 130],\n",
       "         [222, 104, 130],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [199, 191, 191],\n",
       "         [200, 192, 192],\n",
       "         [202, 194, 194]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.659299996390473, 'inference': 24.721299996599555, 'postprocess': 3.7195999975665472},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  49, 113],\n",
       "         ...,\n",
       "         [126,  82, 110],\n",
       "         [130,  86, 114],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        [[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  49, 113],\n",
       "         ...,\n",
       "         [125,  81, 109],\n",
       "         [128,  84, 112],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        [[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  50, 112],\n",
       "         ...,\n",
       "         [125,  81, 109],\n",
       "         [128,  84, 112],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[221, 103, 129],\n",
       "         [221, 103, 129],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [208, 200, 200],\n",
       "         [212, 204, 204],\n",
       "         [213, 205, 205]],\n",
       " \n",
       "        [[221, 103, 129],\n",
       "         [222, 104, 130],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [202, 194, 194],\n",
       "         [205, 197, 197],\n",
       "         [208, 200, 200]],\n",
       " \n",
       "        [[222, 104, 130],\n",
       "         [222, 104, 130],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [199, 191, 191],\n",
       "         [200, 192, 192],\n",
       "         [202, 194, 194]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.474299995810725, 'inference': 23.12789999996312, 'postprocess': 3.5003000011784025},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  49, 113],\n",
       "         ...,\n",
       "         [126,  82, 110],\n",
       "         [130,  86, 114],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        [[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  49, 113],\n",
       "         ...,\n",
       "         [125,  81, 109],\n",
       "         [128,  84, 112],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        [[240,  50, 120],\n",
       "         [240,  50, 120],\n",
       "         [231,  50, 112],\n",
       "         ...,\n",
       "         [125,  81, 109],\n",
       "         [128,  84, 112],\n",
       "         [131,  87, 115]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[221, 103, 129],\n",
       "         [221, 103, 129],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [208, 200, 200],\n",
       "         [212, 204, 204],\n",
       "         [213, 205, 205]],\n",
       " \n",
       "        [[221, 103, 129],\n",
       "         [222, 104, 130],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [202, 194, 194],\n",
       "         [205, 197, 197],\n",
       "         [208, 200, 200]],\n",
       " \n",
       "        [[222, 104, 130],\n",
       "         [222, 104, 130],\n",
       "         [220, 104, 130],\n",
       "         ...,\n",
       "         [199, 191, 191],\n",
       "         [200, 192, 192],\n",
       "         [202, 194, 194]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0893000037176535, 'inference': 31.433299998752773, 'postprocess': 5.50669999938691},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         [231,  58, 109],\n",
       "         ...,\n",
       "         [119,  70, 152],\n",
       "         [117,  69, 155],\n",
       "         [117,  69, 155]],\n",
       " \n",
       "        [[230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         [231,  58, 109],\n",
       "         ...,\n",
       "         [119,  70, 152],\n",
       "         [117,  69, 155],\n",
       "         [117,  69, 155]],\n",
       " \n",
       "        [[230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         [231,  58, 109],\n",
       "         ...,\n",
       "         [119,  70, 152],\n",
       "         [117,  69, 155],\n",
       "         [117,  69, 155]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[219, 102, 131],\n",
       "         [219, 102, 131],\n",
       "         [218, 103, 132],\n",
       "         ...,\n",
       "         [208, 200, 200],\n",
       "         [208, 200, 200],\n",
       "         [208, 200, 200]],\n",
       " \n",
       "        [[219, 102, 131],\n",
       "         [220, 103, 132],\n",
       "         [218, 103, 132],\n",
       "         ...,\n",
       "         [209, 201, 201],\n",
       "         [209, 201, 201],\n",
       "         [209, 201, 201]],\n",
       " \n",
       "        [[220, 103, 132],\n",
       "         [220, 103, 132],\n",
       "         [218, 103, 132],\n",
       "         ...,\n",
       "         [210, 202, 202],\n",
       "         [210, 202, 202],\n",
       "         [210, 202, 202]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.953000006324146, 'inference': 23.012900004687253, 'postprocess': 5.80719999561552},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         ...,\n",
       "         [119,  70, 152],\n",
       "         [117,  69, 155],\n",
       "         [117,  69, 155]],\n",
       " \n",
       "        [[230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         ...,\n",
       "         [119,  70, 152],\n",
       "         [117,  69, 155],\n",
       "         [117,  69, 155]],\n",
       " \n",
       "        [[230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         [230,  57, 108],\n",
       "         ...,\n",
       "         [119,  70, 152],\n",
       "         [117,  69, 155],\n",
       "         [117,  69, 155]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[219, 102, 131],\n",
       "         [219, 102, 131],\n",
       "         [218, 103, 132],\n",
       "         ...,\n",
       "         [208, 200, 200],\n",
       "         [208, 200, 200],\n",
       "         [208, 200, 200]],\n",
       " \n",
       "        [[219, 102, 131],\n",
       "         [220, 103, 132],\n",
       "         [218, 103, 132],\n",
       "         ...,\n",
       "         [209, 201, 201],\n",
       "         [209, 201, 201],\n",
       "         [209, 201, 201]],\n",
       " \n",
       "        [[220, 103, 132],\n",
       "         [220, 103, 132],\n",
       "         [218, 103, 132],\n",
       "         ...,\n",
       "         [210, 202, 202],\n",
       "         [210, 202, 202],\n",
       "         [210, 202, 202]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3220000037108548, 'inference': 22.998899999947753, 'postprocess': 2.055300006759353},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         ...,\n",
       "         [117,  20, 110],\n",
       "         [123,   7,  86],\n",
       "         [111,   0,  74]],\n",
       " \n",
       "        [[230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         ...,\n",
       "         [117,  20, 110],\n",
       "         [123,   7,  86],\n",
       "         [111,   0,  74]],\n",
       " \n",
       "        [[230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         ...,\n",
       "         [116,  19, 109],\n",
       "         [123,   7,  86],\n",
       "         [111,   0,  74]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         ...,\n",
       "         [191, 192, 197],\n",
       "         [191, 192, 197],\n",
       "         [191, 192, 197]],\n",
       " \n",
       "        [[214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         ...,\n",
       "         [192, 193, 198],\n",
       "         [192, 193, 198],\n",
       "         [192, 193, 198]],\n",
       " \n",
       "        [[214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         ...,\n",
       "         [193, 194, 199],\n",
       "         [193, 194, 199],\n",
       "         [193, 194, 199]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.229499997862149, 'inference': 22.906999998667743, 'postprocess': 2.1599999963655137},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         ...,\n",
       "         [117,  20, 110],\n",
       "         [123,   7,  86],\n",
       "         [111,   0,  74]],\n",
       " \n",
       "        [[230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         ...,\n",
       "         [117,  20, 110],\n",
       "         [123,   7,  86],\n",
       "         [111,   0,  74]],\n",
       " \n",
       "        [[230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         [230,  73, 112],\n",
       "         ...,\n",
       "         [116,  19, 109],\n",
       "         [123,   7,  86],\n",
       "         [111,   0,  74]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         ...,\n",
       "         [191, 192, 197],\n",
       "         [191, 192, 197],\n",
       "         [191, 192, 197]],\n",
       " \n",
       "        [[214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         ...,\n",
       "         [192, 193, 198],\n",
       "         [192, 193, 198],\n",
       "         [192, 193, 198]],\n",
       " \n",
       "        [[214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         [214, 104, 132],\n",
       "         ...,\n",
       "         [193, 194, 199],\n",
       "         [193, 194, 199],\n",
       "         [193, 194, 199]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.444699999410659, 'inference': 23.35029999812832, 'postprocess': 4.986600004485808},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [102,  79, 133],\n",
       "         [116,  93, 147],\n",
       "         [129, 106, 160]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [106,  83, 137],\n",
       "         [120,  97, 151],\n",
       "         [132, 109, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [112,  90, 139],\n",
       "         [122, 100, 149],\n",
       "         [134, 112, 161]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 22,   3,  11],\n",
       "         [ 22,   3,  11],\n",
       "         [ 20,   1,   9],\n",
       "         ...,\n",
       "         [ 50,  15,  23],\n",
       "         [ 50,  15,  23],\n",
       "         [ 50,  15,  23]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3102000011713244, 'inference': 23.4165999936522, 'postprocess': 3.2796000014059246},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [102,  79, 133],\n",
       "         [116,  93, 147],\n",
       "         [129, 106, 160]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [106,  83, 137],\n",
       "         [120,  97, 151],\n",
       "         [132, 109, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [112,  90, 139],\n",
       "         [122, 100, 149],\n",
       "         [134, 112, 161]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 22,   3,  11],\n",
       "         ...,\n",
       "         [ 50,  15,  23],\n",
       "         [ 50,  15,  23],\n",
       "         [ 50,  15,  23]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3000999970245175, 'inference': 23.494500004744623, 'postprocess': 2.259000000776723},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [102,  79, 133],\n",
       "         [116,  93, 147],\n",
       "         [129, 106, 160]],\n",
       " \n",
       "        [[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [106,  83, 137],\n",
       "         [120,  97, 151],\n",
       "         [132, 109, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [112,  90, 139],\n",
       "         [122, 100, 149],\n",
       "         [134, 112, 161]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 22,   3,  11],\n",
       "         ...,\n",
       "         [ 50,  15,  23],\n",
       "         [ 50,  15,  23],\n",
       "         [ 50,  15,  23]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 22,   3,  11],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5585000001010485, 'inference': 23.53929999662796, 'postprocess': 2.951399997982662},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [112,  89, 141],\n",
       "         [127, 104, 156],\n",
       "         [133, 110, 162]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [115,  92, 144],\n",
       "         [129, 106, 158],\n",
       "         [135, 112, 164]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [123, 102, 149],\n",
       "         [134, 113, 160],\n",
       "         [141, 120, 167]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 45,  10,  18],\n",
       "         [ 45,  10,  18],\n",
       "         [ 44,   9,  17]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 45,  10,  18],\n",
       "         [ 45,  10,  18],\n",
       "         [ 45,  10,  18]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 46,  11,  19],\n",
       "         [ 45,  10,  18],\n",
       "         [ 45,  10,  18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9459000031929463, 'inference': 23.555200001283083, 'postprocess': 3.073600004427135},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [112,  89, 141],\n",
       "         [127, 104, 156],\n",
       "         [133, 110, 162]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [115,  92, 144],\n",
       "         [129, 106, 158],\n",
       "         [135, 112, 164]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [123, 102, 149],\n",
       "         [134, 113, 160],\n",
       "         [141, 120, 167]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 44,   9,  17],\n",
       "         [ 43,   8,  16],\n",
       "         [ 43,   8,  16]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 45,  10,  18],\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3655000002472661, 'inference': 23.392300005070865, 'postprocess': 2.1333000040613115},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [116,  95, 149],\n",
       "         [128, 107, 161],\n",
       "         [132, 111, 165]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [120,  99, 153],\n",
       "         [131, 110, 164],\n",
       "         [137, 116, 170]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [130, 111, 158],\n",
       "         [139, 120, 167],\n",
       "         [141, 122, 169]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 45,  10,  18],\n",
       "         [ 45,  10,  18],\n",
       "         [ 45,  10,  18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4775999952689745, 'inference': 23.384799998893868, 'postprocess': 4.6236999987741},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [116,  95, 149],\n",
       "         [128, 107, 161],\n",
       "         [132, 111, 165]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [120,  99, 153],\n",
       "         [131, 110, 164],\n",
       "         [137, 116, 170]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [130, 111, 158],\n",
       "         [139, 120, 167],\n",
       "         [141, 122, 169]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17]],\n",
       " \n",
       "        [[ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17],\n",
       "         [ 44,   9,  17]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 45,  10,  18],\n",
       "         [ 45,  10,  18],\n",
       "         [ 45,  10,  18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7038000005413778, 'inference': 23.458600000594743, 'postprocess': 2.184800003306009},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [141, 117, 165],\n",
       "         [146, 122, 170],\n",
       "         [148, 124, 172]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [144, 120, 168],\n",
       "         [151, 127, 175],\n",
       "         [152, 128, 176]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [152, 130, 173],\n",
       "         [157, 135, 178],\n",
       "         [158, 136, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 46,  11,  19],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9059000042034313, 'inference': 31.208100001094863, 'postprocess': 3.7420000007841736},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [141, 117, 165],\n",
       "         [146, 122, 170],\n",
       "         [148, 124, 172]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [144, 120, 168],\n",
       "         [151, 127, 175],\n",
       "         [152, 128, 176]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [152, 130, 173],\n",
       "         [157, 135, 178],\n",
       "         [158, 136, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 46,  11,  19],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7293999990215525, 'inference': 23.24650000082329, 'postprocess': 2.074500000162516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [139, 113, 166],\n",
       "         [148, 123, 173],\n",
       "         [149, 124, 174]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [144, 118, 171],\n",
       "         [151, 126, 176],\n",
       "         [153, 128, 178]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [152, 128, 176],\n",
       "         [156, 133, 178],\n",
       "         [158, 135, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 46,  11,  19],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20],\n",
       "         [ 47,  12,  20]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21],\n",
       "         [ 48,  13,  21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4031999962753616, 'inference': 23.3455000052345, 'postprocess': 2.115299997967668},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [148, 122, 177],\n",
       "         [150, 126, 174],\n",
       "         [150, 126, 174]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [150, 124, 179],\n",
       "         [153, 129, 177],\n",
       "         [153, 129, 177]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [153, 128, 178],\n",
       "         [157, 135, 178],\n",
       "         [157, 135, 178]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 25,   6,  14],\n",
       "         [ 25,   6,  14],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 53,  18,  26],\n",
       "         [ 67,  32,  40],\n",
       "         [ 78,  43,  51]],\n",
       " \n",
       "        [[ 25,   6,  14],\n",
       "         [ 25,   6,  14],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 53,  18,  26],\n",
       "         [ 67,  32,  40],\n",
       "         [ 78,  43,  51]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 53,  18,  26],\n",
       "         [ 67,  32,  40],\n",
       "         [ 78,  43,  51]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4224000042304397, 'inference': 23.494199995184317, 'postprocess': 3.686199997900985},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [148, 122, 177],\n",
       "         [150, 126, 174],\n",
       "         [150, 126, 174]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [150, 124, 179],\n",
       "         [153, 129, 177],\n",
       "         [153, 129, 177]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [153, 128, 178],\n",
       "         [157, 135, 178],\n",
       "         [157, 135, 178]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 25,   6,  14],\n",
       "         [ 25,   6,  14],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 53,  18,  26],\n",
       "         [ 67,  32,  40],\n",
       "         [ 78,  43,  51]],\n",
       " \n",
       "        [[ 25,   6,  14],\n",
       "         [ 25,   6,  14],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 53,  18,  26],\n",
       "         [ 67,  32,  40],\n",
       "         [ 78,  43,  51]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         ...,\n",
       "         [ 53,  18,  26],\n",
       "         [ 67,  32,  40],\n",
       "         [ 78,  43,  51]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4584000018658116, 'inference': 23.310199998377357, 'postprocess': 2.010399999562651},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [150, 129, 167],\n",
       "         [150, 132, 163],\n",
       "         [150, 132, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [153, 132, 170],\n",
       "         [153, 135, 166],\n",
       "         [153, 135, 166]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [157, 138, 171],\n",
       "         [157, 140, 166],\n",
       "         [157, 140, 166]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 25,   6,  14],\n",
       "         [ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9437999944784679, 'inference': 24.473600002238527, 'postprocess': 1.985499999136664},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [150, 129, 167],\n",
       "         [150, 132, 163],\n",
       "         [150, 132, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [153, 132, 170],\n",
       "         [153, 135, 166],\n",
       "         [153, 135, 166]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [157, 138, 171],\n",
       "         [157, 140, 166],\n",
       "         [157, 140, 166]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 25,   6,  14],\n",
       "         [ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.060200000414625, 'inference': 35.48389999923529, 'postprocess': 3.798999998252839},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [150, 129, 167],\n",
       "         [150, 132, 163],\n",
       "         [150, 132, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [153, 132, 170],\n",
       "         [153, 135, 166],\n",
       "         [153, 135, 166]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [157, 138, 171],\n",
       "         [157, 140, 166],\n",
       "         [157, 140, 166]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 25,   6,  14],\n",
       "         [ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]],\n",
       " \n",
       "        [[ 24,   5,  13],\n",
       "         [ 24,   5,  13],\n",
       "         [ 23,   4,  12],\n",
       "         ...,\n",
       "         [ 76,  42,  46],\n",
       "         [ 85,  51,  55],\n",
       "         [ 89,  55,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8646999960765243, 'inference': 23.32330000353977, 'postprocess': 2.0182000007480383},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [152, 134, 165],\n",
       "         [152, 135, 163],\n",
       "         [152, 135, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [156, 138, 169],\n",
       "         [156, 139, 167],\n",
       "         [156, 139, 167]],\n",
       " \n",
       "        [[ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         ...,\n",
       "         [160, 143, 169],\n",
       "         [160, 144, 168],\n",
       "         [160, 144, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 26,   4,  13],\n",
       "         [ 25,   3,  12],\n",
       "         [ 25,   3,  12],\n",
       "         ...,\n",
       "         [ 86,  52,  56],\n",
       "         [ 90,  56,  60],\n",
       "         [ 90,  56,  60]],\n",
       " \n",
       "        [[ 25,   3,  12],\n",
       "         [ 25,   3,  12],\n",
       "         [ 24,   2,  11],\n",
       "         ...,\n",
       "         [ 86,  52,  56],\n",
       "         [ 90,  56,  60],\n",
       "         [ 90,  56,  60]],\n",
       " \n",
       "        [[ 26,   4,  13],\n",
       "         [ 25,   3,  12],\n",
       "         [ 24,   2,  11],\n",
       "         ...,\n",
       "         [ 86,  52,  56],\n",
       "         [ 89,  55,  59],\n",
       "         [ 89,  55,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6929999983403832, 'inference': 23.457499999494758, 'postprocess': 2.1034000019426458},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [152, 134, 165],\n",
       "         [152, 135, 163],\n",
       "         [152, 135, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [156, 138, 169],\n",
       "         [156, 139, 167],\n",
       "         [156, 139, 167]],\n",
       " \n",
       "        [[ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         ...,\n",
       "         [160, 143, 169],\n",
       "         [160, 144, 168],\n",
       "         [160, 144, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 26,   4,  13],\n",
       "         [ 25,   3,  12],\n",
       "         [ 25,   3,  12],\n",
       "         ...,\n",
       "         [ 86,  52,  56],\n",
       "         [ 90,  56,  60],\n",
       "         [ 90,  56,  60]],\n",
       " \n",
       "        [[ 25,   3,  12],\n",
       "         [ 25,   3,  12],\n",
       "         [ 24,   2,  11],\n",
       "         ...,\n",
       "         [ 86,  52,  56],\n",
       "         [ 90,  56,  60],\n",
       "         [ 90,  56,  60]],\n",
       " \n",
       "        [[ 26,   4,  13],\n",
       "         [ 25,   3,  12],\n",
       "         [ 24,   2,  11],\n",
       "         ...,\n",
       "         [ 86,  52,  56],\n",
       "         [ 89,  55,  59],\n",
       "         [ 89,  55,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6189000016311184, 'inference': 23.542599999927916, 'postprocess': 2.1399000033852644},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [152, 134, 165],\n",
       "         [152, 135, 163],\n",
       "         [152, 135, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [156, 138, 169],\n",
       "         [156, 139, 167],\n",
       "         [156, 139, 167]],\n",
       " \n",
       "        [[ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         ...,\n",
       "         [160, 143, 169],\n",
       "         [160, 144, 168],\n",
       "         [160, 144, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 27,   3,  12],\n",
       "         [ 27,   3,  12],\n",
       "         [ 27,   3,  12],\n",
       "         ...,\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62]],\n",
       " \n",
       "        [[ 27,   3,  12],\n",
       "         [ 27,   3,  12],\n",
       "         [ 24,   0,   9],\n",
       "         ...,\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62]],\n",
       " \n",
       "        [[ 28,   4,  13],\n",
       "         [ 27,   3,  12],\n",
       "         [ 26,   2,  11],\n",
       "         ...,\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6998999999486841, 'inference': 23.13729999877978, 'postprocess': 2.157199996872805},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [152, 134, 165],\n",
       "         [152, 135, 163],\n",
       "         [152, 135, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [156, 138, 169],\n",
       "         [156, 139, 167],\n",
       "         [156, 139, 167]],\n",
       " \n",
       "        [[ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         ...,\n",
       "         [160, 143, 169],\n",
       "         [160, 144, 168],\n",
       "         [160, 144, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 27,   3,  12],\n",
       "         [ 27,   3,  12],\n",
       "         [ 27,   3,  12],\n",
       "         ...,\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62]],\n",
       " \n",
       "        [[ 27,   3,  12],\n",
       "         [ 27,   3,  12],\n",
       "         [ 24,   0,   9],\n",
       "         ...,\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62]],\n",
       " \n",
       "        [[ 28,   4,  13],\n",
       "         [ 27,   3,  12],\n",
       "         [ 26,   2,  11],\n",
       "         ...,\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62],\n",
       "         [ 98,  57,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8608000027597882, 'inference': 24.089200000162236, 'postprocess': 2.057400000921916},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         [101,  79,  94],\n",
       "         ...,\n",
       "         [154, 135, 163],\n",
       "         [154, 135, 163],\n",
       "         [154, 135, 163]],\n",
       " \n",
       "        [[100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         [100,  78,  93],\n",
       "         ...,\n",
       "         [158, 139, 167],\n",
       "         [158, 139, 167],\n",
       "         [158, 139, 167]],\n",
       " \n",
       "        [[ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         [ 99,  77,  92],\n",
       "         ...,\n",
       "         [162, 144, 168],\n",
       "         [162, 144, 168],\n",
       "         [162, 144, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 27,   3,  12],\n",
       "         [ 27,   3,  12],\n",
       "         [ 26,   2,  11],\n",
       "         ...,\n",
       "         [100,  59,  64],\n",
       "         [100,  59,  64],\n",
       "         [100,  59,  64]],\n",
       " \n",
       "        [[ 28,   4,  13],\n",
       "         [ 28,   4,  13],\n",
       "         [ 27,   3,  12],\n",
       "         ...,\n",
       "         [100,  59,  64],\n",
       "         [100,  59,  64],\n",
       "         [100,  59,  64]],\n",
       " \n",
       "        [[ 27,   3,  12],\n",
       "         [ 27,   3,  12],\n",
       "         [ 26,   2,  11],\n",
       "         ...,\n",
       "         [100,  59,  64],\n",
       "         [100,  59,  64],\n",
       "         [100,  59,  64]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6801000019768253, 'inference': 23.373199997877236, 'postprocess': 4.556499996397179},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89, 169, 120],\n",
       "         [ 89, 169, 120],\n",
       "         [ 89, 169, 120],\n",
       "         ...,\n",
       "         [130,  92, 103],\n",
       "         [128,  90, 101],\n",
       "         [128,  90, 101]],\n",
       " \n",
       "        [[ 89, 169, 120],\n",
       "         [ 89, 169, 120],\n",
       "         [ 89, 169, 120],\n",
       "         ...,\n",
       "         [130,  92, 103],\n",
       "         [128,  90, 101],\n",
       "         [128,  90, 101]],\n",
       " \n",
       "        [[ 89, 169, 120],\n",
       "         [ 89, 169, 120],\n",
       "         [ 89, 169, 120],\n",
       "         ...,\n",
       "         [128,  90, 101],\n",
       "         [127,  89, 100],\n",
       "         [127,  89, 100]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  13],\n",
       "         [  0,   0,  13],\n",
       "         [  0,   0,  13],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  11],\n",
       "         [  0,   0,  11],\n",
       "         [  0,   0,  11],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  11],\n",
       "         [  0,   0,  11],\n",
       "         [  0,   0,  11],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2712000025203452, 'inference': 23.389900001347996, 'postprocess': 4.890100004558917},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         ...,\n",
       "         [130,  92, 103],\n",
       "         [128,  90, 101],\n",
       "         [128,  90, 101]],\n",
       " \n",
       "        [[ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         ...,\n",
       "         [130,  92, 103],\n",
       "         [128,  90, 101],\n",
       "         [128,  90, 101]],\n",
       " \n",
       "        [[ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         ...,\n",
       "         [128,  90, 101],\n",
       "         [127,  89, 100],\n",
       "         [127,  89, 100]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  13],\n",
       "         [  0,   0,  13],\n",
       "         [  0,   0,  13],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  11],\n",
       "         [  0,   0,  11],\n",
       "         [  0,   0,  11],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  11],\n",
       "         [  0,   0,  11],\n",
       "         [  0,   0,  11],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6417000006185845, 'inference': 25.528799997118767, 'postprocess': 2.1379999961936846},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 87, 170, 120],\n",
       "         [ 87, 170, 120],\n",
       "         [ 87, 170, 118],\n",
       "         ...,\n",
       "         [133,  98, 106],\n",
       "         [133,  98, 106],\n",
       "         [133,  98, 106]],\n",
       " \n",
       "        [[ 87, 170, 120],\n",
       "         [ 87, 170, 120],\n",
       "         [ 87, 170, 118],\n",
       "         ...,\n",
       "         [133,  98, 106],\n",
       "         [133,  98, 106],\n",
       "         [133,  98, 106]],\n",
       " \n",
       "        [[ 87, 170, 120],\n",
       "         [ 87, 170, 120],\n",
       "         [ 87, 170, 118],\n",
       "         ...,\n",
       "         [131,  98, 106],\n",
       "         [131,  98, 106],\n",
       "         [131,  98, 106]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  13],\n",
       "         [  0,   2,  15],\n",
       "         [  1,   6,  19],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  10],\n",
       "         [  0,   0,  11],\n",
       "         [  0,   2,  13],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  10],\n",
       "         [  0,   0,  10],\n",
       "         [  0,   0,  11],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.513600000180304, 'inference': 23.380900005577132, 'postprocess': 1.8099000008078292},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 87, 170, 120],\n",
       "         [ 87, 170, 120],\n",
       "         [ 87, 170, 118],\n",
       "         ...,\n",
       "         [133,  98, 106],\n",
       "         [133,  98, 106],\n",
       "         [133,  98, 106]],\n",
       " \n",
       "        [[ 87, 170, 120],\n",
       "         [ 87, 170, 120],\n",
       "         [ 87, 170, 118],\n",
       "         ...,\n",
       "         [133,  98, 106],\n",
       "         [133,  98, 106],\n",
       "         [133,  98, 106]],\n",
       " \n",
       "        [[ 87, 170, 120],\n",
       "         [ 87, 170, 120],\n",
       "         [ 87, 170, 118],\n",
       "         ...,\n",
       "         [131,  98, 106],\n",
       "         [131,  98, 106],\n",
       "         [131,  98, 106]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  13],\n",
       "         [  0,   2,  15],\n",
       "         [  1,   6,  19],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  10],\n",
       "         [  0,   0,  11],\n",
       "         [  0,   2,  13],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  10],\n",
       "         [  0,   0,  10],\n",
       "         [  0,   0,  11],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3661999983014539, 'inference': 23.392200004309416, 'postprocess': 6.678900004772004},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         [ 89, 169, 120],\n",
       "         ...,\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124]],\n",
       " \n",
       "        [[ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         [ 89, 169, 120],\n",
       "         ...,\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124]],\n",
       " \n",
       "        [[ 89, 168, 122],\n",
       "         [ 89, 168, 122],\n",
       "         [ 89, 169, 120],\n",
       "         ...,\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  8,  14,  30],\n",
       "         [ 13,  19,  35],\n",
       "         [ 16,  25,  40],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  8,  13,  24],\n",
       "         [ 14,  19,  30],\n",
       "         [ 18,  23,  34],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  7,  12,  23],\n",
       "         [ 13,  18,  29],\n",
       "         [ 18,  23,  34],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.846099996531848, 'inference': 40.343599997868296, 'postprocess': 2.4783000044408254},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 87, 167, 116],\n",
       "         [ 87, 167, 116],\n",
       "         [ 85, 168, 116],\n",
       "         ...,\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124]],\n",
       " \n",
       "        [[ 87, 167, 116],\n",
       "         [ 87, 167, 116],\n",
       "         [ 85, 168, 116],\n",
       "         ...,\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124]],\n",
       " \n",
       "        [[ 87, 167, 116],\n",
       "         [ 87, 167, 116],\n",
       "         [ 85, 168, 116],\n",
       "         ...,\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124],\n",
       "         [145, 114, 124]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 11,  16,  34],\n",
       "         [ 13,  18,  36],\n",
       "         [ 19,  24,  42],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 11,  13,  29],\n",
       "         [ 15,  17,  33],\n",
       "         [ 22,  24,  40],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  9,  11,  27],\n",
       "         [ 13,  15,  31],\n",
       "         [ 22,  24,  40],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4612000013585202, 'inference': 25.443600003200117, 'postprocess': 4.648100002668798},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 83, 168, 116],\n",
       "         [ 83, 168, 116],\n",
       "         [ 81, 169, 116],\n",
       "         ...,\n",
       "         [137, 120, 128],\n",
       "         [138, 121, 129],\n",
       "         [138, 121, 129]],\n",
       " \n",
       "        [[ 83, 168, 116],\n",
       "         [ 83, 168, 116],\n",
       "         [ 81, 169, 116],\n",
       "         ...,\n",
       "         [137, 120, 128],\n",
       "         [138, 121, 129],\n",
       "         [138, 121, 129]],\n",
       " \n",
       "        [[ 83, 168, 116],\n",
       "         [ 83, 168, 116],\n",
       "         [ 81, 169, 116],\n",
       "         ...,\n",
       "         [137, 120, 128],\n",
       "         [138, 121, 129],\n",
       "         [138, 121, 129]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  26,  44],\n",
       "         [ 21,  26,  44],\n",
       "         [ 17,  20,  38],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 26,  28,  44],\n",
       "         [ 27,  29,  45],\n",
       "         [ 22,  24,  40],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 27,  29,  45],\n",
       "         [ 29,  31,  47],\n",
       "         [ 24,  26,  42],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.193799999076873, 'inference': 27.814900000521448, 'postprocess': 6.844499999715481},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 83, 168, 116],\n",
       "         [ 83, 168, 116],\n",
       "         [ 81, 169, 116],\n",
       "         ...,\n",
       "         [137, 120, 128],\n",
       "         [138, 121, 129],\n",
       "         [138, 121, 129]],\n",
       " \n",
       "        [[ 83, 168, 116],\n",
       "         [ 83, 168, 116],\n",
       "         [ 81, 169, 116],\n",
       "         ...,\n",
       "         [137, 120, 128],\n",
       "         [138, 121, 129],\n",
       "         [138, 121, 129]],\n",
       " \n",
       "        [[ 83, 168, 116],\n",
       "         [ 83, 168, 116],\n",
       "         [ 81, 169, 116],\n",
       "         ...,\n",
       "         [137, 120, 128],\n",
       "         [138, 121, 129],\n",
       "         [138, 121, 129]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  26,  44],\n",
       "         [ 21,  26,  44],\n",
       "         [ 17,  20,  38],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 26,  28,  44],\n",
       "         [ 27,  29,  45],\n",
       "         [ 22,  24,  40],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 27,  29,  45],\n",
       "         [ 29,  31,  47],\n",
       "         [ 24,  26,  42],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9962000005762093, 'inference': 24.40569999453146, 'postprocess': 2.0445000045583583},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84, 169, 119],\n",
       "         [ 84, 169, 119],\n",
       "         [ 83, 168, 118],\n",
       "         ...,\n",
       "         [120, 112, 120],\n",
       "         [120, 112, 120],\n",
       "         [120, 112, 120]],\n",
       " \n",
       "        [[ 84, 169, 119],\n",
       "         [ 84, 169, 119],\n",
       "         [ 83, 168, 118],\n",
       "         ...,\n",
       "         [120, 112, 120],\n",
       "         [120, 112, 120],\n",
       "         [120, 112, 120]],\n",
       " \n",
       "        [[ 84, 169, 119],\n",
       "         [ 84, 169, 119],\n",
       "         [ 83, 168, 118],\n",
       "         ...,\n",
       "         [120, 112, 120],\n",
       "         [120, 112, 120],\n",
       "         [120, 112, 120]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 11,  12,  30],\n",
       "         [  5,   6,  24],\n",
       "         [  4,   2,  21],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 13,  15,  31],\n",
       "         [  9,  11,  27],\n",
       "         [  4,   6,  22],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 13,  15,  31],\n",
       "         [ 10,  12,  28],\n",
       "         [  5,   7,  23],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3940000028233044, 'inference': 37.825200000952464, 'postprocess': 5.97379999817349},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84, 169, 119],\n",
       "         [ 84, 169, 119],\n",
       "         [ 83, 168, 118],\n",
       "         ...,\n",
       "         [119, 111, 119],\n",
       "         [119, 111, 119],\n",
       "         [119, 111, 119]],\n",
       " \n",
       "        [[ 84, 169, 119],\n",
       "         [ 84, 169, 119],\n",
       "         [ 83, 168, 118],\n",
       "         ...,\n",
       "         [119, 111, 119],\n",
       "         [119, 111, 119],\n",
       "         [119, 111, 119]],\n",
       " \n",
       "        [[ 84, 169, 119],\n",
       "         [ 84, 169, 119],\n",
       "         [ 83, 168, 118],\n",
       "         ...,\n",
       "         [119, 111, 119],\n",
       "         [119, 111, 119],\n",
       "         [119, 111, 119]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 11,  12,  30],\n",
       "         [  5,   6,  24],\n",
       "         [  4,   2,  21],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 13,  15,  31],\n",
       "         [  9,  11,  27],\n",
       "         [  4,   6,  22],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[ 13,  15,  31],\n",
       "         [ 10,  12,  28],\n",
       "         [  5,   7,  23],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.5298999971710145, 'inference': 40.13739999936661, 'postprocess': 6.061200001568068},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84, 167, 117],\n",
       "         [ 84, 167, 117],\n",
       "         [ 82, 165, 120],\n",
       "         ...,\n",
       "         [116, 112, 115],\n",
       "         [116, 112, 115],\n",
       "         [116, 112, 115]],\n",
       " \n",
       "        [[ 84, 167, 117],\n",
       "         [ 84, 167, 117],\n",
       "         [ 82, 165, 120],\n",
       "         ...,\n",
       "         [116, 112, 115],\n",
       "         [117, 113, 116],\n",
       "         [117, 113, 116]],\n",
       " \n",
       "        [[ 83, 166, 116],\n",
       "         [ 83, 166, 116],\n",
       "         [ 82, 165, 120],\n",
       "         ...,\n",
       "         [118, 114, 117],\n",
       "         [119, 115, 118],\n",
       "         [119, 115, 118]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  1,   3,  19],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   1,  17],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0965999938198365, 'inference': 24.029200001677964, 'postprocess': 2.263899994431995},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84, 167, 117],\n",
       "         [ 84, 167, 117],\n",
       "         [ 82, 165, 120],\n",
       "         ...,\n",
       "         [116, 112, 115],\n",
       "         [116, 112, 115],\n",
       "         [116, 112, 115]],\n",
       " \n",
       "        [[ 84, 167, 117],\n",
       "         [ 84, 167, 117],\n",
       "         [ 82, 165, 120],\n",
       "         ...,\n",
       "         [116, 112, 115],\n",
       "         [117, 113, 116],\n",
       "         [117, 113, 116]],\n",
       " \n",
       "        [[ 83, 166, 116],\n",
       "         [ 83, 166, 116],\n",
       "         [ 82, 165, 120],\n",
       "         ...,\n",
       "         [118, 114, 117],\n",
       "         [119, 115, 118],\n",
       "         [119, 115, 118]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  1,   3,  19],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   1,  17],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 4.45449999824632, 'inference': 34.5136999967508, 'postprocess': 4.813999999896623},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84, 164, 122],\n",
       "         [ 83, 163, 121],\n",
       "         [ 85, 161, 122],\n",
       "         ...,\n",
       "         [109, 101, 109],\n",
       "         [111, 103, 111],\n",
       "         [111, 103, 111]],\n",
       " \n",
       "        [[ 84, 164, 122],\n",
       "         [ 83, 163, 121],\n",
       "         [ 85, 161, 122],\n",
       "         ...,\n",
       "         [112, 104, 112],\n",
       "         [113, 105, 113],\n",
       "         [113, 105, 113]],\n",
       " \n",
       "        [[ 84, 164, 122],\n",
       "         [ 83, 163, 121],\n",
       "         [ 85, 161, 122],\n",
       "         ...,\n",
       "         [112, 104, 112],\n",
       "         [113, 105, 113],\n",
       "         [113, 105, 113]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         ...,\n",
       "         [ 91,  79,  99],\n",
       "         [ 91,  79,  99],\n",
       "         [ 91,  79,  99]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 91,  79,  99],\n",
       "         [ 91,  79,  99],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 91,  79,  99],\n",
       "         [ 91,  79,  99],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6930999991018325, 'inference': 24.396500004513655, 'postprocess': 3.2484000039403327},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84, 164, 122],\n",
       "         [ 83, 163, 121],\n",
       "         [ 85, 161, 122],\n",
       "         ...,\n",
       "         [109, 101, 109],\n",
       "         [111, 103, 111],\n",
       "         [111, 103, 111]],\n",
       " \n",
       "        [[ 84, 164, 122],\n",
       "         [ 83, 163, 121],\n",
       "         [ 85, 161, 122],\n",
       "         ...,\n",
       "         [111, 103, 111],\n",
       "         [112, 104, 112],\n",
       "         [112, 104, 112]],\n",
       " \n",
       "        [[ 84, 164, 122],\n",
       "         [ 83, 163, 121],\n",
       "         [ 85, 161, 122],\n",
       "         ...,\n",
       "         [112, 104, 112],\n",
       "         [113, 105, 113],\n",
       "         [113, 105, 113]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         ...,\n",
       "         [ 91,  79,  99],\n",
       "         [ 91,  79,  99],\n",
       "         [ 91,  79,  99]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 91,  79,  99],\n",
       "         [ 91,  79,  99],\n",
       "         [ 92,  80, 100]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 91,  79,  99],\n",
       "         [ 91,  79,  99],\n",
       "         [ 92,  80, 100]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3395999994827434, 'inference': 27.74420000059763, 'postprocess': 2.0868999999947846},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89, 162, 126],\n",
       "         [ 87, 160, 124],\n",
       "         [ 84, 155, 121],\n",
       "         ...,\n",
       "         [ 99,  87,  99],\n",
       "         [100,  88, 100],\n",
       "         [101,  89, 101]],\n",
       " \n",
       "        [[ 89, 162, 126],\n",
       "         [ 87, 160, 124],\n",
       "         [ 84, 155, 121],\n",
       "         ...,\n",
       "         [100,  88, 100],\n",
       "         [101,  89, 101],\n",
       "         [101,  89, 101]],\n",
       " \n",
       "        [[ 87, 160, 124],\n",
       "         [ 84, 157, 121],\n",
       "         [ 84, 155, 121],\n",
       "         ...,\n",
       "         [100,  88, 100],\n",
       "         [102,  90, 102],\n",
       "         [102,  90, 102]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         ...,\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9707999963429756, 'inference': 26.248099995427765, 'postprocess': 2.137900002708193},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89, 162, 126],\n",
       "         [ 87, 160, 124],\n",
       "         [ 84, 155, 121],\n",
       "         ...,\n",
       "         [ 99,  87,  99],\n",
       "         [100,  88, 100],\n",
       "         [101,  89, 101]],\n",
       " \n",
       "        [[ 89, 162, 126],\n",
       "         [ 87, 160, 124],\n",
       "         [ 84, 155, 121],\n",
       "         ...,\n",
       "         [100,  88, 100],\n",
       "         [101,  89, 101],\n",
       "         [101,  89, 101]],\n",
       " \n",
       "        [[ 87, 160, 124],\n",
       "         [ 84, 157, 121],\n",
       "         [ 84, 155, 121],\n",
       "         ...,\n",
       "         [100,  88, 100],\n",
       "         [102,  90, 102],\n",
       "         [102,  90, 102]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         ...,\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98],\n",
       "         [ 90,  78,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3980000003357418, 'inference': 24.541699996916577, 'postprocess': 3.123900001810398},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89, 160, 126],\n",
       "         [ 86, 157, 123],\n",
       "         [ 85, 152, 121],\n",
       "         ...,\n",
       "         [ 79,  63,  87],\n",
       "         [ 80,  64,  88],\n",
       "         [ 80,  64,  88]],\n",
       " \n",
       "        [[ 89, 160, 126],\n",
       "         [ 86, 157, 123],\n",
       "         [ 85, 152, 121],\n",
       "         ...,\n",
       "         [ 79,  63,  87],\n",
       "         [ 80,  64,  88],\n",
       "         [ 80,  64,  88]],\n",
       " \n",
       "        [[ 86, 157, 123],\n",
       "         [ 85, 156, 122],\n",
       "         [ 85, 152, 121],\n",
       "         ...,\n",
       "         [ 78,  62,  86],\n",
       "         [ 79,  63,  87],\n",
       "         [ 79,  63,  87]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 94,  82, 102],\n",
       "         [ 91,  79,  99],\n",
       "         [ 86,  74,  94]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 94,  82, 102],\n",
       "         [ 91,  79,  99],\n",
       "         [ 90,  78,  98]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  15],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 89,  77,  97],\n",
       "         [ 89,  77,  97]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2829000042984262, 'inference': 24.89120000245748, 'postprocess': 2.2247000015340745},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89, 160, 126],\n",
       "         [ 86, 157, 123],\n",
       "         [ 85, 152, 121],\n",
       "         ...,\n",
       "         [ 79,  63,  87],\n",
       "         [ 80,  64,  88],\n",
       "         [ 80,  64,  88]],\n",
       " \n",
       "        [[ 89, 160, 126],\n",
       "         [ 86, 157, 123],\n",
       "         [ 85, 152, 121],\n",
       "         ...,\n",
       "         [ 79,  63,  87],\n",
       "         [ 80,  64,  88],\n",
       "         [ 80,  64,  88]],\n",
       " \n",
       "        [[ 86, 157, 123],\n",
       "         [ 85, 156, 122],\n",
       "         [ 85, 152, 121],\n",
       "         ...,\n",
       "         [ 78,  62,  86],\n",
       "         [ 79,  63,  87],\n",
       "         [ 79,  63,  87]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 94,  82, 102],\n",
       "         [ 91,  79,  99],\n",
       "         [ 86,  74,  94]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 94,  82, 102],\n",
       "         [ 91,  79,  99],\n",
       "         [ 90,  78,  98]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  15],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 89,  77,  97],\n",
       "         [ 89,  77,  97]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3879999969503842, 'inference': 23.274400002264883, 'postprocess': 2.8736000022036023},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 83, 152, 123],\n",
       "         [ 79, 148, 119],\n",
       "         [ 82, 142, 121],\n",
       "         ...,\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80]],\n",
       " \n",
       "        [[ 83, 152, 123],\n",
       "         [ 79, 148, 119],\n",
       "         [ 82, 142, 121],\n",
       "         ...,\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80]],\n",
       " \n",
       "        [[ 83, 152, 123],\n",
       "         [ 79, 148, 119],\n",
       "         [ 82, 142, 121],\n",
       "         ...,\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 89,  77,  97],\n",
       "         [ 92,  80, 100],\n",
       "         [ 93,  81, 101]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 86,  74,  94],\n",
       "         [ 92,  80, 100],\n",
       "         [ 95,  83, 103]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  15],\n",
       "         ...,\n",
       "         [ 87,  75,  95],\n",
       "         [ 93,  81, 101],\n",
       "         [ 98,  86, 106]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2366999944788404, 'inference': 23.155499999120366, 'postprocess': 3.131600002234336},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 83, 152, 123],\n",
       "         [ 79, 148, 119],\n",
       "         [ 82, 142, 121],\n",
       "         ...,\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80]],\n",
       " \n",
       "        [[ 83, 152, 123],\n",
       "         [ 79, 148, 119],\n",
       "         [ 82, 142, 121],\n",
       "         ...,\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80]],\n",
       " \n",
       "        [[ 83, 152, 123],\n",
       "         [ 79, 148, 119],\n",
       "         [ 82, 142, 121],\n",
       "         ...,\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80],\n",
       "         [ 72,  56,  80]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  17],\n",
       "         [  0,   0,  17],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 89,  77,  97],\n",
       "         [ 92,  80, 100],\n",
       "         [ 93,  81, 101]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         ...,\n",
       "         [ 86,  74,  94],\n",
       "         [ 92,  80, 100],\n",
       "         [ 94,  82, 102]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   0,  15],\n",
       "         ...,\n",
       "         [ 86,  74,  94],\n",
       "         [ 92,  80, 100],\n",
       "         [ 97,  85, 105]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4067000010982156, 'inference': 24.334599998837803, 'postprocess': 2.888100003474392},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 88, 149, 123],\n",
       "         [ 86, 147, 121],\n",
       "         [ 87, 141, 123],\n",
       "         ...,\n",
       "         [ 70,  54,  78],\n",
       "         [ 71,  55,  79],\n",
       "         [ 71,  55,  79]],\n",
       " \n",
       "        [[ 88, 149, 123],\n",
       "         [ 86, 147, 121],\n",
       "         [ 87, 141, 123],\n",
       "         ...,\n",
       "         [ 70,  54,  78],\n",
       "         [ 71,  55,  79],\n",
       "         [ 71,  55,  79]],\n",
       " \n",
       "        [[ 88, 149, 123],\n",
       "         [ 86, 147, 121],\n",
       "         [ 87, 141, 123],\n",
       "         ...,\n",
       "         [ 70,  54,  78],\n",
       "         [ 71,  55,  79],\n",
       "         [ 71,  55,  79]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   2,  20],\n",
       "         [  0,   2,  20],\n",
       "         [  0,   2,  20],\n",
       "         ...,\n",
       "         [ 93,  81, 101],\n",
       "         [ 94,  82, 102],\n",
       "         [ 94,  82, 102]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   1,  17],\n",
       "         [  0,   1,  17],\n",
       "         ...,\n",
       "         [ 95,  83, 103],\n",
       "         [ 94,  82, 102],\n",
       "         [ 94,  82, 102]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   1,  17],\n",
       "         ...,\n",
       "         [ 95,  83, 103],\n",
       "         [ 95,  83, 103],\n",
       "         [ 94,  82, 102]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4202000020304695, 'inference': 24.84340000228258, 'postprocess': 2.601899999717716},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 88, 149, 123],\n",
       "         [ 86, 147, 121],\n",
       "         [ 87, 141, 123],\n",
       "         ...,\n",
       "         [ 70,  54,  78],\n",
       "         [ 71,  55,  79],\n",
       "         [ 71,  55,  79]],\n",
       " \n",
       "        [[ 88, 149, 123],\n",
       "         [ 86, 147, 121],\n",
       "         [ 87, 141, 123],\n",
       "         ...,\n",
       "         [ 70,  54,  78],\n",
       "         [ 71,  55,  79],\n",
       "         [ 71,  55,  79]],\n",
       " \n",
       "        [[ 88, 149, 123],\n",
       "         [ 86, 147, 121],\n",
       "         [ 87, 141, 123],\n",
       "         ...,\n",
       "         [ 70,  54,  78],\n",
       "         [ 71,  55,  79],\n",
       "         [ 71,  55,  79]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   2,  20],\n",
       "         [  0,   2,  20],\n",
       "         [  0,   2,  20],\n",
       "         ...,\n",
       "         [ 93,  81, 101],\n",
       "         [ 94,  82, 102],\n",
       "         [ 94,  82, 102]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   1,  17],\n",
       "         [  0,   1,  17],\n",
       "         ...,\n",
       "         [ 95,  83, 103],\n",
       "         [ 94,  82, 102],\n",
       "         [ 94,  82, 102]],\n",
       " \n",
       "        [[  0,   0,  16],\n",
       "         [  0,   0,  16],\n",
       "         [  0,   1,  17],\n",
       "         ...,\n",
       "         [ 95,  83, 103],\n",
       "         [ 95,  83, 103],\n",
       "         [ 94,  82, 102]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3794000042253174, 'inference': 22.93910000298638, 'postprocess': 1.943200004461687},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 91, 141, 122],\n",
       "         [ 91, 141, 122],\n",
       "         [ 94, 132, 120],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        [[ 91, 141, 122],\n",
       "         [ 92, 142, 123],\n",
       "         [ 93, 131, 119],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        [[ 91, 141, 122],\n",
       "         [ 92, 142, 123],\n",
       "         [ 92, 130, 118],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   1,  22],\n",
       "         [  0,   1,  22],\n",
       "         [  0,   1,  22],\n",
       "         ...,\n",
       "         [ 94,  82, 102],\n",
       "         [ 92,  80, 100],\n",
       "         [ 91,  79,  99]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 93,  81, 101],\n",
       "         [ 91,  79,  99],\n",
       "         [ 90,  78,  98]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 90,  78,  98],\n",
       "         [ 89,  77,  97]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.309600003878586, 'inference': 22.69939999678172, 'postprocess': 3.728900002897717},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 91, 141, 122],\n",
       "         [ 91, 141, 122],\n",
       "         [ 94, 132, 120],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        [[ 91, 141, 122],\n",
       "         [ 92, 142, 123],\n",
       "         [ 93, 131, 119],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        [[ 91, 141, 122],\n",
       "         [ 92, 142, 123],\n",
       "         [ 92, 130, 118],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   1,  22],\n",
       "         [  0,   1,  22],\n",
       "         [  0,   1,  22],\n",
       "         ...,\n",
       "         [ 94,  82, 102],\n",
       "         [ 92,  80, 100],\n",
       "         [ 91,  79,  99]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 93,  81, 101],\n",
       "         [ 91,  79,  99],\n",
       "         [ 90,  78,  98]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 92,  80, 100],\n",
       "         [ 90,  78,  98],\n",
       "         [ 89,  77,  97]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.567100000102073, 'inference': 23.3522000053199, 'postprocess': 2.0667999997385778},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 92, 125, 115],\n",
       "         [ 78, 111, 101],\n",
       "         [ 73,  97,  94],\n",
       "         ...,\n",
       "         [ 65,  52,  75],\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76]],\n",
       " \n",
       "        [[ 90, 123, 113],\n",
       "         [ 78, 111, 101],\n",
       "         [ 70,  94,  91],\n",
       "         ...,\n",
       "         [ 65,  52,  75],\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76]],\n",
       " \n",
       "        [[ 89, 122, 112],\n",
       "         [ 76, 109,  99],\n",
       "         [ 69,  93,  90],\n",
       "         ...,\n",
       "         [ 65,  52,  75],\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,  23],\n",
       "         [  0,   0,  23],\n",
       "         [  0,   0,  23],\n",
       "         ...,\n",
       "         [ 95,  85, 105],\n",
       "         [ 95,  85, 105],\n",
       "         [ 96,  86, 106]],\n",
       " \n",
       "        [[  0,   0,  20],\n",
       "         [  0,   0,  20],\n",
       "         [  0,   0,  20],\n",
       "         ...,\n",
       "         [ 95,  85, 105],\n",
       "         [ 95,  85, 105],\n",
       "         [ 93,  83, 103]],\n",
       " \n",
       "        [[  0,   0,  20],\n",
       "         [  0,   0,  20],\n",
       "         [  0,   0,  20],\n",
       "         ...,\n",
       "         [ 96,  86, 106],\n",
       "         [ 93,  83, 103],\n",
       "         [ 92,  82, 102]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4434999975492246, 'inference': 23.33859999635024, 'postprocess': 2.1533999970415607},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 92, 125, 115],\n",
       "         [ 78, 111, 101],\n",
       "         [ 73,  97,  94],\n",
       "         ...,\n",
       "         [ 65,  52,  75],\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76]],\n",
       " \n",
       "        [[ 90, 123, 113],\n",
       "         [ 78, 111, 101],\n",
       "         [ 70,  94,  91],\n",
       "         ...,\n",
       "         [ 65,  52,  75],\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76]],\n",
       " \n",
       "        [[ 89, 122, 112],\n",
       "         [ 76, 109,  99],\n",
       "         [ 69,  93,  90],\n",
       "         ...,\n",
       "         [ 65,  52,  75],\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   1,  22],\n",
       "         [  0,   1,  22],\n",
       "         [  0,   1,  22],\n",
       "         ...,\n",
       "         [ 95,  85, 105],\n",
       "         [ 95,  85, 105],\n",
       "         [ 96,  86, 106]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 95,  85, 105],\n",
       "         [ 95,  85, 105],\n",
       "         [ 93,  83, 103]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 96,  86, 106],\n",
       "         [ 93,  83, 103],\n",
       "         [ 92,  82, 102]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.370699996186886, 'inference': 22.894200003065635, 'postprocess': 3.4538999971118756},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 61,  80,  79],\n",
       "         [ 52,  71,  70],\n",
       "         [ 55,  61,  70],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        [[ 61,  80,  79],\n",
       "         [ 52,  71,  70],\n",
       "         [ 55,  61,  70],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        [[ 61,  80,  79],\n",
       "         [ 52,  71,  70],\n",
       "         [ 55,  61,  70],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   2,  23],\n",
       "         [  0,   2,  23],\n",
       "         [  0,   2,  23],\n",
       "         ...,\n",
       "         [ 91,  81, 101],\n",
       "         [ 92,  82, 102],\n",
       "         [ 93,  83, 103]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 91,  81, 101],\n",
       "         [ 95,  85, 105],\n",
       "         [ 96,  86, 106]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 92,  82, 102],\n",
       "         [ 96,  86, 106],\n",
       "         [ 98,  88, 108]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7051000031642616, 'inference': 23.04089999961434, 'postprocess': 2.4582000041846186},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 61,  80,  79],\n",
       "         [ 52,  71,  70],\n",
       "         [ 55,  61,  70],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        [[ 61,  80,  79],\n",
       "         [ 52,  71,  70],\n",
       "         [ 55,  61,  70],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        [[ 61,  80,  79],\n",
       "         [ 52,  71,  70],\n",
       "         [ 55,  61,  70],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76],\n",
       "         [ 66,  53,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   2,  23],\n",
       "         [  0,   2,  23],\n",
       "         [  0,   2,  23],\n",
       "         ...,\n",
       "         [ 91,  81, 101],\n",
       "         [ 92,  82, 102],\n",
       "         [ 93,  83, 103]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 91,  81, 101],\n",
       "         [ 95,  85, 105],\n",
       "         [ 96,  86, 106]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 92,  82, 102],\n",
       "         [ 96,  86, 106],\n",
       "         [ 98,  88, 108]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.574199995957315, 'inference': 25.07369999511866, 'postprocess': 5.668300000252202},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 57,  57,  71],\n",
       "         [ 55,  55,  69],\n",
       "         [ 59,  53,  70],\n",
       "         ...,\n",
       "         [ 69,  56,  79],\n",
       "         [ 70,  57,  80],\n",
       "         [ 70,  57,  80]],\n",
       " \n",
       "        [[ 57,  57,  71],\n",
       "         [ 55,  55,  69],\n",
       "         [ 59,  53,  70],\n",
       "         ...,\n",
       "         [ 68,  55,  78],\n",
       "         [ 69,  56,  79],\n",
       "         [ 69,  56,  79]],\n",
       " \n",
       "        [[ 57,  57,  71],\n",
       "         [ 55,  55,  69],\n",
       "         [ 60,  54,  71],\n",
       "         ...,\n",
       "         [ 66,  53,  76],\n",
       "         [ 68,  55,  78],\n",
       "         [ 68,  55,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   2,  23],\n",
       "         [  0,   2,  23],\n",
       "         [  0,   2,  23],\n",
       "         ...,\n",
       "         [ 88,  79,  97],\n",
       "         [ 89,  79,  99],\n",
       "         [ 91,  81, 101]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 87,  78,  96],\n",
       "         [ 89,  79,  99],\n",
       "         [ 91,  81, 101]],\n",
       " \n",
       "        [[  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         [  0,   0,  18],\n",
       "         ...,\n",
       "         [ 87,  78,  96],\n",
       "         [ 89,  79,  99],\n",
       "         [ 92,  82, 102]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7953999995370395, 'inference': 23.109800000383984, 'postprocess': 2.695099996344652},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[183, 116, 166],\n",
       "         [183, 116, 166],\n",
       "         [183, 116, 166],\n",
       "         ...,\n",
       "         [200,  85, 129],\n",
       "         [197,  82, 126],\n",
       "         [197,  82, 126]],\n",
       " \n",
       "        [[186, 119, 169],\n",
       "         [186, 119, 169],\n",
       "         [186, 119, 169],\n",
       "         ...,\n",
       "         [200,  85, 129],\n",
       "         [197,  82, 126],\n",
       "         [197,  82, 126]],\n",
       " \n",
       "        [[189, 123, 168],\n",
       "         [189, 123, 168],\n",
       "         [189, 122, 170],\n",
       "         ...,\n",
       "         [200,  85, 129],\n",
       "         [197,  82, 126],\n",
       "         [197,  82, 126]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[162,  87, 161],\n",
       "         [168,  93, 167],\n",
       "         [172,  97, 169],\n",
       "         ...,\n",
       "         [139,  35,  64],\n",
       "         [135,  36,  64],\n",
       "         [135,  36,  64]],\n",
       " \n",
       "        [[168,  93, 167],\n",
       "         [172,  97, 171],\n",
       "         [176, 101, 173],\n",
       "         ...,\n",
       "         [146,  30,  61],\n",
       "         [140,  32,  61],\n",
       "         [140,  32,  61]],\n",
       " \n",
       "        [[172,  97, 171],\n",
       "         [176, 101, 175],\n",
       "         [179, 104, 176],\n",
       "         ...,\n",
       "         [144,  28,  59],\n",
       "         [138,  30,  59],\n",
       "         [138,  30,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5577000012854114, 'inference': 22.87400000204798, 'postprocess': 1.9795999978668988},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[137,  47, 178],\n",
       "         [128,  38, 169],\n",
       "         [118,  25, 170],\n",
       "         ...,\n",
       "         [205, 134, 187],\n",
       "         [209, 140, 176],\n",
       "         [209, 140, 176]],\n",
       " \n",
       "        [[140,  50, 181],\n",
       "         [130,  40, 171],\n",
       "         [120,  27, 172],\n",
       "         ...,\n",
       "         [205, 134, 187],\n",
       "         [209, 140, 176],\n",
       "         [209, 140, 176]],\n",
       " \n",
       "        [[143,  55, 172],\n",
       "         [133,  45, 162],\n",
       "         [122,  30, 166],\n",
       "         ...,\n",
       "         [206, 135, 188],\n",
       "         [210, 141, 177],\n",
       "         [210, 141, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[149,  89, 124],\n",
       "         [144,  84, 119],\n",
       "         [140,  83, 115],\n",
       "         ...,\n",
       "         [114,  31,  66],\n",
       "         [114,  31,  66],\n",
       "         [114,  31,  66]],\n",
       " \n",
       "        [[147,  87, 122],\n",
       "         [144,  84, 119],\n",
       "         [140,  83, 115],\n",
       "         ...,\n",
       "         [112,  34,  63],\n",
       "         [112,  34,  63],\n",
       "         [112,  34,  63]],\n",
       " \n",
       "        [[147,  87, 122],\n",
       "         [145,  85, 120],\n",
       "         [141,  84, 116],\n",
       "         ...,\n",
       "         [112,  34,  63],\n",
       "         [112,  34,  63],\n",
       "         [112,  34,  63]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.367299999401439, 'inference': 22.978699998930097, 'postprocess': 2.444399993692059},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[137,  47, 178],\n",
       "         [128,  38, 169],\n",
       "         [118,  25, 170],\n",
       "         ...,\n",
       "         [205, 134, 187],\n",
       "         [209, 140, 176],\n",
       "         [209, 140, 176]],\n",
       " \n",
       "        [[140,  50, 181],\n",
       "         [130,  40, 171],\n",
       "         [120,  27, 172],\n",
       "         ...,\n",
       "         [205, 134, 187],\n",
       "         [209, 140, 176],\n",
       "         [209, 140, 176]],\n",
       " \n",
       "        [[143,  55, 172],\n",
       "         [133,  45, 162],\n",
       "         [122,  30, 166],\n",
       "         ...,\n",
       "         [206, 135, 188],\n",
       "         [210, 141, 177],\n",
       "         [210, 141, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[149,  89, 124],\n",
       "         [144,  84, 119],\n",
       "         [140,  83, 115],\n",
       "         ...,\n",
       "         [114,  31,  66],\n",
       "         [114,  31,  66],\n",
       "         [114,  31,  66]],\n",
       " \n",
       "        [[147,  87, 122],\n",
       "         [144,  84, 119],\n",
       "         [140,  83, 115],\n",
       "         ...,\n",
       "         [112,  34,  63],\n",
       "         [112,  34,  63],\n",
       "         [112,  34,  63]],\n",
       " \n",
       "        [[147,  87, 122],\n",
       "         [145,  85, 120],\n",
       "         [141,  84, 116],\n",
       "         ...,\n",
       "         [112,  34,  63],\n",
       "         [112,  34,  63],\n",
       "         [112,  34,  63]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3875000004190952, 'inference': 22.75509999890346, 'postprocess': 5.15119999909075},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94,   0, 171],\n",
       "         [ 94,   0, 171],\n",
       "         [ 94,   0, 170],\n",
       "         ...,\n",
       "         [234, 171, 209],\n",
       "         [236, 173, 211],\n",
       "         [236, 173, 211]],\n",
       " \n",
       "        [[ 93,   0, 170],\n",
       "         [ 93,   0, 170],\n",
       "         [ 93,   0, 169],\n",
       "         ...,\n",
       "         [217, 154, 192],\n",
       "         [218, 155, 193],\n",
       "         [218, 155, 193]],\n",
       " \n",
       "        [[ 93,   0, 173],\n",
       "         [ 93,   0, 173],\n",
       "         [ 93,   0, 173],\n",
       "         ...,\n",
       "         [208, 145, 183],\n",
       "         [209, 146, 184],\n",
       "         [209, 146, 184]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 87,  28,  59],\n",
       "         [ 86,  27,  58],\n",
       "         ...,\n",
       "         [114,  33,  69],\n",
       "         [114,  33,  69],\n",
       "         [114,  33,  69]],\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 86,  27,  58],\n",
       "         [ 85,  26,  57],\n",
       "         ...,\n",
       "         [116,  32,  69],\n",
       "         [116,  32,  69],\n",
       "         [116,  32,  69]],\n",
       " \n",
       "        [[ 87,  28,  59],\n",
       "         [ 86,  27,  58],\n",
       "         [ 83,  24,  55],\n",
       "         ...,\n",
       "         [116,  32,  69],\n",
       "         [116,  32,  69],\n",
       "         [116,  32,  69]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3637000010930933, 'inference': 23.146799998357892, 'postprocess': 1.9490999984554946},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94,   0, 171],\n",
       "         [ 94,   0, 171],\n",
       "         [ 94,   0, 170],\n",
       "         ...,\n",
       "         [234, 171, 209],\n",
       "         [236, 173, 211],\n",
       "         [236, 173, 211]],\n",
       " \n",
       "        [[ 93,   0, 170],\n",
       "         [ 93,   0, 170],\n",
       "         [ 93,   0, 169],\n",
       "         ...,\n",
       "         [217, 154, 192],\n",
       "         [218, 155, 193],\n",
       "         [218, 155, 193]],\n",
       " \n",
       "        [[ 93,   0, 173],\n",
       "         [ 93,   0, 173],\n",
       "         [ 93,   0, 173],\n",
       "         ...,\n",
       "         [208, 145, 183],\n",
       "         [209, 146, 184],\n",
       "         [209, 146, 184]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 87,  28,  59],\n",
       "         [ 86,  27,  58],\n",
       "         ...,\n",
       "         [114,  33,  69],\n",
       "         [114,  33,  69],\n",
       "         [114,  33,  69]],\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 86,  27,  58],\n",
       "         [ 85,  26,  57],\n",
       "         ...,\n",
       "         [116,  32,  69],\n",
       "         [116,  32,  69],\n",
       "         [116,  32,  69]],\n",
       " \n",
       "        [[ 87,  28,  59],\n",
       "         [ 86,  27,  58],\n",
       "         [ 83,  24,  55],\n",
       "         ...,\n",
       "         [116,  32,  69],\n",
       "         [116,  32,  69],\n",
       "         [116,  32,  69]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2754999988828786, 'inference': 22.973799997998867, 'postprocess': 3.6799000008613802},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 92,  16, 145],\n",
       "         [ 94,  18, 147],\n",
       "         [ 96,  23, 143],\n",
       "         ...,\n",
       "         [194, 177, 205],\n",
       "         [192, 175, 203],\n",
       "         [188, 171, 199]],\n",
       " \n",
       "        [[ 90,  14, 143],\n",
       "         [ 90,  14, 143],\n",
       "         [ 93,  20, 140],\n",
       "         ...,\n",
       "         [196, 179, 207],\n",
       "         [194, 177, 205],\n",
       "         [192, 175, 203]],\n",
       " \n",
       "        [[ 92,   4, 155],\n",
       "         [ 94,   6, 157],\n",
       "         [ 92,  11, 149],\n",
       "         ...,\n",
       "         [199, 181, 212],\n",
       "         [196, 178, 209],\n",
       "         [194, 176, 207]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  18,  44],\n",
       "         [ 76,  19,  45],\n",
       "         [ 78,  21,  47],\n",
       "         ...,\n",
       "         [117,  48,  89],\n",
       "         [115,  48,  89],\n",
       "         [117,  50,  91]],\n",
       " \n",
       "        [[ 75,  18,  44],\n",
       "         [ 75,  18,  44],\n",
       "         [ 76,  19,  45],\n",
       "         ...,\n",
       "         [113,  44,  85],\n",
       "         [114,  45,  86],\n",
       "         [115,  46,  87]],\n",
       " \n",
       "        [[ 74,  17,  43],\n",
       "         [ 75,  18,  44],\n",
       "         [ 75,  18,  44],\n",
       "         ...,\n",
       "         [109,  40,  81],\n",
       "         [110,  41,  82],\n",
       "         [112,  43,  84]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3741000002482906, 'inference': 22.87349999824073, 'postprocess': 2.290500000526663},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 92,  16, 145],\n",
       "         [ 94,  18, 147],\n",
       "         [ 96,  23, 143],\n",
       "         ...,\n",
       "         [194, 177, 205],\n",
       "         [192, 175, 203],\n",
       "         [188, 171, 199]],\n",
       " \n",
       "        [[ 90,  14, 143],\n",
       "         [ 90,  14, 143],\n",
       "         [ 93,  20, 140],\n",
       "         ...,\n",
       "         [196, 179, 207],\n",
       "         [194, 177, 205],\n",
       "         [192, 175, 203]],\n",
       " \n",
       "        [[ 92,   4, 155],\n",
       "         [ 94,   6, 157],\n",
       "         [ 92,  11, 149],\n",
       "         ...,\n",
       "         [199, 181, 212],\n",
       "         [196, 178, 209],\n",
       "         [194, 176, 207]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  18,  44],\n",
       "         [ 76,  19,  45],\n",
       "         [ 78,  21,  47],\n",
       "         ...,\n",
       "         [117,  48,  89],\n",
       "         [115,  48,  89],\n",
       "         [117,  50,  91]],\n",
       " \n",
       "        [[ 75,  18,  44],\n",
       "         [ 75,  18,  44],\n",
       "         [ 76,  19,  45],\n",
       "         ...,\n",
       "         [113,  44,  85],\n",
       "         [114,  45,  86],\n",
       "         [115,  46,  87]],\n",
       " \n",
       "        [[ 74,  17,  43],\n",
       "         [ 75,  18,  44],\n",
       "         [ 75,  18,  44],\n",
       "         ...,\n",
       "         [109,  40,  81],\n",
       "         [110,  41,  82],\n",
       "         [112,  43,  84]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7584000015631318, 'inference': 27.020399997127242, 'postprocess': 2.404200000455603},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[161, 109, 181],\n",
       "         [170, 118, 190],\n",
       "         [183, 131, 195],\n",
       "         ...,\n",
       "         [121,  55, 168],\n",
       "         [125,  52, 172],\n",
       "         [125,  52, 172]],\n",
       " \n",
       "        [[138,  86, 158],\n",
       "         [149,  97, 169],\n",
       "         [163, 111, 175],\n",
       "         ...,\n",
       "         [118,  52, 165],\n",
       "         [122,  49, 169],\n",
       "         [122,  49, 169]],\n",
       " \n",
       "        [[119,  62, 154],\n",
       "         [127,  70, 162],\n",
       "         [139,  83, 166],\n",
       "         ...,\n",
       "         [111,  47, 160],\n",
       "         [115,  44, 164],\n",
       "         [115,  44, 164]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         ...,\n",
       "         [123,  66,  92],\n",
       "         [120,  63,  89],\n",
       "         [116,  59,  85]],\n",
       " \n",
       "        [[ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         ...,\n",
       "         [128,  71,  97],\n",
       "         [127,  70,  96],\n",
       "         [123,  66,  92]],\n",
       " \n",
       "        [[ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         ...,\n",
       "         [132,  75, 101],\n",
       "         [130,  73,  99],\n",
       "         [128,  71,  97]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3963000019430183, 'inference': 23.45989999594167, 'postprocess': 3.2042999955592677},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[161, 109, 181],\n",
       "         [170, 118, 190],\n",
       "         [183, 131, 195],\n",
       "         ...,\n",
       "         [121,  55, 168],\n",
       "         [125,  52, 172],\n",
       "         [125,  52, 172]],\n",
       " \n",
       "        [[138,  86, 158],\n",
       "         [149,  97, 169],\n",
       "         [163, 111, 175],\n",
       "         ...,\n",
       "         [118,  52, 165],\n",
       "         [122,  49, 169],\n",
       "         [122,  49, 169]],\n",
       " \n",
       "        [[119,  62, 154],\n",
       "         [127,  70, 162],\n",
       "         [139,  83, 166],\n",
       "         ...,\n",
       "         [111,  47, 160],\n",
       "         [115,  44, 164],\n",
       "         [115,  44, 164]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         ...,\n",
       "         [123,  66,  92],\n",
       "         [120,  63,  89],\n",
       "         [116,  59,  85]],\n",
       " \n",
       "        [[ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         ...,\n",
       "         [128,  71,  97],\n",
       "         [127,  70,  96],\n",
       "         [123,  66,  92]],\n",
       " \n",
       "        [[ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         [ 83,  24,  55],\n",
       "         ...,\n",
       "         [132,  75, 101],\n",
       "         [130,  73,  99],\n",
       "         [128,  71,  97]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8877999973483384, 'inference': 70.61840000096709, 'postprocess': 5.454999998619314},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[229, 165, 205],\n",
       "         [229, 165, 205],\n",
       "         [232, 167, 203],\n",
       "         ...,\n",
       "         [159,   3, 176],\n",
       "         [164,   5, 179],\n",
       "         [169,  10, 184]],\n",
       " \n",
       "        [[229, 165, 205],\n",
       "         [229, 165, 205],\n",
       "         [231, 166, 202],\n",
       "         ...,\n",
       "         [151,   0, 168],\n",
       "         [157,   0, 172],\n",
       "         [162,   3, 177]],\n",
       " \n",
       "        [[223, 163, 210],\n",
       "         [224, 164, 211],\n",
       "         [228, 166, 206],\n",
       "         ...,\n",
       "         [150,   0, 168],\n",
       "         [154,   0, 172],\n",
       "         [156,   0, 174]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 85,  30,  62],\n",
       "         [ 85,  30,  62],\n",
       "         [ 87,  30,  62],\n",
       "         ...,\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33]],\n",
       " \n",
       "        [[ 85,  30,  62],\n",
       "         [ 85,  30,  62],\n",
       "         [ 87,  30,  62],\n",
       "         ...,\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33]],\n",
       " \n",
       "        [[ 85,  30,  62],\n",
       "         [ 85,  30,  62],\n",
       "         [ 87,  30,  62],\n",
       "         ...,\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.564699996379204, 'inference': 30.51189999678172, 'postprocess': 4.742899996927008},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[229, 165, 205],\n",
       "         [229, 165, 205],\n",
       "         [232, 167, 203],\n",
       "         ...,\n",
       "         [159,   3, 176],\n",
       "         [164,   5, 179],\n",
       "         [169,  10, 184]],\n",
       " \n",
       "        [[229, 165, 205],\n",
       "         [229, 165, 205],\n",
       "         [231, 166, 202],\n",
       "         ...,\n",
       "         [151,   0, 168],\n",
       "         [157,   0, 172],\n",
       "         [162,   3, 177]],\n",
       " \n",
       "        [[223, 163, 210],\n",
       "         [224, 164, 211],\n",
       "         [228, 166, 206],\n",
       "         ...,\n",
       "         [150,   0, 168],\n",
       "         [154,   0, 172],\n",
       "         [156,   0, 174]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 85,  30,  62],\n",
       "         [ 85,  30,  62],\n",
       "         [ 87,  30,  62],\n",
       "         ...,\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33]],\n",
       " \n",
       "        [[ 85,  30,  62],\n",
       "         [ 85,  30,  62],\n",
       "         [ 87,  30,  62],\n",
       "         ...,\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33]],\n",
       " \n",
       "        [[ 85,  30,  62],\n",
       "         [ 85,  30,  62],\n",
       "         [ 87,  30,  62],\n",
       "         ...,\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33],\n",
       "         [ 77,  16,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.147700004570652, 'inference': 27.022000002034474, 'postprocess': 3.1216999996104278},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[229, 167, 194],\n",
       "         [229, 167, 194],\n",
       "         [231, 167, 194],\n",
       "         ...,\n",
       "         [127,  83, 179],\n",
       "         [120,  86, 178],\n",
       "         [118,  84, 176]],\n",
       " \n",
       "        [[229, 167, 194],\n",
       "         [229, 167, 194],\n",
       "         [231, 167, 194],\n",
       "         ...,\n",
       "         [126,  82, 178],\n",
       "         [116,  82, 174],\n",
       "         [112,  78, 170]],\n",
       " \n",
       "        [[225, 168, 194],\n",
       "         [225, 168, 194],\n",
       "         [225, 167, 195],\n",
       "         ...,\n",
       "         [122,  72, 177],\n",
       "         [112,  73, 173],\n",
       "         [112,  73, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         ...,\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29]],\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         ...,\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29]],\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         ...,\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7487000004621223, 'inference': 23.041500004183035, 'postprocess': 2.5126999971689656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[229, 167, 194],\n",
       "         [229, 167, 194],\n",
       "         [231, 167, 194],\n",
       "         ...,\n",
       "         [127,  83, 179],\n",
       "         [120,  86, 178],\n",
       "         [118,  84, 176]],\n",
       " \n",
       "        [[229, 167, 194],\n",
       "         [229, 167, 194],\n",
       "         [231, 167, 194],\n",
       "         ...,\n",
       "         [126,  82, 178],\n",
       "         [116,  82, 174],\n",
       "         [112,  78, 170]],\n",
       " \n",
       "        [[225, 168, 194],\n",
       "         [225, 168, 194],\n",
       "         [225, 167, 195],\n",
       "         ...,\n",
       "         [122,  72, 177],\n",
       "         [112,  73, 173],\n",
       "         [112,  73, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         ...,\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29]],\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         ...,\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29]],\n",
       " \n",
       "        [[ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         [ 89,  30,  61],\n",
       "         ...,\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29],\n",
       "         [ 76,  14,  29]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4872000028844923, 'inference': 27.858599998580758, 'postprocess': 4.102400002011564},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[236, 170, 197],\n",
       "         [236, 170, 197],\n",
       "         [234, 170, 197],\n",
       "         ...,\n",
       "         [ 98,  92, 144],\n",
       "         [ 98,  93, 140],\n",
       "         [ 98,  93, 140]],\n",
       " \n",
       "        [[236, 170, 197],\n",
       "         [236, 170, 197],\n",
       "         [234, 170, 197],\n",
       "         ...,\n",
       "         [ 98,  92, 144],\n",
       "         [ 98,  93, 140],\n",
       "         [ 98,  93, 140]],\n",
       " \n",
       "        [[236, 170, 197],\n",
       "         [236, 170, 197],\n",
       "         [234, 170, 197],\n",
       "         ...,\n",
       "         [ 98,  92, 142],\n",
       "         [ 98,  94, 139],\n",
       "         [ 98,  94, 139]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         ...,\n",
       "         [ 76,  16,  26],\n",
       "         [ 76,  16,  26],\n",
       "         [ 76,  16,  26]],\n",
       " \n",
       "        [[ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         ...,\n",
       "         [ 76,  16,  26],\n",
       "         [ 76,  16,  26],\n",
       "         [ 76,  16,  26]],\n",
       " \n",
       "        [[ 90,  34,  64],\n",
       "         [ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         ...,\n",
       "         [ 76,  16,  26],\n",
       "         [ 76,  16,  26],\n",
       "         [ 76,  16,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7268000010517426, 'inference': 23.43230000406038, 'postprocess': 3.410400000575464},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[236, 170, 197],\n",
       "         [236, 170, 197],\n",
       "         [234, 170, 197],\n",
       "         ...,\n",
       "         [ 98,  92, 144],\n",
       "         [ 98,  93, 140],\n",
       "         [ 98,  93, 140]],\n",
       " \n",
       "        [[236, 170, 197],\n",
       "         [236, 170, 197],\n",
       "         [234, 170, 197],\n",
       "         ...,\n",
       "         [ 98,  92, 144],\n",
       "         [ 98,  93, 140],\n",
       "         [ 98,  93, 140]],\n",
       " \n",
       "        [[236, 170, 197],\n",
       "         [236, 170, 197],\n",
       "         [234, 170, 197],\n",
       "         ...,\n",
       "         [ 98,  92, 142],\n",
       "         [ 98,  94, 139],\n",
       "         [ 98,  94, 139]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         ...,\n",
       "         [ 78,  15,  26],\n",
       "         [ 78,  15,  26],\n",
       "         [ 78,  15,  26]],\n",
       " \n",
       "        [[ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         ...,\n",
       "         [ 78,  15,  26],\n",
       "         [ 78,  15,  26],\n",
       "         [ 78,  15,  26]],\n",
       " \n",
       "        [[ 90,  34,  64],\n",
       "         [ 91,  35,  65],\n",
       "         [ 91,  35,  65],\n",
       "         ...,\n",
       "         [ 78,  15,  26],\n",
       "         [ 78,  15,  26],\n",
       "         [ 78,  15,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.291799999307841, 'inference': 23.346800000581425, 'postprocess': 3.344700002344325},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[238, 173, 197],\n",
       "         [238, 173, 197],\n",
       "         [238, 173, 197],\n",
       "         ...,\n",
       "         [176,  96, 164],\n",
       "         [186,  96, 166],\n",
       "         [186,  96, 166]],\n",
       " \n",
       "        [[238, 173, 197],\n",
       "         [238, 173, 197],\n",
       "         [238, 173, 197],\n",
       "         ...,\n",
       "         [176,  96, 164],\n",
       "         [186,  96, 166],\n",
       "         [186,  96, 166]],\n",
       " \n",
       "        [[238, 172, 199],\n",
       "         [238, 172, 199],\n",
       "         [238, 173, 197],\n",
       "         ...,\n",
       "         [176,  96, 164],\n",
       "         [186,  96, 166],\n",
       "         [186,  96, 166]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 97,  35,  68],\n",
       "         [ 97,  35,  68],\n",
       "         [ 97,  35,  68],\n",
       "         ...,\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26]],\n",
       " \n",
       "        [[ 97,  35,  68],\n",
       "         [ 97,  35,  68],\n",
       "         [ 97,  36,  67],\n",
       "         ...,\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26]],\n",
       " \n",
       "        [[ 97,  35,  68],\n",
       "         [ 97,  35,  68],\n",
       "         [ 97,  36,  67],\n",
       "         ...,\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3409000021056272, 'inference': 23.469899999327026, 'postprocess': 1.9945000021834858},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[238, 173, 197],\n",
       "         [238, 173, 197],\n",
       "         [238, 173, 197],\n",
       "         ...,\n",
       "         [176,  96, 164],\n",
       "         [186,  96, 166],\n",
       "         [186,  96, 166]],\n",
       " \n",
       "        [[238, 173, 197],\n",
       "         [238, 173, 197],\n",
       "         [238, 173, 197],\n",
       "         ...,\n",
       "         [176,  96, 164],\n",
       "         [186,  96, 166],\n",
       "         [186,  96, 166]],\n",
       " \n",
       "        [[238, 172, 199],\n",
       "         [238, 172, 199],\n",
       "         [238, 173, 197],\n",
       "         ...,\n",
       "         [176,  96, 164],\n",
       "         [186,  96, 166],\n",
       "         [186,  96, 166]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 97,  35,  68],\n",
       "         [ 97,  35,  68],\n",
       "         [ 97,  35,  68],\n",
       "         ...,\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26]],\n",
       " \n",
       "        [[ 97,  35,  68],\n",
       "         [ 97,  35,  68],\n",
       "         [ 97,  36,  67],\n",
       "         ...,\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26]],\n",
       " \n",
       "        [[ 97,  35,  68],\n",
       "         [ 97,  35,  68],\n",
       "         [ 97,  36,  67],\n",
       "         ...,\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26],\n",
       "         [ 80,  15,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2819000039598905, 'inference': 23.218599999381695, 'postprocess': 2.1498999994946644},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[195, 109, 146],\n",
       "         [186, 100, 137],\n",
       "         [182,  90, 133],\n",
       "         ...,\n",
       "         [193,  22, 128],\n",
       "         [195,  22, 133],\n",
       "         [198,  25, 136]],\n",
       " \n",
       "        [[197, 111, 148],\n",
       "         [187, 101, 138],\n",
       "         [184,  92, 135],\n",
       "         ...,\n",
       "         [193,  22, 128],\n",
       "         [195,  22, 133],\n",
       "         [198,  25, 136]],\n",
       " \n",
       "        [[201, 115, 152],\n",
       "         [189, 103, 140],\n",
       "         [185,  97, 136],\n",
       "         ...,\n",
       "         [193,  22, 128],\n",
       "         [195,  22, 133],\n",
       "         [198,  25, 136]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[100,  35,  71],\n",
       "         [101,  36,  72],\n",
       "         [101,  36,  72],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[ 98,  36,  71],\n",
       "         [ 98,  36,  71],\n",
       "         [ 99,  37,  72],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[ 98,  36,  71],\n",
       "         [ 98,  36,  71],\n",
       "         [ 98,  36,  71],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.688500000454951, 'inference': 23.560799992992543, 'postprocess': 2.8795000034733675},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[195, 109, 146],\n",
       "         [186, 100, 137],\n",
       "         [182,  90, 133],\n",
       "         ...,\n",
       "         [193,  22, 128],\n",
       "         [195,  22, 133],\n",
       "         [198,  25, 136]],\n",
       " \n",
       "        [[197, 111, 148],\n",
       "         [187, 101, 138],\n",
       "         [184,  92, 135],\n",
       "         ...,\n",
       "         [193,  22, 128],\n",
       "         [195,  22, 133],\n",
       "         [198,  25, 136]],\n",
       " \n",
       "        [[201, 115, 152],\n",
       "         [189, 103, 140],\n",
       "         [185,  97, 136],\n",
       "         ...,\n",
       "         [193,  22, 128],\n",
       "         [195,  22, 133],\n",
       "         [198,  25, 136]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[100,  35,  71],\n",
       "         [101,  36,  72],\n",
       "         [101,  36,  72],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[ 98,  36,  71],\n",
       "         [ 98,  36,  71],\n",
       "         [ 99,  37,  72],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[ 98,  36,  71],\n",
       "         [ 98,  36,  71],\n",
       "         [ 98,  36,  71],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2940000015078112, 'inference': 23.440500001015607, 'postprocess': 2.8609000000869855},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[191,  95, 143],\n",
       "         [191,  95, 143],\n",
       "         [190,  96, 144],\n",
       "         ...,\n",
       "         [150,  75, 154],\n",
       "         [150,  75, 154],\n",
       "         [150,  75, 154]],\n",
       " \n",
       "        [[192,  96, 144],\n",
       "         [192,  96, 144],\n",
       "         [189,  95, 143],\n",
       "         ...,\n",
       "         [150,  75, 154],\n",
       "         [150,  75, 154],\n",
       "         [150,  75, 154]],\n",
       " \n",
       "        [[192,  96, 144],\n",
       "         [193,  97, 145],\n",
       "         [192,  96, 144],\n",
       "         ...,\n",
       "         [152,  75, 154],\n",
       "         [152,  75, 154],\n",
       "         [152,  75, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[104,  39,  75],\n",
       "         [105,  40,  76],\n",
       "         [105,  40,  76],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[103,  38,  74],\n",
       "         [104,  39,  75],\n",
       "         [106,  39,  75],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[103,  38,  74],\n",
       "         [104,  39,  75],\n",
       "         [106,  39,  75],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5641000063624233, 'inference': 23.376199998892844, 'postprocess': 1.9020999970962293},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[191,  95, 143],\n",
       "         [191,  95, 143],\n",
       "         [190,  96, 144],\n",
       "         ...,\n",
       "         [150,  75, 154],\n",
       "         [150,  75, 154],\n",
       "         [150,  75, 154]],\n",
       " \n",
       "        [[192,  96, 144],\n",
       "         [192,  96, 144],\n",
       "         [189,  95, 143],\n",
       "         ...,\n",
       "         [150,  75, 154],\n",
       "         [150,  75, 154],\n",
       "         [150,  75, 154]],\n",
       " \n",
       "        [[192,  96, 144],\n",
       "         [193,  97, 145],\n",
       "         [192,  96, 144],\n",
       "         ...,\n",
       "         [152,  75, 154],\n",
       "         [152,  75, 154],\n",
       "         [152,  75, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[104,  39,  75],\n",
       "         [105,  40,  76],\n",
       "         [105,  40,  76],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[103,  38,  74],\n",
       "         [104,  39,  75],\n",
       "         [106,  39,  75],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[103,  38,  74],\n",
       "         [104,  39,  75],\n",
       "         [106,  39,  75],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2931000019307248, 'inference': 23.33790000557201, 'postprocess': 2.1447000035550445},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[207,  88, 142],\n",
       "         [212,  93, 147],\n",
       "         [216,  97, 151],\n",
       "         ...,\n",
       "         [106,  77, 171],\n",
       "         [106,  77, 171],\n",
       "         [104,  75, 169]],\n",
       " \n",
       "        [[193,  74, 128],\n",
       "         [202,  83, 137],\n",
       "         [204,  85, 139],\n",
       "         ...,\n",
       "         [105,  76, 170],\n",
       "         [105,  76, 170],\n",
       "         [102,  73, 167]],\n",
       " \n",
       "        [[176,  61, 112],\n",
       "         [180,  65, 116],\n",
       "         [186,  68, 120],\n",
       "         ...,\n",
       "         [104,  75, 169],\n",
       "         [104,  75, 169],\n",
       "         [102,  73, 167]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[105,  40,  76],\n",
       "         [106,  41,  77],\n",
       "         [106,  40,  79],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[105,  39,  78],\n",
       "         [106,  40,  79],\n",
       "         [106,  40,  79],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[105,  39,  78],\n",
       "         [104,  38,  77],\n",
       "         [106,  40,  79],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5294999975594692, 'inference': 23.404499996104278, 'postprocess': 2.1030999996582977},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[209,  90, 144],\n",
       "         [213,  94, 148],\n",
       "         [217,  98, 152],\n",
       "         ...,\n",
       "         [106,  77, 171],\n",
       "         [106,  77, 171],\n",
       "         [104,  75, 169]],\n",
       " \n",
       "        [[196,  77, 131],\n",
       "         [203,  84, 138],\n",
       "         [205,  86, 140],\n",
       "         ...,\n",
       "         [105,  76, 170],\n",
       "         [105,  76, 170],\n",
       "         [102,  73, 167]],\n",
       " \n",
       "        [[177,  62, 113],\n",
       "         [181,  66, 117],\n",
       "         [188,  70, 122],\n",
       "         ...,\n",
       "         [104,  75, 169],\n",
       "         [104,  75, 169],\n",
       "         [102,  73, 167]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[105,  40,  76],\n",
       "         [106,  41,  77],\n",
       "         [106,  40,  79],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[105,  39,  78],\n",
       "         [106,  40,  79],\n",
       "         [106,  40,  79],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[105,  39,  78],\n",
       "         [104,  38,  77],\n",
       "         [106,  40,  79],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3917999967816286, 'inference': 23.33599999838043, 'postprocess': 1.956599997356534},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[222, 105, 161],\n",
       "         [223, 106, 162],\n",
       "         [225, 108, 166],\n",
       "         ...,\n",
       "         [ 92,  69, 178],\n",
       "         [ 88,  63, 177],\n",
       "         [ 85,  60, 174]],\n",
       " \n",
       "        [[222, 105, 161],\n",
       "         [223, 106, 162],\n",
       "         [224, 107, 165],\n",
       "         ...,\n",
       "         [ 88,  65, 174],\n",
       "         [ 83,  58, 172],\n",
       "         [ 82,  57, 171]],\n",
       " \n",
       "        [[222, 106, 159],\n",
       "         [223, 107, 160],\n",
       "         [224, 107, 163],\n",
       "         ...,\n",
       "         [ 83,  62, 166],\n",
       "         [ 80,  57, 166],\n",
       "         [ 78,  55, 164]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[114,  48,  87],\n",
       "         [114,  48,  87],\n",
       "         [114,  48,  87],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[108,  42,  81],\n",
       "         [108,  42,  81],\n",
       "         [108,  42,  81],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[108,  42,  81],\n",
       "         [108,  42,  81],\n",
       "         [107,  41,  80],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1794000020017847, 'inference': 23.360899998806417, 'postprocess': 2.055800003290642},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[222, 105, 161],\n",
       "         [223, 106, 162],\n",
       "         [225, 108, 166],\n",
       "         ...,\n",
       "         [ 91,  68, 177],\n",
       "         [ 87,  62, 176],\n",
       "         [ 84,  59, 173]],\n",
       " \n",
       "        [[222, 105, 161],\n",
       "         [223, 106, 162],\n",
       "         [224, 107, 165],\n",
       "         ...,\n",
       "         [ 87,  64, 173],\n",
       "         [ 82,  57, 171],\n",
       "         [ 81,  56, 170]],\n",
       " \n",
       "        [[222, 106, 159],\n",
       "         [223, 107, 160],\n",
       "         [224, 107, 163],\n",
       "         ...,\n",
       "         [ 82,  61, 165],\n",
       "         [ 78,  55, 164],\n",
       "         [ 77,  54, 163]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[114,  48,  87],\n",
       "         [114,  48,  87],\n",
       "         [114,  48,  87],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[108,  42,  81],\n",
       "         [108,  42,  81],\n",
       "         [108,  42,  81],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]],\n",
       " \n",
       "        [[108,  42,  81],\n",
       "         [108,  42,  81],\n",
       "         [107,  41,  80],\n",
       "         ...,\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28],\n",
       "         [ 83,  15,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8385000003036112, 'inference': 23.68370000476716, 'postprocess': 2.9853999949409626},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[224, 104, 163],\n",
       "         [224, 104, 163],\n",
       "         [225, 103, 162],\n",
       "         ...,\n",
       "         [ 90,  75, 153],\n",
       "         [ 96,  81, 158],\n",
       "         [ 98,  83, 160]],\n",
       " \n",
       "        [[226, 106, 165],\n",
       "         [225, 105, 164],\n",
       "         [227, 105, 164],\n",
       "         ...,\n",
       "         [ 90,  75, 153],\n",
       "         [ 96,  81, 158],\n",
       "         [ 98,  83, 160]],\n",
       " \n",
       "        [[224, 107, 165],\n",
       "         [226, 109, 167],\n",
       "         [225, 105, 164],\n",
       "         ...,\n",
       "         [ 90,  75, 153],\n",
       "         [ 96,  81, 158],\n",
       "         [ 98,  83, 160]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[154,  89, 123],\n",
       "         [157,  92, 126],\n",
       "         [155,  93, 126],\n",
       "         ...,\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26]],\n",
       " \n",
       "        [[133,  68, 104],\n",
       "         [135,  70, 106],\n",
       "         [140,  75, 111],\n",
       "         ...,\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26]],\n",
       " \n",
       "        [[118,  53,  89],\n",
       "         [119,  54,  90],\n",
       "         [124,  59,  95],\n",
       "         ...,\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.252099999168422, 'inference': 29.86560000135796, 'postprocess': 3.9598000003024936},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[224, 104, 163],\n",
       "         [224, 104, 163],\n",
       "         [225, 103, 162],\n",
       "         ...,\n",
       "         [ 90,  75, 153],\n",
       "         [ 96,  81, 158],\n",
       "         [ 98,  83, 160]],\n",
       " \n",
       "        [[226, 106, 165],\n",
       "         [225, 105, 164],\n",
       "         [227, 105, 164],\n",
       "         ...,\n",
       "         [ 90,  75, 153],\n",
       "         [ 96,  81, 158],\n",
       "         [ 98,  83, 160]],\n",
       " \n",
       "        [[224, 107, 165],\n",
       "         [226, 109, 167],\n",
       "         [225, 105, 164],\n",
       "         ...,\n",
       "         [ 90,  75, 153],\n",
       "         [ 96,  81, 158],\n",
       "         [ 98,  83, 160]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[154,  89, 123],\n",
       "         [157,  92, 126],\n",
       "         [155,  93, 126],\n",
       "         ...,\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26]],\n",
       " \n",
       "        [[133,  68, 104],\n",
       "         [135,  70, 106],\n",
       "         [140,  75, 111],\n",
       "         ...,\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26]],\n",
       " \n",
       "        [[118,  53,  89],\n",
       "         [119,  54,  90],\n",
       "         [124,  59,  95],\n",
       "         ...,\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26],\n",
       "         [ 77,  13,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7389999993611127, 'inference': 24.352300002647098, 'postprocess': 4.33369999518618},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[220,  93, 158],\n",
       "         [218,  91, 156],\n",
       "         [220,  90, 157],\n",
       "         ...,\n",
       "         [177,  85, 168],\n",
       "         [183,  83, 168],\n",
       "         [183,  83, 168]],\n",
       " \n",
       "        [[221,  94, 159],\n",
       "         [221,  94, 159],\n",
       "         [223,  93, 160],\n",
       "         ...,\n",
       "         [177,  85, 168],\n",
       "         [183,  83, 168],\n",
       "         [183,  83, 168]],\n",
       " \n",
       "        [[219,  97, 161],\n",
       "         [218,  96, 160],\n",
       "         [221,  97, 161],\n",
       "         ...,\n",
       "         [177,  85, 168],\n",
       "         [183,  83, 168],\n",
       "         [183,  83, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[186, 116, 155],\n",
       "         [186, 116, 155],\n",
       "         [187, 114, 154],\n",
       "         ...,\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23]],\n",
       " \n",
       "        [[178, 108, 147],\n",
       "         [179, 109, 148],\n",
       "         [182, 107, 147],\n",
       "         ...,\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23]],\n",
       " \n",
       "        [[167,  97, 136],\n",
       "         [167,  97, 136],\n",
       "         [170,  95, 135],\n",
       "         ...,\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 5.952999999863096, 'inference': 42.315799997595605, 'postprocess': 5.3187999947112985},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[220,  93, 158],\n",
       "         [218,  91, 156],\n",
       "         [220,  90, 157],\n",
       "         ...,\n",
       "         [177,  85, 168],\n",
       "         [183,  83, 168],\n",
       "         [183,  83, 168]],\n",
       " \n",
       "        [[221,  94, 159],\n",
       "         [221,  94, 159],\n",
       "         [223,  93, 160],\n",
       "         ...,\n",
       "         [177,  85, 168],\n",
       "         [183,  83, 168],\n",
       "         [183,  83, 168]],\n",
       " \n",
       "        [[219,  97, 161],\n",
       "         [218,  96, 160],\n",
       "         [221,  97, 161],\n",
       "         ...,\n",
       "         [177,  85, 168],\n",
       "         [183,  83, 168],\n",
       "         [183,  83, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[186, 116, 155],\n",
       "         [186, 116, 155],\n",
       "         [187, 114, 154],\n",
       "         ...,\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23]],\n",
       " \n",
       "        [[178, 108, 147],\n",
       "         [179, 109, 148],\n",
       "         [182, 107, 147],\n",
       "         ...,\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23]],\n",
       " \n",
       "        [[167,  97, 136],\n",
       "         [167,  97, 136],\n",
       "         [170,  95, 135],\n",
       "         ...,\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23],\n",
       "         [ 73,  15,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.442299996095244, 'inference': 32.422399999632034, 'postprocess': 5.812800001876894},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[237,  95, 132],\n",
       "         [235,  93, 130],\n",
       "         [238,  94, 120],\n",
       "         ...,\n",
       "         [125,   9,  83],\n",
       "         [121,  10,  83],\n",
       "         [123,  12,  85]],\n",
       " \n",
       "        [[237,  95, 132],\n",
       "         [236,  94, 131],\n",
       "         [240,  96, 122],\n",
       "         ...,\n",
       "         [125,   9,  83],\n",
       "         [121,  10,  83],\n",
       "         [123,  12,  85]],\n",
       " \n",
       "        [[236,  97, 133],\n",
       "         [234,  95, 131],\n",
       "         [235,  95, 120],\n",
       "         ...,\n",
       "         [125,   9,  83],\n",
       "         [121,  10,  83],\n",
       "         [123,  12,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]],\n",
       " \n",
       "        [[194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]],\n",
       " \n",
       "        [[194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2227999943424948, 'inference': 26.653599998098798, 'postprocess': 2.199500006099697},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[237,  95, 132],\n",
       "         [235,  93, 130],\n",
       "         [238,  94, 120],\n",
       "         ...,\n",
       "         [125,   9,  83],\n",
       "         [121,  10,  83],\n",
       "         [123,  12,  85]],\n",
       " \n",
       "        [[237,  95, 132],\n",
       "         [236,  94, 131],\n",
       "         [240,  96, 122],\n",
       "         ...,\n",
       "         [125,   9,  83],\n",
       "         [121,  10,  83],\n",
       "         [123,  12,  85]],\n",
       " \n",
       "        [[236,  97, 133],\n",
       "         [234,  95, 131],\n",
       "         [235,  95, 120],\n",
       "         ...,\n",
       "         [125,   9,  83],\n",
       "         [121,  10,  83],\n",
       "         [123,  12,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]],\n",
       " \n",
       "        [[194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]],\n",
       " \n",
       "        [[194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3838000013493001, 'inference': 27.453299997432623, 'postprocess': 3.3445000008214265},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[247, 105,  90],\n",
       "         [247, 105,  90],\n",
       "         [247, 106,  89],\n",
       "         ...,\n",
       "         [ 94,  35, 100],\n",
       "         [ 94,  35, 100],\n",
       "         [ 94,  35, 100]],\n",
       " \n",
       "        [[247, 105,  90],\n",
       "         [247, 105,  90],\n",
       "         [247, 106,  89],\n",
       "         ...,\n",
       "         [ 94,  35, 100],\n",
       "         [ 94,  35, 100],\n",
       "         [ 94,  35, 100]],\n",
       " \n",
       "        [[245, 106,  92],\n",
       "         [245, 106,  92],\n",
       "         [245, 106,  90],\n",
       "         ...,\n",
       "         [ 94,  35, 100],\n",
       "         [ 94,  35, 100],\n",
       "         [ 94,  35, 100]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[192, 111, 149],\n",
       "         [192, 111, 149],\n",
       "         [192, 111, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]],\n",
       " \n",
       "        [[194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]],\n",
       " \n",
       "        [[194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         [194, 110, 149],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0125000010011718, 'inference': 33.60939999402035, 'postprocess': 4.778799993800931},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[249, 105,  90],\n",
       "         [249, 105,  90],\n",
       "         [249, 105,  90],\n",
       "         ...,\n",
       "         [ 92,  36, 100],\n",
       "         [ 92,  36, 100],\n",
       "         [ 92,  36, 100]],\n",
       " \n",
       "        [[249, 105,  90],\n",
       "         [249, 105,  90],\n",
       "         [249, 105,  90],\n",
       "         ...,\n",
       "         [ 92,  36, 100],\n",
       "         [ 92,  36, 100],\n",
       "         [ 92,  36, 100]],\n",
       " \n",
       "        [[247, 105,  90],\n",
       "         [247, 105,  90],\n",
       "         [247, 105,  90],\n",
       "         ...,\n",
       "         [ 92,  36, 100],\n",
       "         [ 92,  36, 100],\n",
       "         [ 92,  36, 100]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[189, 109, 150],\n",
       "         [189, 109, 150],\n",
       "         [189, 109, 150],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]],\n",
       " \n",
       "        [[191, 110, 148],\n",
       "         [191, 110, 148],\n",
       "         [191, 110, 148],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]],\n",
       " \n",
       "        [[191, 110, 148],\n",
       "         [191, 110, 148],\n",
       "         [191, 110, 148],\n",
       "         ...,\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23],\n",
       "         [ 69,  16,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.721400000154972, 'inference': 23.409599998558406, 'postprocess': 5.9115999974892475},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[246, 108,  90],\n",
       "         [246, 108,  90],\n",
       "         [246, 109,  88],\n",
       "         ...,\n",
       "         [ 88,  67, 150],\n",
       "         [ 84,  66, 152],\n",
       "         [ 84,  66, 152]],\n",
       " \n",
       "        [[246, 108,  90],\n",
       "         [246, 108,  90],\n",
       "         [246, 109,  88],\n",
       "         ...,\n",
       "         [ 88,  67, 150],\n",
       "         [ 84,  66, 152],\n",
       "         [ 84,  66, 152]],\n",
       " \n",
       "        [[244, 108,  90],\n",
       "         [244, 108,  90],\n",
       "         [244, 109,  88],\n",
       "         ...,\n",
       "         [ 88,  67, 150],\n",
       "         [ 84,  66, 152],\n",
       "         [ 84,  66, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[198, 114, 160],\n",
       "         [198, 114, 160],\n",
       "         [197, 115, 161],\n",
       "         ...,\n",
       "         [ 69,  18,  25],\n",
       "         [ 69,  18,  25],\n",
       "         [ 69,  18,  25]],\n",
       " \n",
       "        [[199, 113, 157],\n",
       "         [200, 114, 158],\n",
       "         [199, 116, 159],\n",
       "         ...,\n",
       "         [ 73,  22,  29],\n",
       "         [ 73,  22,  29],\n",
       "         [ 73,  22,  29]],\n",
       " \n",
       "        [[199, 113, 157],\n",
       "         [199, 113, 157],\n",
       "         [198, 115, 158],\n",
       "         ...,\n",
       "         [ 74,  23,  30],\n",
       "         [ 74,  23,  30],\n",
       "         [ 74,  23,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.240800004277844, 'inference': 32.69860000000335, 'postprocess': 5.765200003224891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[246, 108,  90],\n",
       "         [246, 108,  90],\n",
       "         [246, 109,  88],\n",
       "         ...,\n",
       "         [ 88,  67, 150],\n",
       "         [ 84,  66, 152],\n",
       "         [ 84,  66, 152]],\n",
       " \n",
       "        [[246, 108,  90],\n",
       "         [246, 108,  90],\n",
       "         [246, 109,  88],\n",
       "         ...,\n",
       "         [ 88,  67, 150],\n",
       "         [ 84,  66, 152],\n",
       "         [ 84,  66, 152]],\n",
       " \n",
       "        [[244, 108,  90],\n",
       "         [244, 108,  90],\n",
       "         [244, 109,  88],\n",
       "         ...,\n",
       "         [ 88,  67, 150],\n",
       "         [ 84,  66, 152],\n",
       "         [ 84,  66, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[198, 114, 160],\n",
       "         [198, 114, 160],\n",
       "         [197, 115, 161],\n",
       "         ...,\n",
       "         [ 69,  18,  25],\n",
       "         [ 69,  18,  25],\n",
       "         [ 69,  18,  25]],\n",
       " \n",
       "        [[199, 113, 157],\n",
       "         [200, 114, 158],\n",
       "         [199, 116, 159],\n",
       "         ...,\n",
       "         [ 73,  22,  29],\n",
       "         [ 73,  22,  29],\n",
       "         [ 73,  22,  29]],\n",
       " \n",
       "        [[199, 113, 157],\n",
       "         [199, 113, 157],\n",
       "         [198, 115, 158],\n",
       "         ...,\n",
       "         [ 74,  23,  30],\n",
       "         [ 74,  23,  30],\n",
       "         [ 74,  23,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5983999983291142, 'inference': 23.42789999966044, 'postprocess': 3.3752000017557293},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[246, 109,  80],\n",
       "         [244, 107,  78],\n",
       "         [243, 104,  75],\n",
       "         ...,\n",
       "         [128,  97, 180],\n",
       "         [140,  96, 183],\n",
       "         [140,  96, 183]],\n",
       " \n",
       "        [[248, 111,  82],\n",
       "         [246, 109,  80],\n",
       "         [245, 106,  77],\n",
       "         ...,\n",
       "         [126,  95, 178],\n",
       "         [138,  94, 181],\n",
       "         [140,  96, 183]],\n",
       " \n",
       "        [[246, 114,  84],\n",
       "         [243, 111,  81],\n",
       "         [242, 108,  78],\n",
       "         ...,\n",
       "         [125,  94, 177],\n",
       "         [137,  93, 180],\n",
       "         [140,  96, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[197, 130, 180],\n",
       "         [198, 131, 181],\n",
       "         [196, 130, 182],\n",
       "         ...,\n",
       "         [ 75,  17,  25],\n",
       "         [ 75,  17,  25],\n",
       "         [ 75,  17,  25]],\n",
       " \n",
       "        [[197, 127, 176],\n",
       "         [197, 127, 176],\n",
       "         [199, 127, 178],\n",
       "         ...,\n",
       "         [ 79,  21,  29],\n",
       "         [ 79,  21,  29],\n",
       "         [ 79,  21,  29]],\n",
       " \n",
       "        [[195, 125, 174],\n",
       "         [196, 126, 175],\n",
       "         [198, 126, 177],\n",
       "         ...,\n",
       "         [ 80,  22,  30],\n",
       "         [ 80,  22,  30],\n",
       "         [ 80,  22,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2879999994765967, 'inference': 33.074800005124416, 'postprocess': 4.969200002960861},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[246, 109,  80],\n",
       "         [244, 107,  78],\n",
       "         [243, 104,  75],\n",
       "         ...,\n",
       "         [128,  97, 180],\n",
       "         [140,  96, 183],\n",
       "         [140,  96, 183]],\n",
       " \n",
       "        [[248, 111,  82],\n",
       "         [246, 109,  80],\n",
       "         [245, 106,  77],\n",
       "         ...,\n",
       "         [126,  95, 178],\n",
       "         [138,  94, 181],\n",
       "         [140,  96, 183]],\n",
       " \n",
       "        [[246, 114,  84],\n",
       "         [243, 111,  81],\n",
       "         [242, 108,  78],\n",
       "         ...,\n",
       "         [125,  94, 177],\n",
       "         [137,  93, 180],\n",
       "         [140,  96, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[197, 130, 180],\n",
       "         [198, 131, 181],\n",
       "         [196, 130, 182],\n",
       "         ...,\n",
       "         [ 75,  17,  25],\n",
       "         [ 75,  17,  25],\n",
       "         [ 75,  17,  25]],\n",
       " \n",
       "        [[197, 127, 176],\n",
       "         [197, 127, 176],\n",
       "         [199, 127, 178],\n",
       "         ...,\n",
       "         [ 79,  21,  29],\n",
       "         [ 79,  21,  29],\n",
       "         [ 79,  21,  29]],\n",
       " \n",
       "        [[195, 125, 174],\n",
       "         [196, 126, 175],\n",
       "         [198, 126, 177],\n",
       "         ...,\n",
       "         [ 80,  22,  30],\n",
       "         [ 80,  22,  30],\n",
       "         [ 80,  22,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4683999979752116, 'inference': 31.466100001125596, 'postprocess': 3.923900003428571},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[240,  96,  88],\n",
       "         [247, 103,  95],\n",
       "         [246, 107, 105],\n",
       "         ...,\n",
       "         [176, 132, 180],\n",
       "         [179, 133, 180],\n",
       "         [179, 133, 180]],\n",
       " \n",
       "        [[241,  97,  89],\n",
       "         [247, 103,  95],\n",
       "         [248, 109, 107],\n",
       "         ...,\n",
       "         [176, 132, 180],\n",
       "         [179, 133, 180],\n",
       "         [180, 134, 181]],\n",
       " \n",
       "        [[239,  99,  88],\n",
       "         [245, 105,  94],\n",
       "         [243, 109, 104],\n",
       "         ...,\n",
       "         [178, 134, 182],\n",
       "         [180, 134, 181],\n",
       "         [183, 137, 184]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[206, 143, 194],\n",
       "         [205, 142, 193],\n",
       "         [206, 143, 194],\n",
       "         ...,\n",
       "         [ 84,  21,  30],\n",
       "         [ 84,  21,  30],\n",
       "         [ 84,  21,  30]],\n",
       " \n",
       "        [[208, 140, 192],\n",
       "         [208, 140, 192],\n",
       "         [209, 141, 193],\n",
       "         ...,\n",
       "         [ 86,  21,  30],\n",
       "         [ 86,  21,  30],\n",
       "         [ 86,  21,  30]],\n",
       " \n",
       "        [[204, 136, 188],\n",
       "         [204, 136, 188],\n",
       "         [204, 136, 188],\n",
       "         ...,\n",
       "         [ 86,  21,  30],\n",
       "         [ 86,  21,  30],\n",
       "         [ 86,  21,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9437000009929761, 'inference': 23.410499998135492, 'postprocess': 2.8202000030432828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[240,  96,  88],\n",
       "         [247, 103,  95],\n",
       "         [246, 107, 105],\n",
       "         ...,\n",
       "         [176, 132, 180],\n",
       "         [179, 133, 180],\n",
       "         [179, 133, 180]],\n",
       " \n",
       "        [[241,  97,  89],\n",
       "         [247, 103,  95],\n",
       "         [248, 109, 107],\n",
       "         ...,\n",
       "         [176, 132, 180],\n",
       "         [179, 133, 180],\n",
       "         [180, 134, 181]],\n",
       " \n",
       "        [[239,  99,  88],\n",
       "         [245, 105,  94],\n",
       "         [243, 109, 104],\n",
       "         ...,\n",
       "         [178, 134, 182],\n",
       "         [180, 134, 181],\n",
       "         [183, 137, 184]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[206, 143, 194],\n",
       "         [205, 142, 193],\n",
       "         [206, 143, 194],\n",
       "         ...,\n",
       "         [ 84,  21,  30],\n",
       "         [ 84,  21,  30],\n",
       "         [ 84,  21,  30]],\n",
       " \n",
       "        [[208, 140, 192],\n",
       "         [208, 140, 192],\n",
       "         [209, 141, 193],\n",
       "         ...,\n",
       "         [ 86,  21,  30],\n",
       "         [ 86,  21,  30],\n",
       "         [ 86,  21,  30]],\n",
       " \n",
       "        [[204, 136, 188],\n",
       "         [204, 136, 188],\n",
       "         [204, 136, 188],\n",
       "         ...,\n",
       "         [ 86,  21,  30],\n",
       "         [ 86,  21,  30],\n",
       "         [ 86,  21,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1299999934853986, 'inference': 23.72789999935776, 'postprocess': 2.13649999932386},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[245, 163, 190],\n",
       "         [245, 163, 190],\n",
       "         [245, 163, 188],\n",
       "         ...,\n",
       "         [185, 123, 172],\n",
       "         [178, 116, 165],\n",
       "         [175, 113, 162]],\n",
       " \n",
       "        [[246, 164, 191],\n",
       "         [246, 164, 191],\n",
       "         [246, 164, 189],\n",
       "         ...,\n",
       "         [185, 123, 172],\n",
       "         [178, 116, 165],\n",
       "         [175, 113, 162]],\n",
       " \n",
       "        [[244, 164, 191],\n",
       "         [244, 164, 191],\n",
       "         [244, 164, 191],\n",
       "         ...,\n",
       "         [185, 123, 172],\n",
       "         [178, 116, 165],\n",
       "         [175, 113, 162]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[211, 147, 206],\n",
       "         [211, 147, 206],\n",
       "         [211, 147, 206],\n",
       "         ...,\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28]],\n",
       " \n",
       "        [[213, 147, 206],\n",
       "         [213, 147, 206],\n",
       "         [213, 147, 206],\n",
       "         ...,\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28]],\n",
       " \n",
       "        [[213, 147, 206],\n",
       "         [213, 147, 206],\n",
       "         [214, 148, 207],\n",
       "         ...,\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3824999987264164, 'inference': 23.576599996886216, 'postprocess': 4.6208000057959},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[245, 163, 190],\n",
       "         [245, 163, 190],\n",
       "         [245, 163, 188],\n",
       "         ...,\n",
       "         [185, 123, 172],\n",
       "         [178, 116, 165],\n",
       "         [175, 113, 162]],\n",
       " \n",
       "        [[246, 164, 191],\n",
       "         [246, 164, 191],\n",
       "         [246, 164, 189],\n",
       "         ...,\n",
       "         [185, 123, 172],\n",
       "         [178, 116, 165],\n",
       "         [175, 113, 162]],\n",
       " \n",
       "        [[244, 164, 191],\n",
       "         [244, 164, 191],\n",
       "         [244, 164, 191],\n",
       "         ...,\n",
       "         [185, 123, 172],\n",
       "         [178, 116, 165],\n",
       "         [175, 113, 162]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[211, 147, 206],\n",
       "         [211, 147, 206],\n",
       "         [211, 147, 206],\n",
       "         ...,\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28]],\n",
       " \n",
       "        [[213, 147, 206],\n",
       "         [213, 147, 206],\n",
       "         [213, 147, 206],\n",
       "         ...,\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28]],\n",
       " \n",
       "        [[213, 147, 206],\n",
       "         [213, 147, 206],\n",
       "         [214, 148, 207],\n",
       "         ...,\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28],\n",
       "         [ 96,  17,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.643200001330115, 'inference': 24.76359999855049, 'postprocess': 3.631899999163579},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[249, 141, 138],\n",
       "         [242, 134, 131],\n",
       "         [237, 126, 112],\n",
       "         ...,\n",
       "         [126,  78, 171],\n",
       "         [130,  77, 171],\n",
       "         [132,  79, 173]],\n",
       " \n",
       "        [[253, 145, 142],\n",
       "         [243, 135, 132],\n",
       "         [239, 128, 114],\n",
       "         ...,\n",
       "         [126,  78, 171],\n",
       "         [130,  77, 171],\n",
       "         [132,  79, 173]],\n",
       " \n",
       "        [[245, 147, 147],\n",
       "         [236, 138, 138],\n",
       "         [232, 130, 120],\n",
       "         ...,\n",
       "         [123,  76, 173],\n",
       "         [128,  77, 172],\n",
       "         [128,  77, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[210, 151, 209],\n",
       "         [210, 151, 209],\n",
       "         [210, 151, 209],\n",
       "         ...,\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28]],\n",
       " \n",
       "        [[214, 150, 209],\n",
       "         [214, 150, 209],\n",
       "         [214, 150, 209],\n",
       "         ...,\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28]],\n",
       " \n",
       "        [[213, 149, 208],\n",
       "         [213, 149, 208],\n",
       "         [213, 149, 208],\n",
       "         ...,\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2725999986287206, 'inference': 23.68650000425987, 'postprocess': 2.0405000032042153},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[249, 141, 138],\n",
       "         [242, 134, 131],\n",
       "         [237, 126, 112],\n",
       "         ...,\n",
       "         [126,  78, 171],\n",
       "         [130,  77, 171],\n",
       "         [132,  79, 173]],\n",
       " \n",
       "        [[253, 145, 142],\n",
       "         [243, 135, 132],\n",
       "         [239, 128, 114],\n",
       "         ...,\n",
       "         [126,  78, 171],\n",
       "         [130,  77, 171],\n",
       "         [132,  79, 173]],\n",
       " \n",
       "        [[245, 147, 147],\n",
       "         [236, 138, 138],\n",
       "         [232, 130, 120],\n",
       "         ...,\n",
       "         [123,  76, 173],\n",
       "         [128,  77, 172],\n",
       "         [128,  77, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[210, 151, 209],\n",
       "         [210, 151, 209],\n",
       "         [210, 151, 209],\n",
       "         ...,\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28]],\n",
       " \n",
       "        [[214, 150, 209],\n",
       "         [214, 150, 209],\n",
       "         [214, 150, 209],\n",
       "         ...,\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28]],\n",
       " \n",
       "        [[213, 149, 208],\n",
       "         [213, 149, 208],\n",
       "         [213, 149, 208],\n",
       "         ...,\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28],\n",
       "         [ 98,  16,  28]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.409200002148282, 'inference': 40.86010000173701, 'postprocess': 5.320900003425777},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[197,  89,  33],\n",
       "         [195,  87,  31],\n",
       "         [193,  87,  31],\n",
       "         ...,\n",
       "         [ 83,  59, 211],\n",
       "         [ 83,  57, 214],\n",
       "         [ 83,  57, 214]],\n",
       " \n",
       "        [[200,  92,  36],\n",
       "         [199,  91,  35],\n",
       "         [197,  91,  35],\n",
       "         ...,\n",
       "         [ 83,  59, 211],\n",
       "         [ 83,  57, 214],\n",
       "         [ 83,  57, 214]],\n",
       " \n",
       "        [[190,  95,  40],\n",
       "         [190,  95,  40],\n",
       "         [189,  94,  39],\n",
       "         ...,\n",
       "         [ 82,  58, 210],\n",
       "         [ 82,  56, 213],\n",
       "         [ 82,  56, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[210, 153, 206],\n",
       "         [212, 155, 208],\n",
       "         [214, 154, 208],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]],\n",
       " \n",
       "        [[212, 152, 206],\n",
       "         [214, 154, 208],\n",
       "         [216, 154, 208],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]],\n",
       " \n",
       "        [[211, 151, 205],\n",
       "         [211, 151, 205],\n",
       "         [216, 154, 208],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.517600001534447, 'inference': 24.984399999084417, 'postprocess': 5.616900001768954},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[197,  89,  33],\n",
       "         [195,  87,  31],\n",
       "         [193,  87,  31],\n",
       "         ...,\n",
       "         [ 83,  59, 211],\n",
       "         [ 83,  57, 214],\n",
       "         [ 83,  57, 214]],\n",
       " \n",
       "        [[200,  92,  36],\n",
       "         [199,  91,  35],\n",
       "         [197,  91,  35],\n",
       "         ...,\n",
       "         [ 83,  59, 211],\n",
       "         [ 83,  57, 214],\n",
       "         [ 83,  57, 214]],\n",
       " \n",
       "        [[190,  95,  40],\n",
       "         [189,  94,  39],\n",
       "         [189,  94,  39],\n",
       "         ...,\n",
       "         [ 83,  59, 211],\n",
       "         [ 83,  57, 214],\n",
       "         [ 83,  57, 214]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[210, 153, 206],\n",
       "         [212, 155, 208],\n",
       "         [214, 154, 208],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]],\n",
       " \n",
       "        [[212, 152, 206],\n",
       "         [214, 154, 208],\n",
       "         [216, 154, 208],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]],\n",
       " \n",
       "        [[211, 151, 205],\n",
       "         [211, 151, 205],\n",
       "         [216, 154, 208],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.750499999616295, 'inference': 23.54660000128206, 'postprocess': 5.5444000026909634},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[167,  98,  39],\n",
       "         [169, 100,  41],\n",
       "         [167, 103,  43],\n",
       "         ...,\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214]],\n",
       " \n",
       "        [[166,  97,  38],\n",
       "         [168,  99,  40],\n",
       "         [165, 101,  41],\n",
       "         ...,\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214]],\n",
       " \n",
       "        [[163,  98,  41],\n",
       "         [163,  98,  41],\n",
       "         [160, 101,  40],\n",
       "         ...,\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[204, 144, 198],\n",
       "         [200, 140, 194],\n",
       "         [200, 137, 188],\n",
       "         ...,\n",
       "         [100,  18,  30],\n",
       "         [100,  18,  30],\n",
       "         [100,  18,  30]],\n",
       " \n",
       "        [[202, 136, 188],\n",
       "         [198, 132, 184],\n",
       "         [199, 129, 180],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]],\n",
       " \n",
       "        [[194, 128, 180],\n",
       "         [192, 126, 178],\n",
       "         [192, 122, 173],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3235000005806796, 'inference': 25.100899998506065, 'postprocess': 6.642200001806486},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[167,  98,  39],\n",
       "         [169, 100,  41],\n",
       "         [167, 103,  43],\n",
       "         ...,\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214]],\n",
       " \n",
       "        [[166,  97,  38],\n",
       "         [168,  99,  40],\n",
       "         [165, 101,  41],\n",
       "         ...,\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214]],\n",
       " \n",
       "        [[163,  98,  41],\n",
       "         [163,  98,  41],\n",
       "         [160, 101,  40],\n",
       "         ...,\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214],\n",
       "         [ 59,  55, 214]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[204, 144, 198],\n",
       "         [200, 140, 194],\n",
       "         [200, 137, 188],\n",
       "         ...,\n",
       "         [100,  18,  30],\n",
       "         [100,  18,  30],\n",
       "         [100,  18,  30]],\n",
       " \n",
       "        [[202, 136, 188],\n",
       "         [198, 132, 184],\n",
       "         [199, 129, 180],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]],\n",
       " \n",
       "        [[194, 128, 180],\n",
       "         [192, 126, 178],\n",
       "         [192, 122, 173],\n",
       "         ...,\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30],\n",
       "         [102,  18,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.5605999981053174, 'inference': 34.57469999557361, 'postprocess': 6.057200000213925},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[146, 127,  60],\n",
       "         [146, 127,  60],\n",
       "         [146, 127,  60],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        [[146, 127,  60],\n",
       "         [146, 127,  60],\n",
       "         [146, 127,  60],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        [[144, 128,  60],\n",
       "         [144, 128,  60],\n",
       "         [144, 128,  60],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[172,  99, 145],\n",
       "         [162,  89, 135],\n",
       "         [154,  81, 127],\n",
       "         ...,\n",
       "         [ 94,  19,  30],\n",
       "         [ 94,  19,  30],\n",
       "         [ 94,  19,  30]],\n",
       " \n",
       "        [[168,  89, 134],\n",
       "         [160,  81, 126],\n",
       "         [152,  75, 120],\n",
       "         ...,\n",
       "         [ 96,  19,  30],\n",
       "         [ 96,  19,  30],\n",
       "         [ 96,  19,  30]],\n",
       " \n",
       "        [[163,  84, 129],\n",
       "         [156,  77, 122],\n",
       "         [148,  71, 116],\n",
       "         ...,\n",
       "         [ 96,  19,  30],\n",
       "         [ 96,  19,  30],\n",
       "         [ 96,  19,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.6559999969322234, 'inference': 38.054500000725966, 'postprocess': 4.03359999472741},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[146, 127,  60],\n",
       "         [146, 127,  60],\n",
       "         [146, 127,  60],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        [[146, 127,  60],\n",
       "         [146, 127,  60],\n",
       "         [146, 127,  60],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        [[144, 128,  60],\n",
       "         [144, 128,  60],\n",
       "         [144, 128,  60],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[172,  99, 145],\n",
       "         [162,  89, 135],\n",
       "         [154,  81, 127],\n",
       "         ...,\n",
       "         [ 94,  19,  30],\n",
       "         [ 94,  19,  30],\n",
       "         [ 94,  19,  30]],\n",
       " \n",
       "        [[168,  89, 134],\n",
       "         [160,  81, 126],\n",
       "         [152,  75, 120],\n",
       "         ...,\n",
       "         [ 96,  19,  30],\n",
       "         [ 96,  19,  30],\n",
       "         [ 96,  19,  30]],\n",
       " \n",
       "        [[163,  84, 129],\n",
       "         [156,  77, 122],\n",
       "         [148,  71, 116],\n",
       "         ...,\n",
       "         [ 96,  19,  30],\n",
       "         [ 96,  19,  30],\n",
       "         [ 96,  19,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6340999936801381, 'inference': 27.149900000949856, 'postprocess': 3.3723000015015714},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[147, 133,  65],\n",
       "         [146, 132,  64],\n",
       "         [147, 133,  65],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        [[147, 133,  65],\n",
       "         [146, 132,  64],\n",
       "         [147, 133,  65],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        [[143, 134,  65],\n",
       "         [142, 133,  64],\n",
       "         [143, 134,  65],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[103,  38,  86],\n",
       "         [103,  38,  86],\n",
       "         [104,  39,  87],\n",
       "         ...,\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31]],\n",
       " \n",
       "        [[103,  38,  86],\n",
       "         [103,  38,  86],\n",
       "         [104,  39,  87],\n",
       "         ...,\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31]],\n",
       " \n",
       "        [[103,  38,  86],\n",
       "         [103,  38,  86],\n",
       "         [104,  39,  87],\n",
       "         ...,\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.328400001511909, 'inference': 23.470400003134273, 'postprocess': 2.193199994508177},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[147, 133,  65],\n",
       "         [146, 132,  64],\n",
       "         [147, 133,  65],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        [[147, 133,  65],\n",
       "         [146, 132,  64],\n",
       "         [147, 133,  65],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        [[143, 134,  65],\n",
       "         [142, 133,  64],\n",
       "         [143, 134,  65],\n",
       "         ...,\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214],\n",
       "         [ 55,  56, 214]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[103,  38,  86],\n",
       "         [103,  38,  86],\n",
       "         [104,  39,  87],\n",
       "         ...,\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31]],\n",
       " \n",
       "        [[103,  38,  86],\n",
       "         [103,  38,  86],\n",
       "         [104,  39,  87],\n",
       "         ...,\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31]],\n",
       " \n",
       "        [[103,  38,  86],\n",
       "         [103,  38,  86],\n",
       "         [104,  39,  87],\n",
       "         ...,\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31],\n",
       "         [ 93,  21,  31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.295499998377636, 'inference': 23.494899993238505, 'postprocess': 3.7415000042528845},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[133, 127,  54],\n",
       "         [134, 128,  55],\n",
       "         [135, 129,  57],\n",
       "         ...,\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212]],\n",
       " \n",
       "        [[133, 127,  54],\n",
       "         [134, 128,  55],\n",
       "         [135, 129,  57],\n",
       "         ...,\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212]],\n",
       " \n",
       "        [[133, 127,  54],\n",
       "         [134, 128,  55],\n",
       "         [134, 128,  56],\n",
       "         ...,\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[108,  35,  81],\n",
       "         [105,  32,  78],\n",
       "         [106,  31,  76],\n",
       "         ...,\n",
       "         [ 85,  22,  31],\n",
       "         [ 85,  22,  31],\n",
       "         [ 85,  22,  31]],\n",
       " \n",
       "        [[103,  32,  78],\n",
       "         [101,  30,  76],\n",
       "         [103,  31,  75],\n",
       "         ...,\n",
       "         [ 85,  22,  31],\n",
       "         [ 85,  22,  31],\n",
       "         [ 85,  22,  31]],\n",
       " \n",
       "        [[103,  32,  78],\n",
       "         [101,  30,  76],\n",
       "         [103,  31,  75],\n",
       "         ...,\n",
       "         [ 85,  22,  31],\n",
       "         [ 85,  22,  31],\n",
       "         [ 85,  22,  31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4713000055053271, 'inference': 23.45229999627918, 'postprocess': 1.9276000020909123},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[133, 127,  54],\n",
       "         [134, 128,  55],\n",
       "         [135, 129,  57],\n",
       "         ...,\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212]],\n",
       " \n",
       "        [[133, 127,  54],\n",
       "         [134, 128,  55],\n",
       "         [135, 129,  57],\n",
       "         ...,\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212]],\n",
       " \n",
       "        [[133, 127,  54],\n",
       "         [134, 128,  55],\n",
       "         [134, 128,  56],\n",
       "         ...,\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212],\n",
       "         [ 55,  57, 212]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[108,  35,  81],\n",
       "         [105,  32,  78],\n",
       "         [106,  31,  76],\n",
       "         ...,\n",
       "         [ 87,  22,  31],\n",
       "         [ 87,  22,  31],\n",
       "         [ 87,  22,  31]],\n",
       " \n",
       "        [[103,  32,  78],\n",
       "         [101,  30,  76],\n",
       "         [103,  31,  75],\n",
       "         ...,\n",
       "         [ 87,  22,  31],\n",
       "         [ 87,  22,  31],\n",
       "         [ 87,  22,  31]],\n",
       " \n",
       "        [[103,  32,  78],\n",
       "         [101,  30,  76],\n",
       "         [103,  31,  75],\n",
       "         ...,\n",
       "         [ 87,  22,  31],\n",
       "         [ 87,  22,  31],\n",
       "         [ 87,  22,  31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8751000025076792, 'inference': 39.776800003892276, 'postprocess': 5.0325000047450885},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[154,  72, 131],\n",
       "         [147,  65, 124],\n",
       "         [148,  50, 130],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[154,  72, 131],\n",
       "         [145,  63, 122],\n",
       "         [149,  51, 131],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[151,  68, 130],\n",
       "         [145,  62, 124],\n",
       "         [149,  50, 133],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         ...,\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35]],\n",
       " \n",
       "        [[ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         ...,\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35]],\n",
       " \n",
       "        [[ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         ...,\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3133999964338727, 'inference': 25.942499996745028, 'postprocess': 1.949999998032581},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[154,  72, 131],\n",
       "         [147,  65, 124],\n",
       "         [148,  50, 130],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[154,  72, 131],\n",
       "         [145,  63, 122],\n",
       "         [149,  51, 131],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[151,  68, 130],\n",
       "         [145,  62, 124],\n",
       "         [149,  50, 133],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         ...,\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35]],\n",
       " \n",
       "        [[ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         ...,\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35]],\n",
       " \n",
       "        [[ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         [ 90,  19,  40],\n",
       "         ...,\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35],\n",
       "         [ 95,  25,  35]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5878000049269758, 'inference': 23.303299996769056, 'postprocess': 6.671700000879355},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[156,  19, 127],\n",
       "         [156,  19, 127],\n",
       "         [154,  21, 125],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[156,  19, 127],\n",
       "         [156,  19, 127],\n",
       "         [154,  21, 125],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[150,  20, 127],\n",
       "         [150,  20, 127],\n",
       "         [146,  22, 125],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         ...,\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36]],\n",
       " \n",
       "        [[ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         ...,\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36]],\n",
       " \n",
       "        [[ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         ...,\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.8114000015193596, 'inference': 28.452300000935793, 'postprocess': 2.9887999990023673},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[156,  19, 127],\n",
       "         [156,  19, 127],\n",
       "         [154,  21, 125],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[156,  19, 127],\n",
       "         [156,  19, 127],\n",
       "         [154,  21, 125],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[150,  20, 127],\n",
       "         [150,  20, 127],\n",
       "         [146,  22, 125],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         ...,\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36]],\n",
       " \n",
       "        [[ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         ...,\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36]],\n",
       " \n",
       "        [[ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         [ 90,  21,  37],\n",
       "         ...,\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36],\n",
       "         [100,  25,  36]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6703000001143664, 'inference': 27.693700001691468, 'postprocess': 8.00370000069961},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[154,  20, 128],\n",
       "         [154,  20, 128],\n",
       "         [154,  20, 128],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[154,  20, 128],\n",
       "         [154,  20, 128],\n",
       "         [154,  20, 128],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[152,  20, 127],\n",
       "         [152,  20, 127],\n",
       "         [152,  20, 127],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[100,  22,  37],\n",
       "         [100,  22,  37],\n",
       "         [100,  22,  37],\n",
       "         ...,\n",
       "         [131,  59,  71],\n",
       "         [135,  63,  75],\n",
       "         [139,  67,  79]],\n",
       " \n",
       "        [[ 98,  22,  37],\n",
       "         [ 98,  22,  37],\n",
       "         [100,  23,  36],\n",
       "         ...,\n",
       "         [131,  59,  71],\n",
       "         [136,  64,  76],\n",
       "         [139,  67,  79]],\n",
       " \n",
       "        [[ 98,  22,  37],\n",
       "         [ 98,  22,  37],\n",
       "         [100,  23,  36],\n",
       "         ...,\n",
       "         [131,  59,  71],\n",
       "         [136,  64,  76],\n",
       "         [139,  67,  79]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6038000030675903, 'inference': 23.35770000354387, 'postprocess': 2.2595000045839697},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[154,  20, 128],\n",
       "         [154,  20, 128],\n",
       "         [154,  20, 128],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[154,  20, 128],\n",
       "         [154,  20, 128],\n",
       "         [154,  20, 128],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        [[152,  20, 127],\n",
       "         [152,  20, 127],\n",
       "         [152,  20, 127],\n",
       "         ...,\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210],\n",
       "         [ 55,  58, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[100,  22,  37],\n",
       "         [100,  22,  37],\n",
       "         [100,  22,  37],\n",
       "         ...,\n",
       "         [131,  59,  71],\n",
       "         [135,  63,  75],\n",
       "         [138,  66,  78]],\n",
       " \n",
       "        [[ 98,  22,  37],\n",
       "         [ 98,  22,  37],\n",
       "         [100,  23,  36],\n",
       "         ...,\n",
       "         [131,  59,  71],\n",
       "         [135,  63,  75],\n",
       "         [139,  67,  79]],\n",
       " \n",
       "        [[ 98,  22,  37],\n",
       "         [ 98,  22,  37],\n",
       "         [100,  23,  36],\n",
       "         ...,\n",
       "         [131,  59,  71],\n",
       "         [136,  64,  76],\n",
       "         [139,  67,  79]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9893999997293577, 'inference': 26.38219999789726, 'postprocess': 5.6650000042282045},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[142,  26, 134],\n",
       "         [142,  26, 134],\n",
       "         [142,  27, 132],\n",
       "         ...,\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209]],\n",
       " \n",
       "        [[142,  26, 134],\n",
       "         [142,  26, 134],\n",
       "         [142,  27, 132],\n",
       "         ...,\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209]],\n",
       " \n",
       "        [[142,  27, 132],\n",
       "         [143,  28, 133],\n",
       "         [141,  28, 133],\n",
       "         ...,\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[102,  21,  39],\n",
       "         [102,  21,  39],\n",
       "         [102,  21,  39],\n",
       "         ...,\n",
       "         [180,  21,  79],\n",
       "         [186,  19,  79],\n",
       "         [186,  19,  79]],\n",
       " \n",
       "        [[100,  21,  39],\n",
       "         [100,  21,  39],\n",
       "         [102,  22,  37],\n",
       "         ...,\n",
       "         [180,  23,  81],\n",
       "         [186,  22,  81],\n",
       "         [186,  22,  81]],\n",
       " \n",
       "        [[100,  21,  39],\n",
       "         [100,  21,  39],\n",
       "         [102,  22,  37],\n",
       "         ...,\n",
       "         [183,  26,  84],\n",
       "         [189,  25,  84],\n",
       "         [189,  25,  84]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6677000021445565, 'inference': 23.450000000593718, 'postprocess': 5.503499996848404},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[142,  26, 134],\n",
       "         [142,  26, 134],\n",
       "         [142,  27, 132],\n",
       "         ...,\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209]],\n",
       " \n",
       "        [[142,  26, 134],\n",
       "         [142,  26, 134],\n",
       "         [142,  27, 132],\n",
       "         ...,\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209]],\n",
       " \n",
       "        [[142,  27, 132],\n",
       "         [143,  28, 133],\n",
       "         [141,  28, 133],\n",
       "         ...,\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209],\n",
       "         [ 54,  57, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[102,  21,  39],\n",
       "         [102,  21,  39],\n",
       "         [102,  21,  39],\n",
       "         ...,\n",
       "         [178,  19,  77],\n",
       "         [184,  17,  77],\n",
       "         [184,  17,  77]],\n",
       " \n",
       "        [[100,  21,  39],\n",
       "         [100,  21,  39],\n",
       "         [102,  22,  37],\n",
       "         ...,\n",
       "         [179,  22,  80],\n",
       "         [185,  21,  80],\n",
       "         [185,  21,  80]],\n",
       " \n",
       "        [[100,  21,  39],\n",
       "         [100,  21,  39],\n",
       "         [102,  22,  37],\n",
       "         ...,\n",
       "         [182,  25,  83],\n",
       "         [188,  24,  83],\n",
       "         [188,  24,  83]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2350000033620745, 'inference': 23.421599995344877, 'postprocess': 3.358299996762071},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[192,  96, 164],\n",
       "         [192,  96, 164],\n",
       "         [192,  96, 164],\n",
       "         ...,\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208]],\n",
       " \n",
       "        [[187,  91, 159],\n",
       "         [187,  91, 159],\n",
       "         [188,  92, 160],\n",
       "         ...,\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208]],\n",
       " \n",
       "        [[180,  84, 152],\n",
       "         [181,  85, 153],\n",
       "         [183,  87, 155],\n",
       "         ...,\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 98,  19,  37],\n",
       "         [ 98,  19,  37],\n",
       "         [ 97,  18,  36],\n",
       "         ...,\n",
       "         [203,  42,  91],\n",
       "         [203,  43,  90],\n",
       "         [202,  42,  89]],\n",
       " \n",
       "        [[ 98,  19,  37],\n",
       "         [ 98,  19,  37],\n",
       "         [ 97,  18,  36],\n",
       "         ...,\n",
       "         [205,  44,  93],\n",
       "         [205,  45,  92],\n",
       "         [205,  45,  92]],\n",
       " \n",
       "        [[ 97,  18,  36],\n",
       "         [ 97,  18,  36],\n",
       "         [ 97,  18,  36],\n",
       "         ...,\n",
       "         [205,  44,  93],\n",
       "         [205,  45,  92],\n",
       "         [205,  45,  92]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2330999961704947, 'inference': 23.136799994972534, 'postprocess': 1.9405999992159195},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[192,  96, 164],\n",
       "         [192,  96, 164],\n",
       "         [192,  96, 164],\n",
       "         ...,\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208]],\n",
       " \n",
       "        [[187,  91, 159],\n",
       "         [187,  91, 159],\n",
       "         [188,  92, 160],\n",
       "         ...,\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208]],\n",
       " \n",
       "        [[180,  84, 152],\n",
       "         [181,  85, 153],\n",
       "         [183,  87, 155],\n",
       "         ...,\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208],\n",
       "         [ 54,  58, 208]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 98,  19,  37],\n",
       "         [ 98,  19,  37],\n",
       "         [ 97,  18,  36],\n",
       "         ...,\n",
       "         [203,  42,  91],\n",
       "         [203,  43,  90],\n",
       "         [202,  42,  89]],\n",
       " \n",
       "        [[ 98,  19,  37],\n",
       "         [ 98,  19,  37],\n",
       "         [ 97,  18,  36],\n",
       "         ...,\n",
       "         [205,  44,  93],\n",
       "         [205,  45,  92],\n",
       "         [205,  45,  92]],\n",
       " \n",
       "        [[ 97,  18,  36],\n",
       "         [ 97,  18,  36],\n",
       "         [ 97,  18,  36],\n",
       "         ...,\n",
       "         [205,  44,  93],\n",
       "         [205,  45,  92],\n",
       "         [205,  45,  92]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.414399994246196, 'inference': 23.64339999621734, 'postprocess': 4.0638999998918734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[185,  83, 175],\n",
       "         [177,  75, 167],\n",
       "         [168,  67, 163],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        [[191,  89, 181],\n",
       "         [186,  84, 176],\n",
       "         [175,  74, 170],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        [[197,  94, 177],\n",
       "         [192,  89, 172],\n",
       "         [182,  78, 169],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  17,  31],\n",
       "         [ 90,  17,  31],\n",
       "         [ 91,  18,  32],\n",
       "         ...,\n",
       "         [156,  51,  85],\n",
       "         [148,  50,  84],\n",
       "         [144,  46,  80]],\n",
       " \n",
       "        [[ 90,  17,  31],\n",
       "         [ 90,  17,  31],\n",
       "         [ 91,  18,  32],\n",
       "         ...,\n",
       "         [156,  51,  85],\n",
       "         [149,  51,  85],\n",
       "         [145,  47,  81]],\n",
       " \n",
       "        [[ 90,  17,  31],\n",
       "         [ 90,  17,  31],\n",
       "         [ 91,  18,  32],\n",
       "         ...,\n",
       "         [156,  51,  85],\n",
       "         [149,  51,  85],\n",
       "         [147,  49,  83]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2933999969391152, 'inference': 23.518699999840464, 'postprocess': 4.790300001332071},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[185,  83, 175],\n",
       "         [177,  75, 167],\n",
       "         [168,  67, 163],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        [[191,  89, 181],\n",
       "         [186,  84, 176],\n",
       "         [175,  74, 170],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        [[197,  94, 177],\n",
       "         [192,  89, 172],\n",
       "         [182,  78, 169],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  17,  31],\n",
       "         [ 90,  17,  31],\n",
       "         [ 91,  18,  32],\n",
       "         ...,\n",
       "         [156,  51,  85],\n",
       "         [148,  50,  84],\n",
       "         [144,  46,  80]],\n",
       " \n",
       "        [[ 90,  17,  31],\n",
       "         [ 90,  17,  31],\n",
       "         [ 91,  18,  32],\n",
       "         ...,\n",
       "         [156,  51,  85],\n",
       "         [149,  51,  85],\n",
       "         [145,  47,  81]],\n",
       " \n",
       "        [[ 90,  17,  31],\n",
       "         [ 90,  17,  31],\n",
       "         [ 91,  18,  32],\n",
       "         ...,\n",
       "         [156,  51,  85],\n",
       "         [149,  51,  85],\n",
       "         [147,  49,  83]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.081500002532266, 'inference': 28.377299997373484, 'postprocess': 4.614500001480337},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[115,   9, 140],\n",
       "         [114,   8, 139],\n",
       "         [113,   6, 140],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        [[126,  20, 151],\n",
       "         [121,  15, 146],\n",
       "         [118,  11, 145],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        [[139,  34, 156],\n",
       "         [134,  29, 151],\n",
       "         [127,  20, 147],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         ...,\n",
       "         [101,  94,  86],\n",
       "         [ 99,  98,  87],\n",
       "         [104, 103,  92]],\n",
       " \n",
       "        [[ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         ...,\n",
       "         [ 98,  91,  83],\n",
       "         [ 97,  96,  85],\n",
       "         [101, 100,  89]],\n",
       " \n",
       "        [[ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         ...,\n",
       "         [ 96,  89,  81],\n",
       "         [ 95,  94,  83],\n",
       "         [ 99,  98,  87]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.9272999963723123, 'inference': 25.996600001235493, 'postprocess': 3.991700003098231},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[115,   9, 140],\n",
       "         [114,   8, 139],\n",
       "         [113,   6, 140],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        [[126,  20, 151],\n",
       "         [121,  15, 146],\n",
       "         [118,  11, 145],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        [[139,  34, 156],\n",
       "         [134,  29, 151],\n",
       "         [127,  20, 147],\n",
       "         ...,\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206],\n",
       "         [ 54,  59, 206]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         ...,\n",
       "         [101,  94,  86],\n",
       "         [ 99,  98,  87],\n",
       "         [104, 103,  92]],\n",
       " \n",
       "        [[ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         ...,\n",
       "         [ 98,  91,  83],\n",
       "         [ 97,  96,  85],\n",
       "         [101, 100,  89]],\n",
       " \n",
       "        [[ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         [ 96,  22,  39],\n",
       "         ...,\n",
       "         [ 96,  89,  81],\n",
       "         [ 95,  94,  83],\n",
       "         [ 99,  98,  87]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.06389999948442, 'inference': 23.56780000263825, 'postprocess': 6.437699994421564},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[113,  10, 132],\n",
       "         [113,  10, 132],\n",
       "         [117,  12, 127],\n",
       "         ...,\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205]],\n",
       " \n",
       "        [[113,  10, 132],\n",
       "         [113,  10, 132],\n",
       "         [117,  12, 127],\n",
       "         ...,\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205]],\n",
       " \n",
       "        [[117,  13, 132],\n",
       "         [117,  13, 132],\n",
       "         [119,  14, 128],\n",
       "         ...,\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         ...,\n",
       "         [200, 109, 115],\n",
       "         [208, 107, 117],\n",
       "         [208, 107, 117]],\n",
       " \n",
       "        [[ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         ...,\n",
       "         [200, 109, 115],\n",
       "         [208, 107, 117],\n",
       "         [208, 107, 117]],\n",
       " \n",
       "        [[ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         ...,\n",
       "         [200, 109, 115],\n",
       "         [208, 107, 117],\n",
       "         [208, 107, 117]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5120000025490299, 'inference': 23.442999998223968, 'postprocess': 2.4011999994399957},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[113,  10, 132],\n",
       "         [113,  10, 132],\n",
       "         [117,  12, 127],\n",
       "         ...,\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205]],\n",
       " \n",
       "        [[113,  10, 132],\n",
       "         [113,  10, 132],\n",
       "         [117,  12, 127],\n",
       "         ...,\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205]],\n",
       " \n",
       "        [[117,  13, 132],\n",
       "         [117,  13, 132],\n",
       "         [119,  14, 128],\n",
       "         ...,\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205],\n",
       "         [ 68,  60, 205]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         ...,\n",
       "         [200, 109, 115],\n",
       "         [208, 107, 117],\n",
       "         [208, 107, 117]],\n",
       " \n",
       "        [[ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         ...,\n",
       "         [200, 109, 115],\n",
       "         [208, 107, 117],\n",
       "         [208, 107, 117]],\n",
       " \n",
       "        [[ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         [ 86,  24,  39],\n",
       "         ...,\n",
       "         [200, 109, 115],\n",
       "         [208, 107, 117],\n",
       "         [208, 107, 117]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.433100005669985, 'inference': 23.4857000032207, 'postprocess': 2.1828000026289374},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[201,  49,  65],\n",
       "         [203,  51,  67],\n",
       "         [215,  55,  61],\n",
       "         ...,\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192]],\n",
       " \n",
       "        [[201,  49,  65],\n",
       "         [203,  51,  67],\n",
       "         [215,  55,  61],\n",
       "         ...,\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192]],\n",
       " \n",
       "        [[199,  51,  69],\n",
       "         [201,  53,  71],\n",
       "         [209,  55,  64],\n",
       "         ...,\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         ...,\n",
       "         [245,  81, 121],\n",
       "         [249,  81, 125],\n",
       "         [249,  81, 125]],\n",
       " \n",
       "        [[ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         ...,\n",
       "         [248,  78, 122],\n",
       "         [251,  78, 123],\n",
       "         [251,  78, 123]],\n",
       " \n",
       "        [[ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         ...,\n",
       "         [247,  77, 121],\n",
       "         [250,  77, 122],\n",
       "         [250,  77, 122]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6071999998530373, 'inference': 23.64070000476204, 'postprocess': 3.6169000013615005},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[202,  50,  66],\n",
       "         [204,  52,  68],\n",
       "         [217,  57,  63],\n",
       "         ...,\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192]],\n",
       " \n",
       "        [[202,  50,  66],\n",
       "         [204,  52,  68],\n",
       "         [215,  55,  61],\n",
       "         ...,\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192]],\n",
       " \n",
       "        [[200,  52,  70],\n",
       "         [201,  53,  71],\n",
       "         [209,  55,  64],\n",
       "         ...,\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192],\n",
       "         [ 83,  55, 192]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         ...,\n",
       "         [245,  81, 121],\n",
       "         [249,  81, 125],\n",
       "         [249,  81, 125]],\n",
       " \n",
       "        [[ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         ...,\n",
       "         [248,  78, 122],\n",
       "         [251,  78, 123],\n",
       "         [251,  78, 123]],\n",
       " \n",
       "        [[ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         [ 90,  23,  39],\n",
       "         ...,\n",
       "         [247,  77, 121],\n",
       "         [250,  77, 122],\n",
       "         [250,  77, 122]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.829699998779688, 'inference': 24.331300002813805, 'postprocess': 3.6006999944220297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[233,  45,  35],\n",
       "         [229,  41,  31],\n",
       "         [231,  38,  29],\n",
       "         ...,\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200]],\n",
       " \n",
       "        [[233,  45,  35],\n",
       "         [229,  41,  31],\n",
       "         [232,  39,  30],\n",
       "         ...,\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200]],\n",
       " \n",
       "        [[235,  44,  35],\n",
       "         [231,  40,  31],\n",
       "         [232,  40,  28],\n",
       "         ...,\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 80,  23,  35],\n",
       "         ...,\n",
       "         [246, 106, 157],\n",
       "         [247, 107, 158],\n",
       "         [248, 108, 159]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 82,  23,  35],\n",
       "         ...,\n",
       "         [249, 102, 154],\n",
       "         [249, 104, 157],\n",
       "         [250, 105, 158]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 82,  23,  35],\n",
       "         ...,\n",
       "         [245,  98, 150],\n",
       "         [245, 100, 153],\n",
       "         [247, 102, 155]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.599700000951998, 'inference': 26.779599997098558, 'postprocess': 4.547799995634705},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[233,  45,  35],\n",
       "         [229,  41,  31],\n",
       "         [231,  38,  29],\n",
       "         ...,\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200]],\n",
       " \n",
       "        [[233,  45,  35],\n",
       "         [229,  41,  31],\n",
       "         [232,  39,  30],\n",
       "         ...,\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200]],\n",
       " \n",
       "        [[235,  44,  35],\n",
       "         [231,  40,  31],\n",
       "         [232,  40,  28],\n",
       "         ...,\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200],\n",
       "         [ 71,  56, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 80,  23,  35],\n",
       "         ...,\n",
       "         [246, 106, 157],\n",
       "         [247, 107, 158],\n",
       "         [248, 108, 159]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 82,  23,  35],\n",
       "         ...,\n",
       "         [249, 102, 154],\n",
       "         [249, 104, 157],\n",
       "         [250, 105, 158]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 82,  23,  35],\n",
       "         ...,\n",
       "         [245,  98, 150],\n",
       "         [245, 100, 153],\n",
       "         [247, 102, 155]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6306999968946911, 'inference': 24.905300000682473, 'postprocess': 2.77059999643825},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[219,  18,  24],\n",
       "         [223,  22,  28],\n",
       "         [226,  27,  35],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        [[216,  15,  21],\n",
       "         [220,  19,  25],\n",
       "         [223,  24,  32],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        [[216,  14,  18],\n",
       "         [218,  16,  20],\n",
       "         [222,  19,  25],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 80,  23,  35],\n",
       "         ...,\n",
       "         [157,  66, 125],\n",
       "         [157,  66, 125],\n",
       "         [157,  66, 125]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 82,  23,  35],\n",
       "         ...,\n",
       "         [155,  64, 123],\n",
       "         [155,  64, 123],\n",
       "         [155,  64, 123]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 82,  23,  35],\n",
       "         ...,\n",
       "         [153,  62, 121],\n",
       "         [153,  62, 121],\n",
       "         [153,  62, 121]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7083000057027675, 'inference': 28.044700004102197, 'postprocess': 4.953299998305738},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[220,  19,  25],\n",
       "         [225,  24,  30],\n",
       "         [227,  28,  36],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        [[216,  15,  21],\n",
       "         [221,  20,  26],\n",
       "         [223,  24,  32],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        [[217,  15,  19],\n",
       "         [218,  16,  20],\n",
       "         [223,  20,  26],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 80,  23,  35],\n",
       "         ...,\n",
       "         [157,  66, 125],\n",
       "         [157,  66, 125],\n",
       "         [157,  66, 125]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 82,  23,  35],\n",
       "         ...,\n",
       "         [155,  64, 123],\n",
       "         [155,  64, 123],\n",
       "         [155,  64, 123]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 82,  23,  35],\n",
       "         ...,\n",
       "         [153,  62, 121],\n",
       "         [153,  62, 121],\n",
       "         [153,  62, 121]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1110000016051345, 'inference': 27.285999996820465, 'postprocess': 5.771100004494656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[217,   0,   2],\n",
       "         [215,   0,   0],\n",
       "         [221,   0,   0],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        [[217,   0,   2],\n",
       "         [217,   0,   2],\n",
       "         [221,   0,   0],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        [[216,   0,   5],\n",
       "         [215,   0,   4],\n",
       "         [222,   0,   2],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         ...,\n",
       "         [154,  71, 128],\n",
       "         [157,  74, 131],\n",
       "         [160,  77, 134]],\n",
       " \n",
       "        [[ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         ...,\n",
       "         [154,  68, 126],\n",
       "         [156,  70, 128],\n",
       "         [161,  75, 133]],\n",
       " \n",
       "        [[ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         ...,\n",
       "         [153,  67, 125],\n",
       "         [155,  69, 127],\n",
       "         [156,  70, 128]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.588499995705206, 'inference': 23.433599999407306, 'postprocess': 2.147700004570652},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[217,   0,   2],\n",
       "         [215,   0,   0],\n",
       "         [221,   0,   0],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        [[217,   0,   2],\n",
       "         [217,   0,   2],\n",
       "         [221,   0,   0],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        [[216,   0,   5],\n",
       "         [215,   0,   4],\n",
       "         [222,   0,   2],\n",
       "         ...,\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205],\n",
       "         [ 71,  54, 205]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         ...,\n",
       "         [154,  71, 128],\n",
       "         [157,  74, 131],\n",
       "         [160,  77, 134]],\n",
       " \n",
       "        [[ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         ...,\n",
       "         [154,  68, 126],\n",
       "         [156,  70, 128],\n",
       "         [161,  75, 133]],\n",
       " \n",
       "        [[ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         [ 86,  22,  35],\n",
       "         ...,\n",
       "         [153,  67, 125],\n",
       "         [155,  69, 127],\n",
       "         [156,  70, 128]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2457999982871115, 'inference': 23.48820000042906, 'postprocess': 10.345299997425172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[226,   4,  13],\n",
       "         [226,   4,  13],\n",
       "         [226,   4,  13],\n",
       "         ...,\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203]],\n",
       " \n",
       "        [[229,   7,  16],\n",
       "         [229,   7,  16],\n",
       "         [229,   7,  16],\n",
       "         ...,\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203]],\n",
       " \n",
       "        [[228,   7,  19],\n",
       "         [228,   7,  19],\n",
       "         [229,   8,  20],\n",
       "         ...,\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         ...,\n",
       "         [150,  99, 140],\n",
       "         [154, 103, 144],\n",
       "         [155, 104, 145]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         ...,\n",
       "         [144,  93, 134],\n",
       "         [148,  97, 138],\n",
       "         [150,  99, 140]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         ...,\n",
       "         [137,  86, 127],\n",
       "         [141,  90, 131],\n",
       "         [144,  93, 134]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.756900004693307, 'inference': 42.72569999739062, 'postprocess': 7.10609999805456},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[226,   4,  13],\n",
       "         [226,   4,  13],\n",
       "         [226,   4,  13],\n",
       "         ...,\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203]],\n",
       " \n",
       "        [[229,   7,  16],\n",
       "         [229,   7,  16],\n",
       "         [229,   7,  16],\n",
       "         ...,\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203]],\n",
       " \n",
       "        [[228,   7,  19],\n",
       "         [228,   7,  19],\n",
       "         [229,   8,  20],\n",
       "         ...,\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203],\n",
       "         [ 73,  52, 203]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         ...,\n",
       "         [150,  99, 140],\n",
       "         [154, 103, 144],\n",
       "         [155, 104, 145]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         ...,\n",
       "         [144,  93, 134],\n",
       "         [148,  97, 138],\n",
       "         [150,  99, 140]],\n",
       " \n",
       "        [[ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         [ 84,  23,  35],\n",
       "         ...,\n",
       "         [137,  86, 127],\n",
       "         [141,  90, 131],\n",
       "         [144,  93, 134]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.658999994106125, 'inference': 24.259500001790002, 'postprocess': 3.5322999974596314},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[235,  26,  38],\n",
       "         [235,  26,  38],\n",
       "         [235,  26,  36],\n",
       "         ...,\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200]],\n",
       " \n",
       "        [[235,  26,  38],\n",
       "         [235,  26,  38],\n",
       "         [235,  26,  36],\n",
       "         ...,\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200]],\n",
       " \n",
       "        [[234,  27,  40],\n",
       "         [233,  26,  39],\n",
       "         [234,  28,  39],\n",
       "         ...,\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  28,  38],\n",
       "         [ 84,  28,  38],\n",
       "         [ 86,  28,  38],\n",
       "         ...,\n",
       "         [191, 129, 183],\n",
       "         [192, 130, 184],\n",
       "         [192, 130, 184]],\n",
       " \n",
       "        [[ 84,  28,  38],\n",
       "         [ 84,  28,  38],\n",
       "         [ 86,  28,  38],\n",
       "         ...,\n",
       "         [184, 121, 177],\n",
       "         [185, 122, 178],\n",
       "         [185, 122, 178]],\n",
       " \n",
       "        [[ 84,  28,  38],\n",
       "         [ 84,  28,  38],\n",
       "         [ 86,  28,  38],\n",
       "         ...,\n",
       "         [181, 118, 174],\n",
       "         [181, 118, 174],\n",
       "         [181, 118, 174]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.069499998469837, 'inference': 23.622500004421454, 'postprocess': 2.1474999957717955},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[235,  26,  38],\n",
       "         [235,  26,  38],\n",
       "         [235,  26,  36],\n",
       "         ...,\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200]],\n",
       " \n",
       "        [[235,  26,  38],\n",
       "         [235,  26,  38],\n",
       "         [235,  26,  36],\n",
       "         ...,\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200]],\n",
       " \n",
       "        [[234,  27,  40],\n",
       "         [233,  26,  39],\n",
       "         [234,  28,  39],\n",
       "         ...,\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200],\n",
       "         [ 82,  46, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  28,  38],\n",
       "         [ 84,  28,  38],\n",
       "         [ 86,  28,  38],\n",
       "         ...,\n",
       "         [191, 129, 183],\n",
       "         [192, 130, 184],\n",
       "         [192, 130, 184]],\n",
       " \n",
       "        [[ 84,  28,  38],\n",
       "         [ 84,  28,  38],\n",
       "         [ 86,  28,  38],\n",
       "         ...,\n",
       "         [184, 121, 177],\n",
       "         [185, 122, 178],\n",
       "         [185, 122, 178]],\n",
       " \n",
       "        [[ 84,  28,  38],\n",
       "         [ 84,  28,  38],\n",
       "         [ 86,  28,  38],\n",
       "         ...,\n",
       "         [181, 118, 174],\n",
       "         [181, 118, 174],\n",
       "         [181, 118, 174]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4793000009376556, 'inference': 29.237700000521727, 'postprocess': 4.908499999146443},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[237,  51,  75],\n",
       "         [243,  57,  81],\n",
       "         [237,  61,  88],\n",
       "         ...,\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200]],\n",
       " \n",
       "        [[239,  53,  77],\n",
       "         [247,  61,  85],\n",
       "         [241,  65,  92],\n",
       "         ...,\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200]],\n",
       " \n",
       "        [[236,  54,  79],\n",
       "         [246,  64,  89],\n",
       "         [241,  67,  94],\n",
       "         ...,\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         ...,\n",
       "         [124,  79, 116],\n",
       "         [108,  63, 100],\n",
       "         [ 96,  51,  88]],\n",
       " \n",
       "        [[ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         ...,\n",
       "         [159, 113, 160],\n",
       "         [149, 103, 150],\n",
       "         [137,  91, 138]],\n",
       " \n",
       "        [[ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         ...,\n",
       "         [189, 143, 190],\n",
       "         [183, 137, 184],\n",
       "         [176, 130, 177]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5660999997635372, 'inference': 26.28720000211615, 'postprocess': 6.70870000612922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[237,  51,  75],\n",
       "         [243,  57,  81],\n",
       "         [237,  61,  88],\n",
       "         ...,\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200]],\n",
       " \n",
       "        [[239,  53,  77],\n",
       "         [247,  61,  85],\n",
       "         [241,  65,  92],\n",
       "         ...,\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200]],\n",
       " \n",
       "        [[236,  54,  79],\n",
       "         [246,  64,  89],\n",
       "         [241,  67,  94],\n",
       "         ...,\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200],\n",
       "         [ 90,  45, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         ...,\n",
       "         [124,  79, 116],\n",
       "         [108,  63, 100],\n",
       "         [ 96,  51,  88]],\n",
       " \n",
       "        [[ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         ...,\n",
       "         [159, 113, 160],\n",
       "         [149, 103, 150],\n",
       "         [137,  91, 138]],\n",
       " \n",
       "        [[ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         [ 80,  36,  44],\n",
       "         ...,\n",
       "         [189, 143, 190],\n",
       "         [183, 137, 184],\n",
       "         [176, 130, 177]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.202900002885144, 'inference': 34.91270000085933, 'postprocess': 1.978100000997074},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[185,  50, 127],\n",
       "         [185,  50, 127],\n",
       "         [197,  50, 129],\n",
       "         ...,\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200]],\n",
       " \n",
       "        [[187,  52, 129],\n",
       "         [187,  52, 129],\n",
       "         [200,  53, 132],\n",
       "         ...,\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200]],\n",
       " \n",
       "        [[189,  54, 131],\n",
       "         [189,  54, 131],\n",
       "         [201,  54, 133],\n",
       "         ...,\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 78,  37,  44],\n",
       "         [ 77,  36,  43],\n",
       "         [ 79,  35,  43],\n",
       "         ...,\n",
       "         [ 94,  36,  57],\n",
       "         [ 92,  34,  55],\n",
       "         [ 92,  34,  55]],\n",
       " \n",
       "        [[ 78,  37,  44],\n",
       "         [ 77,  36,  43],\n",
       "         [ 79,  35,  43],\n",
       "         ...,\n",
       "         [ 96,  37,  63],\n",
       "         [ 94,  35,  61],\n",
       "         [ 92,  33,  59]],\n",
       " \n",
       "        [[ 78,  37,  44],\n",
       "         [ 77,  36,  43],\n",
       "         [ 79,  35,  43],\n",
       "         ...,\n",
       "         [ 98,  39,  65],\n",
       "         [ 94,  35,  61],\n",
       "         [ 92,  33,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7444999975850806, 'inference': 32.07950000069104, 'postprocess': 6.863499998871703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[185,  50, 127],\n",
       "         [185,  50, 127],\n",
       "         [197,  50, 129],\n",
       "         ...,\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200]],\n",
       " \n",
       "        [[187,  52, 129],\n",
       "         [187,  52, 129],\n",
       "         [200,  53, 132],\n",
       "         ...,\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200]],\n",
       " \n",
       "        [[189,  54, 131],\n",
       "         [189,  54, 131],\n",
       "         [201,  54, 133],\n",
       "         ...,\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200],\n",
       "         [ 94,  44, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 78,  37,  44],\n",
       "         [ 77,  36,  43],\n",
       "         [ 79,  35,  43],\n",
       "         ...,\n",
       "         [ 94,  36,  57],\n",
       "         [ 92,  34,  55],\n",
       "         [ 92,  34,  55]],\n",
       " \n",
       "        [[ 78,  37,  44],\n",
       "         [ 77,  36,  43],\n",
       "         [ 79,  35,  43],\n",
       "         ...,\n",
       "         [ 96,  37,  63],\n",
       "         [ 94,  35,  61],\n",
       "         [ 92,  33,  59]],\n",
       " \n",
       "        [[ 78,  37,  44],\n",
       "         [ 77,  36,  43],\n",
       "         [ 79,  35,  43],\n",
       "         ...,\n",
       "         [ 98,  39,  65],\n",
       "         [ 94,  35,  61],\n",
       "         [ 92,  33,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5848000039113685, 'inference': 23.448600004485343, 'postprocess': 4.098199999134522},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[198,  50, 113],\n",
       "         [193,  45, 108],\n",
       "         [178,  40, 111],\n",
       "         ...,\n",
       "         [103,  42, 200],\n",
       "         [103,  42, 200],\n",
       "         [103,  42, 200]],\n",
       " \n",
       "        [[199,  51, 114],\n",
       "         [193,  45, 108],\n",
       "         [178,  40, 111],\n",
       "         ...,\n",
       "         [103,  42, 200],\n",
       "         [103,  42, 200],\n",
       "         [103,  42, 200]],\n",
       " \n",
       "        [[199,  51, 114],\n",
       "         [195,  47, 110],\n",
       "         [180,  44, 110],\n",
       "         ...,\n",
       "         [104,  41, 199],\n",
       "         [104,  41, 199],\n",
       "         [104,  41, 199]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39]],\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39]],\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.31280000298284, 'inference': 33.019400005287025, 'postprocess': 6.525999997393228},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[198,  50, 113],\n",
       "         [193,  45, 108],\n",
       "         [178,  40, 111],\n",
       "         ...,\n",
       "         [103,  42, 200],\n",
       "         [103,  42, 200],\n",
       "         [103,  42, 200]],\n",
       " \n",
       "        [[199,  51, 114],\n",
       "         [193,  45, 108],\n",
       "         [178,  40, 111],\n",
       "         ...,\n",
       "         [103,  42, 200],\n",
       "         [103,  42, 200],\n",
       "         [103,  42, 200]],\n",
       " \n",
       "        [[199,  51, 114],\n",
       "         [195,  47, 110],\n",
       "         [180,  44, 110],\n",
       "         ...,\n",
       "         [104,  41, 199],\n",
       "         [104,  41, 199],\n",
       "         [104,  41, 199]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39]],\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39]],\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39],\n",
       "         [ 91,  31,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4892000035615638, 'inference': 23.39139999821782, 'postprocess': 4.545800002233591},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[119,   5, 113],\n",
       "         [121,   7, 115],\n",
       "         [121,  11, 114],\n",
       "         ...,\n",
       "         [149,  31, 191],\n",
       "         [151,  30, 191],\n",
       "         [151,  30, 191]],\n",
       " \n",
       "        [[120,   6, 114],\n",
       "         [122,   8, 116],\n",
       "         [123,  13, 116],\n",
       "         ...,\n",
       "         [149,  31, 191],\n",
       "         [151,  30, 191],\n",
       "         [151,  30, 191]],\n",
       " \n",
       "        [[117,   6, 113],\n",
       "         [119,   8, 115],\n",
       "         [119,  11, 115],\n",
       "         ...,\n",
       "         [151,  29, 193],\n",
       "         [153,  29, 193],\n",
       "         [153,  29, 193]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41]],\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41]],\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.241499998490326, 'inference': 28.732200000376906, 'postprocess': 4.6647000053781085},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[119,   5, 113],\n",
       "         [121,   7, 115],\n",
       "         [121,  11, 114],\n",
       "         ...,\n",
       "         [149,  31, 191],\n",
       "         [151,  30, 191],\n",
       "         [151,  30, 191]],\n",
       " \n",
       "        [[120,   6, 114],\n",
       "         [122,   8, 116],\n",
       "         [123,  13, 116],\n",
       "         ...,\n",
       "         [149,  31, 191],\n",
       "         [151,  30, 191],\n",
       "         [151,  30, 191]],\n",
       " \n",
       "        [[117,   6, 113],\n",
       "         [119,   8, 115],\n",
       "         [119,  11, 115],\n",
       "         ...,\n",
       "         [151,  29, 193],\n",
       "         [153,  29, 193],\n",
       "         [153,  29, 193]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41]],\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41]],\n",
       " \n",
       "        [[ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         [ 70,  22,  30],\n",
       "         ...,\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41],\n",
       "         [ 93,  33,  41]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2207999970996752, 'inference': 25.086300003749784, 'postprocess': 2.3654000033275224},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[248,  85, 121],\n",
       "         [248,  85, 121],\n",
       "         [248,  86, 119],\n",
       "         ...,\n",
       "         [198,  64, 123],\n",
       "         [198,  64, 123],\n",
       "         [198,  64, 123]],\n",
       " \n",
       "        [[248,  85, 121],\n",
       "         [248,  85, 121],\n",
       "         [248,  86, 119],\n",
       "         ...,\n",
       "         [203,  69, 128],\n",
       "         [203,  69, 128],\n",
       "         [203,  69, 128]],\n",
       " \n",
       "        [[248,  85, 121],\n",
       "         [248,  85, 121],\n",
       "         [248,  85, 121],\n",
       "         ...,\n",
       "         [205,  72, 144],\n",
       "         [205,  72, 144],\n",
       "         [205,  72, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35]],\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35]],\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4814000023761764, 'inference': 24.908999999752268, 'postprocess': 6.088400004955474},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[250,  83, 122],\n",
       "         [250,  83, 122],\n",
       "         [250,  83, 122],\n",
       "         ...,\n",
       "         [198,  63, 119],\n",
       "         [198,  63, 119],\n",
       "         [198,  63, 119]],\n",
       " \n",
       "        [[250,  83, 122],\n",
       "         [250,  83, 122],\n",
       "         [250,  83, 122],\n",
       "         ...,\n",
       "         [204,  69, 125],\n",
       "         [204,  69, 125],\n",
       "         [204,  69, 125]],\n",
       " \n",
       "        [[250,  83, 122],\n",
       "         [250,  83, 122],\n",
       "         [250,  83, 122],\n",
       "         ...,\n",
       "         [208,  72, 145],\n",
       "         [208,  72, 145],\n",
       "         [208,  72, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35]],\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35]],\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35],\n",
       "         [ 99,  24,  35]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.873699999123346, 'inference': 32.06350000255043, 'postprocess': 4.503399999521207},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[214,  56, 111],\n",
       "         [211,  53, 108],\n",
       "         [204,  48, 108],\n",
       "         ...,\n",
       "         [225,  80,  83],\n",
       "         [225,  80,  83],\n",
       "         [225,  80,  83]],\n",
       " \n",
       "        [[210,  52, 107],\n",
       "         [209,  51, 106],\n",
       "         [201,  45, 105],\n",
       "         ...,\n",
       "         [217,  72,  75],\n",
       "         [217,  72,  75],\n",
       "         [217,  72,  75]],\n",
       " \n",
       "        [[207,  49, 109],\n",
       "         [206,  48, 108],\n",
       "         [196,  45, 109],\n",
       "         ...,\n",
       "         [210,  64,  77],\n",
       "         [210,  64,  77],\n",
       "         [210,  64,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]],\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]],\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.355599997623358, 'inference': 26.702999995904975, 'postprocess': 6.1234000022523105},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[214,  56, 111],\n",
       "         [211,  53, 108],\n",
       "         [204,  48, 108],\n",
       "         ...,\n",
       "         [225,  80,  83],\n",
       "         [225,  80,  83],\n",
       "         [225,  80,  83]],\n",
       " \n",
       "        [[210,  52, 107],\n",
       "         [209,  51, 106],\n",
       "         [201,  45, 105],\n",
       "         ...,\n",
       "         [217,  72,  75],\n",
       "         [217,  72,  75],\n",
       "         [217,  72,  75]],\n",
       " \n",
       "        [[207,  49, 109],\n",
       "         [206,  48, 108],\n",
       "         [196,  45, 109],\n",
       "         ...,\n",
       "         [210,  64,  77],\n",
       "         [210,  64,  77],\n",
       "         [210,  64,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]],\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]],\n",
       " \n",
       "        [[ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         [ 74,  21,  30],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6040999980759807, 'inference': 24.159599997801706, 'postprocess': 2.18239999958314},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         ...,\n",
       "         [239,  79,  85],\n",
       "         [240,  80,  86],\n",
       "         [240,  80,  86]],\n",
       " \n",
       "        [[230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         ...,\n",
       "         [239,  79,  85],\n",
       "         [240,  80,  86],\n",
       "         [240,  80,  86]],\n",
       " \n",
       "        [[230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         ...,\n",
       "         [238,  78,  91],\n",
       "         [238,  78,  91],\n",
       "         [238,  78,  91]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2385999943944626, 'inference': 23.33550000184914, 'postprocess': 2.397799995378591},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         ...,\n",
       "         [239,  79,  85],\n",
       "         [240,  80,  86],\n",
       "         [240,  80,  86]],\n",
       " \n",
       "        [[230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         ...,\n",
       "         [239,  79,  85],\n",
       "         [240,  80,  86],\n",
       "         [240,  80,  86]],\n",
       " \n",
       "        [[230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         ...,\n",
       "         [238,  78,  91],\n",
       "         [238,  78,  91],\n",
       "         [238,  78,  91]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34],\n",
       "         [100,  23,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2916000050609, 'inference': 23.505999997723848, 'postprocess': 4.88970000151312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[227,  54, 119],\n",
       "         [227,  54, 119],\n",
       "         [227,  54, 119],\n",
       "         ...,\n",
       "         [244,  81,  95],\n",
       "         [246,  83,  97],\n",
       "         [246,  83,  97]],\n",
       " \n",
       "        [[224,  51, 116],\n",
       "         [224,  51, 116],\n",
       "         [224,  51, 116],\n",
       "         ...,\n",
       "         [244,  81,  95],\n",
       "         [246,  83,  97],\n",
       "         [246,  83,  97]],\n",
       " \n",
       "        [[230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         ...,\n",
       "         [244,  81,  95],\n",
       "         [246,  83,  97],\n",
       "         [246,  83,  97]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3913000002503395, 'inference': 23.398299999826122, 'postprocess': 1.9197000001440756},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[227,  54, 119],\n",
       "         [227,  54, 119],\n",
       "         [227,  54, 119],\n",
       "         ...,\n",
       "         [244,  81,  95],\n",
       "         [246,  83,  97],\n",
       "         [246,  83,  97]],\n",
       " \n",
       "        [[224,  51, 116],\n",
       "         [224,  51, 116],\n",
       "         [224,  51, 116],\n",
       "         ...,\n",
       "         [244,  81,  95],\n",
       "         [246,  83,  97],\n",
       "         [246,  83,  97]],\n",
       " \n",
       "        [[230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         [230,  49, 118],\n",
       "         ...,\n",
       "         [244,  81,  95],\n",
       "         [246,  83,  97],\n",
       "         [246,  83,  97]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32],\n",
       "         [102,  24,  32]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.0331000016303733, 'inference': 41.45379999681609, 'postprocess': 9.098800001083873},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[234,  52, 123],\n",
       "         [234,  52, 123],\n",
       "         [234,  52, 123],\n",
       "         ...,\n",
       "         [222,  54,  77],\n",
       "         [221,  53,  76],\n",
       "         [221,  53,  76]],\n",
       " \n",
       "        [[235,  53, 124],\n",
       "         [235,  53, 124],\n",
       "         [235,  53, 124],\n",
       "         ...,\n",
       "         [224,  56,  79],\n",
       "         [223,  55,  78],\n",
       "         [223,  55,  78]],\n",
       " \n",
       "        [[226,  52, 126],\n",
       "         [226,  52, 126],\n",
       "         [225,  51, 125],\n",
       "         ...,\n",
       "         [230,  62,  85],\n",
       "         [230,  62,  85],\n",
       "         [230,  62,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [ 91,  21,  31],\n",
       "         [ 91,  21,  31],\n",
       "         [ 92,  22,  32]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [ 92,  22,  32],\n",
       "         [ 92,  22,  32],\n",
       "         [ 94,  24,  34]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [ 92,  22,  32],\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.5950999988708645, 'inference': 28.103199998440687, 'postprocess': 9.975199995096773},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[234,  52, 123],\n",
       "         [234,  52, 123],\n",
       "         [234,  52, 123],\n",
       "         ...,\n",
       "         [222,  54,  77],\n",
       "         [221,  53,  76],\n",
       "         [221,  53,  76]],\n",
       " \n",
       "        [[235,  53, 124],\n",
       "         [235,  53, 124],\n",
       "         [235,  53, 124],\n",
       "         ...,\n",
       "         [224,  56,  79],\n",
       "         [223,  55,  78],\n",
       "         [223,  55,  78]],\n",
       " \n",
       "        [[226,  52, 126],\n",
       "         [226,  52, 126],\n",
       "         [225,  51, 125],\n",
       "         ...,\n",
       "         [230,  62,  85],\n",
       "         [230,  62,  85],\n",
       "         [230,  62,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [ 91,  21,  31],\n",
       "         [ 91,  21,  31],\n",
       "         [ 92,  22,  32]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [ 92,  22,  32],\n",
       "         [ 92,  22,  32],\n",
       "         [ 94,  24,  34]],\n",
       " \n",
       "        [[ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         [ 75,  22,  29],\n",
       "         ...,\n",
       "         [ 92,  22,  32],\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4060000030440278, 'inference': 23.298200001590885, 'postprocess': 3.7999999985913746},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[196,  27, 107],\n",
       "         [196,  27, 107],\n",
       "         [197,  27, 110],\n",
       "         ...,\n",
       "         [255, 196, 204],\n",
       "         [254, 198, 206],\n",
       "         [253, 197, 205]],\n",
       " \n",
       "        [[199,  30, 110],\n",
       "         [198,  29, 109],\n",
       "         [197,  27, 110],\n",
       "         ...,\n",
       "         [233, 173, 181],\n",
       "         [228, 172, 180],\n",
       "         [240, 184, 192]],\n",
       " \n",
       "        [[209,  41, 125],\n",
       "         [206,  38, 122],\n",
       "         [203,  36, 123],\n",
       "         ...,\n",
       "         [225, 134, 147],\n",
       "         [210, 126, 138],\n",
       "         [231, 147, 159]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [ 99,  32,  41],\n",
       "         [ 99,  32,  41],\n",
       "         [ 99,  32,  41]],\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [ 99,  29,  39],\n",
       "         [ 99,  29,  39],\n",
       "         [ 99,  29,  39]],\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [ 99,  29,  39],\n",
       "         [ 99,  29,  39],\n",
       "         [ 99,  29,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.240999998524785, 'inference': 33.67509999952745, 'postprocess': 4.863599999225698},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[196,  27, 107],\n",
       "         [196,  27, 107],\n",
       "         [197,  27, 110],\n",
       "         ...,\n",
       "         [255, 196, 204],\n",
       "         [254, 198, 206],\n",
       "         [252, 196, 204]],\n",
       " \n",
       "        [[199,  30, 110],\n",
       "         [198,  29, 109],\n",
       "         [197,  27, 110],\n",
       "         ...,\n",
       "         [233, 173, 181],\n",
       "         [228, 172, 180],\n",
       "         [243, 187, 195]],\n",
       " \n",
       "        [[209,  41, 125],\n",
       "         [206,  38, 122],\n",
       "         [203,  36, 123],\n",
       "         ...,\n",
       "         [223, 132, 145],\n",
       "         [208, 126, 138],\n",
       "         [236, 154, 166]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [ 99,  32,  41],\n",
       "         [ 99,  32,  41],\n",
       "         [ 99,  32,  41]],\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [ 99,  29,  39],\n",
       "         [ 99,  29,  39],\n",
       "         [ 99,  29,  39]],\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [ 99,  29,  39],\n",
       "         [ 99,  29,  39],\n",
       "         [ 99,  29,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6974000027403235, 'inference': 27.345400005287956, 'postprocess': 7.085800003551412},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[227,  23, 105],\n",
       "         [229,  25, 107],\n",
       "         [231,  28, 107],\n",
       "         ...,\n",
       "         [255, 211, 214],\n",
       "         [255, 211, 214],\n",
       "         [255, 211, 214]],\n",
       " \n",
       "        [[228,  24, 106],\n",
       "         [233,  29, 111],\n",
       "         [235,  32, 111],\n",
       "         ...,\n",
       "         [247, 202, 205],\n",
       "         [247, 202, 205],\n",
       "         [247, 202, 205]],\n",
       " \n",
       "        [[224,  25, 106],\n",
       "         [230,  31, 112],\n",
       "         [234,  37, 113],\n",
       "         ...,\n",
       "         [238, 195, 198],\n",
       "         [238, 195, 198],\n",
       "         [238, 195, 198]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39]],\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39]],\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8640999987837858, 'inference': 24.353500004508533, 'postprocess': 3.224599997338373},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[227,  23, 105],\n",
       "         [229,  25, 107],\n",
       "         [231,  28, 107],\n",
       "         ...,\n",
       "         [255, 211, 214],\n",
       "         [255, 211, 214],\n",
       "         [255, 211, 214]],\n",
       " \n",
       "        [[228,  24, 106],\n",
       "         [233,  29, 111],\n",
       "         [235,  32, 111],\n",
       "         ...,\n",
       "         [247, 202, 205],\n",
       "         [247, 202, 205],\n",
       "         [247, 202, 205]],\n",
       " \n",
       "        [[224,  25, 106],\n",
       "         [230,  31, 112],\n",
       "         [234,  37, 113],\n",
       "         ...,\n",
       "         [238, 195, 198],\n",
       "         [238, 195, 198],\n",
       "         [238, 195, 198]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39]],\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39]],\n",
       " \n",
       "        [[ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         [ 71,  23,  29],\n",
       "         ...,\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39],\n",
       "         [103,  28,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2233999950694852, 'inference': 23.46370000304887, 'postprocess': 3.3012999992934056},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[252, 101, 142],\n",
       "         [251, 100, 141],\n",
       "         [249,  95, 138],\n",
       "         ...,\n",
       "         [239, 233, 241],\n",
       "         [240, 234, 242],\n",
       "         [240, 234, 242]],\n",
       " \n",
       "        [[253, 102, 143],\n",
       "         [247,  96, 137],\n",
       "         [247,  93, 136],\n",
       "         ...,\n",
       "         [239, 233, 241],\n",
       "         [240, 234, 242],\n",
       "         [240, 234, 242]],\n",
       " \n",
       "        [[253,  99, 142],\n",
       "         [248,  94, 137],\n",
       "         [249,  88, 137],\n",
       "         ...,\n",
       "         [243, 233, 240],\n",
       "         [244, 234, 241],\n",
       "         [244, 234, 241]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 72,  24,  32],\n",
       "         [ 72,  24,  32],\n",
       "         [ 73,  25,  33],\n",
       "         ...,\n",
       "         [112,  36,  44],\n",
       "         [112,  36,  44],\n",
       "         [114,  38,  46]],\n",
       " \n",
       "        [[ 72,  24,  32],\n",
       "         [ 72,  24,  32],\n",
       "         [ 73,  25,  33],\n",
       "         ...,\n",
       "         [111,  35,  43],\n",
       "         [111,  35,  43],\n",
       "         [112,  36,  44]],\n",
       " \n",
       "        [[ 72,  24,  32],\n",
       "         [ 72,  24,  32],\n",
       "         [ 73,  25,  33],\n",
       "         ...,\n",
       "         [110,  34,  42],\n",
       "         [111,  35,  43],\n",
       "         [112,  36,  44]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5027999979793094, 'inference': 23.395500000333413, 'postprocess': 2.5640999956522137},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[252, 101, 142],\n",
       "         [251, 100, 141],\n",
       "         [249,  95, 138],\n",
       "         ...,\n",
       "         [239, 233, 241],\n",
       "         [240, 234, 242],\n",
       "         [240, 234, 242]],\n",
       " \n",
       "        [[253, 102, 143],\n",
       "         [247,  96, 137],\n",
       "         [247,  93, 136],\n",
       "         ...,\n",
       "         [239, 233, 241],\n",
       "         [240, 234, 242],\n",
       "         [240, 234, 242]],\n",
       " \n",
       "        [[253,  99, 142],\n",
       "         [248,  94, 137],\n",
       "         [249,  88, 137],\n",
       "         ...,\n",
       "         [243, 233, 240],\n",
       "         [244, 234, 241],\n",
       "         [244, 234, 241]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 72,  24,  32],\n",
       "         [ 72,  24,  32],\n",
       "         [ 73,  25,  33],\n",
       "         ...,\n",
       "         [112,  36,  44],\n",
       "         [112,  36,  44],\n",
       "         [114,  38,  46]],\n",
       " \n",
       "        [[ 72,  24,  32],\n",
       "         [ 72,  24,  32],\n",
       "         [ 73,  25,  33],\n",
       "         ...,\n",
       "         [111,  35,  43],\n",
       "         [111,  35,  43],\n",
       "         [112,  36,  44]],\n",
       " \n",
       "        [[ 72,  24,  32],\n",
       "         [ 72,  24,  32],\n",
       "         [ 73,  25,  33],\n",
       "         ...,\n",
       "         [110,  34,  42],\n",
       "         [111,  35,  43],\n",
       "         [112,  36,  44]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.5525999953970313, 'inference': 23.331600001256447, 'postprocess': 2.814400002534967},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[244,  23, 137],\n",
       "         [246,  25, 139],\n",
       "         [248,  23, 142],\n",
       "         ...,\n",
       "         [253, 187, 180],\n",
       "         [255, 185, 179],\n",
       "         [255, 185, 179]],\n",
       " \n",
       "        [[248,  27, 141],\n",
       "         [249,  28, 142],\n",
       "         [250,  25, 144],\n",
       "         ...,\n",
       "         [231, 165, 158],\n",
       "         [234, 163, 157],\n",
       "         [234, 163, 157]],\n",
       " \n",
       "        [[246,  29, 138],\n",
       "         [246,  29, 138],\n",
       "         [249,  26, 140],\n",
       "         ...,\n",
       "         [208, 137, 131],\n",
       "         [211, 135, 130],\n",
       "         [211, 135, 130]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  26,  40],\n",
       "         [ 80,  27,  41],\n",
       "         [ 79,  30,  40],\n",
       "         ...,\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39]],\n",
       " \n",
       "        [[ 80,  27,  41],\n",
       "         [ 80,  27,  41],\n",
       "         [ 80,  30,  43],\n",
       "         ...,\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39]],\n",
       " \n",
       "        [[ 80,  27,  41],\n",
       "         [ 80,  27,  41],\n",
       "         [ 80,  30,  43],\n",
       "         ...,\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.8032999980496243, 'inference': 25.99750000081258, 'postprocess': 7.387099998595659},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[244,  23, 137],\n",
       "         [246,  25, 139],\n",
       "         [248,  23, 142],\n",
       "         ...,\n",
       "         [253, 187, 180],\n",
       "         [255, 185, 179],\n",
       "         [255, 185, 179]],\n",
       " \n",
       "        [[248,  27, 141],\n",
       "         [249,  28, 142],\n",
       "         [250,  25, 144],\n",
       "         ...,\n",
       "         [231, 165, 158],\n",
       "         [234, 163, 157],\n",
       "         [234, 163, 157]],\n",
       " \n",
       "        [[246,  29, 138],\n",
       "         [246,  29, 138],\n",
       "         [249,  26, 140],\n",
       "         ...,\n",
       "         [208, 137, 131],\n",
       "         [211, 135, 130],\n",
       "         [211, 135, 130]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  26,  40],\n",
       "         [ 80,  27,  41],\n",
       "         [ 79,  30,  40],\n",
       "         ...,\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39]],\n",
       " \n",
       "        [[ 80,  27,  41],\n",
       "         [ 80,  27,  41],\n",
       "         [ 80,  30,  43],\n",
       "         ...,\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39]],\n",
       " \n",
       "        [[ 80,  27,  41],\n",
       "         [ 80,  27,  41],\n",
       "         [ 80,  30,  43],\n",
       "         ...,\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39],\n",
       "         [109,  31,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.223199997388292, 'inference': 28.519800005597062, 'postprocess': 4.002300003776327},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[212,   0, 131],\n",
       "         [210,   0, 129],\n",
       "         [206,   0, 127],\n",
       "         ...,\n",
       "         [207,  17,  32],\n",
       "         [209,  12,  28],\n",
       "         [206,   9,  25]],\n",
       " \n",
       "        [[209,   0, 128],\n",
       "         [207,   0, 126],\n",
       "         [205,   0, 126],\n",
       "         ...,\n",
       "         [206,  16,  31],\n",
       "         [207,  10,  26],\n",
       "         [206,   9,  25]],\n",
       " \n",
       "        [[206,   0, 130],\n",
       "         [205,   0, 129],\n",
       "         [203,   0, 129],\n",
       "         ...,\n",
       "         [202,  19,  33],\n",
       "         [204,  14,  29],\n",
       "         [204,  14,  29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[106,  42,  74],\n",
       "         [106,  42,  74],\n",
       "         [105,  40,  74],\n",
       "         ...,\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35]],\n",
       " \n",
       "        [[110,  42,  74],\n",
       "         [110,  42,  74],\n",
       "         [110,  41,  75],\n",
       "         ...,\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35]],\n",
       " \n",
       "        [[110,  42,  74],\n",
       "         [110,  42,  74],\n",
       "         [110,  41,  75],\n",
       "         ...,\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.848499996413011, 'inference': 23.293899997952394, 'postprocess': 1.8324999982723966},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[212,   0, 131],\n",
       "         [210,   0, 129],\n",
       "         [206,   0, 127],\n",
       "         ...,\n",
       "         [207,  17,  32],\n",
       "         [209,  12,  28],\n",
       "         [206,   9,  25]],\n",
       " \n",
       "        [[209,   0, 128],\n",
       "         [207,   0, 126],\n",
       "         [205,   0, 126],\n",
       "         ...,\n",
       "         [206,  16,  31],\n",
       "         [207,  10,  26],\n",
       "         [206,   9,  25]],\n",
       " \n",
       "        [[206,   0, 130],\n",
       "         [205,   0, 129],\n",
       "         [203,   0, 129],\n",
       "         ...,\n",
       "         [202,  19,  33],\n",
       "         [204,  14,  29],\n",
       "         [204,  14,  29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[106,  42,  74],\n",
       "         [106,  42,  74],\n",
       "         [105,  40,  74],\n",
       "         ...,\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35]],\n",
       " \n",
       "        [[110,  42,  74],\n",
       "         [110,  42,  74],\n",
       "         [110,  41,  75],\n",
       "         ...,\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35]],\n",
       " \n",
       "        [[110,  42,  74],\n",
       "         [110,  42,  74],\n",
       "         [110,  41,  75],\n",
       "         ...,\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35],\n",
       "         [105,  27,  35]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.54159999510739, 'inference': 23.34759999939706, 'postprocess': 3.4490999969420955},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[210,   0, 127],\n",
       "         [218,   0, 135],\n",
       "         [225,  11, 137],\n",
       "         ...,\n",
       "         [243,  12,  50],\n",
       "         [246,  15,  53],\n",
       "         [246,  15,  53]],\n",
       " \n",
       "        [[208,   0, 125],\n",
       "         [217,   0, 134],\n",
       "         [224,  10, 136],\n",
       "         ...,\n",
       "         [243,  12,  50],\n",
       "         [246,  15,  53],\n",
       "         [246,  15,  53]],\n",
       " \n",
       "        [[206,   0, 124],\n",
       "         [213,   0, 131],\n",
       "         [222,   4, 136],\n",
       "         ...,\n",
       "         [235,  13,  50],\n",
       "         [238,  16,  53],\n",
       "         [238,  16,  53]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[100,  43,  77],\n",
       "         [100,  43,  77],\n",
       "         [100,  43,  77],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]],\n",
       " \n",
       "        [[104,  44,  79],\n",
       "         [104,  44,  79],\n",
       "         [102,  45,  79],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]],\n",
       " \n",
       "        [[106,  46,  81],\n",
       "         [106,  46,  81],\n",
       "         [102,  45,  79],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2471000009099953, 'inference': 23.383100000501145, 'postprocess': 3.5057999994023703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[210,   0, 127],\n",
       "         [218,   0, 135],\n",
       "         [225,  11, 137],\n",
       "         ...,\n",
       "         [243,  12,  50],\n",
       "         [246,  15,  53],\n",
       "         [246,  15,  53]],\n",
       " \n",
       "        [[208,   0, 125],\n",
       "         [217,   0, 134],\n",
       "         [224,  10, 136],\n",
       "         ...,\n",
       "         [243,  12,  50],\n",
       "         [246,  15,  53],\n",
       "         [246,  15,  53]],\n",
       " \n",
       "        [[206,   0, 124],\n",
       "         [213,   0, 131],\n",
       "         [222,   4, 136],\n",
       "         ...,\n",
       "         [235,  13,  50],\n",
       "         [238,  16,  53],\n",
       "         [238,  16,  53]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[100,  43,  77],\n",
       "         [100,  43,  77],\n",
       "         [100,  43,  77],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]],\n",
       " \n",
       "        [[104,  44,  79],\n",
       "         [104,  44,  79],\n",
       "         [102,  45,  79],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]],\n",
       " \n",
       "        [[106,  46,  81],\n",
       "         [106,  46,  81],\n",
       "         [102,  45,  79],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2999999962630682, 'inference': 23.27270000387216, 'postprocess': 2.2394999978132546},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[210,  53, 111],\n",
       "         [202,  45, 103],\n",
       "         [195,  39,  94],\n",
       "         ...,\n",
       "         [254,  62,  98],\n",
       "         [251,  66, 101],\n",
       "         [254,  69, 104]],\n",
       " \n",
       "        [[208,  51, 109],\n",
       "         [200,  43, 101],\n",
       "         [193,  37,  92],\n",
       "         ...,\n",
       "         [255,  69, 105],\n",
       "         [255,  73, 108],\n",
       "         [255,  75, 110]],\n",
       " \n",
       "        [[210,  48, 107],\n",
       "         [203,  41, 100],\n",
       "         [194,  36,  91],\n",
       "         ...,\n",
       "         [252,  79, 112],\n",
       "         [249,  80, 113],\n",
       "         [249,  80, 113]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 96,  34,  74],\n",
       "         [101,  39,  79],\n",
       "         [103,  41,  81],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]],\n",
       " \n",
       "        [[ 96,  34,  74],\n",
       "         [100,  38,  78],\n",
       "         [102,  40,  80],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]],\n",
       " \n",
       "        [[ 95,  33,  73],\n",
       "         [100,  38,  78],\n",
       "         [102,  40,  80],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3008000023546629, 'inference': 23.383300002024043, 'postprocess': 2.4616000009700656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[210,  53, 111],\n",
       "         [202,  45, 103],\n",
       "         [195,  39,  94],\n",
       "         ...,\n",
       "         [254,  62,  98],\n",
       "         [251,  66, 101],\n",
       "         [254,  69, 104]],\n",
       " \n",
       "        [[208,  51, 109],\n",
       "         [200,  43, 101],\n",
       "         [193,  37,  92],\n",
       "         ...,\n",
       "         [255,  69, 105],\n",
       "         [255,  73, 108],\n",
       "         [255,  75, 110]],\n",
       " \n",
       "        [[210,  48, 107],\n",
       "         [203,  41, 100],\n",
       "         [194,  36,  91],\n",
       "         ...,\n",
       "         [252,  79, 112],\n",
       "         [249,  80, 113],\n",
       "         [249,  80, 113]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 96,  34,  74],\n",
       "         [101,  39,  79],\n",
       "         [103,  41,  81],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]],\n",
       " \n",
       "        [[ 96,  34,  74],\n",
       "         [100,  38,  78],\n",
       "         [102,  40,  80],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]],\n",
       " \n",
       "        [[ 95,  33,  73],\n",
       "         [100,  38,  78],\n",
       "         [102,  40,  80],\n",
       "         ...,\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33],\n",
       "         [103,  25,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4658000000054017, 'inference': 23.216100002173334, 'postprocess': 3.21319999784464},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[223,  71, 156],\n",
       "         [222,  70, 155],\n",
       "         [214,  65, 156],\n",
       "         ...,\n",
       "         [249,  63, 100],\n",
       "         [249,  63, 100],\n",
       "         [249,  63, 100]],\n",
       " \n",
       "        [[223,  71, 156],\n",
       "         [220,  68, 153],\n",
       "         [213,  64, 155],\n",
       "         ...,\n",
       "         [249,  63, 100],\n",
       "         [249,  63, 100],\n",
       "         [249,  63, 100]],\n",
       " \n",
       "        [[222,  70, 155],\n",
       "         [219,  67, 152],\n",
       "         [212,  63, 154],\n",
       "         ...,\n",
       "         [248,  64, 101],\n",
       "         [248,  64, 101],\n",
       "         [248,  64, 101]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[110,  43,  98],\n",
       "         [110,  43,  98],\n",
       "         [110,  42,  99],\n",
       "         ...,\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32]],\n",
       " \n",
       "        [[107,  40,  95],\n",
       "         [107,  40,  95],\n",
       "         [107,  39,  96],\n",
       "         ...,\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32]],\n",
       " \n",
       "        [[107,  40,  95],\n",
       "         [106,  39,  94],\n",
       "         [106,  38,  95],\n",
       "         ...,\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4575000022887252, 'inference': 23.49799999501556, 'postprocess': 3.4464999989722855},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[221,  72, 156],\n",
       "         [218,  69, 153],\n",
       "         [213,  64, 155],\n",
       "         ...,\n",
       "         [249,  63, 100],\n",
       "         [249,  63, 100],\n",
       "         [249,  63, 100]],\n",
       " \n",
       "        [[221,  72, 156],\n",
       "         [218,  69, 153],\n",
       "         [212,  63, 154],\n",
       "         ...,\n",
       "         [249,  63, 100],\n",
       "         [249,  63, 100],\n",
       "         [249,  63, 100]],\n",
       " \n",
       "        [[223,  71, 156],\n",
       "         [220,  68, 153],\n",
       "         [213,  64, 155],\n",
       "         ...,\n",
       "         [248,  64, 101],\n",
       "         [248,  64, 101],\n",
       "         [248,  64, 101]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[110,  43,  98],\n",
       "         [110,  43,  98],\n",
       "         [110,  42,  99],\n",
       "         ...,\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32]],\n",
       " \n",
       "        [[107,  40,  95],\n",
       "         [107,  40,  95],\n",
       "         [107,  39,  96],\n",
       "         ...,\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32]],\n",
       " \n",
       "        [[107,  40,  95],\n",
       "         [106,  39,  94],\n",
       "         [106,  38,  95],\n",
       "         ...,\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32],\n",
       "         [ 96,  21,  32]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3834999990649521, 'inference': 23.440500001015607, 'postprocess': 5.061199997726362},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[250, 120, 155],\n",
       "         [249, 119, 154],\n",
       "         [249, 120, 151],\n",
       "         ...,\n",
       "         [248,  52,  91],\n",
       "         [248,  52,  91],\n",
       "         [248,  52,  91]],\n",
       " \n",
       "        [[250, 120, 155],\n",
       "         [249, 119, 154],\n",
       "         [249, 120, 151],\n",
       "         ...,\n",
       "         [249,  53,  92],\n",
       "         [249,  53,  92],\n",
       "         [249,  53,  92]],\n",
       " \n",
       "        [[250, 120, 155],\n",
       "         [249, 119, 154],\n",
       "         [247, 121, 151],\n",
       "         ...,\n",
       "         [247,  54,  92],\n",
       "         [247,  54,  92],\n",
       "         [247,  54,  92]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 89,  34,  87],\n",
       "         [ 86,  31,  84],\n",
       "         [ 85,  30,  83],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]],\n",
       " \n",
       "        [[ 87,  32,  85],\n",
       "         [ 85,  30,  83],\n",
       "         [ 85,  30,  83],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]],\n",
       " \n",
       "        [[ 86,  31,  84],\n",
       "         [ 85,  30,  83],\n",
       "         [ 85,  30,  83],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3393999945255928, 'inference': 29.07730000151787, 'postprocess': 7.57250000606291},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[250, 120, 155],\n",
       "         [249, 119, 154],\n",
       "         [249, 120, 151],\n",
       "         ...,\n",
       "         [248,  52,  91],\n",
       "         [248,  52,  91],\n",
       "         [248,  52,  91]],\n",
       " \n",
       "        [[250, 120, 155],\n",
       "         [249, 119, 154],\n",
       "         [249, 120, 151],\n",
       "         ...,\n",
       "         [248,  52,  91],\n",
       "         [248,  52,  91],\n",
       "         [248,  52,  91]],\n",
       " \n",
       "        [[250, 120, 155],\n",
       "         [249, 119, 154],\n",
       "         [247, 121, 151],\n",
       "         ...,\n",
       "         [247,  54,  92],\n",
       "         [247,  54,  92],\n",
       "         [247,  54,  92]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 89,  34,  87],\n",
       "         [ 86,  31,  84],\n",
       "         [ 85,  30,  83],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]],\n",
       " \n",
       "        [[ 87,  32,  85],\n",
       "         [ 85,  30,  83],\n",
       "         [ 85,  30,  83],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]],\n",
       " \n",
       "        [[ 86,  31,  84],\n",
       "         [ 85,  30,  83],\n",
       "         [ 85,  30,  83],\n",
       "         ...,\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34],\n",
       "         [ 98,  23,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9290999989607371, 'inference': 24.19730000110576, 'postprocess': 4.539000001386739},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[249, 123, 153],\n",
       "         [248, 122, 152],\n",
       "         [250, 121, 152],\n",
       "         ...,\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90]],\n",
       " \n",
       "        [[249, 123, 153],\n",
       "         [248, 122, 152],\n",
       "         [250, 121, 152],\n",
       "         ...,\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90]],\n",
       " \n",
       "        [[249, 123, 153],\n",
       "         [248, 122, 152],\n",
       "         [248, 122, 152],\n",
       "         ...,\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 88,  33,  79],\n",
       "         [ 87,  32,  78],\n",
       "         [ 90,  32,  79],\n",
       "         ...,\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34]],\n",
       " \n",
       "        [[ 89,  31,  78],\n",
       "         [ 90,  32,  79],\n",
       "         [ 91,  31,  78],\n",
       "         ...,\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34]],\n",
       " \n",
       "        [[ 88,  30,  77],\n",
       "         [ 90,  32,  79],\n",
       "         [ 92,  32,  79],\n",
       "         ...,\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6413000048487447, 'inference': 23.325699999986682, 'postprocess': 3.693299993756227},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[249, 123, 153],\n",
       "         [248, 122, 152],\n",
       "         [250, 121, 152],\n",
       "         ...,\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90]],\n",
       " \n",
       "        [[249, 123, 153],\n",
       "         [248, 122, 152],\n",
       "         [250, 121, 152],\n",
       "         ...,\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90]],\n",
       " \n",
       "        [[249, 123, 153],\n",
       "         [248, 122, 152],\n",
       "         [248, 122, 152],\n",
       "         ...,\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90],\n",
       "         [246,  54,  90]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 88,  33,  79],\n",
       "         [ 87,  32,  78],\n",
       "         [ 90,  32,  79],\n",
       "         ...,\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34]],\n",
       " \n",
       "        [[ 89,  31,  78],\n",
       "         [ 90,  32,  79],\n",
       "         [ 91,  31,  78],\n",
       "         ...,\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34]],\n",
       " \n",
       "        [[ 88,  30,  77],\n",
       "         [ 90,  32,  79],\n",
       "         [ 92,  32,  79],\n",
       "         ...,\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34],\n",
       "         [ 94,  24,  34]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.7599000022746623, 'inference': 23.43480000126874, 'postprocess': 3.2862000007298775},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[147, 122, 154],\n",
       "         [147, 122, 154],\n",
       "         [137, 123, 155],\n",
       "         ...,\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93]],\n",
       " \n",
       "        [[147, 122, 154],\n",
       "         [147, 122, 154],\n",
       "         [137, 123, 155],\n",
       "         ...,\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93]],\n",
       " \n",
       "        [[149, 122, 154],\n",
       "         [149, 122, 154],\n",
       "         [137, 123, 155],\n",
       "         ...,\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         ...,\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31]],\n",
       " \n",
       "        [[ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         ...,\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31]],\n",
       " \n",
       "        [[ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         ...,\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7615000033401884, 'inference': 29.02939999330556, 'postprocess': 4.782800002431031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[147, 122, 154],\n",
       "         [147, 122, 154],\n",
       "         [137, 123, 155],\n",
       "         ...,\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93]],\n",
       " \n",
       "        [[147, 122, 154],\n",
       "         [147, 122, 154],\n",
       "         [137, 123, 155],\n",
       "         ...,\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93]],\n",
       " \n",
       "        [[149, 122, 154],\n",
       "         [149, 122, 154],\n",
       "         [137, 123, 155],\n",
       "         ...,\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93],\n",
       "         [249,  57,  93]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         ...,\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31]],\n",
       " \n",
       "        [[ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         ...,\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31]],\n",
       " \n",
       "        [[ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         [ 95,  39,  76],\n",
       "         ...,\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31],\n",
       "         [ 86,  28,  31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.236699998320546, 'inference': 23.863900001742877, 'postprocess': 3.892100001394283},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[116, 128, 159],\n",
       "         [116, 128, 159],\n",
       "         [117, 130, 158],\n",
       "         ...,\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97]],\n",
       " \n",
       "        [[117, 129, 160],\n",
       "         [117, 129, 160],\n",
       "         [117, 130, 158],\n",
       "         ...,\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97]],\n",
       " \n",
       "        [[117, 129, 160],\n",
       "         [117, 129, 160],\n",
       "         [115, 131, 158],\n",
       "         ...,\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 93,  34,  73],\n",
       "         [ 93,  34,  73],\n",
       "         [ 92,  33,  72],\n",
       "         ...,\n",
       "         [166, 108, 111],\n",
       "         [171, 113, 116],\n",
       "         [171, 113, 116]],\n",
       " \n",
       "        [[ 89,  34,  73],\n",
       "         [ 88,  33,  72],\n",
       "         [ 87,  32,  71],\n",
       "         ...,\n",
       "         [168, 110, 113],\n",
       "         [172, 114, 117],\n",
       "         [172, 114, 117]],\n",
       " \n",
       "        [[ 88,  33,  72],\n",
       "         [ 88,  33,  72],\n",
       "         [ 86,  31,  70],\n",
       "         ...,\n",
       "         [168, 110, 113],\n",
       "         [172, 114, 117],\n",
       "         [172, 114, 117]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.590500003658235, 'inference': 28.03890000359388, 'postprocess': 5.764799992903136},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[116, 128, 159],\n",
       "         [116, 128, 159],\n",
       "         [117, 130, 158],\n",
       "         ...,\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97]],\n",
       " \n",
       "        [[117, 129, 160],\n",
       "         [117, 129, 160],\n",
       "         [117, 130, 158],\n",
       "         ...,\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97]],\n",
       " \n",
       "        [[117, 129, 160],\n",
       "         [117, 129, 160],\n",
       "         [115, 131, 158],\n",
       "         ...,\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97],\n",
       "         [249,  61,  97]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 93,  34,  73],\n",
       "         [ 93,  34,  73],\n",
       "         [ 92,  33,  72],\n",
       "         ...,\n",
       "         [166, 108, 111],\n",
       "         [171, 113, 116],\n",
       "         [171, 113, 116]],\n",
       " \n",
       "        [[ 89,  34,  73],\n",
       "         [ 88,  33,  72],\n",
       "         [ 87,  32,  71],\n",
       "         ...,\n",
       "         [168, 110, 113],\n",
       "         [172, 114, 117],\n",
       "         [172, 114, 117]],\n",
       " \n",
       "        [[ 88,  33,  72],\n",
       "         [ 88,  33,  72],\n",
       "         [ 86,  31,  70],\n",
       "         ...,\n",
       "         [168, 110, 113],\n",
       "         [172, 114, 117],\n",
       "         [172, 114, 117]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.48690000444185, 'inference': 23.537799999758136, 'postprocess': 7.728600001428276},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[113, 131, 153],\n",
       "         [114, 132, 154],\n",
       "         [114, 132, 152],\n",
       "         ...,\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98]],\n",
       " \n",
       "        [[115, 133, 155],\n",
       "         [114, 132, 154],\n",
       "         [114, 132, 152],\n",
       "         ...,\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98]],\n",
       " \n",
       "        [[117, 131, 157],\n",
       "         [117, 131, 157],\n",
       "         [116, 131, 152],\n",
       "         ...,\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         ...,\n",
       "         [189, 106, 122],\n",
       "         [190, 107, 123],\n",
       "         [190, 107, 123]],\n",
       " \n",
       "        [[ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         ...,\n",
       "         [189, 106, 122],\n",
       "         [190, 107, 123],\n",
       "         [190, 107, 123]],\n",
       " \n",
       "        [[ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         ...,\n",
       "         [190, 107, 123],\n",
       "         [190, 107, 123],\n",
       "         [190, 107, 123]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.051800001936499, 'inference': 31.741700004204176, 'postprocess': 15.1897999967332},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[113, 131, 153],\n",
       "         [114, 132, 154],\n",
       "         [114, 132, 152],\n",
       "         ...,\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98]],\n",
       " \n",
       "        [[115, 133, 155],\n",
       "         [114, 132, 154],\n",
       "         [114, 132, 152],\n",
       "         ...,\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98]],\n",
       " \n",
       "        [[117, 131, 157],\n",
       "         [117, 131, 157],\n",
       "         [116, 131, 152],\n",
       "         ...,\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98],\n",
       "         [249,  74,  98]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         ...,\n",
       "         [189, 106, 122],\n",
       "         [190, 107, 123],\n",
       "         [190, 107, 123]],\n",
       " \n",
       "        [[ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         ...,\n",
       "         [189, 106, 122],\n",
       "         [190, 107, 123],\n",
       "         [190, 107, 123]],\n",
       " \n",
       "        [[ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         [ 80,  35,  67],\n",
       "         ...,\n",
       "         [190, 107, 123],\n",
       "         [190, 107, 123],\n",
       "         [190, 107, 123]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8650999991223216, 'inference': 23.381599996355362, 'postprocess': 5.143000002135523},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[116, 124, 155],\n",
       "         [116, 124, 155],\n",
       "         [118, 120, 154],\n",
       "         ...,\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100]],\n",
       " \n",
       "        [[114, 122, 153],\n",
       "         [113, 121, 152],\n",
       "         [115, 117, 151],\n",
       "         ...,\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100]],\n",
       " \n",
       "        [[114, 110, 148],\n",
       "         [114, 110, 148],\n",
       "         [115, 109, 149],\n",
       "         ...,\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         ...,\n",
       "         [211, 119, 146],\n",
       "         [211, 119, 146],\n",
       "         [211, 119, 146]],\n",
       " \n",
       "        [[ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         ...,\n",
       "         [229, 130, 158],\n",
       "         [229, 130, 158],\n",
       "         [229, 130, 158]],\n",
       " \n",
       "        [[ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         ...,\n",
       "         [236, 137, 165],\n",
       "         [236, 137, 165],\n",
       "         [236, 137, 165]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.510500002244953, 'inference': 25.841700000455603, 'postprocess': 5.998100001306739},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[116, 124, 155],\n",
       "         [116, 124, 155],\n",
       "         [118, 120, 154],\n",
       "         ...,\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100]],\n",
       " \n",
       "        [[114, 122, 153],\n",
       "         [113, 121, 152],\n",
       "         [115, 117, 151],\n",
       "         ...,\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100]],\n",
       " \n",
       "        [[114, 110, 148],\n",
       "         [114, 110, 148],\n",
       "         [115, 109, 149],\n",
       "         ...,\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100],\n",
       "         [248,  82, 100]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         ...,\n",
       "         [211, 119, 146],\n",
       "         [211, 119, 146],\n",
       "         [211, 119, 146]],\n",
       " \n",
       "        [[ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         ...,\n",
       "         [229, 130, 158],\n",
       "         [229, 130, 158],\n",
       "         [229, 130, 158]],\n",
       " \n",
       "        [[ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         [ 76,  35,  65],\n",
       "         ...,\n",
       "         [236, 137, 165],\n",
       "         [236, 137, 165],\n",
       "         [236, 137, 165]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1955000009038486, 'inference': 23.40109999931883, 'postprocess': 2.9308000011951663},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[128, 111, 159],\n",
       "         [128, 111, 159],\n",
       "         [128, 110, 161],\n",
       "         ...,\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102]],\n",
       " \n",
       "        [[115,  98, 146],\n",
       "         [117, 100, 148],\n",
       "         [118, 100, 151],\n",
       "         ...,\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102]],\n",
       " \n",
       "        [[110,  82, 137],\n",
       "         [112,  84, 139],\n",
       "         [111,  85, 140],\n",
       "         ...,\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         ...,\n",
       "         [218, 158, 193],\n",
       "         [217, 157, 192],\n",
       "         [217, 157, 192]],\n",
       " \n",
       "        [[ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         ...,\n",
       "         [227, 160, 196],\n",
       "         [227, 160, 196],\n",
       "         [227, 160, 196]],\n",
       " \n",
       "        [[ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         ...,\n",
       "         [228, 161, 197],\n",
       "         [229, 162, 198],\n",
       "         [229, 162, 198]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.360399997793138, 'inference': 23.30960000108462, 'postprocess': 1.822799997171387},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[128, 111, 159],\n",
       "         [128, 111, 159],\n",
       "         [129, 111, 162],\n",
       "         ...,\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102]],\n",
       " \n",
       "        [[116,  99, 147],\n",
       "         [118, 101, 149],\n",
       "         [118, 100, 151],\n",
       "         ...,\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102]],\n",
       " \n",
       "        [[111,  83, 138],\n",
       "         [113,  85, 140],\n",
       "         [111,  85, 140],\n",
       "         ...,\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102],\n",
       "         [244,  85, 102]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         ...,\n",
       "         [218, 158, 193],\n",
       "         [217, 157, 192],\n",
       "         [217, 157, 192]],\n",
       " \n",
       "        [[ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         ...,\n",
       "         [227, 160, 196],\n",
       "         [227, 160, 196],\n",
       "         [227, 160, 196]],\n",
       " \n",
       "        [[ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         [ 79,  38,  68],\n",
       "         ...,\n",
       "         [228, 161, 197],\n",
       "         [229, 162, 198],\n",
       "         [229, 162, 198]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.29420000303071, 'inference': 23.247299999638926, 'postprocess': 1.861699995060917},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[107,  81, 134],\n",
       "         [108,  82, 135],\n",
       "         [106,  84, 133],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        [[107,  81, 134],\n",
       "         [106,  80, 133],\n",
       "         [102,  80, 129],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        [[116,  83, 139],\n",
       "         [115,  82, 138],\n",
       "         [112,  82, 137],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         ...,\n",
       "         [225, 167, 188],\n",
       "         [225, 167, 188],\n",
       "         [225, 167, 188]],\n",
       " \n",
       "        [[ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         ...,\n",
       "         [223, 167, 183],\n",
       "         [223, 167, 183],\n",
       "         [223, 167, 183]],\n",
       " \n",
       "        [[ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         ...,\n",
       "         [222, 166, 182],\n",
       "         [222, 166, 182],\n",
       "         [222, 166, 182]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5551999968010932, 'inference': 25.64859999984037, 'postprocess': 2.5714999937918037},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[107,  81, 134],\n",
       "         [108,  82, 135],\n",
       "         [106,  84, 133],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        [[107,  81, 134],\n",
       "         [106,  80, 133],\n",
       "         [102,  80, 129],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        [[116,  83, 139],\n",
       "         [115,  82, 138],\n",
       "         [112,  82, 137],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         ...,\n",
       "         [225, 167, 188],\n",
       "         [225, 167, 188],\n",
       "         [225, 167, 188]],\n",
       " \n",
       "        [[ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         ...,\n",
       "         [223, 167, 183],\n",
       "         [223, 167, 183],\n",
       "         [223, 167, 183]],\n",
       " \n",
       "        [[ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         [ 76,  35,  67],\n",
       "         ...,\n",
       "         [222, 166, 182],\n",
       "         [222, 166, 182],\n",
       "         [222, 166, 182]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8217999968328513, 'inference': 23.54649999324465, 'postprocess': 4.668800000217743},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  88, 133],\n",
       "         [ 96,  88, 133],\n",
       "         [ 94,  88, 133],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        [[ 96,  88, 133],\n",
       "         [ 96,  88, 133],\n",
       "         [ 94,  88, 133],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        [[101,  86, 137],\n",
       "         [100,  85, 136],\n",
       "         [ 99,  87, 135],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 71,  30,  60],\n",
       "         [ 71,  30,  60],\n",
       "         [ 70,  29,  61],\n",
       "         ...,\n",
       "         [205, 155, 159],\n",
       "         [205, 155, 159],\n",
       "         [205, 155, 159]],\n",
       " \n",
       "        [[ 71,  30,  60],\n",
       "         [ 70,  29,  59],\n",
       "         [ 71,  30,  62],\n",
       "         ...,\n",
       "         [202, 154, 153],\n",
       "         [201, 153, 152],\n",
       "         [201, 153, 152]],\n",
       " \n",
       "        [[ 72,  31,  61],\n",
       "         [ 71,  30,  60],\n",
       "         [ 71,  30,  62],\n",
       "         ...,\n",
       "         [200, 152, 151],\n",
       "         [199, 151, 150],\n",
       "         [199, 151, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2705999979516491, 'inference': 23.152900001150556, 'postprocess': 2.762199997960124},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  88, 133],\n",
       "         [ 96,  88, 133],\n",
       "         [ 94,  88, 133],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        [[ 96,  88, 133],\n",
       "         [ 96,  88, 133],\n",
       "         [ 94,  88, 133],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        [[101,  86, 137],\n",
       "         [100,  85, 136],\n",
       "         [ 99,  87, 135],\n",
       "         ...,\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108],\n",
       "         [240,  93, 108]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 71,  30,  60],\n",
       "         [ 71,  30,  60],\n",
       "         [ 70,  29,  61],\n",
       "         ...,\n",
       "         [205, 155, 159],\n",
       "         [205, 155, 159],\n",
       "         [205, 155, 159]],\n",
       " \n",
       "        [[ 71,  30,  60],\n",
       "         [ 70,  29,  59],\n",
       "         [ 71,  30,  62],\n",
       "         ...,\n",
       "         [202, 154, 153],\n",
       "         [201, 153, 152],\n",
       "         [201, 153, 152]],\n",
       " \n",
       "        [[ 72,  31,  61],\n",
       "         [ 71,  30,  60],\n",
       "         [ 71,  30,  62],\n",
       "         ...,\n",
       "         [200, 152, 151],\n",
       "         [199, 151, 150],\n",
       "         [199, 151, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9261999987065792, 'inference': 36.30680000060238, 'postprocess': 9.395399996719789},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  90, 131],\n",
       "         [101,  90, 131],\n",
       "         [ 99,  90, 131],\n",
       "         ...,\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109]],\n",
       " \n",
       "        [[101,  90, 131],\n",
       "         [101,  90, 131],\n",
       "         [ 99,  90, 131],\n",
       "         ...,\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109]],\n",
       " \n",
       "        [[101,  89, 132],\n",
       "         [101,  89, 132],\n",
       "         [ 99,  89, 132],\n",
       "         ...,\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 98,  50,  83],\n",
       "         [ 94,  46,  79],\n",
       "         [ 96,  48,  81],\n",
       "         ...,\n",
       "         [219, 150, 144],\n",
       "         [219, 150, 144],\n",
       "         [219, 150, 144]],\n",
       " \n",
       "        [[124,  74, 107],\n",
       "         [122,  72, 105],\n",
       "         [117,  67, 100],\n",
       "         ...,\n",
       "         [223, 150, 144],\n",
       "         [223, 150, 144],\n",
       "         [223, 150, 144]],\n",
       " \n",
       "        [[144,  94, 127],\n",
       "         [144,  94, 127],\n",
       "         [136,  86, 119],\n",
       "         ...,\n",
       "         [223, 150, 144],\n",
       "         [223, 150, 144],\n",
       "         [223, 150, 144]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.024399997026194, 'inference': 23.523800002294593, 'postprocess': 2.0337999958428554},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  90, 131],\n",
       "         [101,  90, 131],\n",
       "         [ 99,  90, 131],\n",
       "         ...,\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109]],\n",
       " \n",
       "        [[101,  90, 131],\n",
       "         [101,  90, 131],\n",
       "         [ 99,  90, 131],\n",
       "         ...,\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109]],\n",
       " \n",
       "        [[101,  89, 132],\n",
       "         [101,  89, 132],\n",
       "         [ 99,  89, 132],\n",
       "         ...,\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109],\n",
       "         [240,  99, 109]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 98,  50,  83],\n",
       "         [ 94,  46,  79],\n",
       "         [ 96,  48,  81],\n",
       "         ...,\n",
       "         [219, 150, 144],\n",
       "         [219, 150, 144],\n",
       "         [219, 150, 144]],\n",
       " \n",
       "        [[124,  74, 107],\n",
       "         [122,  72, 105],\n",
       "         [117,  67, 100],\n",
       "         ...,\n",
       "         [223, 150, 144],\n",
       "         [223, 150, 144],\n",
       "         [223, 150, 144]],\n",
       " \n",
       "        [[144,  94, 127],\n",
       "         [144,  94, 127],\n",
       "         [136,  86, 119],\n",
       "         ...,\n",
       "         [223, 150, 144],\n",
       "         [223, 150, 144],\n",
       "         [223, 150, 144]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5644000013708137, 'inference': 25.287000004027504, 'postprocess': 6.0357000038493425},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[100,  93, 135],\n",
       "         [ 98,  91, 133],\n",
       "         [100,  93, 135],\n",
       "         ...,\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112]],\n",
       " \n",
       "        [[100,  93, 135],\n",
       "         [100,  93, 135],\n",
       "         [100,  93, 135],\n",
       "         ...,\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112]],\n",
       " \n",
       "        [[100,  92, 137],\n",
       "         [100,  92, 137],\n",
       "         [ 99,  94, 136],\n",
       "         ...,\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  19,  47],\n",
       "         [ 60,  20,  48],\n",
       "         [ 63,  17,  43],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]],\n",
       " \n",
       "        [[ 61,  19,  47],\n",
       "         [ 61,  19,  47],\n",
       "         [ 66,  17,  46],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]],\n",
       " \n",
       "        [[ 59,  17,  45],\n",
       "         [ 59,  17,  45],\n",
       "         [ 66,  17,  46],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5110000022104941, 'inference': 26.017700001830235, 'postprocess': 2.187299993238412},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[100,  93, 135],\n",
       "         [ 98,  91, 133],\n",
       "         [100,  93, 135],\n",
       "         ...,\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112]],\n",
       " \n",
       "        [[100,  93, 135],\n",
       "         [100,  93, 135],\n",
       "         [100,  93, 135],\n",
       "         ...,\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112]],\n",
       " \n",
       "        [[100,  92, 137],\n",
       "         [100,  92, 137],\n",
       "         [ 99,  94, 136],\n",
       "         ...,\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112],\n",
       "         [234, 104, 112]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  19,  47],\n",
       "         [ 60,  20,  48],\n",
       "         [ 63,  17,  43],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]],\n",
       " \n",
       "        [[ 61,  19,  47],\n",
       "         [ 61,  19,  47],\n",
       "         [ 66,  17,  46],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]],\n",
       " \n",
       "        [[ 59,  17,  45],\n",
       "         [ 59,  17,  45],\n",
       "         [ 66,  17,  46],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8792999981087632, 'inference': 29.89279999746941, 'postprocess': 4.6465999985230155},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[100,  93, 135],\n",
       "         [ 98,  91, 133],\n",
       "         [100,  93, 135],\n",
       "         ...,\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115]],\n",
       " \n",
       "        [[100,  93, 135],\n",
       "         [100,  93, 135],\n",
       "         [100,  93, 135],\n",
       "         ...,\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115]],\n",
       " \n",
       "        [[100,  92, 137],\n",
       "         [100,  92, 137],\n",
       "         [ 99,  94, 136],\n",
       "         ...,\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]],\n",
       " \n",
       "        [[ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]],\n",
       " \n",
       "        [[ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.526199994259514, 'inference': 26.011199995991774, 'postprocess': 5.4862999968463555},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[100,  93, 135],\n",
       "         [ 98,  91, 133],\n",
       "         [100,  93, 135],\n",
       "         ...,\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115]],\n",
       " \n",
       "        [[100,  93, 135],\n",
       "         [100,  93, 135],\n",
       "         [100,  93, 135],\n",
       "         ...,\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115]],\n",
       " \n",
       "        [[100,  92, 137],\n",
       "         [100,  92, 137],\n",
       "         [ 99,  94, 136],\n",
       "         ...,\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115],\n",
       "         [231, 108, 115]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]],\n",
       " \n",
       "        [[ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]],\n",
       " \n",
       "        [[ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         [ 65,  21,  27],\n",
       "         ...,\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150],\n",
       "         [229, 145, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4172000010148622, 'inference': 23.431100002198946, 'postprocess': 2.1601999978884123},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[113,  95, 126],\n",
       "         [113,  95, 126],\n",
       "         [113,  95, 126],\n",
       "         ...,\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119]],\n",
       " \n",
       "        [[113,  95, 126],\n",
       "         [113,  95, 126],\n",
       "         [113,  95, 126],\n",
       "         ...,\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119]],\n",
       " \n",
       "        [[109,  94, 129],\n",
       "         [109,  94, 129],\n",
       "         [111,  94, 129],\n",
       "         ...,\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [213, 127, 132],\n",
       "         [213, 127, 132],\n",
       "         [213, 127, 132]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [203, 117, 122],\n",
       "         [203, 117, 122],\n",
       "         [202, 116, 121]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [195, 109, 114],\n",
       "         [195, 109, 114],\n",
       "         [195, 109, 114]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4536999951815233, 'inference': 23.322000000916887, 'postprocess': 2.740199997788295},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[113,  95, 126],\n",
       "         [113,  95, 126],\n",
       "         [113,  95, 126],\n",
       "         ...,\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119]],\n",
       " \n",
       "        [[113,  95, 126],\n",
       "         [113,  95, 126],\n",
       "         [113,  95, 126],\n",
       "         ...,\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119]],\n",
       " \n",
       "        [[109,  94, 129],\n",
       "         [109,  94, 129],\n",
       "         [111,  94, 129],\n",
       "         ...,\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119],\n",
       "         [227, 113, 119]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [213, 127, 132],\n",
       "         [213, 127, 132],\n",
       "         [213, 127, 132]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [203, 117, 122],\n",
       "         [203, 117, 122],\n",
       "         [202, 116, 121]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [195, 109, 114],\n",
       "         [195, 109, 114],\n",
       "         [195, 109, 114]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.335499993932899, 'inference': 25.436800002353266, 'postprocess': 6.847399999969639},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[241, 129, 150],\n",
       "         [242, 130, 151],\n",
       "         [241, 130, 149],\n",
       "         ...,\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123]],\n",
       " \n",
       "        [[241, 129, 150],\n",
       "         [241, 129, 150],\n",
       "         [241, 130, 149],\n",
       "         ...,\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123]],\n",
       " \n",
       "        [[241, 129, 150],\n",
       "         [241, 129, 150],\n",
       "         [241, 129, 150],\n",
       "         ...,\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [138,  66,  69],\n",
       "         [135,  63,  66],\n",
       "         [134,  62,  65]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [140,  68,  71],\n",
       "         [135,  63,  66],\n",
       "         [133,  61,  64]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [140,  68,  71],\n",
       "         [135,  63,  66],\n",
       "         [131,  59,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.144500002032146, 'inference': 23.513300002377946, 'postprocess': 4.80960000277264},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[241, 129, 150],\n",
       "         [242, 130, 151],\n",
       "         [241, 130, 149],\n",
       "         ...,\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123]],\n",
       " \n",
       "        [[241, 129, 150],\n",
       "         [241, 129, 150],\n",
       "         [241, 130, 149],\n",
       "         ...,\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123]],\n",
       " \n",
       "        [[241, 129, 150],\n",
       "         [241, 129, 150],\n",
       "         [241, 129, 150],\n",
       "         ...,\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123],\n",
       "         [221, 119, 123]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [138,  66,  69],\n",
       "         [135,  63,  66],\n",
       "         [134,  62,  65]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [140,  68,  71],\n",
       "         [135,  63,  66],\n",
       "         [133,  61,  64]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [140,  68,  71],\n",
       "         [135,  63,  66],\n",
       "         [131,  59,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9167999998899177, 'inference': 26.469500000530388, 'postprocess': 4.088599998794962},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[233, 119, 154],\n",
       "         [227, 113, 148],\n",
       "         [222, 105, 147],\n",
       "         ...,\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123]],\n",
       " \n",
       "        [[230, 116, 151],\n",
       "         [225, 111, 146],\n",
       "         [220, 103, 145],\n",
       "         ...,\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123]],\n",
       " \n",
       "        [[228, 113, 150],\n",
       "         [223, 108, 145],\n",
       "         [219, 102, 146],\n",
       "         ...,\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9564999965950847, 'inference': 24.059099996520672, 'postprocess': 3.614200002630241},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[233, 119, 154],\n",
       "         [227, 113, 148],\n",
       "         [222, 105, 147],\n",
       "         ...,\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123]],\n",
       " \n",
       "        [[230, 116, 151],\n",
       "         [225, 111, 146],\n",
       "         [220, 103, 145],\n",
       "         ...,\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123]],\n",
       " \n",
       "        [[228, 113, 150],\n",
       "         [223, 108, 145],\n",
       "         [219, 102, 146],\n",
       "         ...,\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123],\n",
       "         [217, 120, 123]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33]],\n",
       " \n",
       "        [[ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         [ 61,  23,  25],\n",
       "         ...,\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33],\n",
       "         [ 70,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5352000045822933, 'inference': 23.467400002118666, 'postprocess': 5.3343000035965815},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[215,  93, 152],\n",
       "         [219,  97, 156],\n",
       "         [220, 101, 155],\n",
       "         ...,\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128]],\n",
       " \n",
       "        [[220,  98, 157],\n",
       "         [221,  99, 158],\n",
       "         [223, 104, 158],\n",
       "         ...,\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128]],\n",
       " \n",
       "        [[221, 101, 160],\n",
       "         [223, 103, 162],\n",
       "         [223, 107, 160],\n",
       "         ...,\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         ...,\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35]],\n",
       " \n",
       "        [[ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         ...,\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35]],\n",
       " \n",
       "        [[ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         ...,\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3483000002452172, 'inference': 23.250500002177432, 'postprocess': 3.840099998342339},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[215,  93, 152],\n",
       "         [219,  97, 156],\n",
       "         [220, 101, 155],\n",
       "         ...,\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128]],\n",
       " \n",
       "        [[220,  98, 157],\n",
       "         [221,  99, 158],\n",
       "         [223, 104, 158],\n",
       "         ...,\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128]],\n",
       " \n",
       "        [[221, 101, 160],\n",
       "         [223, 103, 162],\n",
       "         [223, 107, 160],\n",
       "         ...,\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128],\n",
       "         [218, 126, 128]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         ...,\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35]],\n",
       " \n",
       "        [[ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         ...,\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35]],\n",
       " \n",
       "        [[ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         [ 57,  24,  25],\n",
       "         ...,\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35],\n",
       "         [ 75,  32,  35]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.563599995279219, 'inference': 24.810900002194103, 'postprocess': 2.1249999990686774},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[143,  74,  90],\n",
       "         [143,  74,  90],\n",
       "         [141,  74,  90],\n",
       "         ...,\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132]],\n",
       " \n",
       "        [[129,  60,  76],\n",
       "         [129,  60,  76],\n",
       "         [127,  60,  76],\n",
       "         ...,\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132]],\n",
       " \n",
       "        [[118,  52,  65],\n",
       "         [118,  52,  65],\n",
       "         [116,  52,  65],\n",
       "         ...,\n",
       "         [220, 130, 132],\n",
       "         [220, 130, 132],\n",
       "         [220, 130, 132]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  25,  24],\n",
       "         [ 55,  25,  24],\n",
       "         [ 55,  25,  24],\n",
       "         ...,\n",
       "         [134,  50,  64],\n",
       "         [138,  49,  64],\n",
       "         [138,  49,  64]],\n",
       " \n",
       "        [[ 55,  25,  24],\n",
       "         [ 55,  25,  24],\n",
       "         [ 55,  25,  24],\n",
       "         ...,\n",
       "         [134,  50,  64],\n",
       "         [138,  49,  64],\n",
       "         [138,  49,  64]],\n",
       " \n",
       "        [[ 55,  25,  24],\n",
       "         [ 55,  25,  24],\n",
       "         [ 55,  25,  24],\n",
       "         ...,\n",
       "         [134,  50,  64],\n",
       "         [138,  49,  64],\n",
       "         [138,  49,  64]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.404700000421144, 'inference': 23.387499997625127, 'postprocess': 2.4418000029982068},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[137,  73,  86],\n",
       "         [137,  73,  86],\n",
       "         [137,  73,  86],\n",
       "         ...,\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132]],\n",
       " \n",
       "        [[127,  63,  76],\n",
       "         [127,  63,  76],\n",
       "         [127,  63,  76],\n",
       "         ...,\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132]],\n",
       " \n",
       "        [[116,  52,  65],\n",
       "         [116,  52,  65],\n",
       "         [116,  52,  65],\n",
       "         ...,\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132],\n",
       "         [218, 131, 132]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 57,  25,  24],\n",
       "         [ 57,  25,  24],\n",
       "         [ 57,  25,  24],\n",
       "         ...,\n",
       "         [135,  51,  65],\n",
       "         [139,  50,  65],\n",
       "         [139,  50,  65]],\n",
       " \n",
       "        [[ 57,  25,  24],\n",
       "         [ 57,  25,  24],\n",
       "         [ 57,  25,  24],\n",
       "         ...,\n",
       "         [135,  51,  65],\n",
       "         [139,  50,  65],\n",
       "         [139,  50,  65]],\n",
       " \n",
       "        [[ 57,  25,  24],\n",
       "         [ 57,  25,  24],\n",
       "         [ 57,  25,  24],\n",
       "         ...,\n",
       "         [135,  51,  65],\n",
       "         [139,  50,  65],\n",
       "         [139,  50,  65]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7686999999568798, 'inference': 23.45929999864893, 'postprocess': 4.5881000041845255},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[109,  50,  62],\n",
       "         [110,  51,  63],\n",
       "         [110,  49,  66],\n",
       "         ...,\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135]],\n",
       " \n",
       "        [[110,  51,  63],\n",
       "         [110,  51,  63],\n",
       "         [112,  51,  68],\n",
       "         ...,\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135]],\n",
       " \n",
       "        [[113,  54,  66],\n",
       "         [114,  55,  67],\n",
       "         [113,  53,  68],\n",
       "         ...,\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [165,  47,  67],\n",
       "         [169,  47,  67],\n",
       "         [169,  47,  67]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [165,  47,  67],\n",
       "         [169,  47,  67],\n",
       "         [169,  47,  67]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [165,  47,  67],\n",
       "         [169,  47,  67],\n",
       "         [169,  47,  67]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4330000049085356, 'inference': 24.706700001843274, 'postprocess': 2.2030999971320853},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[109,  50,  62],\n",
       "         [110,  51,  63],\n",
       "         [110,  49,  66],\n",
       "         ...,\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135]],\n",
       " \n",
       "        [[110,  51,  63],\n",
       "         [110,  51,  63],\n",
       "         [112,  51,  68],\n",
       "         ...,\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135]],\n",
       " \n",
       "        [[113,  54,  66],\n",
       "         [114,  55,  67],\n",
       "         [113,  53,  68],\n",
       "         ...,\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135],\n",
       "         [217, 134, 135]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [165,  47,  67],\n",
       "         [169,  47,  67],\n",
       "         [169,  47,  67]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [165,  47,  67],\n",
       "         [169,  47,  67],\n",
       "         [169,  47,  67]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [165,  47,  67],\n",
       "         [169,  47,  67],\n",
       "         [169,  47,  67]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4104000001680106, 'inference': 23.32919999753358, 'postprocess': 4.3038999938289635},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[111,  40,  68],\n",
       "         [112,  41,  69],\n",
       "         [110,  38,  73],\n",
       "         ...,\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138]],\n",
       " \n",
       "        [[112,  41,  69],\n",
       "         [112,  41,  69],\n",
       "         [110,  38,  73],\n",
       "         ...,\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138]],\n",
       " \n",
       "        [[117,  42,  68],\n",
       "         [116,  41,  67],\n",
       "         [114,  40,  70],\n",
       "         ...,\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.832100002502557, 'inference': 26.898600001004525, 'postprocess': 5.6827000007615425},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[111,  40,  68],\n",
       "         [112,  41,  69],\n",
       "         [110,  38,  73],\n",
       "         ...,\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138]],\n",
       " \n",
       "        [[112,  41,  69],\n",
       "         [112,  41,  69],\n",
       "         [110,  38,  73],\n",
       "         ...,\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138]],\n",
       " \n",
       "        [[117,  42,  68],\n",
       "         [116,  41,  67],\n",
       "         [114,  40,  70],\n",
       "         ...,\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138],\n",
       "         [217, 144, 138]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 53,  21,  27],\n",
       "         ...,\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69],\n",
       "         [182,  41,  69]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0579999982146546, 'inference': 25.10489999986021, 'postprocess': 4.409200002555735},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[123,  46, 104],\n",
       "         [124,  47, 105],\n",
       "         [130,  54, 110],\n",
       "         ...,\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140]],\n",
       " \n",
       "        [[124,  47, 105],\n",
       "         [125,  48, 106],\n",
       "         [129,  53, 109],\n",
       "         ...,\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140]],\n",
       " \n",
       "        [[126,  48, 109],\n",
       "         [129,  51, 112],\n",
       "         [130,  52, 113],\n",
       "         ...,\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         ...,\n",
       "         [177,  44,  73],\n",
       "         [175,  45,  73],\n",
       "         [175,  45,  73]],\n",
       " \n",
       "        [[ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         ...,\n",
       "         [179,  44,  73],\n",
       "         [177,  44,  73],\n",
       "         [177,  44,  73]],\n",
       " \n",
       "        [[ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         ...,\n",
       "         [179,  44,  73],\n",
       "         [177,  44,  73],\n",
       "         [177,  44,  73]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6489999979967251, 'inference': 24.64450000115903, 'postprocess': 6.140900004538707},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[123,  46, 104],\n",
       "         [124,  47, 105],\n",
       "         [130,  54, 110],\n",
       "         ...,\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140]],\n",
       " \n",
       "        [[124,  47, 105],\n",
       "         [125,  48, 106],\n",
       "         [129,  53, 109],\n",
       "         ...,\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140]],\n",
       " \n",
       "        [[126,  48, 109],\n",
       "         [129,  51, 112],\n",
       "         [130,  52, 113],\n",
       "         ...,\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140],\n",
       "         [215, 146, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         ...,\n",
       "         [177,  44,  73],\n",
       "         [175,  45,  73],\n",
       "         [175,  45,  73]],\n",
       " \n",
       "        [[ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         ...,\n",
       "         [179,  44,  73],\n",
       "         [177,  44,  73],\n",
       "         [177,  44,  73]],\n",
       " \n",
       "        [[ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         [ 56,  24,  30],\n",
       "         ...,\n",
       "         [179,  44,  73],\n",
       "         [177,  44,  73],\n",
       "         [177,  44,  73]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0732999983010814, 'inference': 25.64400000119349, 'postprocess': 1.8653000006452203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[121,  35, 127],\n",
       "         [121,  35, 127],\n",
       "         [121,  34, 128],\n",
       "         ...,\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142]],\n",
       " \n",
       "        [[121,  35, 127],\n",
       "         [120,  34, 126],\n",
       "         [120,  33, 127],\n",
       "         ...,\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142]],\n",
       " \n",
       "        [[119,  33, 125],\n",
       "         [119,  33, 125],\n",
       "         [119,  32, 126],\n",
       "         ...,\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  27],\n",
       "         ...,\n",
       "         [226,  70,  98],\n",
       "         [229,  71,  99],\n",
       "         [231,  73, 101]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  27],\n",
       "         ...,\n",
       "         [223,  70,  97],\n",
       "         [226,  70,  98],\n",
       "         [227,  71,  99]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  27],\n",
       "         ...,\n",
       "         [222,  69,  96],\n",
       "         [225,  69,  97],\n",
       "         [226,  70,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8379000030108728, 'inference': 26.13740000379039, 'postprocess': 5.291399997076951},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[121,  35, 127],\n",
       "         [121,  35, 127],\n",
       "         [121,  34, 128],\n",
       "         ...,\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142]],\n",
       " \n",
       "        [[121,  35, 127],\n",
       "         [120,  34, 126],\n",
       "         [120,  33, 127],\n",
       "         ...,\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142]],\n",
       " \n",
       "        [[119,  33, 125],\n",
       "         [119,  33, 125],\n",
       "         [119,  32, 126],\n",
       "         ...,\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142],\n",
       "         [219, 151, 142]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  27],\n",
       "         ...,\n",
       "         [226,  70,  98],\n",
       "         [229,  71,  99],\n",
       "         [231,  73, 101]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  27],\n",
       "         ...,\n",
       "         [223,  70,  97],\n",
       "         [226,  70,  98],\n",
       "         [227,  71,  99]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  27],\n",
       "         ...,\n",
       "         [222,  69,  96],\n",
       "         [225,  69,  97],\n",
       "         [226,  70,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7798000044422224, 'inference': 24.055000001681037, 'postprocess': 3.037499998754356},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[129,  65, 119],\n",
       "         [131,  67, 121],\n",
       "         [131,  69, 116],\n",
       "         ...,\n",
       "         [215, 155, 144],\n",
       "         [216, 156, 145],\n",
       "         [217, 157, 146]],\n",
       " \n",
       "        [[118,  54, 108],\n",
       "         [121,  57, 111],\n",
       "         [121,  59, 106],\n",
       "         ...,\n",
       "         [215, 155, 144],\n",
       "         [216, 156, 145],\n",
       "         [217, 157, 146]],\n",
       " \n",
       "        [[115,  46, 106],\n",
       "         [117,  48, 108],\n",
       "         [118,  52, 104],\n",
       "         ...,\n",
       "         [215, 155, 144],\n",
       "         [216, 156, 145],\n",
       "         [217, 157, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         ...,\n",
       "         [208,  39,  72],\n",
       "         [208,  39,  72],\n",
       "         [208,  39,  72]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         ...,\n",
       "         [211,  42,  75],\n",
       "         [210,  41,  74],\n",
       "         [210,  41,  74]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         ...,\n",
       "         [212,  43,  76],\n",
       "         [210,  41,  74],\n",
       "         [210,  41,  74]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8084000039380044, 'inference': 25.34130000276491, 'postprocess': 3.552599999238737},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[131,  67, 121],\n",
       "         [133,  69, 123],\n",
       "         [133,  71, 118],\n",
       "         ...,\n",
       "         [215, 155, 144],\n",
       "         [216, 156, 145],\n",
       "         [217, 157, 146]],\n",
       " \n",
       "        [[120,  56, 110],\n",
       "         [123,  59, 113],\n",
       "         [123,  61, 108],\n",
       "         ...,\n",
       "         [215, 155, 144],\n",
       "         [216, 156, 145],\n",
       "         [217, 157, 146]],\n",
       " \n",
       "        [[115,  46, 106],\n",
       "         [118,  49, 109],\n",
       "         [118,  52, 104],\n",
       "         ...,\n",
       "         [215, 155, 144],\n",
       "         [216, 156, 145],\n",
       "         [217, 157, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         ...,\n",
       "         [208,  39,  72],\n",
       "         [208,  39,  72],\n",
       "         [208,  39,  72]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         ...,\n",
       "         [211,  42,  75],\n",
       "         [210,  41,  74],\n",
       "         [210,  41,  74]],\n",
       " \n",
       "        [[ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         [ 55,  21,  25],\n",
       "         ...,\n",
       "         [212,  43,  76],\n",
       "         [210,  41,  74],\n",
       "         [210,  41,  74]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7951999980141409, 'inference': 25.83269999740878, 'postprocess': 2.636799996253103},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[235, 165, 170],\n",
       "         [234, 164, 169],\n",
       "         [225, 165, 166],\n",
       "         ...,\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149]],\n",
       " \n",
       "        [[238, 168, 173],\n",
       "         [238, 168, 173],\n",
       "         [231, 171, 172],\n",
       "         ...,\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149]],\n",
       " \n",
       "        [[238, 167, 174],\n",
       "         [239, 168, 175],\n",
       "         [236, 173, 177],\n",
       "         ...,\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [193,  35,  63],\n",
       "         [193,  35,  63],\n",
       "         [193,  35,  63]],\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [195,  35,  63],\n",
       "         [195,  35,  63],\n",
       "         [195,  35,  63]],\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [195,  35,  63],\n",
       "         [195,  35,  63],\n",
       "         [195,  35,  63]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.544799997645896, 'inference': 24.438499996904284, 'postprocess': 1.8856000024243258},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[235, 165, 170],\n",
       "         [234, 164, 169],\n",
       "         [225, 165, 166],\n",
       "         ...,\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149]],\n",
       " \n",
       "        [[238, 168, 173],\n",
       "         [238, 168, 173],\n",
       "         [231, 171, 172],\n",
       "         ...,\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149]],\n",
       " \n",
       "        [[238, 167, 174],\n",
       "         [239, 168, 175],\n",
       "         [236, 173, 177],\n",
       "         ...,\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149],\n",
       "         [216, 160, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [193,  35,  63],\n",
       "         [193,  35,  63],\n",
       "         [193,  35,  63]],\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [195,  35,  63],\n",
       "         [195,  35,  63],\n",
       "         [195,  35,  63]],\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [195,  35,  63],\n",
       "         [195,  35,  63],\n",
       "         [195,  35,  63]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5626999957021326, 'inference': 23.3994999944116, 'postprocess': 1.8774999989545904},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[153, 154, 136],\n",
       "         [153, 154, 136],\n",
       "         [143, 156, 138],\n",
       "         ...,\n",
       "         [214, 163, 151],\n",
       "         [214, 163, 151],\n",
       "         [214, 163, 151]],\n",
       " \n",
       "        [[154, 155, 137],\n",
       "         [154, 155, 137],\n",
       "         [143, 156, 138],\n",
       "         ...,\n",
       "         [214, 163, 151],\n",
       "         [214, 163, 151],\n",
       "         [214, 163, 151]],\n",
       " \n",
       "        [[165, 153, 139],\n",
       "         [165, 153, 139],\n",
       "         [153, 155, 139],\n",
       "         ...,\n",
       "         [215, 164, 152],\n",
       "         [215, 164, 152],\n",
       "         [215, 164, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [ 85,  33,  37],\n",
       "         [ 83,  33,  37],\n",
       "         [ 83,  33,  37]],\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [ 87,  32,  37],\n",
       "         [ 87,  32,  37],\n",
       "         [ 87,  32,  37]],\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [ 87,  32,  37],\n",
       "         [ 87,  32,  37],\n",
       "         [ 87,  32,  37]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1779999986174516, 'inference': 23.662999999942258, 'postprocess': 2.1452000000863336},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[153, 154, 136],\n",
       "         [153, 154, 136],\n",
       "         [143, 156, 138],\n",
       "         ...,\n",
       "         [214, 163, 151],\n",
       "         [214, 163, 151],\n",
       "         [214, 163, 151]],\n",
       " \n",
       "        [[154, 155, 137],\n",
       "         [154, 155, 137],\n",
       "         [143, 156, 138],\n",
       "         ...,\n",
       "         [214, 163, 151],\n",
       "         [214, 163, 151],\n",
       "         [214, 163, 151]],\n",
       " \n",
       "        [[165, 153, 139],\n",
       "         [165, 153, 139],\n",
       "         [153, 155, 139],\n",
       "         ...,\n",
       "         [215, 164, 152],\n",
       "         [215, 164, 152],\n",
       "         [215, 164, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [ 85,  33,  37],\n",
       "         [ 83,  33,  37],\n",
       "         [ 83,  33,  37]],\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [ 87,  32,  37],\n",
       "         [ 87,  32,  37],\n",
       "         [ 87,  32,  37]],\n",
       " \n",
       "        [[ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         [ 59,  25,  29],\n",
       "         ...,\n",
       "         [ 87,  32,  37],\n",
       "         [ 87,  32,  37],\n",
       "         [ 87,  32,  37]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4942999987397343, 'inference': 23.30900000379188, 'postprocess': 3.0262000000220723},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[159, 167, 164],\n",
       "         [160, 168, 165],\n",
       "         [164, 167, 165],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[157, 165, 162],\n",
       "         [158, 166, 163],\n",
       "         [163, 166, 164],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[160, 163, 161],\n",
       "         [161, 164, 162],\n",
       "         [162, 165, 163],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7634000032558106, 'inference': 23.893099998531397, 'postprocess': 2.9800999982398935},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[159, 167, 164],\n",
       "         [160, 168, 165],\n",
       "         [164, 167, 165],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[157, 165, 162],\n",
       "         [158, 166, 163],\n",
       "         [163, 166, 164],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[160, 163, 161],\n",
       "         [161, 164, 162],\n",
       "         [162, 165, 163],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8022000003838912, 'inference': 24.164900001778733, 'postprocess': 5.043400000431575},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[159, 167, 164],\n",
       "         [160, 168, 165],\n",
       "         [164, 167, 165],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[157, 165, 162],\n",
       "         [158, 166, 163],\n",
       "         [163, 166, 164],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[160, 163, 161],\n",
       "         [161, 164, 162],\n",
       "         [162, 165, 163],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5952000030665658, 'inference': 23.53920000314247, 'postprocess': 4.218300004140474},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[159, 167, 164],\n",
       "         [160, 168, 165],\n",
       "         [164, 167, 165],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[157, 165, 162],\n",
       "         [158, 166, 163],\n",
       "         [163, 166, 164],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[160, 163, 161],\n",
       "         [161, 164, 162],\n",
       "         [162, 165, 163],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.224199997726828, 'inference': 24.482000000716653, 'postprocess': 4.42040000052657},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[173, 170, 169],\n",
       "         [173, 170, 169],\n",
       "         [172, 169, 168],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        [[173, 170, 169],\n",
       "         [173, 170, 169],\n",
       "         [172, 169, 168],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        [[172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         [171, 171, 171],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2385000009089708, 'inference': 23.353700002189726, 'postprocess': 2.7502000011736527},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[173, 170, 169],\n",
       "         [173, 170, 169],\n",
       "         [172, 169, 168],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        [[173, 170, 169],\n",
       "         [173, 170, 169],\n",
       "         [172, 169, 168],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        [[172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         [171, 171, 171],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1713999992934987, 'inference': 23.45929999864893, 'postprocess': 2.1097999997437},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[173, 170, 169],\n",
       "         [173, 170, 169],\n",
       "         [172, 169, 168],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        [[173, 170, 169],\n",
       "         [173, 170, 169],\n",
       "         [172, 169, 168],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        [[172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         [171, 171, 171],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.443900000595022, 'inference': 23.35809999931371, 'postprocess': 2.0507999943220057},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[173, 170, 169],\n",
       "         [173, 170, 169],\n",
       "         [172, 169, 168],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        [[173, 170, 169],\n",
       "         [173, 170, 169],\n",
       "         [172, 169, 168],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        [[172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         [171, 171, 171],\n",
       "         ...,\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175],\n",
       "         [175, 175, 175]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.155599999241531, 'inference': 25.233300002582837, 'postprocess': 3.367099998285994},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[183, 180, 181],\n",
       "         [183, 180, 181],\n",
       "         [182, 179, 180],\n",
       "         ...,\n",
       "         [178, 178, 178],\n",
       "         [178, 178, 178],\n",
       "         [178, 178, 178]],\n",
       " \n",
       "        [[182, 179, 180],\n",
       "         [182, 179, 180],\n",
       "         [181, 178, 179],\n",
       "         ...,\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179]],\n",
       " \n",
       "        [[181, 178, 177],\n",
       "         [181, 178, 177],\n",
       "         [183, 180, 179],\n",
       "         ...,\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5000999992480502, 'inference': 22.977199994784314, 'postprocess': 2.634000004036352},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[183, 180, 181],\n",
       "         [183, 180, 181],\n",
       "         [182, 179, 180],\n",
       "         ...,\n",
       "         [178, 178, 178],\n",
       "         [178, 178, 178],\n",
       "         [178, 178, 178]],\n",
       " \n",
       "        [[182, 179, 180],\n",
       "         [182, 179, 180],\n",
       "         [181, 178, 179],\n",
       "         ...,\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179]],\n",
       " \n",
       "        [[181, 178, 177],\n",
       "         [181, 178, 177],\n",
       "         [183, 180, 179],\n",
       "         ...,\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0002000019303523, 'inference': 40.88200000114739, 'postprocess': 4.95519999822136},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[183, 180, 181],\n",
       "         [183, 180, 181],\n",
       "         [182, 179, 180],\n",
       "         ...,\n",
       "         [178, 178, 178],\n",
       "         [178, 178, 178],\n",
       "         [178, 178, 178]],\n",
       " \n",
       "        [[182, 179, 180],\n",
       "         [182, 179, 180],\n",
       "         [181, 178, 179],\n",
       "         ...,\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179]],\n",
       " \n",
       "        [[181, 178, 177],\n",
       "         [181, 178, 177],\n",
       "         [183, 180, 179],\n",
       "         ...,\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6381000023102388, 'inference': 22.807800000009593, 'postprocess': 5.3568000002997},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[183, 180, 181],\n",
       "         [183, 180, 181],\n",
       "         [182, 179, 180],\n",
       "         ...,\n",
       "         [178, 178, 178],\n",
       "         [178, 178, 178],\n",
       "         [178, 178, 178]],\n",
       " \n",
       "        [[182, 179, 180],\n",
       "         [182, 179, 180],\n",
       "         [181, 178, 179],\n",
       "         ...,\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179]],\n",
       " \n",
       "        [[181, 178, 177],\n",
       "         [181, 178, 177],\n",
       "         [183, 180, 179],\n",
       "         ...,\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179],\n",
       "         [179, 179, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5883999949437566, 'inference': 27.414099997258745, 'postprocess': 4.910199997539166},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[177, 180, 180],\n",
       "         [177, 180, 180],\n",
       "         [175, 178, 176],\n",
       "         ...,\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152]],\n",
       " \n",
       "        [[176, 179, 179],\n",
       "         [176, 179, 179],\n",
       "         [173, 176, 174],\n",
       "         ...,\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152]],\n",
       " \n",
       "        [[172, 175, 175],\n",
       "         [172, 175, 175],\n",
       "         [171, 174, 172],\n",
       "         ...,\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.118800002790522, 'inference': 32.898700002988335, 'postprocess': 4.7187000018311664},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[177, 180, 180],\n",
       "         [177, 180, 180],\n",
       "         [175, 178, 176],\n",
       "         ...,\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152]],\n",
       " \n",
       "        [[176, 179, 179],\n",
       "         [176, 179, 179],\n",
       "         [173, 176, 174],\n",
       "         ...,\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152]],\n",
       " \n",
       "        [[172, 175, 175],\n",
       "         [172, 175, 175],\n",
       "         [171, 174, 172],\n",
       "         ...,\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152],\n",
       "         [151, 150, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.483399999618996, 'inference': 23.757999995723367, 'postprocess': 7.2183000011136755},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[177, 180, 180],\n",
       "         [177, 180, 180],\n",
       "         [175, 178, 176],\n",
       "         ...,\n",
       "         [152, 151, 153],\n",
       "         [152, 151, 153],\n",
       "         [152, 151, 153]],\n",
       " \n",
       "        [[176, 179, 179],\n",
       "         [176, 179, 179],\n",
       "         [173, 176, 174],\n",
       "         ...,\n",
       "         [152, 151, 153],\n",
       "         [152, 151, 153],\n",
       "         [152, 151, 153]],\n",
       " \n",
       "        [[172, 175, 175],\n",
       "         [172, 175, 175],\n",
       "         [171, 174, 172],\n",
       "         ...,\n",
       "         [152, 151, 153],\n",
       "         [152, 151, 153],\n",
       "         [152, 151, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.207799996540416, 'inference': 25.53030000126455, 'postprocess': 3.966199998103548},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[185, 185, 185],\n",
       "         [182, 182, 182],\n",
       "         [179, 179, 179],\n",
       "         ...,\n",
       "         [148, 150, 152],\n",
       "         [148, 150, 152],\n",
       "         [148, 150, 152]],\n",
       " \n",
       "        [[181, 181, 181],\n",
       "         [180, 180, 180],\n",
       "         [176, 176, 176],\n",
       "         ...,\n",
       "         [148, 150, 152],\n",
       "         [148, 150, 152],\n",
       "         [148, 150, 152]],\n",
       " \n",
       "        [[174, 174, 174],\n",
       "         [173, 173, 173],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [148, 150, 152],\n",
       "         [148, 150, 152],\n",
       "         [148, 150, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4369000055012293, 'inference': 23.03389999724459, 'postprocess': 2.9490999950212426},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        [[171, 171, 171],\n",
       "         [172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        [[171, 171, 171],\n",
       "         [171, 171, 171],\n",
       "         [171, 171, 171],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.369599995086901, 'inference': 22.93869999994058, 'postprocess': 2.1540000016102567},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        [[171, 171, 171],\n",
       "         [172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        [[171, 171, 171],\n",
       "         [171, 171, 171],\n",
       "         [171, 171, 171],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7389999993611127, 'inference': 23.859599998104386, 'postprocess': 2.0083999988855794},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        [[171, 171, 171],\n",
       "         [172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        [[171, 171, 171],\n",
       "         [171, 171, 171],\n",
       "         [171, 171, 171],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.188300000852905, 'inference': 39.48849999869708, 'postprocess': 9.348499996121973},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        [[171, 171, 171],\n",
       "         [172, 172, 172],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        [[171, 171, 171],\n",
       "         [171, 171, 171],\n",
       "         [171, 171, 171],\n",
       "         ...,\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187],\n",
       "         [187, 187, 187]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         [ 14,  17,  17],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3711999965598807, 'inference': 24.69740000378806, 'postprocess': 5.889200001547579},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[144, 143, 145],\n",
       "         [144, 143, 145],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[146, 145, 147],\n",
       "         [143, 142, 144],\n",
       "         [139, 138, 140],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[156, 155, 157],\n",
       "         [147, 146, 148],\n",
       "         [138, 137, 139],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2027999948477373, 'inference': 29.46689999953378, 'postprocess': 6.047599999874365},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[144, 143, 145],\n",
       "         [144, 143, 145],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[146, 145, 147],\n",
       "         [143, 142, 144],\n",
       "         [139, 138, 140],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[156, 155, 157],\n",
       "         [147, 146, 148],\n",
       "         [138, 137, 139],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3649000029545277, 'inference': 24.59140000428306, 'postprocess': 4.9337999953422695},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[144, 143, 145],\n",
       "         [144, 143, 145],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[146, 145, 147],\n",
       "         [143, 142, 144],\n",
       "         [139, 138, 140],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[156, 155, 157],\n",
       "         [147, 146, 148],\n",
       "         [138, 137, 139],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.460799998312723, 'inference': 22.917400005098898, 'postprocess': 2.0184999957564287},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[145, 144, 146],\n",
       "         [145, 144, 146],\n",
       "         [144, 143, 145],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[147, 146, 148],\n",
       "         [143, 142, 144],\n",
       "         [139, 138, 140],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[156, 155, 157],\n",
       "         [145, 144, 146],\n",
       "         [138, 137, 139],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]],\n",
       " \n",
       "        [[ 14,  17,  17],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5112999972188845, 'inference': 23.01649999571964, 'postprocess': 2.364200001466088},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[123, 125, 127],\n",
       "         [123, 125, 127],\n",
       "         [123, 125, 127],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[144, 146, 148],\n",
       "         [143, 145, 147],\n",
       "         [140, 142, 144],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[163, 165, 167],\n",
       "         [163, 165, 167],\n",
       "         [158, 160, 162],\n",
       "         ...,\n",
       "         [195, 195, 195],\n",
       "         [195, 195, 195],\n",
       "         [195, 195, 195]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5123999983188696, 'inference': 23.73069999885047, 'postprocess': 4.200400006084237},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[123, 125, 127],\n",
       "         [123, 125, 127],\n",
       "         [123, 125, 127],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[144, 146, 148],\n",
       "         [143, 145, 147],\n",
       "         [141, 143, 145],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[163, 165, 167],\n",
       "         [163, 165, 167],\n",
       "         [160, 162, 164],\n",
       "         ...,\n",
       "         [195, 195, 195],\n",
       "         [195, 195, 195],\n",
       "         [195, 195, 195]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5020999999251217, 'inference': 23.414900002535433, 'postprocess': 3.9506999964942224},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[123, 125, 127],\n",
       "         [123, 125, 127],\n",
       "         [123, 125, 127],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[144, 146, 148],\n",
       "         [143, 145, 147],\n",
       "         [141, 143, 145],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[163, 165, 167],\n",
       "         [163, 165, 167],\n",
       "         [160, 162, 164],\n",
       "         ...,\n",
       "         [195, 195, 195],\n",
       "         [195, 195, 195],\n",
       "         [195, 195, 195]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.876900001661852, 'inference': 23.477200003981125, 'postprocess': 3.4329999980400316},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[123, 125, 127],\n",
       "         [123, 125, 127],\n",
       "         [123, 125, 127],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[144, 146, 148],\n",
       "         [143, 145, 147],\n",
       "         [141, 143, 145],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[163, 165, 167],\n",
       "         [163, 165, 167],\n",
       "         [160, 162, 164],\n",
       "         ...,\n",
       "         [195, 195, 195],\n",
       "         [195, 195, 195],\n",
       "         [195, 195, 195]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3480999987223186, 'inference': 23.528500001702923, 'postprocess': 2.008900002692826},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[170, 170, 170],\n",
       "         [165, 165, 165],\n",
       "         [158, 160, 162],\n",
       "         ...,\n",
       "         [199, 199, 199],\n",
       "         [199, 199, 199],\n",
       "         [199, 199, 199]],\n",
       " \n",
       "        [[173, 173, 173],\n",
       "         [174, 174, 174],\n",
       "         [169, 171, 173],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       " \n",
       "        [[178, 178, 178],\n",
       "         [179, 179, 179],\n",
       "         [181, 181, 181],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0912999971187674, 'inference': 24.017200004891492, 'postprocess': 6.232899999304209},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[170, 170, 170],\n",
       "         [165, 165, 165],\n",
       "         [158, 160, 162],\n",
       "         ...,\n",
       "         [199, 199, 199],\n",
       "         [199, 199, 199],\n",
       "         [199, 199, 199]],\n",
       " \n",
       "        [[173, 173, 173],\n",
       "         [174, 174, 174],\n",
       "         [169, 171, 173],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       " \n",
       "        [[178, 178, 178],\n",
       "         [179, 179, 179],\n",
       "         [181, 181, 181],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4713999989908189, 'inference': 23.43029999610735, 'postprocess': 2.0622000010916963},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[171, 171, 171],\n",
       "         [165, 165, 165],\n",
       "         [157, 159, 161],\n",
       "         ...,\n",
       "         [199, 199, 199],\n",
       "         [199, 199, 199],\n",
       "         [199, 199, 199]],\n",
       " \n",
       "        [[174, 174, 174],\n",
       "         [174, 174, 174],\n",
       "         [169, 171, 173],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       " \n",
       "        [[178, 178, 178],\n",
       "         [179, 179, 179],\n",
       "         [181, 181, 181],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2573999993037432, 'inference': 23.327100003371015, 'postprocess': 1.949699995748233},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[171, 171, 171],\n",
       "         [164, 164, 164],\n",
       "         [156, 158, 160],\n",
       "         ...,\n",
       "         [199, 199, 199],\n",
       "         [199, 199, 199],\n",
       "         [199, 199, 199]],\n",
       " \n",
       "        [[174, 174, 174],\n",
       "         [173, 173, 173],\n",
       "         [169, 171, 173],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       " \n",
       "        [[176, 176, 176],\n",
       "         [179, 179, 179],\n",
       "         [181, 181, 181],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  76,  76],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1844000036944635, 'inference': 23.41879999585217, 'postprocess': 4.3224999972153455},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[182, 184, 186],\n",
       "         [182, 184, 186],\n",
       "         [182, 184, 186],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        [[183, 185, 187],\n",
       "         [183, 185, 187],\n",
       "         [182, 184, 186],\n",
       "         ...,\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203]],\n",
       " \n",
       "        [[183, 182, 184],\n",
       "         [182, 181, 183],\n",
       "         [183, 182, 184],\n",
       "         ...,\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]],\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]],\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6719000050215982, 'inference': 26.082800002768636, 'postprocess': 10.432299997773953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[182, 184, 186],\n",
       "         [182, 184, 186],\n",
       "         [182, 184, 186],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        [[183, 185, 187],\n",
       "         [183, 185, 187],\n",
       "         [182, 184, 186],\n",
       "         ...,\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203]],\n",
       " \n",
       "        [[183, 182, 184],\n",
       "         [182, 181, 183],\n",
       "         [183, 182, 184],\n",
       "         ...,\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]],\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]],\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7946000007214025, 'inference': 25.95149999979185, 'postprocess': 5.705600000510458},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[182, 184, 186],\n",
       "         [182, 184, 186],\n",
       "         [182, 184, 186],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        [[183, 185, 187],\n",
       "         [183, 185, 187],\n",
       "         [182, 184, 186],\n",
       "         ...,\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203]],\n",
       " \n",
       "        [[183, 182, 184],\n",
       "         [182, 181, 183],\n",
       "         [183, 182, 184],\n",
       "         ...,\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]],\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]],\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5932000023894943, 'inference': 29.160199999751057, 'postprocess': 2.344299995456822},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[182, 184, 186],\n",
       "         [182, 184, 186],\n",
       "         [182, 184, 186],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        [[183, 185, 187],\n",
       "         [183, 185, 187],\n",
       "         [182, 184, 186],\n",
       "         ...,\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203]],\n",
       " \n",
       "        [[183, 182, 184],\n",
       "         [182, 181, 183],\n",
       "         [183, 182, 184],\n",
       "         ...,\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [203, 203, 203]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]],\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]],\n",
       " \n",
       "        [[ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         [ 85,  88,  88],\n",
       "         ...,\n",
       "         [ 28,  30,  32],\n",
       "         [ 26,  28,  30],\n",
       "         [ 23,  25,  27]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5623999934177846, 'inference': 24.51139999902807, 'postprocess': 3.833000002487097},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[189, 189, 189],\n",
       "         [187, 187, 187],\n",
       "         [182, 182, 182],\n",
       "         ...,\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208]],\n",
       " \n",
       "        [[189, 189, 189],\n",
       "         [188, 188, 188],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[187, 187, 187],\n",
       "         [189, 189, 189],\n",
       "         [187, 187, 187],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]],\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]],\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.5061000051209703, 'inference': 28.027500004100148, 'postprocess': 4.105199994228315},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[189, 189, 189],\n",
       "         [187, 187, 187],\n",
       "         [182, 182, 182],\n",
       "         ...,\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208]],\n",
       " \n",
       "        [[189, 189, 189],\n",
       "         [188, 188, 188],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[187, 187, 187],\n",
       "         [189, 189, 189],\n",
       "         [187, 187, 187],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]],\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]],\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6505000021425076, 'inference': 27.569499994569924, 'postprocess': 5.396699998527765},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[190, 190, 190],\n",
       "         [187, 187, 187],\n",
       "         [182, 182, 182],\n",
       "         ...,\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208]],\n",
       " \n",
       "        [[190, 190, 190],\n",
       "         [188, 188, 188],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[187, 187, 187],\n",
       "         [189, 189, 189],\n",
       "         [187, 187, 187],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]],\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]],\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3346000050660223, 'inference': 25.275699998019263, 'postprocess': 3.4603000021888874},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[190, 190, 190],\n",
       "         [187, 187, 187],\n",
       "         [182, 182, 182],\n",
       "         ...,\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208]],\n",
       " \n",
       "        [[190, 190, 190],\n",
       "         [188, 188, 188],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[187, 187, 187],\n",
       "         [189, 189, 189],\n",
       "         [187, 187, 187],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]],\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]],\n",
       " \n",
       "        [[ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         [ 83,  86,  86],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.863699999579694, 'inference': 23.765300000377465, 'postprocess': 8.311700003105216},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[202, 202, 202],\n",
       "         [201, 201, 201],\n",
       "         [202, 202, 202],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        [[202, 202, 202],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        [[201, 201, 201],\n",
       "         [199, 199, 199],\n",
       "         [196, 196, 196],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5809000033186749, 'inference': 24.324700003489852, 'postprocess': 2.927800000179559},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[202, 202, 202],\n",
       "         [201, 201, 201],\n",
       "         [202, 202, 202],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        [[202, 202, 202],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        [[201, 201, 201],\n",
       "         [199, 199, 199],\n",
       "         [196, 196, 196],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.734799996484071, 'inference': 27.17090000078315, 'postprocess': 5.373300002247561},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[202, 202, 202],\n",
       "         [201, 201, 201],\n",
       "         [202, 202, 202],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        [[202, 202, 202],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        [[201, 201, 201],\n",
       "         [199, 199, 199],\n",
       "         [196, 196, 196],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3377999968943186, 'inference': 48.41689999739174, 'postprocess': 6.662100000539795},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[202, 202, 202],\n",
       "         [201, 201, 201],\n",
       "         [202, 202, 202],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        [[202, 202, 202],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        [[201, 201, 201],\n",
       "         [199, 199, 199],\n",
       "         [196, 196, 196],\n",
       "         ...,\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210],\n",
       "         [210, 210, 210]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.761099996860139, 'inference': 45.799799998349044, 'postprocess': 4.815699998289347},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105, 107, 109],\n",
       "         [104, 106, 108],\n",
       "         [101, 103, 105],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[ 97,  99, 101],\n",
       "         [ 95,  97,  99],\n",
       "         [ 93,  95,  97],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[ 97,  99, 101],\n",
       "         [ 95,  97,  99],\n",
       "         [ 93,  95,  97],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5069000000949018, 'inference': 23.280900000827387, 'postprocess': 3.4956000017700717},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105, 107, 109],\n",
       "         [104, 106, 108],\n",
       "         [101, 103, 105],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[ 97,  99, 101],\n",
       "         [ 95,  97,  99],\n",
       "         [ 93,  95,  97],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[ 97,  99, 101],\n",
       "         [ 95,  97,  99],\n",
       "         [ 93,  95,  97],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.494800002546981, 'inference': 24.437599997327197, 'postprocess': 4.244600000674836},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105, 107, 109],\n",
       "         [104, 106, 108],\n",
       "         [101, 103, 105],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[ 97,  99, 101],\n",
       "         [ 95,  97,  99],\n",
       "         [ 93,  95,  97],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[ 97,  99, 101],\n",
       "         [ 95,  97,  99],\n",
       "         [ 93,  95,  97],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8964000046253204, 'inference': 32.541299995500594, 'postprocess': 2.0509000023594126},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105, 107, 109],\n",
       "         [104, 106, 108],\n",
       "         [101, 103, 105],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[ 97,  99, 101],\n",
       "         [ 95,  97,  99],\n",
       "         [ 93,  95,  97],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[ 97,  99, 101],\n",
       "         [ 95,  97,  99],\n",
       "         [ 93,  95,  97],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2080000014975667, 'inference': 23.363699998299126, 'postprocess': 2.5040000036824495},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         [156, 156, 156],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[164, 164, 164],\n",
       "         [165, 165, 165],\n",
       "         [163, 163, 163],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[166, 166, 166],\n",
       "         [167, 167, 167],\n",
       "         [166, 166, 166],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3217999949119985, 'inference': 23.553099999844562, 'postprocess': 5.471899996337015},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         [156, 156, 156],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[164, 164, 164],\n",
       "         [165, 165, 165],\n",
       "         [163, 163, 163],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[166, 166, 166],\n",
       "         [167, 167, 167],\n",
       "         [166, 166, 166],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8536999996285886, 'inference': 26.319800002966076, 'postprocess': 5.7996000032289885},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         [156, 156, 156],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[164, 164, 164],\n",
       "         [165, 165, 165],\n",
       "         [163, 163, 163],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[166, 166, 166],\n",
       "         [167, 167, 167],\n",
       "         [166, 166, 166],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6002999982447363, 'inference': 24.539099998946767, 'postprocess': 4.634000004443806},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         [156, 156, 156],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[164, 164, 164],\n",
       "         [165, 165, 165],\n",
       "         [163, 163, 163],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[166, 166, 166],\n",
       "         [167, 167, 167],\n",
       "         [166, 166, 166],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         ...,\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5347000007750466, 'inference': 23.47139999619685, 'postprocess': 2.0914000051561743},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 125, 127],\n",
       "         [131, 130, 132],\n",
       "         [136, 135, 137],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[131, 130, 132],\n",
       "         [136, 135, 137],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[133, 132, 134],\n",
       "         [140, 139, 141],\n",
       "         [145, 144, 146],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.731700001982972, 'inference': 23.629499999515247, 'postprocess': 1.8064000032609329},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 125, 127],\n",
       "         [131, 130, 132],\n",
       "         [137, 136, 138],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[131, 130, 132],\n",
       "         [136, 135, 137],\n",
       "         [144, 143, 145],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[133, 132, 134],\n",
       "         [140, 139, 141],\n",
       "         [146, 145, 147],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1873000039486215, 'inference': 23.327200004132465, 'postprocess': 2.038999999058433},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[125, 124, 126],\n",
       "         [131, 130, 132],\n",
       "         [137, 136, 138],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[130, 129, 131],\n",
       "         [136, 135, 137],\n",
       "         [144, 143, 145],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[132, 131, 133],\n",
       "         [140, 139, 141],\n",
       "         [146, 145, 147],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7538000029162504, 'inference': 23.38890000100946, 'postprocess': 9.196999999403488},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[125, 124, 126],\n",
       "         [131, 130, 132],\n",
       "         [137, 136, 138],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[130, 129, 131],\n",
       "         [136, 135, 137],\n",
       "         [144, 143, 145],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        [[132, 131, 133],\n",
       "         [140, 139, 141],\n",
       "         [146, 145, 147],\n",
       "         ...,\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213],\n",
       "         [213, 213, 213]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 78,  80,  82],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3365999984671362, 'inference': 23.537999994005077, 'postprocess': 2.4062000011326745},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.05130000540521, 'inference': 32.07960000145249, 'postprocess': 6.892400000651833},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2202000036486425, 'inference': 27.357799997844268, 'postprocess': 5.682299997715745},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.593700006196741, 'inference': 24.099000002024695, 'postprocess': 4.280400004063267},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         [207, 207, 207],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6575999979977496, 'inference': 26.600900004268624, 'postprocess': 3.2375000009778887},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66]],\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 72,  74,  76],\n",
       "         [ 72,  74,  76],\n",
       "         [ 72,  74,  76]],\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 78,  80,  82],\n",
       "         [ 78,  80,  82],\n",
       "         [ 78,  80,  82]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6388000003644265, 'inference': 23.838699999032542, 'postprocess': 7.814099997631274},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66]],\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 72,  74,  76],\n",
       "         [ 72,  74,  76],\n",
       "         [ 72,  74,  76]],\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6513999944436364, 'inference': 28.582099999766797, 'postprocess': 4.085400003532413},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 61,  63,  65]],\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 72,  74,  76],\n",
       "         [ 72,  74,  76],\n",
       "         [ 72,  74,  76]],\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4755000011064112, 'inference': 23.45140000397805, 'postprocess': 2.0300000032875687},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 61,  63,  65]],\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 72,  74,  76],\n",
       "         [ 72,  74,  76],\n",
       "         [ 72,  74,  76]],\n",
       " \n",
       "        [[ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         [ 77,  79,  81],\n",
       "         ...,\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5039999998407438, 'inference': 24.99119999993127, 'postprocess': 2.589700001408346},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[175, 175, 175],\n",
       "         [173, 173, 173],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[176, 176, 176],\n",
       "         [174, 174, 174],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[178, 178, 178],\n",
       "         [174, 174, 174],\n",
       "         [173, 173, 173],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 61,  63,  65],\n",
       "         [ 55,  57,  59],\n",
       "         [ 54,  56,  58]],\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 55,  57,  59],\n",
       "         [ 49,  51,  53],\n",
       "         [ 48,  50,  52]],\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 50,  52,  54],\n",
       "         [ 44,  46,  48],\n",
       "         [ 43,  45,  47]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7874999975902028, 'inference': 25.495300003967714, 'postprocess': 4.803700001502875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[175, 175, 175],\n",
       "         [173, 173, 173],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[176, 176, 176],\n",
       "         [174, 174, 174],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[178, 178, 178],\n",
       "         [174, 174, 174],\n",
       "         [173, 173, 173],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 61,  63,  65],\n",
       "         [ 55,  57,  59],\n",
       "         [ 54,  56,  58]],\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 55,  57,  59],\n",
       "         [ 49,  51,  53],\n",
       "         [ 48,  50,  52]],\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 50,  52,  54],\n",
       "         [ 45,  47,  49],\n",
       "         [ 44,  46,  48]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.668600001721643, 'inference': 26.0197999959928, 'postprocess': 4.131500005314592},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[175, 175, 175],\n",
       "         [173, 173, 173],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[176, 176, 176],\n",
       "         [174, 174, 174],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[178, 178, 178],\n",
       "         [174, 174, 174],\n",
       "         [173, 173, 173],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 61,  63,  65],\n",
       "         [ 55,  57,  59],\n",
       "         [ 54,  56,  58]],\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 54,  56,  58],\n",
       "         [ 49,  51,  53],\n",
       "         [ 48,  50,  52]],\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 49,  51,  53],\n",
       "         [ 45,  47,  49],\n",
       "         [ 44,  46,  48]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4646999989054166, 'inference': 23.71579999453388, 'postprocess': 2.4238000041805208},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[175, 175, 175],\n",
       "         [173, 173, 173],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[176, 176, 176],\n",
       "         [174, 174, 174],\n",
       "         [172, 172, 172],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[178, 178, 178],\n",
       "         [174, 174, 174],\n",
       "         [173, 173, 173],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 61,  63,  65],\n",
       "         [ 55,  57,  59],\n",
       "         [ 54,  56,  58]],\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 54,  56,  58],\n",
       "         [ 49,  51,  53],\n",
       "         [ 48,  50,  52]],\n",
       " \n",
       "        [[ 76,  79,  79],\n",
       "         [ 78,  81,  81],\n",
       "         [ 79,  82,  82],\n",
       "         ...,\n",
       "         [ 49,  51,  53],\n",
       "         [ 45,  47,  49],\n",
       "         [ 44,  46,  48]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1580999998841435, 'inference': 23.74190000409726, 'postprocess': 5.020600001444109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         [214, 214, 214],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3938000047346577, 'inference': 23.44219999940833, 'postprocess': 3.163400004268624},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         [214, 214, 214],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [142, 141, 143],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 38,  40,  42]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4436999990721233, 'inference': 27.08909999637399, 'postprocess': 1.9147999992128462},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         [214, 214, 214],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[142, 141, 143],\n",
       "         [143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 38,  40,  42]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6742999941925518, 'inference': 27.895300001546275, 'postprocess': 2.0369999983813614},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         [142, 141, 143],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[143, 142, 144],\n",
       "         [143, 142, 144],\n",
       "         [142, 141, 143],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[143, 142, 144],\n",
       "         [142, 141, 143],\n",
       "         [140, 139, 141],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3204999995650724, 'inference': 22.77749999484513, 'postprocess': 2.2364999967976473},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[214, 214, 214],\n",
       "         [211, 211, 211],\n",
       "         [209, 209, 209],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[217, 217, 217],\n",
       "         [216, 216, 216],\n",
       "         [214, 214, 214],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[220, 220, 220],\n",
       "         [218, 218, 218],\n",
       "         [217, 217, 217],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 65,  67,  69],\n",
       "         [ 70,  72,  74],\n",
       "         [ 73,  75,  77]],\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 50,  52,  54],\n",
       "         [ 51,  53,  55],\n",
       "         [ 57,  59,  61]],\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 43,  45,  47],\n",
       "         [ 41,  43,  45],\n",
       "         [ 42,  44,  46]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2614000006578863, 'inference': 23.48139999958221, 'postprocess': 2.5037000013981014},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[214, 214, 214],\n",
       "         [211, 211, 211],\n",
       "         [209, 209, 209],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[217, 217, 217],\n",
       "         [216, 216, 216],\n",
       "         [214, 214, 214],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[220, 220, 220],\n",
       "         [218, 218, 218],\n",
       "         [217, 217, 217],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 65,  67,  69],\n",
       "         [ 70,  72,  74],\n",
       "         [ 73,  75,  77]],\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 50,  52,  54],\n",
       "         [ 51,  53,  55],\n",
       "         [ 57,  59,  61]],\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 43,  45,  47],\n",
       "         [ 41,  43,  45],\n",
       "         [ 42,  44,  46]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1331999960239045, 'inference': 23.576599996886216, 'postprocess': 3.9858999953139573},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[214, 214, 214],\n",
       "         [211, 211, 211],\n",
       "         [209, 209, 209],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[217, 217, 217],\n",
       "         [216, 216, 216],\n",
       "         [214, 214, 214],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[220, 220, 220],\n",
       "         [218, 218, 218],\n",
       "         [217, 217, 217],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 65,  67,  69],\n",
       "         [ 70,  72,  74],\n",
       "         [ 73,  75,  77]],\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 50,  52,  54],\n",
       "         [ 51,  53,  55],\n",
       "         [ 57,  59,  61]],\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 43,  45,  47],\n",
       "         [ 41,  43,  45],\n",
       "         [ 42,  44,  46]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.02980000176467, 'inference': 22.843500002636574, 'postprocess': 2.707400002691429},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[214, 214, 214],\n",
       "         [211, 211, 211],\n",
       "         [209, 209, 209],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[217, 217, 217],\n",
       "         [216, 216, 216],\n",
       "         [214, 214, 214],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[220, 220, 220],\n",
       "         [218, 218, 218],\n",
       "         [217, 217, 217],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 64,  66,  68],\n",
       "         [ 70,  72,  74],\n",
       "         [ 75,  77,  79]],\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 50,  52,  54],\n",
       "         [ 52,  54,  56],\n",
       "         [ 58,  60,  62]],\n",
       " \n",
       "        [[ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         [ 62,  64,  66],\n",
       "         ...,\n",
       "         [ 44,  46,  48],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3349000000744127, 'inference': 23.051699994539376, 'postprocess': 3.567399995517917},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[225, 225, 225],\n",
       "         [224, 224, 224],\n",
       "         [224, 224, 224],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[225, 225, 225],\n",
       "         [224, 224, 224],\n",
       "         [224, 224, 224],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[224, 224, 224],\n",
       "         [223, 223, 223],\n",
       "         [223, 223, 223],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [109, 111, 113],\n",
       "         [111, 113, 115],\n",
       "         [112, 114, 116]],\n",
       " \n",
       "        [[ 54,  56,  58],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [111, 113, 115],\n",
       "         [113, 115, 117],\n",
       "         [113, 115, 117]],\n",
       " \n",
       "        [[ 57,  59,  61],\n",
       "         [ 58,  60,  62],\n",
       "         [ 59,  61,  63],\n",
       "         ...,\n",
       "         [112, 114, 116],\n",
       "         [113, 115, 117],\n",
       "         [114, 116, 118]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0714999991469085, 'inference': 27.62059999804478, 'postprocess': 6.517399997392204},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[225, 225, 225],\n",
       "         [224, 224, 224],\n",
       "         [224, 224, 224],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[225, 225, 225],\n",
       "         [224, 224, 224],\n",
       "         [224, 224, 224],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[224, 224, 224],\n",
       "         [223, 223, 223],\n",
       "         [223, 223, 223],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [109, 111, 113],\n",
       "         [111, 113, 115],\n",
       "         [112, 114, 116]],\n",
       " \n",
       "        [[ 54,  56,  58],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [111, 113, 115],\n",
       "         [113, 115, 117],\n",
       "         [113, 115, 117]],\n",
       " \n",
       "        [[ 57,  59,  61],\n",
       "         [ 58,  60,  62],\n",
       "         [ 59,  61,  63],\n",
       "         ...,\n",
       "         [112, 114, 116],\n",
       "         [113, 115, 117],\n",
       "         [114, 116, 118]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8210999987786636, 'inference': 23.01239999360405, 'postprocess': 2.4648999969940633},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[225, 225, 225],\n",
       "         [224, 224, 224],\n",
       "         [224, 224, 224],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[225, 225, 225],\n",
       "         [224, 224, 224],\n",
       "         [224, 224, 224],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[224, 224, 224],\n",
       "         [223, 223, 223],\n",
       "         [223, 223, 223],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [111, 113, 115],\n",
       "         [112, 114, 116],\n",
       "         [114, 116, 118]],\n",
       " \n",
       "        [[ 54,  56,  58],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [112, 114, 116],\n",
       "         [114, 116, 118],\n",
       "         [115, 117, 119]],\n",
       " \n",
       "        [[ 57,  59,  61],\n",
       "         [ 58,  60,  62],\n",
       "         [ 59,  61,  63],\n",
       "         ...,\n",
       "         [112, 114, 116],\n",
       "         [114, 116, 118],\n",
       "         [115, 117, 119]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.513299997895956, 'inference': 24.527900000975933, 'postprocess': 2.0820999998250045},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[225, 225, 225],\n",
       "         [224, 224, 224],\n",
       "         [224, 224, 224],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[225, 225, 225],\n",
       "         [224, 224, 224],\n",
       "         [224, 224, 224],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[224, 224, 224],\n",
       "         [223, 223, 223],\n",
       "         [223, 223, 223],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [111, 113, 115],\n",
       "         [112, 114, 116],\n",
       "         [114, 116, 118]],\n",
       " \n",
       "        [[ 54,  56,  58],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [112, 114, 116],\n",
       "         [114, 116, 118],\n",
       "         [115, 117, 119]],\n",
       " \n",
       "        [[ 57,  59,  61],\n",
       "         [ 58,  60,  62],\n",
       "         [ 59,  61,  63],\n",
       "         ...,\n",
       "         [112, 114, 116],\n",
       "         [114, 116, 118],\n",
       "         [115, 117, 119]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.6599000048008747, 'inference': 23.048800001561176, 'postprocess': 2.2724000009475276},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[208, 208, 208],\n",
       "         [203, 203, 203],\n",
       "         [201, 201, 201],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[213, 213, 213],\n",
       "         [209, 209, 209],\n",
       "         [206, 206, 206],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[215, 215, 215],\n",
       "         [213, 213, 213],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [165, 168, 168],\n",
       "         [165, 168, 168],\n",
       "         [165, 168, 168]],\n",
       " \n",
       "        [[ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [176, 179, 179],\n",
       "         [176, 179, 179],\n",
       "         [176, 179, 179]],\n",
       " \n",
       "        [[ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         ...,\n",
       "         [180, 183, 183],\n",
       "         [179, 182, 182],\n",
       "         [179, 182, 182]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7300999970757402, 'inference': 23.073199998179916, 'postprocess': 2.2492999996757135},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[208, 208, 208],\n",
       "         [203, 203, 203],\n",
       "         [201, 201, 201],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[213, 213, 213],\n",
       "         [209, 209, 209],\n",
       "         [206, 206, 206],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[215, 215, 215],\n",
       "         [213, 213, 213],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [165, 168, 168],\n",
       "         [165, 168, 168],\n",
       "         [165, 168, 168]],\n",
       " \n",
       "        [[ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [176, 179, 179],\n",
       "         [176, 179, 179],\n",
       "         [176, 179, 179]],\n",
       " \n",
       "        [[ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         ...,\n",
       "         [180, 183, 183],\n",
       "         [179, 182, 182],\n",
       "         [179, 182, 182]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3538999992306344, 'inference': 22.988900003838353, 'postprocess': 6.760000003851019},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[208, 208, 208],\n",
       "         [203, 203, 203],\n",
       "         [201, 201, 201],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[213, 213, 213],\n",
       "         [209, 209, 209],\n",
       "         [206, 206, 206],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[215, 215, 215],\n",
       "         [213, 213, 213],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [165, 168, 168],\n",
       "         [165, 168, 168],\n",
       "         [165, 168, 168]],\n",
       " \n",
       "        [[ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [176, 179, 179],\n",
       "         [176, 179, 179],\n",
       "         [176, 179, 179]],\n",
       " \n",
       "        [[ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         ...,\n",
       "         [180, 183, 183],\n",
       "         [179, 182, 182],\n",
       "         [179, 182, 182]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3622999977087602, 'inference': 22.930599996470846, 'postprocess': 3.1541999996989034},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[208, 208, 208],\n",
       "         [203, 203, 203],\n",
       "         [201, 201, 201],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[213, 213, 213],\n",
       "         [209, 209, 209],\n",
       "         [206, 206, 206],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[215, 215, 215],\n",
       "         [213, 213, 213],\n",
       "         [208, 208, 208],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       " \n",
       "        [[ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         ...,\n",
       "         [180, 180, 180],\n",
       "         [180, 180, 180],\n",
       "         [180, 180, 180]],\n",
       " \n",
       "        [[ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         ...,\n",
       "         [183, 183, 183],\n",
       "         [182, 182, 182],\n",
       "         [182, 182, 182]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2712000025203452, 'inference': 22.915400004421826, 'postprocess': 1.8353999985265546},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[188, 188, 188],\n",
       "         [190, 190, 190],\n",
       "         [192, 192, 192],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[190, 190, 190],\n",
       "         [193, 193, 193],\n",
       "         [194, 194, 194],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[193, 193, 193],\n",
       "         [194, 194, 194],\n",
       "         [195, 195, 195],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  45,  45],\n",
       "         [ 41,  44,  44],\n",
       "         [ 38,  41,  41],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 45,  48,  48],\n",
       "         [ 43,  46,  46],\n",
       "         [ 41,  44,  44],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 44,  47,  47],\n",
       "         [ 42,  45,  45],\n",
       "         [ 42,  45,  45],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2541000032797456, 'inference': 22.877700001117773, 'postprocess': 3.5472000017762184},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[188, 188, 188],\n",
       "         [189, 189, 189],\n",
       "         [190, 190, 190],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[189, 189, 189],\n",
       "         [192, 192, 192],\n",
       "         [193, 193, 193],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[192, 192, 192],\n",
       "         [193, 193, 193],\n",
       "         [195, 195, 195],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  45,  45],\n",
       "         [ 41,  44,  44],\n",
       "         [ 38,  41,  41],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 45,  48,  48],\n",
       "         [ 43,  46,  46],\n",
       "         [ 41,  44,  44],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 44,  47,  47],\n",
       "         [ 42,  45,  45],\n",
       "         [ 42,  45,  45],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3803999972878955, 'inference': 22.454400001151953, 'postprocess': 2.0433999961824156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[188, 188, 188],\n",
       "         [189, 189, 189],\n",
       "         [190, 190, 190],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[189, 189, 189],\n",
       "         [192, 192, 192],\n",
       "         [193, 193, 193],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[192, 192, 192],\n",
       "         [193, 193, 193],\n",
       "         [195, 195, 195],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  45,  45],\n",
       "         [ 41,  44,  44],\n",
       "         [ 38,  41,  41],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 44,  47,  47],\n",
       "         [ 42,  45,  45],\n",
       "         [ 40,  43,  43],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 44,  47,  47],\n",
       "         [ 42,  45,  45],\n",
       "         [ 42,  45,  45],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3896999953431077, 'inference': 22.5231000003987, 'postprocess': 5.59899999643676},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[188, 188, 188],\n",
       "         [189, 189, 189],\n",
       "         [190, 190, 190],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[189, 189, 189],\n",
       "         [192, 192, 192],\n",
       "         [193, 193, 193],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        [[192, 192, 192],\n",
       "         [193, 193, 193],\n",
       "         [195, 195, 195],\n",
       "         ...,\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218],\n",
       "         [218, 218, 218]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  45,  45],\n",
       "         [ 41,  44,  44],\n",
       "         [ 38,  41,  41],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 44,  47,  47],\n",
       "         [ 42,  45,  45],\n",
       "         [ 40,  43,  43],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 44,  47,  47],\n",
       "         [ 42,  45,  45],\n",
       "         [ 42,  45,  45],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2306999997235835, 'inference': 23.32380000007106, 'postprocess': 2.472900006978307},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[138, 138, 138],\n",
       "         [140, 140, 140],\n",
       "         [146, 146, 146],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[137, 137, 137],\n",
       "         [142, 142, 142],\n",
       "         [149, 149, 149],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[138, 138, 138],\n",
       "         [144, 144, 144],\n",
       "         [151, 151, 151],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 26,  29,  29],\n",
       "         [ 27,  30,  30],\n",
       "         [ 29,  32,  32],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 29,  32,  32],\n",
       "         [ 33,  36,  36],\n",
       "         [ 36,  39,  39],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[ 36,  39,  39],\n",
       "         [ 38,  41,  41],\n",
       "         [ 44,  47,  47],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [195, 195, 195]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4174999960232526, 'inference': 22.69949999754317, 'postprocess': 4.408399996464141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[138, 138, 138],\n",
       "         [140, 140, 140],\n",
       "         [146, 146, 146],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[137, 137, 137],\n",
       "         [142, 142, 142],\n",
       "         [149, 149, 149],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[138, 138, 138],\n",
       "         [144, 144, 144],\n",
       "         [151, 151, 151],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 26,  29,  29],\n",
       "         [ 27,  30,  30],\n",
       "         [ 29,  32,  32],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 29,  32,  32],\n",
       "         [ 33,  36,  36],\n",
       "         [ 36,  39,  39],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[ 36,  39,  39],\n",
       "         [ 38,  41,  41],\n",
       "         [ 44,  47,  47],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [195, 195, 195]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.015500002016779, 'inference': 23.60439999756636, 'postprocess': 2.6211000003968365},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[138, 138, 138],\n",
       "         [140, 140, 140],\n",
       "         [146, 146, 146],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[137, 137, 137],\n",
       "         [142, 142, 142],\n",
       "         [149, 149, 149],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[138, 138, 138],\n",
       "         [144, 144, 144],\n",
       "         [151, 151, 151],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 26,  29,  29],\n",
       "         [ 27,  30,  30],\n",
       "         [ 29,  32,  32],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 29,  32,  32],\n",
       "         [ 33,  36,  36],\n",
       "         [ 36,  39,  39],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[ 36,  39,  39],\n",
       "         [ 38,  41,  41],\n",
       "         [ 44,  47,  47],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [195, 195, 195]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.299499999731779, 'inference': 22.403200004191604, 'postprocess': 1.941800001077354},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[137, 137, 137],\n",
       "         [140, 140, 140],\n",
       "         [146, 146, 146],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[137, 137, 137],\n",
       "         [142, 142, 142],\n",
       "         [149, 149, 149],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[138, 138, 138],\n",
       "         [144, 144, 144],\n",
       "         [151, 151, 151],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 26,  29,  29],\n",
       "         [ 27,  30,  30],\n",
       "         [ 29,  32,  32],\n",
       "         ...,\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192],\n",
       "         [192, 192, 192]],\n",
       " \n",
       "        [[ 29,  32,  32],\n",
       "         [ 33,  36,  36],\n",
       "         [ 36,  39,  39],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194]],\n",
       " \n",
       "        [[ 36,  39,  39],\n",
       "         [ 38,  41,  41],\n",
       "         [ 44,  47,  47],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [194, 194, 194],\n",
       "         [195, 195, 195]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3756999978795648, 'inference': 22.437699997681193, 'postprocess': 3.612000000430271},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [199, 199, 199],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [199, 199, 199],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 59,  61,  63],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[ 56,  58,  60],\n",
       "         [ 57,  59,  61],\n",
       "         [ 57,  59,  61],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3694999943254516, 'inference': 22.389699995983392, 'postprocess': 1.8967999931192026},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [199, 199, 199],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [199, 199, 199],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 59,  61,  63],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[ 56,  58,  60],\n",
       "         [ 57,  59,  61],\n",
       "         [ 57,  59,  61],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5031000002636574, 'inference': 22.899999996297993, 'postprocess': 2.5641000029281713},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [201, 201, 201],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 59,  61,  63],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[ 56,  58,  60],\n",
       "         [ 57,  59,  61],\n",
       "         [ 57,  59,  61],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2606000018422492, 'inference': 22.553699993295595, 'postprocess': 2.0384000017656945},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [201, 201, 201],\n",
       "         ...,\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216],\n",
       "         [216, 216, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 59,  61,  63],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[ 56,  58,  60],\n",
       "         [ 57,  59,  61],\n",
       "         [ 57,  59,  61],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]],\n",
       " \n",
       "        [[ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         ...,\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193],\n",
       "         [193, 193, 193]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2232999943080358, 'inference': 22.46719999675406, 'postprocess': 3.3375999992131256},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[196, 196, 196],\n",
       "         [192, 192, 192],\n",
       "         [186, 186, 186],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[197, 197, 197],\n",
       "         [192, 192, 192],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[199, 199, 199],\n",
       "         [192, 192, 192],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  70,  72],\n",
       "         [ 66,  68,  70],\n",
       "         [ 66,  68,  70],\n",
       "         ...,\n",
       "         [127, 130, 130],\n",
       "         [123, 126, 126],\n",
       "         [122, 125, 125]],\n",
       " \n",
       "        [[ 55,  57,  59],\n",
       "         [ 52,  54,  56],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [119, 122, 122],\n",
       "         [116, 119, 119],\n",
       "         [116, 119, 119]],\n",
       " \n",
       "        [[ 43,  45,  47],\n",
       "         [ 43,  45,  47],\n",
       "         [ 43,  45,  47],\n",
       "         ...,\n",
       "         [112, 115, 115],\n",
       "         [112, 115, 115],\n",
       "         [112, 115, 115]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7585000023245811, 'inference': 23.68929999647662, 'postprocess': 2.1982000034768134},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[196, 196, 196],\n",
       "         [192, 192, 192],\n",
       "         [186, 186, 186],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[197, 197, 197],\n",
       "         [192, 192, 192],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[199, 199, 199],\n",
       "         [192, 192, 192],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  70,  72],\n",
       "         [ 66,  68,  70],\n",
       "         [ 66,  68,  70],\n",
       "         ...,\n",
       "         [130, 130, 130],\n",
       "         [126, 126, 126],\n",
       "         [125, 125, 125]],\n",
       " \n",
       "        [[ 55,  57,  59],\n",
       "         [ 52,  54,  56],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [122, 122, 122],\n",
       "         [119, 119, 119],\n",
       "         [119, 119, 119]],\n",
       " \n",
       "        [[ 43,  45,  47],\n",
       "         [ 43,  45,  47],\n",
       "         [ 43,  45,  47],\n",
       "         ...,\n",
       "         [115, 115, 115],\n",
       "         [115, 115, 115],\n",
       "         [115, 115, 115]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6366999989259057, 'inference': 26.431300000695046, 'postprocess': 3.8685999970766716},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[196, 196, 196],\n",
       "         [192, 192, 192],\n",
       "         [186, 186, 186],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[197, 197, 197],\n",
       "         [192, 192, 192],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[199, 199, 199],\n",
       "         [192, 192, 192],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  70,  72],\n",
       "         [ 66,  68,  70],\n",
       "         [ 66,  68,  70],\n",
       "         ...,\n",
       "         [127, 130, 130],\n",
       "         [123, 126, 126],\n",
       "         [122, 125, 125]],\n",
       " \n",
       "        [[ 55,  57,  59],\n",
       "         [ 52,  54,  56],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [119, 122, 122],\n",
       "         [116, 119, 119],\n",
       "         [116, 119, 119]],\n",
       " \n",
       "        [[ 43,  45,  47],\n",
       "         [ 43,  45,  47],\n",
       "         [ 43,  45,  47],\n",
       "         ...,\n",
       "         [112, 115, 115],\n",
       "         [112, 115, 115],\n",
       "         [112, 115, 115]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5706999984104186, 'inference': 22.273399998084642, 'postprocess': 3.500400001939852},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[197, 197, 197],\n",
       "         [193, 193, 193],\n",
       "         [186, 186, 186],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[199, 199, 199],\n",
       "         [193, 193, 193],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        [[200, 200, 200],\n",
       "         [193, 193, 193],\n",
       "         [185, 185, 185],\n",
       "         ...,\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  70,  72],\n",
       "         [ 66,  68,  70],\n",
       "         [ 66,  68,  70],\n",
       "         ...,\n",
       "         [129, 129, 129],\n",
       "         [125, 125, 125],\n",
       "         [124, 124, 124]],\n",
       " \n",
       "        [[ 55,  57,  59],\n",
       "         [ 52,  54,  56],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [121, 121, 121],\n",
       "         [118, 118, 118],\n",
       "         [118, 118, 118]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 43,  45,  47],\n",
       "         ...,\n",
       "         [114, 114, 114],\n",
       "         [114, 114, 114],\n",
       "         [114, 114, 114]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2817999959224835, 'inference': 22.41159999539377, 'postprocess': 1.9836999999824911},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 37,  39,  41],\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41],\n",
       "         ...,\n",
       "         [ 86,  88,  90],\n",
       "         [ 73,  75,  77],\n",
       "         [ 65,  67,  69]],\n",
       " \n",
       "        [[ 40,  42,  44],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44],\n",
       "         ...,\n",
       "         [ 99, 101, 103],\n",
       "         [ 87,  89,  91],\n",
       "         [ 79,  81,  83]],\n",
       " \n",
       "        [[ 41,  43,  45],\n",
       "         [ 41,  43,  45],\n",
       "         [ 41,  43,  45],\n",
       "         ...,\n",
       "         [107, 109, 111],\n",
       "         [100, 102, 104],\n",
       "         [ 92,  94,  96]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2846000026911497, 'inference': 22.37460000469582, 'postprocess': 2.0997999963583425},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 37,  40,  40],\n",
       "         [ 37,  40,  40],\n",
       "         [ 37,  40,  40],\n",
       "         ...,\n",
       "         [ 86,  88,  90],\n",
       "         [ 73,  75,  77],\n",
       "         [ 65,  67,  69]],\n",
       " \n",
       "        [[ 40,  43,  43],\n",
       "         [ 40,  43,  43],\n",
       "         [ 40,  43,  43],\n",
       "         ...,\n",
       "         [ 99, 101, 103],\n",
       "         [ 87,  89,  91],\n",
       "         [ 79,  81,  83]],\n",
       " \n",
       "        [[ 41,  44,  44],\n",
       "         [ 41,  44,  44],\n",
       "         [ 41,  44,  44],\n",
       "         ...,\n",
       "         [107, 109, 111],\n",
       "         [100, 102, 104],\n",
       "         [ 92,  94,  96]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.279600000998471, 'inference': 22.35590000054799, 'postprocess': 1.8944999974337406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 37,  39,  41],\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41],\n",
       "         ...,\n",
       "         [ 86,  88,  90],\n",
       "         [ 73,  75,  77],\n",
       "         [ 65,  67,  69]],\n",
       " \n",
       "        [[ 40,  42,  44],\n",
       "         [ 40,  42,  44],\n",
       "         [ 40,  42,  44],\n",
       "         ...,\n",
       "         [ 99, 101, 103],\n",
       "         [ 87,  89,  91],\n",
       "         [ 79,  81,  83]],\n",
       " \n",
       "        [[ 41,  43,  45],\n",
       "         [ 41,  43,  45],\n",
       "         [ 41,  43,  45],\n",
       "         ...,\n",
       "         [107, 109, 111],\n",
       "         [100, 102, 104],\n",
       "         [ 92,  94,  96]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2501999954110943, 'inference': 22.70509999652859, 'postprocess': 2.281600005517248},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        [[120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211],\n",
       "         [211, 211, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 37,  40,  40],\n",
       "         [ 37,  40,  40],\n",
       "         [ 37,  40,  40],\n",
       "         ...,\n",
       "         [ 86,  88,  90],\n",
       "         [ 73,  75,  77],\n",
       "         [ 65,  67,  69]],\n",
       " \n",
       "        [[ 40,  43,  43],\n",
       "         [ 40,  43,  43],\n",
       "         [ 40,  43,  43],\n",
       "         ...,\n",
       "         [ 99, 101, 103],\n",
       "         [ 87,  89,  91],\n",
       "         [ 79,  81,  83]],\n",
       " \n",
       "        [[ 41,  44,  44],\n",
       "         [ 41,  44,  44],\n",
       "         [ 41,  44,  44],\n",
       "         ...,\n",
       "         [107, 109, 111],\n",
       "         [100, 102, 104],\n",
       "         [ 92,  94,  96]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2314999985392205, 'inference': 22.49419999861857, 'postprocess': 2.147500003047753},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 44,  47,  47],\n",
       "         [ 43,  46,  46],\n",
       "         [ 43,  46,  46]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2032000013277866, 'inference': 22.56679999845801, 'postprocess': 3.598499999498017},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 44,  47,  47],\n",
       "         [ 43,  46,  46],\n",
       "         [ 43,  46,  46]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4238000003388152, 'inference': 32.240300002740696, 'postprocess': 3.284500002337154},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 44,  47,  47],\n",
       "         [ 43,  46,  46],\n",
       "         [ 43,  46,  46]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.009600000747014, 'inference': 22.736900005838834, 'postprocess': 2.3087000008672476},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        [[161, 161, 161],\n",
       "         [167, 167, 167],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209],\n",
       "         [209, 209, 209]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 44,  47,  47],\n",
       "         [ 43,  46,  46],\n",
       "         [ 43,  46,  46]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 35,  38,  38],\n",
       "         [ 36,  39,  39],\n",
       "         [ 36,  39,  39]],\n",
       " \n",
       "        [[ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2411000027204864, 'inference': 25.92680000088876, 'postprocess': 6.237800000235438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        [[183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        [[183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         ...,\n",
       "         [ 79,  82,  82],\n",
       "         [ 79,  82,  82],\n",
       "         [ 79,  82,  82]],\n",
       " \n",
       "        [[ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         ...,\n",
       "         [108, 111, 111],\n",
       "         [108, 111, 111],\n",
       "         [108, 111, 111]],\n",
       " \n",
       "        [[ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         ...,\n",
       "         [122, 125, 125],\n",
       "         [122, 125, 125],\n",
       "         [122, 125, 125]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3432999985525385, 'inference': 24.206100002629682, 'postprocess': 2.4608000021544285},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        [[183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        [[183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         [183, 183, 183],\n",
       "         ...,\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202],\n",
       "         [202, 202, 202]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         ...,\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83]],\n",
       " \n",
       "        [[ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         ...,\n",
       "         [108, 110, 112],\n",
       "         [108, 110, 112],\n",
       "         [108, 110, 112]],\n",
       " \n",
       "        [[ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         ...,\n",
       "         [122, 124, 126],\n",
       "         [122, 124, 126],\n",
       "         [122, 124, 126]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5837999962968752, 'inference': 27.37110000452958, 'postprocess': 5.010900000343099},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[174, 174, 174],\n",
       "         [174, 174, 174],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[174, 174, 174],\n",
       "         [174, 174, 174],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        [[174, 174, 174],\n",
       "         [174, 174, 174],\n",
       "         [174, 174, 174],\n",
       "         ...,\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217],\n",
       "         [217, 217, 217]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 38,  41,  41],\n",
       "         [ 38,  41,  41],\n",
       "         [ 38,  41,  41],\n",
       "         ...,\n",
       "         [156, 156, 156],\n",
       "         [156, 156, 156],\n",
       "         [156, 156, 156]],\n",
       " \n",
       "        [[ 38,  41,  41],\n",
       "         [ 38,  41,  41],\n",
       "         [ 38,  41,  41],\n",
       "         ...,\n",
       "         [156, 156, 156],\n",
       "         [156, 156, 156],\n",
       "         [156, 156, 156]],\n",
       " \n",
       "        [[ 38,  41,  41],\n",
       "         [ 38,  41,  41],\n",
       "         [ 38,  41,  41],\n",
       "         ...,\n",
       "         [156, 156, 156],\n",
       "         [156, 156, 156],\n",
       "         [156, 156, 156]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3799000007566065, 'inference': 23.5605999987456, 'postprocess': 5.750600001192652},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[172, 174, 176],\n",
       "         [169, 171, 173],\n",
       "         [158, 160, 162],\n",
       "         ...,\n",
       "         [225, 225, 225],\n",
       "         [225, 225, 225],\n",
       "         [225, 225, 225]],\n",
       " \n",
       "        [[172, 174, 176],\n",
       "         [169, 171, 173],\n",
       "         [158, 160, 162],\n",
       "         ...,\n",
       "         [225, 225, 225],\n",
       "         [225, 225, 225],\n",
       "         [225, 225, 225]],\n",
       " \n",
       "        [[173, 175, 177],\n",
       "         [169, 171, 173],\n",
       "         [158, 160, 162],\n",
       "         ...,\n",
       "         [225, 225, 225],\n",
       "         [225, 225, 225],\n",
       "         [225, 225, 225]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         ...,\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124]],\n",
       " \n",
       "        [[ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         ...,\n",
       "         [116, 118, 120],\n",
       "         [116, 118, 120],\n",
       "         [116, 118, 120]],\n",
       " \n",
       "        [[ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         ...,\n",
       "         [114, 116, 118],\n",
       "         [114, 116, 118],\n",
       "         [115, 117, 119]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3069999986328185, 'inference': 32.16900000552414, 'postprocess': 4.337799997301772},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[175, 175, 175],\n",
       "         [182, 182, 182],\n",
       "         [193, 193, 193],\n",
       "         ...,\n",
       "         [229, 229, 229],\n",
       "         [229, 229, 229],\n",
       "         [228, 228, 228]],\n",
       " \n",
       "        [[178, 178, 178],\n",
       "         [183, 183, 183],\n",
       "         [194, 194, 194],\n",
       "         ...,\n",
       "         [228, 228, 228],\n",
       "         [228, 228, 228],\n",
       "         [228, 228, 228]],\n",
       " \n",
       "        [[176, 176, 176],\n",
       "         [183, 183, 183],\n",
       "         [194, 194, 194],\n",
       "         ...,\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [156, 158, 160],\n",
       "         [156, 158, 160],\n",
       "         [156, 158, 160]],\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [155, 157, 159],\n",
       "         [155, 157, 159],\n",
       "         [155, 157, 159]],\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [154, 156, 158],\n",
       "         [154, 156, 158],\n",
       "         [154, 156, 158]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.7095999976154417, 'inference': 23.7221000061254, 'postprocess': 3.073600004427135},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[107, 109, 111],\n",
       "         [107, 109, 111],\n",
       "         [107, 109, 111],\n",
       "         ...,\n",
       "         [181, 181, 181],\n",
       "         [180, 179, 181],\n",
       "         [179, 178, 180]],\n",
       " \n",
       "        [[108, 110, 112],\n",
       "         [107, 109, 111],\n",
       "         [107, 109, 111],\n",
       "         ...,\n",
       "         [178, 178, 178],\n",
       "         [173, 172, 174],\n",
       "         [173, 172, 174]],\n",
       " \n",
       "        [[108, 110, 112],\n",
       "         [107, 109, 111],\n",
       "         [107, 109, 111],\n",
       "         ...,\n",
       "         [165, 165, 165],\n",
       "         [168, 167, 169],\n",
       "         [171, 170, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [163, 162, 164],\n",
       "         [163, 162, 164],\n",
       "         [163, 162, 164]],\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [161, 160, 162],\n",
       "         [163, 162, 164],\n",
       "         [163, 162, 164]],\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [161, 160, 162],\n",
       "         [163, 162, 164],\n",
       "         [163, 162, 164]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.526399999624118, 'inference': 28.66830000129994, 'postprocess': 5.015199996705633},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 116, 118],\n",
       "         [114, 116, 118],\n",
       "         [114, 116, 118],\n",
       "         ...,\n",
       "         [ 34,  36,  38],\n",
       "         [ 34,  36,  38],\n",
       "         [ 34,  36,  38]],\n",
       " \n",
       "        [[114, 116, 118],\n",
       "         [114, 116, 118],\n",
       "         [114, 116, 118],\n",
       "         ...,\n",
       "         [ 34,  36,  38],\n",
       "         [ 34,  36,  38],\n",
       "         [ 34,  36,  38]],\n",
       " \n",
       "        [[115, 117, 119],\n",
       "         [115, 117, 119],\n",
       "         [115, 117, 119],\n",
       "         ...,\n",
       "         [ 35,  37,  39],\n",
       "         [ 35,  37,  39],\n",
       "         [ 35,  37,  39]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         ...,\n",
       "         [ 92,  94,  96],\n",
       "         [ 86,  88,  90],\n",
       "         [ 80,  82,  84]],\n",
       " \n",
       "        [[ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         ...,\n",
       "         [ 92,  94,  96],\n",
       "         [ 86,  88,  90],\n",
       "         [ 80,  82,  84]],\n",
       " \n",
       "        [[ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         ...,\n",
       "         [ 92,  94,  96],\n",
       "         [ 86,  88,  90],\n",
       "         [ 80,  82,  84]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.5421000027563423, 'inference': 29.09180000278866, 'postprocess': 8.043800000450574},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[119, 121, 123],\n",
       "         [119, 121, 123],\n",
       "         [119, 121, 123],\n",
       "         ...,\n",
       "         [ 47,  49,  51],\n",
       "         [ 47,  49,  51],\n",
       "         [ 47,  49,  51]],\n",
       " \n",
       "        [[118, 120, 122],\n",
       "         [118, 120, 122],\n",
       "         [118, 120, 122],\n",
       "         ...,\n",
       "         [ 48,  50,  52],\n",
       "         [ 48,  50,  52],\n",
       "         [ 47,  49,  51]],\n",
       " \n",
       "        [[119, 121, 123],\n",
       "         [119, 121, 123],\n",
       "         [119, 121, 123],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 43,  45,  47]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 16,  19,  19],\n",
       "         [ 16,  19,  19],\n",
       "         [ 16,  19,  19],\n",
       "         ...,\n",
       "         [147, 149, 151],\n",
       "         [147, 149, 151],\n",
       "         [148, 150, 152]],\n",
       " \n",
       "        [[ 16,  19,  19],\n",
       "         [ 16,  19,  19],\n",
       "         [ 16,  19,  19],\n",
       "         ...,\n",
       "         [147, 149, 151],\n",
       "         [147, 149, 151],\n",
       "         [148, 150, 152]],\n",
       " \n",
       "        [[ 16,  19,  19],\n",
       "         [ 16,  19,  19],\n",
       "         [ 16,  19,  19],\n",
       "         ...,\n",
       "         [147, 149, 151],\n",
       "         [147, 149, 151],\n",
       "         [148, 150, 152]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6333000021404587, 'inference': 25.262900002417155, 'postprocess': 5.374200001824647},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[121, 123, 125],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [ 72,  75,  75],\n",
       "         [ 71,  74,  74],\n",
       "         [ 70,  73,  73]],\n",
       " \n",
       "        [[121, 123, 125],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [ 76,  79,  79],\n",
       "         [ 76,  79,  79],\n",
       "         [ 76,  79,  79]],\n",
       " \n",
       "        [[121, 123, 125],\n",
       "         [120, 122, 124],\n",
       "         [120, 122, 124],\n",
       "         ...,\n",
       "         [ 78,  80,  82],\n",
       "         [ 78,  80,  82],\n",
       "         [ 78,  80,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [133, 135, 137],\n",
       "         [134, 136, 138],\n",
       "         [135, 137, 139]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [136, 138, 140],\n",
       "         [136, 138, 140],\n",
       "         [136, 138, 140]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [136, 138, 140],\n",
       "         [136, 138, 140],\n",
       "         [136, 138, 140]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5790999968885444, 'inference': 23.398299999826122, 'postprocess': 3.8628000038443133},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[118, 120, 122],\n",
       "         [118, 120, 122],\n",
       "         [118, 120, 122],\n",
       "         ...,\n",
       "         [ 84,  86,  88],\n",
       "         [ 84,  86,  88],\n",
       "         [ 84,  86,  88]],\n",
       " \n",
       "        [[118, 120, 122],\n",
       "         [118, 120, 122],\n",
       "         [118, 120, 122],\n",
       "         ...,\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86],\n",
       "         [ 82,  84,  86]],\n",
       " \n",
       "        [[118, 120, 122],\n",
       "         [118, 120, 122],\n",
       "         [118, 120, 122],\n",
       "         ...,\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83],\n",
       "         [ 79,  81,  83]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 95,  97,  99]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 95,  97,  99]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 95,  97,  99]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5665000028093345, 'inference': 25.25969999987865, 'postprocess': 2.7619999964372255},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[111, 113, 115],\n",
       "         [111, 113, 115],\n",
       "         [112, 114, 116],\n",
       "         ...,\n",
       "         [ 73,  75,  77],\n",
       "         [ 73,  75,  77],\n",
       "         [ 73,  75,  77]],\n",
       " \n",
       "        [[112, 114, 116],\n",
       "         [112, 114, 116],\n",
       "         [111, 113, 115],\n",
       "         ...,\n",
       "         [ 73,  75,  77],\n",
       "         [ 73,  75,  77],\n",
       "         [ 73,  75,  77]],\n",
       " \n",
       "        [[113, 115, 117],\n",
       "         [113, 115, 117],\n",
       "         [112, 114, 116],\n",
       "         ...,\n",
       "         [ 73,  75,  77],\n",
       "         [ 73,  75,  77],\n",
       "         [ 73,  75,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 52,  54,  56],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 52,  54,  56],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59]],\n",
       " \n",
       "        [[ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         [ 15,  18,  18],\n",
       "         ...,\n",
       "         [ 52,  54,  56],\n",
       "         [ 55,  57,  59],\n",
       "         [ 55,  57,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9080999991274439, 'inference': 23.8413999977638, 'postprocess': 4.234699998050928},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105, 107, 109],\n",
       "         [105, 107, 109],\n",
       "         [105, 107, 109],\n",
       "         ...,\n",
       "         [ 75,  77,  79],\n",
       "         [ 76,  78,  80],\n",
       "         [ 75,  77,  79]],\n",
       " \n",
       "        [[105, 107, 109],\n",
       "         [105, 107, 109],\n",
       "         [105, 107, 109],\n",
       "         ...,\n",
       "         [ 75,  77,  79],\n",
       "         [ 75,  77,  79],\n",
       "         [ 73,  75,  77]],\n",
       " \n",
       "        [[105, 107, 109],\n",
       "         [105, 107, 109],\n",
       "         [105, 107, 109],\n",
       "         ...,\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80],\n",
       "         [ 75,  77,  79]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [ 40,  43,  43],\n",
       "         [ 41,  44,  44],\n",
       "         [ 42,  45,  45]],\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [ 41,  44,  44],\n",
       "         [ 42,  45,  45],\n",
       "         [ 43,  46,  46]],\n",
       " \n",
       "        [[ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         [ 17,  20,  20],\n",
       "         ...,\n",
       "         [ 42,  45,  45],\n",
       "         [ 43,  46,  46],\n",
       "         [ 44,  47,  47]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3186999969766475, 'inference': 24.88469999661902, 'postprocess': 6.153899994387757},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 99, 101, 103],\n",
       "         [ 99, 101, 103],\n",
       "         [ 99, 101, 103],\n",
       "         ...,\n",
       "         [ 71,  73,  75],\n",
       "         [ 72,  74,  76],\n",
       "         [ 75,  77,  79]],\n",
       " \n",
       "        [[ 98, 100, 102],\n",
       "         [ 99, 101, 103],\n",
       "         [ 99, 101, 103],\n",
       "         ...,\n",
       "         [ 68,  70,  72],\n",
       "         [ 71,  73,  75],\n",
       "         [ 73,  75,  77]],\n",
       " \n",
       "        [[ 98, 100, 102],\n",
       "         [ 98, 100, 102],\n",
       "         [ 99, 101, 103],\n",
       "         ...,\n",
       "         [ 68,  70,  72],\n",
       "         [ 69,  71,  73],\n",
       "         [ 71,  73,  75]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32]],\n",
       " \n",
       "        [[ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32]],\n",
       " \n",
       "        [[ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1087000059196725, 'inference': 25.592199999664444, 'postprocess': 3.360800001246389},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[77, 79, 81],\n",
       "         [77, 79, 81],\n",
       "         [78, 80, 82],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[77, 79, 81],\n",
       "         [78, 80, 82],\n",
       "         [78, 80, 82],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[78, 80, 82],\n",
       "         [78, 80, 82],\n",
       "         [78, 80, 82],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6517999974894337, 'inference': 26.745700000901707, 'postprocess': 5.054600005678367},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[55, 58, 58],\n",
       "         [55, 58, 58],\n",
       "         [56, 59, 59],\n",
       "         ...,\n",
       "         [85, 88, 88],\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89]],\n",
       " \n",
       "        [[55, 58, 58],\n",
       "         [56, 59, 59],\n",
       "         [57, 60, 60],\n",
       "         ...,\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89]],\n",
       " \n",
       "        [[57, 60, 60],\n",
       "         [57, 60, 60],\n",
       "         [57, 60, 60],\n",
       "         ...,\n",
       "         [88, 91, 91],\n",
       "         [87, 90, 90],\n",
       "         [87, 90, 90]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [40, 42, 44],\n",
       "         [40, 42, 44],\n",
       "         [37, 39, 41]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 40, 42],\n",
       "         [38, 40, 42],\n",
       "         [37, 39, 41]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 40, 42],\n",
       "         [38, 40, 42],\n",
       "         [37, 39, 41]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.991900000779424, 'inference': 34.53770000487566, 'postprocess': 9.177400002954528},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[49, 51, 53],\n",
       "         [49, 51, 53],\n",
       "         [49, 51, 53],\n",
       "         ...,\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89]],\n",
       " \n",
       "        [[50, 52, 54],\n",
       "         [50, 52, 54],\n",
       "         [49, 51, 53],\n",
       "         ...,\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89]],\n",
       " \n",
       "        [[50, 52, 54],\n",
       "         [50, 52, 54],\n",
       "         [49, 51, 53],\n",
       "         ...,\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89],\n",
       "         [86, 89, 89]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7951000045286492, 'inference': 30.73440000298433, 'postprocess': 4.670499998610467},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[50, 53, 53],\n",
       "         [49, 52, 52],\n",
       "         [48, 51, 51],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]],\n",
       " \n",
       "        [[50, 53, 53],\n",
       "         [49, 52, 52],\n",
       "         [48, 51, 51],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]],\n",
       " \n",
       "        [[50, 53, 53],\n",
       "         [49, 52, 52],\n",
       "         [48, 51, 51],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [27, 30, 30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.537700001790654, 'inference': 23.469899999327026, 'postprocess': 2.0634000029531308},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[72, 74, 76],\n",
       "         [70, 72, 74],\n",
       "         [71, 73, 75],\n",
       "         ...,\n",
       "         [82, 85, 85],\n",
       "         [82, 85, 85],\n",
       "         [80, 83, 83]],\n",
       " \n",
       "        [[72, 74, 76],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [82, 85, 85],\n",
       "         [82, 85, 85],\n",
       "         [80, 83, 83]],\n",
       " \n",
       "        [[72, 74, 76],\n",
       "         [71, 73, 75],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [82, 85, 85],\n",
       "         [82, 85, 85],\n",
       "         [82, 85, 85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [49, 52, 52],\n",
       "         [49, 52, 52],\n",
       "         [49, 52, 52]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [48, 51, 51],\n",
       "         [48, 51, 51],\n",
       "         [48, 51, 51]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [47, 50, 50],\n",
       "         [48, 51, 51],\n",
       "         [48, 51, 51]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3045000014244579, 'inference': 23.605299997143447, 'postprocess': 2.351399998588022},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[135, 137, 139],\n",
       "         [134, 136, 138],\n",
       "         [135, 137, 139],\n",
       "         ...,\n",
       "         [ 79,  82,  82],\n",
       "         [ 79,  82,  82],\n",
       "         [ 79,  82,  82]],\n",
       " \n",
       "        [[134, 136, 138],\n",
       "         [134, 136, 138],\n",
       "         [135, 137, 139],\n",
       "         ...,\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83]],\n",
       " \n",
       "        [[133, 135, 137],\n",
       "         [135, 137, 139],\n",
       "         [136, 138, 140],\n",
       "         ...,\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         ...,\n",
       "         [ 47,  50,  50],\n",
       "         [ 47,  50,  50],\n",
       "         [ 47,  50,  50]],\n",
       " \n",
       "        [[ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         ...,\n",
       "         [ 47,  50,  50],\n",
       "         [ 47,  50,  50],\n",
       "         [ 47,  50,  50]],\n",
       " \n",
       "        [[ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         [ 24,  27,  27],\n",
       "         ...,\n",
       "         [ 48,  51,  51],\n",
       "         [ 48,  51,  51],\n",
       "         [ 48,  51,  51]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6104000023915432, 'inference': 23.408900000504218, 'postprocess': 2.491100000042934},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[150, 152, 154],\n",
       "         [150, 152, 154],\n",
       "         [150, 152, 154],\n",
       "         ...,\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83]],\n",
       " \n",
       "        [[151, 153, 155],\n",
       "         [151, 153, 155],\n",
       "         [151, 153, 155],\n",
       "         ...,\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83]],\n",
       " \n",
       "        [[151, 153, 155],\n",
       "         [151, 153, 155],\n",
       "         [151, 153, 155],\n",
       "         ...,\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83],\n",
       "         [ 80,  83,  83]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,  26,  26],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48]],\n",
       " \n",
       "        [[ 23,  26,  26],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 43,  45,  47],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48]],\n",
       " \n",
       "        [[ 23,  26,  26],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         ...,\n",
       "         [ 43,  45,  47],\n",
       "         [ 43,  45,  47],\n",
       "         [ 43,  45,  47]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6539000062039122, 'inference': 23.573400001623668, 'postprocess': 1.9969999993918464},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[170, 166, 169],\n",
       "         [170, 166, 169],\n",
       "         [170, 166, 169],\n",
       "         ...,\n",
       "         [ 84,  87,  87],\n",
       "         [ 84,  87,  87],\n",
       "         [ 84,  87,  87]],\n",
       " \n",
       "        [[172, 168, 171],\n",
       "         [172, 168, 171],\n",
       "         [170, 166, 169],\n",
       "         ...,\n",
       "         [ 84,  87,  87],\n",
       "         [ 84,  87,  87],\n",
       "         [ 84,  87,  87]],\n",
       " \n",
       "        [[172, 168, 171],\n",
       "         [172, 168, 171],\n",
       "         [172, 168, 171],\n",
       "         ...,\n",
       "         [ 84,  87,  87],\n",
       "         [ 84,  87,  87],\n",
       "         [ 84,  87,  87]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         ...,\n",
       "         [114, 116, 118],\n",
       "         [114, 116, 118],\n",
       "         [114, 116, 118]],\n",
       " \n",
       "        [[ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         ...,\n",
       "         [115, 117, 119],\n",
       "         [115, 117, 119],\n",
       "         [115, 117, 119]],\n",
       " \n",
       "        [[ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         ...,\n",
       "         [116, 118, 120],\n",
       "         [118, 120, 122],\n",
       "         [118, 120, 122]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4532999994116835, 'inference': 23.66759999858914, 'postprocess': 2.0600000061676838},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         ...,\n",
       "         [ 82,  84,  86],\n",
       "         [ 79,  81,  83],\n",
       "         [ 77,  79,  81]],\n",
       " \n",
       "        [[158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         ...,\n",
       "         [ 80,  82,  84],\n",
       "         [ 77,  79,  81],\n",
       "         [ 76,  78,  80]],\n",
       " \n",
       "        [[158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         [158, 158, 158],\n",
       "         ...,\n",
       "         [ 82,  84,  86],\n",
       "         [ 78,  80,  82],\n",
       "         [ 77,  79,  81]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 38,  40,  42],\n",
       "         [ 40,  42,  44],\n",
       "         [ 43,  45,  47],\n",
       "         ...,\n",
       "         [115, 117, 119],\n",
       "         [115, 117, 119],\n",
       "         [115, 117, 119]],\n",
       " \n",
       "        [[ 38,  40,  42],\n",
       "         [ 40,  42,  44],\n",
       "         [ 43,  45,  47],\n",
       "         ...,\n",
       "         [113, 115, 117],\n",
       "         [113, 115, 117],\n",
       "         [113, 115, 117]],\n",
       " \n",
       "        [[ 38,  40,  42],\n",
       "         [ 40,  42,  44],\n",
       "         [ 43,  45,  47],\n",
       "         ...,\n",
       "         [111, 113, 115],\n",
       "         [111, 113, 115],\n",
       "         [111, 113, 115]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6031999984988943, 'inference': 23.900799998955335, 'postprocess': 5.582999998296145},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[148, 150, 152],\n",
       "         [146, 148, 150],\n",
       "         [144, 146, 148],\n",
       "         ...,\n",
       "         [121, 123, 125],\n",
       "         [121, 123, 125],\n",
       "         [121, 123, 125]],\n",
       " \n",
       "        [[147, 149, 151],\n",
       "         [147, 149, 151],\n",
       "         [146, 148, 150],\n",
       "         ...,\n",
       "         [122, 124, 126],\n",
       "         [122, 124, 126],\n",
       "         [122, 124, 126]],\n",
       " \n",
       "        [[150, 152, 154],\n",
       "         [149, 151, 153],\n",
       "         [148, 150, 152],\n",
       "         ...,\n",
       "         [122, 124, 126],\n",
       "         [122, 124, 126],\n",
       "         [122, 124, 126]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  67,  69],\n",
       "         [ 65,  67,  69],\n",
       "         [ 65,  67,  69],\n",
       "         ...,\n",
       "         [ 40,  43,  43],\n",
       "         [ 37,  40,  40],\n",
       "         [ 35,  38,  38]],\n",
       " \n",
       "        [[ 65,  67,  69],\n",
       "         [ 65,  67,  69],\n",
       "         [ 65,  67,  69],\n",
       "         ...,\n",
       "         [ 44,  47,  47],\n",
       "         [ 43,  46,  46],\n",
       "         [ 41,  44,  44]],\n",
       " \n",
       "        [[ 65,  67,  69],\n",
       "         [ 65,  67,  69],\n",
       "         [ 65,  67,  69],\n",
       "         ...,\n",
       "         [ 48,  51,  51],\n",
       "         [ 48,  51,  51],\n",
       "         [ 47,  50,  50]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.529100005631335, 'inference': 28.597100004844833, 'postprocess': 4.8903999995673075},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[139, 141, 143],\n",
       "         [140, 142, 144],\n",
       "         [140, 142, 144],\n",
       "         ...,\n",
       "         [ 54,  56,  58],\n",
       "         [ 54,  56,  58],\n",
       "         [ 55,  57,  59]],\n",
       " \n",
       "        [[139, 141, 143],\n",
       "         [140, 142, 144],\n",
       "         [140, 142, 144],\n",
       "         ...,\n",
       "         [ 51,  53,  55],\n",
       "         [ 51,  53,  55],\n",
       "         [ 52,  54,  56]],\n",
       " \n",
       "        [[140, 142, 144],\n",
       "         [141, 143, 145],\n",
       "         [141, 143, 145],\n",
       "         ...,\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  71,  71],\n",
       "         [ 69,  72,  72],\n",
       "         [ 69,  72,  72],\n",
       "         ...,\n",
       "         [ 27,  30,  30],\n",
       "         [ 27,  30,  30],\n",
       "         [ 27,  30,  30]],\n",
       " \n",
       "        [[ 64,  67,  67],\n",
       "         [ 64,  67,  67],\n",
       "         [ 64,  67,  67],\n",
       "         ...,\n",
       "         [ 27,  30,  30],\n",
       "         [ 27,  30,  30],\n",
       "         [ 27,  30,  30]],\n",
       " \n",
       "        [[ 62,  65,  65],\n",
       "         [ 63,  66,  66],\n",
       "         [ 63,  66,  66],\n",
       "         ...,\n",
       "         [ 27,  30,  30],\n",
       "         [ 27,  30,  30],\n",
       "         [ 27,  30,  30]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6971000004559755, 'inference': 24.7148999987985, 'postprocess': 5.126099997141864},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[159, 159, 159],\n",
       "         [156, 156, 156],\n",
       "         [151, 150, 152],\n",
       "         ...,\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48]],\n",
       " \n",
       "        [[158, 158, 158],\n",
       "         [156, 156, 156],\n",
       "         [151, 150, 152],\n",
       "         ...,\n",
       "         [ 43,  45,  47],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48]],\n",
       " \n",
       "        [[158, 158, 158],\n",
       "         [156, 156, 156],\n",
       "         [151, 150, 152],\n",
       "         ...,\n",
       "         [ 43,  45,  47],\n",
       "         [ 44,  46,  48],\n",
       "         [ 44,  46,  48]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 26,  29,  29],\n",
       "         [ 26,  29,  29],\n",
       "         [ 26,  29,  29]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 26,  29,  29],\n",
       "         [ 26,  29,  29],\n",
       "         [ 26,  29,  29]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 26,  29,  29],\n",
       "         [ 26,  29,  29],\n",
       "         [ 26,  29,  29]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0197999983793125, 'inference': 36.32569999899715, 'postprocess': 3.089999998337589},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[161, 160, 162],\n",
       "         [161, 160, 162],\n",
       "         [161, 160, 162],\n",
       "         ...,\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41]],\n",
       " \n",
       "        [[163, 162, 164],\n",
       "         [164, 163, 165],\n",
       "         [163, 162, 164],\n",
       "         ...,\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41]],\n",
       " \n",
       "        [[163, 162, 164],\n",
       "         [165, 164, 166],\n",
       "         [163, 162, 164],\n",
       "         ...,\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  51,  53],\n",
       "         [ 50,  52,  54],\n",
       "         [ 52,  54,  56],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 49,  51,  53],\n",
       "         [ 50,  52,  54],\n",
       "         [ 52,  54,  56],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 49,  51,  53],\n",
       "         [ 50,  52,  54],\n",
       "         [ 52,  54,  56],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         [ 33,  36,  36]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.878300001611933, 'inference': 29.74940000422066, 'postprocess': 8.350899996003136},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[139, 141, 143],\n",
       "         [137, 139, 141],\n",
       "         [137, 139, 141],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32]],\n",
       " \n",
       "        [[137, 139, 141],\n",
       "         [137, 139, 141],\n",
       "         [136, 138, 140],\n",
       "         ...,\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32],\n",
       "         [ 29,  32,  32]],\n",
       " \n",
       "        [[135, 137, 139],\n",
       "         [135, 137, 139],\n",
       "         [135, 137, 139],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 28,  31,  31],\n",
       "         [ 28,  31,  31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         ...,\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32],\n",
       "         [ 30,  33,  33]],\n",
       " \n",
       "        [[ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         ...,\n",
       "         [ 27,  30,  30],\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32]],\n",
       " \n",
       "        [[ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         ...,\n",
       "         [ 27,  30,  30],\n",
       "         [ 28,  31,  31],\n",
       "         [ 29,  32,  32]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.790000002074521, 'inference': 23.398099998303223, 'postprocess': 5.060500006948132},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[142, 141, 143],\n",
       "         [144, 143, 145],\n",
       "         [144, 143, 145],\n",
       "         ...,\n",
       "         [ 51,  54,  54],\n",
       "         [ 50,  52,  54],\n",
       "         [ 50,  52,  54]],\n",
       " \n",
       "        [[143, 142, 144],\n",
       "         [145, 144, 146],\n",
       "         [145, 144, 146],\n",
       "         ...,\n",
       "         [ 52,  55,  55],\n",
       "         [ 52,  54,  56],\n",
       "         [ 51,  53,  55]],\n",
       " \n",
       "        [[140, 139, 141],\n",
       "         [144, 143, 145],\n",
       "         [145, 144, 146],\n",
       "         ...,\n",
       "         [ 51,  54,  54],\n",
       "         [ 52,  54,  56],\n",
       "         [ 52,  54,  56]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  58,  60],\n",
       "         [ 56,  58,  60],\n",
       "         [ 56,  58,  60],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 56,  58,  60],\n",
       "         [ 56,  58,  60],\n",
       "         [ 56,  58,  60],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]],\n",
       " \n",
       "        [[ 56,  58,  60],\n",
       "         [ 56,  58,  60],\n",
       "         [ 56,  58,  60],\n",
       "         ...,\n",
       "         [ 20,  23,  23],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6111999939312227, 'inference': 25.262499999371357, 'postprocess': 3.9754000026732683},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[160, 159, 161],\n",
       "         [160, 159, 161],\n",
       "         [157, 159, 161],\n",
       "         ...,\n",
       "         [ 48,  51,  51],\n",
       "         [ 48,  51,  51],\n",
       "         [ 48,  51,  51]],\n",
       " \n",
       "        [[163, 162, 164],\n",
       "         [161, 160, 162],\n",
       "         [157, 159, 161],\n",
       "         ...,\n",
       "         [ 47,  50,  50],\n",
       "         [ 47,  50,  50],\n",
       "         [ 47,  50,  50]],\n",
       " \n",
       "        [[161, 160, 162],\n",
       "         [161, 160, 162],\n",
       "         [158, 160, 162],\n",
       "         ...,\n",
       "         [ 47,  50,  50],\n",
       "         [ 47,  50,  50],\n",
       "         [ 47,  50,  50]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 40,  43,  43],\n",
       "         [ 38,  41,  41],\n",
       "         [ 36,  39,  39],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 40,  43,  43],\n",
       "         [ 38,  41,  41],\n",
       "         [ 36,  39,  39],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 40,  43,  43],\n",
       "         [ 38,  41,  41],\n",
       "         [ 36,  39,  39],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.424800000677351, 'inference': 23.220799994305708, 'postprocess': 2.53540000267094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 87,  89,  91],\n",
       "         [ 80,  82,  84],\n",
       "         [ 76,  78,  80],\n",
       "         ...,\n",
       "         [ 41,  43,  45],\n",
       "         [ 41,  43,  45],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 87,  89,  91],\n",
       "         [ 80,  82,  84],\n",
       "         ...,\n",
       "         [ 38,  40,  42],\n",
       "         [ 38,  40,  42],\n",
       "         [ 40,  42,  44]],\n",
       " \n",
       "        [[101, 103, 105],\n",
       "         [ 94,  96,  98],\n",
       "         [ 87,  89,  91],\n",
       "         ...,\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41],\n",
       "         [ 37,  39,  41]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]],\n",
       " \n",
       "        [[ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         ...,\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22],\n",
       "         [ 19,  22,  22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4249000014388002, 'inference': 24.05920000455808, 'postprocess': 6.433399998059031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[47, 50, 50],\n",
       "         [45, 48, 48],\n",
       "         [44, 47, 47],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[47, 50, 50],\n",
       "         [45, 48, 48],\n",
       "         [44, 47, 47],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[47, 50, 50],\n",
       "         [45, 48, 48],\n",
       "         [44, 47, 47],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9322999942232855, 'inference': 23.173499997938052, 'postprocess': 7.338600000366569},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[47, 50, 50],\n",
       "         [45, 48, 48],\n",
       "         [44, 47, 47],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[47, 50, 50],\n",
       "         [45, 48, 48],\n",
       "         [44, 47, 47],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[47, 50, 50],\n",
       "         [45, 48, 48],\n",
       "         [44, 47, 47],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.343699998164084, 'inference': 23.387799999909475, 'postprocess': 3.9640000031795353},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 40, 40],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[37, 40, 40],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.941999995324295, 'inference': 27.254099994024727, 'postprocess': 8.350199997948948},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 40, 40],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[37, 40, 40],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3013999996474013, 'inference': 23.422000005666632, 'postprocess': 4.324800000176765},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 40, 40],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[37, 40, 40],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3136999987182207, 'inference': 24.068099999567494, 'postprocess': 9.380600000440609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 40, 40],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[37, 40, 40],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         [36, 39, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [21, 24, 24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2048000028007664, 'inference': 36.501700000371784, 'postprocess': 2.8557000041473657},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33]],\n",
       " \n",
       "        [[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4828999992460012, 'inference': 23.40560000448022, 'postprocess': 5.622799995762762},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33]],\n",
       " \n",
       "        [[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.593400003912393, 'inference': 29.15000000211876, 'postprocess': 2.0835000032093376},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [30, 32, 34],\n",
       "         [30, 32, 34],\n",
       "         [30, 32, 34]],\n",
       " \n",
       "        [[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [31, 33, 35],\n",
       "         [31, 33, 35],\n",
       "         [31, 33, 35]],\n",
       " \n",
       "        [[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [31, 33, 35],\n",
       "         [31, 33, 35],\n",
       "         [31, 33, 35]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3854999997420236, 'inference': 23.49079999839887, 'postprocess': 3.4717000016826205},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [30, 32, 34],\n",
       "         [30, 32, 34],\n",
       "         [30, 32, 34]],\n",
       " \n",
       "        [[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [31, 33, 35],\n",
       "         [31, 33, 35],\n",
       "         [31, 33, 35]],\n",
       " \n",
       "        [[30, 33, 33],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         ...,\n",
       "         [31, 33, 35],\n",
       "         [31, 33, 35],\n",
       "         [31, 33, 35]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         ...,\n",
       "         [36, 39, 39],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2505999984568916, 'inference': 24.229100003140047, 'postprocess': 2.7073999954154715},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [31, 34, 34],\n",
       "         [33, 35, 37],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [34, 37, 37],\n",
       "         [35, 37, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[33, 35, 37],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8075999978464097, 'inference': 23.455999995348975, 'postprocess': 2.0072999977855943},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [31, 34, 34],\n",
       "         [33, 35, 37],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [34, 37, 37],\n",
       "         [35, 37, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[33, 35, 37],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.287600003706757, 'inference': 23.28809999744408, 'postprocess': 2.53320000047097},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [31, 34, 34],\n",
       "         [33, 35, 37],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [34, 37, 37],\n",
       "         [35, 37, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[33, 35, 37],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.243300001078751, 'inference': 23.421300000336487, 'postprocess': 2.0396999971126206},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [31, 34, 34],\n",
       "         [33, 35, 37],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [34, 37, 37],\n",
       "         [35, 37, 39],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[33, 35, 37],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33],\n",
       "         [30, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [28, 31, 31]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2441999933798797, 'inference': 23.485300000174902, 'postprocess': 5.145999995875172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 98, 100, 102],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 98, 100, 102],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 98, 100, 102],\n",
       "         [ 99, 101, 103],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4048999946680851, 'inference': 23.95280000200728, 'postprocess': 4.483600001549348},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 98, 100, 102],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 98, 100, 102],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 98, 100, 102],\n",
       "         [ 99, 101, 103],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 23,  26,  26]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25],\n",
       "         [ 23,  26,  26]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.021499996772036, 'inference': 27.94690000155242, 'postprocess': 4.681300000811461},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 98, 100, 102],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 98, 100, 102],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 98, 100, 102],\n",
       "         [ 99, 101, 103],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.105300001858268, 'inference': 27.60800000396557, 'postprocess': 4.833200000575744},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 98, 100, 102],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 95,  97,  99],\n",
       "         [ 98, 100, 102],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 98, 100, 102],\n",
       "         [ 99, 101, 103],\n",
       "         ...,\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37],\n",
       "         [ 34,  37,  37]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]],\n",
       " \n",
       "        [[ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         [ 21,  24,  24],\n",
       "         ...,\n",
       "         [ 21,  24,  24],\n",
       "         [ 22,  25,  25],\n",
       "         [ 22,  25,  25]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3827999975765124, 'inference': 29.23919999739155, 'postprocess': 6.518200003483798},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[133, 135, 137],\n",
       "         [133, 135, 137],\n",
       "         [132, 134, 136],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[133, 135, 137],\n",
       "         [134, 136, 138],\n",
       "         [132, 134, 136],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[132, 134, 136],\n",
       "         [133, 135, 137],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5901000006124377, 'inference': 25.086900001042522, 'postprocess': 5.4509000037796795},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[133, 135, 137],\n",
       "         [133, 135, 137],\n",
       "         [132, 134, 136],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[133, 135, 137],\n",
       "         [134, 136, 138],\n",
       "         [132, 134, 136],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[132, 134, 136],\n",
       "         [133, 135, 137],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.757099998940248, 'inference': 32.03499999654014, 'postprocess': 6.774000001314562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[132, 134, 136],\n",
       "         [132, 134, 136],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[132, 134, 136],\n",
       "         [132, 134, 136],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[130, 132, 134],\n",
       "         [130, 132, 134],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5146999940043315, 'inference': 23.449000000255182, 'postprocess': 3.0537999991793185},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[132, 134, 136],\n",
       "         [132, 134, 136],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[132, 134, 136],\n",
       "         [132, 134, 136],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        [[130, 132, 134],\n",
       "         [130, 132, 134],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46],\n",
       "         [ 42,  44,  46]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]],\n",
       " \n",
       "        [[ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         [ 20,  23,  23],\n",
       "         ...,\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36],\n",
       "         [ 33,  36,  36]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7220000008819625, 'inference': 24.636100002680905, 'postprocess': 3.284500002337154},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[94, 96, 98],\n",
       "         [91, 93, 95],\n",
       "         [87, 89, 91],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[93, 95, 97],\n",
       "         [90, 92, 94],\n",
       "         [85, 87, 89],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[88, 90, 92],\n",
       "         [85, 87, 89],\n",
       "         [80, 82, 84],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1931000010226853, 'inference': 24.80210000067018, 'postprocess': 1.898299997264985},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[94, 96, 98],\n",
       "         [91, 93, 95],\n",
       "         [87, 89, 91],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[93, 95, 97],\n",
       "         [90, 92, 94],\n",
       "         [85, 87, 89],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[88, 90, 92],\n",
       "         [85, 87, 89],\n",
       "         [80, 82, 84],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2801000013714656, 'inference': 46.98859999916749, 'postprocess': 8.356300000741612},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[94, 96, 98],\n",
       "         [91, 93, 95],\n",
       "         [87, 89, 91],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[93, 95, 97],\n",
       "         [90, 92, 94],\n",
       "         [85, 87, 89],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[88, 90, 92],\n",
       "         [85, 87, 89],\n",
       "         [80, 82, 84],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5416000023833476, 'inference': 23.27549999608891, 'postprocess': 3.2066999992821366},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[94, 96, 98],\n",
       "         [91, 93, 95],\n",
       "         [87, 89, 91],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[93, 95, 97],\n",
       "         [90, 92, 94],\n",
       "         [85, 87, 89],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        [[88, 90, 92],\n",
       "         [85, 87, 89],\n",
       "         [80, 82, 84],\n",
       "         ...,\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49],\n",
       "         [45, 47, 49]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38],\n",
       "         [35, 38, 38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8896999972639605, 'inference': 23.21069999743486, 'postprocess': 7.6730000000679865},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [65, 67, 69],\n",
       "         [65, 67, 69],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4854999972158112, 'inference': 23.382700004731305, 'postprocess': 2.7614999999059364},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [65, 67, 69],\n",
       "         [65, 67, 69],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4139999984763563, 'inference': 26.669099999708124, 'postprocess': 6.2653999993926845},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [65, 67, 69],\n",
       "         [65, 67, 69],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.133899997919798, 'inference': 28.667599995969795, 'postprocess': 2.1210999984759837},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [65, 67, 69],\n",
       "         [65, 67, 69],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7340999984298833, 'inference': 24.537499994039536, 'postprocess': 2.1722000019508414},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.5509000042802654, 'inference': 27.29650000401307, 'postprocess': 1.9990000000689179},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7957000018213876, 'inference': 23.37450000050012, 'postprocess': 2.1377000011852942},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4242999968701042, 'inference': 23.523700001533143, 'postprocess': 4.559300003165845},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [80, 82, 84],\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.404000006208662, 'inference': 23.278400003619026, 'postprocess': 1.9335999968461692},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[69, 72, 72],\n",
       "         [69, 72, 72],\n",
       "         [69, 72, 72],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3646000006701797, 'inference': 23.421699996106327, 'postprocess': 3.485900000669062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[69, 72, 72],\n",
       "         [69, 72, 72],\n",
       "         [69, 72, 72],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88],\n",
       "         [84, 86, 88]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2582999988808297, 'inference': 23.10800000122981, 'postprocess': 2.0745999936480075},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[69, 72, 72],\n",
       "         [69, 72, 72],\n",
       "         [69, 72, 72],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88],\n",
       "         [84, 86, 88]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4502000049105845, 'inference': 23.5506000026362, 'postprocess': 4.007399998954497},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[69, 72, 72],\n",
       "         [69, 72, 72],\n",
       "         [69, 72, 72],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87],\n",
       "         [83, 85, 87]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88],\n",
       "         [84, 86, 88]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [83, 85, 87],\n",
       "         [84, 86, 88],\n",
       "         [84, 86, 88]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2428000045474619, 'inference': 23.550799996883143, 'postprocess': 2.0714999991469085},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [47, 49, 51],\n",
       "         [41, 43, 45],\n",
       "         [34, 36, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [47, 49, 51],\n",
       "         [41, 43, 45],\n",
       "         [34, 36, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [48, 50, 52],\n",
       "         [41, 43, 45],\n",
       "         [35, 37, 39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5160999973886646, 'inference': 30.793600002652965, 'postprocess': 4.310600001190323},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [47, 49, 51],\n",
       "         [41, 43, 45],\n",
       "         [34, 36, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [47, 49, 51],\n",
       "         [41, 43, 45],\n",
       "         [34, 36, 38]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [48, 50, 52],\n",
       "         [41, 43, 45],\n",
       "         [35, 37, 39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3978999995742925, 'inference': 23.363599997537676, 'postprocess': 2.142400000593625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [48, 50, 52],\n",
       "         [41, 43, 45],\n",
       "         [33, 35, 37]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [48, 50, 52],\n",
       "         [41, 43, 45],\n",
       "         [33, 35, 37]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [48, 50, 52],\n",
       "         [41, 43, 45],\n",
       "         [34, 36, 38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3364999977056868, 'inference': 23.308000003453344, 'postprocess': 2.4957999994512647},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [48, 50, 52],\n",
       "         [41, 43, 45],\n",
       "         [33, 35, 37]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [48, 50, 52],\n",
       "         [41, 43, 45],\n",
       "         [33, 35, 37]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [48, 50, 52],\n",
       "         [41, 43, 45],\n",
       "         [34, 36, 38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2520999953267165, 'inference': 23.36739999736892, 'postprocess': 4.661899998609442},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[70, 72, 74],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[71, 74, 74],\n",
       "         [70, 73, 73],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [50, 52, 54],\n",
       "         [50, 52, 54],\n",
       "         [50, 52, 54]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [51, 53, 55],\n",
       "         [51, 53, 55],\n",
       "         [51, 53, 55]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [51, 53, 55],\n",
       "         [52, 54, 56],\n",
       "         [52, 54, 56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2425999957486056, 'inference': 23.29259999532951, 'postprocess': 4.725700004200917},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[70, 72, 74],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[71, 74, 74],\n",
       "         [70, 73, 73],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [50, 52, 54],\n",
       "         [50, 52, 54],\n",
       "         [50, 52, 54]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [51, 53, 55],\n",
       "         [51, 53, 55],\n",
       "         [51, 53, 55]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [51, 53, 55],\n",
       "         [52, 54, 56],\n",
       "         [52, 54, 56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8772000039462, 'inference': 23.837200002162717, 'postprocess': 2.483700001903344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[70, 72, 74],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[71, 74, 74],\n",
       "         [70, 73, 73],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [50, 52, 54],\n",
       "         [50, 52, 54],\n",
       "         [50, 52, 54]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [51, 53, 55],\n",
       "         [51, 53, 55],\n",
       "         [51, 53, 55]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [51, 53, 55],\n",
       "         [52, 54, 56],\n",
       "         [52, 54, 56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4363000009325333, 'inference': 24.503699998604134, 'postprocess': 1.8226999964099377},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[70, 72, 74],\n",
       "         [69, 71, 73],\n",
       "         [69, 71, 73],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[71, 74, 74],\n",
       "         [70, 73, 73],\n",
       "         [70, 72, 74],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [50, 52, 54],\n",
       "         [50, 52, 54],\n",
       "         [50, 52, 54]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [51, 53, 55],\n",
       "         [51, 53, 55],\n",
       "         [51, 53, 55]],\n",
       " \n",
       "        [[24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         ...,\n",
       "         [51, 53, 55],\n",
       "         [52, 54, 56],\n",
       "         [52, 54, 56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4754000003449619, 'inference': 23.17149999726098, 'postprocess': 4.050499999721069},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [62, 64, 66],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3049000044702552, 'inference': 22.897000002558343, 'postprocess': 2.0308999955886975},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [62, 64, 66],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.7742000020225532, 'inference': 22.91949999926146, 'postprocess': 4.972599999746308},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [62, 64, 66],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[65, 67, 69],\n",
       "         [64, 66, 68],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]],\n",
       " \n",
       "        [[23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6733999946154654, 'inference': 23.007600000710227, 'postprocess': 2.173700006096624},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[66, 68, 70],\n",
       "         [65, 67, 69],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[66, 68, 70],\n",
       "         [65, 67, 69],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[66, 68, 70],\n",
       "         [65, 67, 69],\n",
       "         [63, 65, 67],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[22, 25, 25],\n",
       "         [22, 25, 25],\n",
       "         [22, 25, 25],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [13, 16, 16],\n",
       "         [13, 16, 16]],\n",
       " \n",
       "        [[22, 25, 25],\n",
       "         [22, 25, 25],\n",
       "         [22, 25, 25],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [13, 16, 16],\n",
       "         [13, 16, 16]],\n",
       " \n",
       "        [[22, 25, 25],\n",
       "         [22, 25, 25],\n",
       "         [22, 25, 25],\n",
       "         ...,\n",
       "         [14, 17, 17],\n",
       "         [13, 16, 16],\n",
       "         [13, 16, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3160000016796403, 'inference': 22.930399994947948, 'postprocess': 4.863400004978757},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7311000046902336, 'inference': 31.786499996087514, 'postprocess': 3.384399999049492},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6835999995237216, 'inference': 23.37919999990845, 'postprocess': 9.14030000421917},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5059000070323236, 'inference': 25.73580000171205, 'postprocess': 3.278099997260142},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        [[56, 57, 62],\n",
       "         [55, 56, 61],\n",
       "         [52, 53, 58],\n",
       "         ...,\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26],\n",
       "         [23, 26, 26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3146999956225045, 'inference': 42.30680000182474, 'postprocess': 7.080700001097284},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4091000048210844, 'inference': 32.58619999542134, 'postprocess': 2.217599998402875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3011999981245026, 'inference': 22.779899998568, 'postprocess': 3.198700003849808},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4099999971222132, 'inference': 22.968500001297798, 'postprocess': 1.982599998882506},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         [49, 50, 55],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         [20, 23, 23],\n",
       "         ...,\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6270999985863455, 'inference': 22.955200001888443, 'postprocess': 2.1125999992364086},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [75, 77, 79],\n",
       "         [73, 75, 77],\n",
       "         [73, 75, 77]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [77, 79, 81],\n",
       "         [76, 78, 80],\n",
       "         [76, 78, 80]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [79, 81, 83],\n",
       "         [78, 80, 82],\n",
       "         [77, 79, 81]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.313000000664033, 'inference': 22.672199993394315, 'postprocess': 3.4585999965202063},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [75, 77, 79],\n",
       "         [73, 75, 77],\n",
       "         [73, 75, 77]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [77, 79, 81],\n",
       "         [76, 78, 80],\n",
       "         [76, 78, 80]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [79, 81, 83],\n",
       "         [78, 80, 82],\n",
       "         [77, 79, 81]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1651000022538938, 'inference': 22.82839999679709, 'postprocess': 2.376299999014009},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [75, 77, 79],\n",
       "         [73, 75, 77],\n",
       "         [73, 75, 77]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [77, 79, 81],\n",
       "         [76, 78, 80],\n",
       "         [76, 78, 80]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [79, 81, 83],\n",
       "         [78, 80, 82],\n",
       "         [77, 79, 81]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2171999987913296, 'inference': 22.789800001191907, 'postprocess': 1.9188000005669892},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        [[44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         [44, 46, 48],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [28, 31, 31],\n",
       "         [28, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [75, 77, 79],\n",
       "         [73, 75, 77],\n",
       "         [73, 75, 77]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [77, 79, 81],\n",
       "         [76, 78, 80],\n",
       "         [76, 78, 80]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [79, 81, 83],\n",
       "         [78, 80, 82],\n",
       "         [77, 79, 81]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4530999978887849, 'inference': 22.91269999841461, 'postprocess': 2.0633000021916814},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [65, 67, 69],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72]],\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [64, 66, 68],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]],\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [64, 66, 68],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2926999988849275, 'inference': 22.55470000091009, 'postprocess': 1.8770000024233013},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [65, 67, 69],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72]],\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [64, 66, 68],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]],\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [64, 66, 68],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7771999991964549, 'inference': 23.557000000437256, 'postprocess': 2.345900000364054},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [65, 67, 69],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72]],\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [64, 66, 68],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]],\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [64, 66, 68],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3794999977108091, 'inference': 22.12650000001304, 'postprocess': 3.4765999953378923},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         [40, 43, 43],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [65, 67, 69],\n",
       "         [68, 70, 72],\n",
       "         [68, 70, 72]],\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [64, 66, 68],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]],\n",
       " \n",
       "        [[17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         [17, 20, 20],\n",
       "         ...,\n",
       "         [64, 66, 68],\n",
       "         [66, 68, 70],\n",
       "         [66, 68, 70]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8819999968400225, 'inference': 23.31889999913983, 'postprocess': 4.535000000032596},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [28, 31, 31],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [28, 31, 31],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [29, 32, 32],\n",
       "         [30, 33, 33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.288299994484987, 'inference': 22.16999999654945, 'postprocess': 1.9854000056511723},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [28, 31, 31],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [28, 31, 31],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [29, 32, 32],\n",
       "         [30, 33, 33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3440000038826838, 'inference': 22.22009999968577, 'postprocess': 3.4379999997327104},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [28, 31, 31],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [28, 31, 31],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [29, 32, 32],\n",
       "         [30, 33, 33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.378699998895172, 'inference': 22.059800001443364, 'postprocess': 1.9140999938827008},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[38, 41, 41],\n",
       "         [38, 41, 41],\n",
       "         [37, 40, 40],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [28, 31, 31],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [28, 31, 31],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [26, 29, 29],\n",
       "         [29, 32, 32],\n",
       "         [30, 33, 33]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.415600003383588, 'inference': 22.11659999738913, 'postprocess': 2.0457999999052845},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [56, 58, 60],\n",
       "         [54, 56, 58],\n",
       "         [51, 53, 55]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [58, 60, 62],\n",
       "         [56, 58, 60],\n",
       "         [54, 56, 58]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [62, 64, 66],\n",
       "         [58, 60, 62],\n",
       "         [56, 58, 60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2573999993037432, 'inference': 22.18910000374308, 'postprocess': 3.3313000021735206},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [56, 58, 60],\n",
       "         [54, 56, 58],\n",
       "         [51, 53, 55]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [58, 60, 62],\n",
       "         [56, 58, 60],\n",
       "         [54, 56, 58]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [62, 64, 66],\n",
       "         [58, 60, 62],\n",
       "         [56, 58, 60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.655599997320678, 'inference': 22.07520000229124, 'postprocess': 1.8550000022514723},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [55, 57, 59],\n",
       "         [52, 54, 56],\n",
       "         [50, 52, 54]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [57, 59, 61],\n",
       "         [55, 57, 59],\n",
       "         [52, 54, 56]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [61, 63, 65],\n",
       "         [57, 59, 61],\n",
       "         [55, 57, 59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.338399997621309, 'inference': 22.037700000510085, 'postprocess': 2.1393999995780177},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27],\n",
       "         [24, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [55, 57, 59],\n",
       "         [52, 54, 56],\n",
       "         [50, 52, 54]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [57, 59, 61],\n",
       "         [55, 57, 59],\n",
       "         [52, 54, 56]],\n",
       " \n",
       "        [[14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         [14, 17, 17],\n",
       "         ...,\n",
       "         [61, 63, 65],\n",
       "         [57, 59, 61],\n",
       "         [55, 57, 59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2988000016775914, 'inference': 22.01009999407688, 'postprocess': 1.80049999471521},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [71, 73, 75],\n",
       "         [70, 72, 74],\n",
       "         [69, 71, 73]],\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [72, 74, 76],\n",
       "         [70, 72, 74],\n",
       "         [69, 71, 73]],\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [73, 75, 77],\n",
       "         [71, 73, 75],\n",
       "         [70, 72, 74]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3366999992285855, 'inference': 22.185199995874427, 'postprocess': 1.9083000006503426},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [71, 73, 75],\n",
       "         [70, 72, 74],\n",
       "         [69, 71, 73]],\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [72, 74, 76],\n",
       "         [70, 72, 74],\n",
       "         [69, 71, 73]],\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [73, 75, 77],\n",
       "         [71, 73, 75],\n",
       "         [70, 72, 74]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5005999957793392, 'inference': 21.659700003510807, 'postprocess': 2.3282999973162077},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [72, 74, 76],\n",
       "         [71, 73, 75],\n",
       "         [69, 71, 73]],\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [73, 75, 77],\n",
       "         [71, 73, 75],\n",
       "         [69, 71, 73]],\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [73, 75, 77],\n",
       "         [72, 74, 76],\n",
       "         [70, 72, 74]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.414800004567951, 'inference': 22.105299998656847, 'postprocess': 2.668900000571739},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34],\n",
       "         [31, 34, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [72, 74, 76],\n",
       "         [71, 73, 75],\n",
       "         [69, 71, 73]],\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [73, 75, 77],\n",
       "         [71, 73, 75],\n",
       "         [69, 71, 73]],\n",
       " \n",
       "        [[15, 18, 18],\n",
       "         [16, 19, 19],\n",
       "         [16, 19, 19],\n",
       "         ...,\n",
       "         [73, 75, 77],\n",
       "         [72, 74, 76],\n",
       "         [70, 72, 74]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3976999980513938, 'inference': 21.051000003353693, 'postprocess': 1.7761999988579191},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         [37, 39, 41],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [49, 51, 53]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [48, 50, 52]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [48, 50, 52]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3223999994806945, 'inference': 21.00110000174027, 'postprocess': 3.650400001788512},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [49, 51, 53]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [48, 50, 52]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [48, 50, 52]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2933000034536235, 'inference': 21.04900000267662, 'postprocess': 1.8202999999630265},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [49, 51, 53]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [48, 50, 52]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [48, 50, 52]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.441300002625212, 'inference': 23.81960000639083, 'postprocess': 1.7931999973370694},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        [[36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         [36, 38, 40],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40],\n",
       "         [37, 40, 40]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [49, 51, 53]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [48, 50, 52]],\n",
       " \n",
       "        [[19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         [19, 22, 22],\n",
       "         ...,\n",
       "         [52, 54, 56],\n",
       "         [51, 53, 55],\n",
       "         [48, 50, 52]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.354999993054662, 'inference': 21.000200002163183, 'postprocess': 2.546899995650165},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [38, 41, 41],\n",
       "         [38, 41, 41]],\n",
       " \n",
       "        [[34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [38, 41, 41],\n",
       "         [38, 41, 41]],\n",
       " \n",
       "        [[34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [38, 41, 41],\n",
       "         [38, 41, 41]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [43, 46, 46],\n",
       "         [45, 48, 48],\n",
       "         [48, 51, 51]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [43, 46, 46],\n",
       "         [45, 48, 48],\n",
       "         [48, 51, 51]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [43, 46, 46],\n",
       "         [45, 48, 48],\n",
       "         [48, 51, 51]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3045000014244579, 'inference': 21.660300000803545, 'postprocess': 4.922300002363045},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [38, 41, 41],\n",
       "         [38, 41, 41]],\n",
       " \n",
       "        [[34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [38, 41, 41],\n",
       "         [38, 41, 41]],\n",
       " \n",
       "        [[34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         [34, 37, 37],\n",
       "         ...,\n",
       "         [37, 40, 40],\n",
       "         [38, 41, 41],\n",
       "         [38, 41, 41]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [43, 46, 46],\n",
       "         [45, 48, 48],\n",
       "         [48, 51, 51]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [43, 46, 46],\n",
       "         [45, 48, 48],\n",
       "         [48, 51, 51]],\n",
       " \n",
       "        [[20, 23, 23],\n",
       "         [21, 24, 24],\n",
       "         [21, 24, 24],\n",
       "         ...,\n",
       "         [43, 46, 46],\n",
       "         [45, 48, 48],\n",
       "         [48, 51, 51]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.004900001338683, 'inference': 31.623400005628355, 'postprocess': 2.395899995462969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.406299998459872, 'inference': 26.20020000176737, 'postprocess': 1.694300000963267},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8444000015733764, 'inference': 21.184400000493042, 'postprocess': 2.017400001932401},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1600000036414713, 'inference': 20.97940000385279, 'postprocess': 2.000100001168903},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5108000006875955, 'inference': 21.101700003782753, 'postprocess': 1.2549999955808744},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.268399995751679, 'inference': 21.708599997509737, 'postprocess': 0.8812000014586374},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6431999974884093, 'inference': 21.933700001682155, 'postprocess': 1.432999997632578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.4195000043837354, 'inference': 32.33460000046762, 'postprocess': 1.3433999993139878},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5953000038280152, 'inference': 20.64999999856809, 'postprocess': 2.3934999990160577},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.3194999996339902, 'inference': 38.90619999583578, 'postprocess': 3.228000001399778},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6400999957113527, 'inference': 28.951000000233762, 'postprocess': 3.1459999954677187},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7261999964830466, 'inference': 25.74830000230577, 'postprocess': 1.781200000550598},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7835000035120174, 'inference': 22.84030000009807, 'postprocess': 0.8646999995107763},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.009700001508463, 'inference': 22.953100000449922, 'postprocess': 1.1382000011508353},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8504999970900826, 'inference': 21.41759999358328, 'postprocess': 0.9221000000252388},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5666999970562756, 'inference': 19.984200000180863, 'postprocess': 1.0408000016468577},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6931999998632818, 'inference': 23.851600002672058, 'postprocess': 1.6482999999425374},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.835999995819293, 'inference': 32.746100005169865, 'postprocess': 1.5527000068686903},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.157899994926993, 'inference': 21.895300000323914, 'postprocess': 3.639000002294779},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.640800001041498, 'inference': 20.179600003757514, 'postprocess': 1.0668999966583215},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.453899996704422, 'inference': 20.092400001885835, 'postprocess': 2.6996999949915335},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9639000020106323, 'inference': 21.06340000318596, 'postprocess': 0.8470000029774383},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.276399998459965, 'inference': 19.97490000212565, 'postprocess': 1.731899996229913},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4888000005157664, 'inference': 23.840800000471063, 'postprocess': 1.5437000038218684},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5955999988364056, 'inference': 19.986100000096485, 'postprocess': 0.8023999980650842},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9253999998909421, 'inference': 20.983299997169524, 'postprocess': 0.8325000017066486},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1187000020290725, 'inference': 12.002600000414532, 'postprocess': 2.309100003913045},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4453999974648468, 'inference': 12.503099998866674, 'postprocess': 0.9862999941105954},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8584999997983687, 'inference': 11.690400002407841, 'postprocess': 0.8280999973067082},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6595000051893294, 'inference': 15.354100003605708, 'postprocess': 0.8846999990055338},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.070300000719726, 'inference': 12.892300001112744, 'postprocess': 0.8452999973087572},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0689000011770986, 'inference': 17.339400001219474, 'postprocess': 1.1067000014008954},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.040400002442766, 'inference': 12.816399997973349, 'postprocess': 0.8435999989160337},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2022000009892508, 'inference': 11.643899997579865, 'postprocess': 1.0745999970822595},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.898599999549333, 'inference': 15.535999998974148, 'postprocess': 0.6968999950913712},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.552300003822893, 'inference': 17.355999996652827, 'postprocess': 1.1228000003029592},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3620999927516095, 'inference': 18.742200001724996, 'postprocess': 1.4470999958575703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4947999952710234, 'inference': 13.829599993187003, 'postprocess': 1.0639999964041635},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2929000004078262, 'inference': 15.640799996617716, 'postprocess': 0.8247000005212612},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9730999993043952, 'inference': 16.937100001086947, 'postprocess': 0.9512999968137592},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5299999940907583, 'inference': 12.269999999261927, 'postprocess': 0.985200000286568},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7331000053673051, 'inference': 33.38159999839263, 'postprocess': 1.578499999595806},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.406199997290969, 'inference': 11.68090000282973, 'postprocess': 0.7652000058442354},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2900000001536682, 'inference': 11.872600000060629, 'postprocess': 0.7848999957786873},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2185000014142133, 'inference': 14.160699996864423, 'postprocess': 0.8175999973900616},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1397000018623658, 'inference': 13.191600002755877, 'postprocess': 0.9165000010398217},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1614999966695905, 'inference': 12.100799998734146, 'postprocess': 0.6587000025319867},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0926000031759031, 'inference': 12.23279999976512, 'postprocess': 0.7571999958599918},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1740000045392662, 'inference': 12.544299999717623, 'postprocess': 0.9336000002804212},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0646000009728596, 'inference': 11.78789999539731, 'postprocess': 1.473900003475137},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5006000030552968, 'inference': 12.300100002903491, 'postprocess': 1.7392000008840114},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4735000004293397, 'inference': 13.911499998357613, 'postprocess': 1.1252999975113198},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7751999985193834, 'inference': 15.55940000253031, 'postprocess': 0.6912000026204623},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.157500002591405, 'inference': 15.626000000338536, 'postprocess': 1.1129000049550086},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 0.9666999976616353, 'inference': 11.557099998753984, 'postprocess': 0.7344000041484833},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.194100004795473, 'inference': 15.27400000486523, 'postprocess': 1.0535999972489662},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.302700002270285, 'inference': 11.515400001371745, 'postprocess': 0.7512000011047348},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0419999962323345, 'inference': 12.489699998695869, 'postprocess': 0.6894000034662895},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1458999942988157, 'inference': 12.835999994422309, 'postprocess': 0.6866999974590726},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.766299996234011, 'inference': 11.569899994356092, 'postprocess': 0.731100000848528},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.283300000068266, 'inference': 13.31190000200877, 'postprocess': 0.9141999980784021},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.468800001021009, 'inference': 11.613700000452809, 'postprocess': 0.7402999981422909},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2707999994745478, 'inference': 17.201800001203083, 'postprocess': 0.811400001111906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0257000030833296, 'inference': 14.244899997720495, 'postprocess': 1.979500004381407},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.652000002854038, 'inference': 32.468799996422604, 'postprocess': 0.6926999994902872},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.29350000154227, 'inference': 12.478399999963585, 'postprocess': 1.3398999944911338},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4503999991575256, 'inference': 11.707699995895382, 'postprocess': 0.7362000033026561},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5364000064437278, 'inference': 22.78610000212211, 'postprocess': 3.737400002137292},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5085999984876253, 'inference': 22.819500001787674, 'postprocess': 2.093299997795839},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.9767000014544465, 'inference': 20.692099998996127, 'postprocess': 2.7160999961779453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.8919000033056363, 'inference': 41.115499996521976, 'postprocess': 2.565299997513648},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.107699998305179, 'inference': 31.798999996681232, 'postprocess': 1.854100002674386},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9390000015846454, 'inference': 21.76830000098562, 'postprocess': 1.2557000009110197},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.569900003436487, 'inference': 20.768000002135523, 'postprocess': 1.4069000026211143},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.715800001169555, 'inference': 20.748099996126257, 'postprocess': 3.137500003504101},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.309799998125527, 'inference': 20.420700006070547, 'postprocess': 0.8390000002691522},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2317000000621192, 'inference': 20.464900000661146, 'postprocess': 0.9066999991773628},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5977000002749264, 'inference': 20.166700000118, 'postprocess': 1.0884999937843531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4567999969585799, 'inference': 20.262799996999092, 'postprocess': 1.4245000056689605},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.576200003910344, 'inference': 20.35309999337187, 'postprocess': 0.8688999951118603},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9507999968482181, 'inference': 20.375699998112395, 'postprocess': 1.0660999978426844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6214999996009283, 'inference': 20.470199997362215, 'postprocess': 0.8824000033200718},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0642999986885116, 'inference': 11.244500004977454, 'postprocess': 0.9582000056980178},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.650300000619609, 'inference': 13.249500007077586, 'postprocess': 0.9104999990086071},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4337000029627234, 'inference': 11.304499996185768, 'postprocess': 0.7226000016089529},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.242900001874659, 'inference': 17.26020000205608, 'postprocess': 0.6935999990673736},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.662800001213327, 'inference': 14.273100001446437, 'postprocess': 1.4693999983137473},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7574999947100878, 'inference': 11.68609999876935, 'postprocess': 0.724500001524575},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6047999961301684, 'inference': 21.49009999993723, 'postprocess': 1.0123999963980168},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0827999978791922, 'inference': 37.35429999505868, 'postprocess': 1.9017000013263896},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8321999959880486, 'inference': 20.28440000140108, 'postprocess': 2.4842000057105906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0990999983041547, 'inference': 16.880099996342324, 'postprocess': 1.4073000056669116},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5340999962063506, 'inference': 12.422599997080397, 'postprocess': 0.6704000043100677},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6027000019676052, 'inference': 16.87099999981001, 'postprocess': 2.4272000009659678},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5148000020417385, 'inference': 17.13949999975739, 'postprocess': 0.9407000034116209},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.60679999680724, 'inference': 12.919000000692904, 'postprocess': 0.6658000056631863},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1261999970884062, 'inference': 19.121500001347158, 'postprocess': 1.516199998150114},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4663000038126484, 'inference': 13.845100002072286, 'postprocess': 0.7218000027933158},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2961000067880377, 'inference': 25.00960000179475, 'postprocess': 1.3005000000703149},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7470999955548905, 'inference': 20.005500002298504, 'postprocess': 0.9609999979147688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6172999967238866, 'inference': 23.933999997098, 'postprocess': 0.7018000032985583},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.138100000389386, 'inference': 11.357399998814799, 'postprocess': 0.8328999974764884},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2582999988808297, 'inference': 11.486099996545818, 'postprocess': 1.0746999978437088},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2559000024339184, 'inference': 14.755299998796545, 'postprocess': 1.0563999967416748},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.215800002682954, 'inference': 11.481699999421835, 'postprocess': 0.7230000046547502},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0363999972469173, 'inference': 11.403699994843919, 'postprocess': 1.0595999992801808},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.189800001156982, 'inference': 14.047600001504179, 'postprocess': 1.1000000013154931},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5247000046656467, 'inference': 14.266199999838136, 'postprocess': 0.7280999998329207},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8210999987786636, 'inference': 22.1531999995932, 'postprocess': 2.0597000038833357},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.15829999797279, 'inference': 19.154399997205473, 'postprocess': 1.254500006325543},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5261000007740222, 'inference': 26.755500002764165, 'postprocess': 0.7482000000891276},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4022999966982752, 'inference': 11.55010000366019, 'postprocess': 0.6962000043131411},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.195600001665298, 'inference': 11.484800001198892, 'postprocess': 0.8538000038242899},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2931999954162166, 'inference': 11.375100002624094, 'postprocess': 0.9678999995230697},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1738999965018593, 'inference': 11.310200003208593, 'postprocess': 0.7322000019485131},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4341999994940124, 'inference': 12.849800004914869, 'postprocess': 0.7045999955153093},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1498999956529588, 'inference': 12.700599996605888, 'postprocess': 0.7895000017015263},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.12490000174148, 'inference': 11.372499997378327, 'postprocess': 0.8137000040733255},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3585000051534735, 'inference': 11.616900002991315, 'postprocess': 0.7392000043182634},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2449999994714744, 'inference': 11.3232000003336, 'postprocess': 0.6896999984746799},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.196599994727876, 'inference': 11.801200002082624, 'postprocess': 0.723899996955879},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2263999960850924, 'inference': 11.527900001965463, 'postprocess': 0.7022999998298474},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1115000015706755, 'inference': 11.313900002278388, 'postprocess': 1.0082000007969327},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4486000000033528, 'inference': 20.053700005519204, 'postprocess': 1.1127999969176017},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3890999980503693, 'inference': 20.494899996265303, 'postprocess': 1.0678000035113655},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7735000001266599, 'inference': 20.00889999908395, 'postprocess': 1.2148000023444183},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.469599999836646, 'inference': 20.76629999646684, 'postprocess': 1.0148000001208857},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5174000000115484, 'inference': 21.157499999389984, 'postprocess': 0.8899999957066029},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5614000003552064, 'inference': 20.046199999342207, 'postprocess': 0.9681000010459684},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3724999953410588, 'inference': 20.053599997481797, 'postprocess': 0.9156000014627352},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3059999982942827, 'inference': 20.07439999579219, 'postprocess': 1.1892999973497353},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9813999970210716, 'inference': 20.815399999264628, 'postprocess': 1.636499997403007},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6651000041747466, 'inference': 17.643900006078184, 'postprocess': 1.4474999989033677},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5455000029760413, 'inference': 14.987700000347104, 'postprocess': 1.1983000003965572},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2706999987130985, 'inference': 11.321600002702326, 'postprocess': 1.4058000015211292},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1629000000539236, 'inference': 14.687100003357045, 'postprocess': 1.1276000004727393},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1133000007248484, 'inference': 11.435000000346918, 'postprocess': 1.1796000035246834},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1881000027642585, 'inference': 11.425599994254299, 'postprocess': 0.7779000006848946},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1744999937945977, 'inference': 13.708900005440228, 'postprocess': 1.6074999948614277},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.927000004798174, 'inference': 20.795700002054218, 'postprocess': 1.393300000927411},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2532999971881509, 'inference': 13.241100001323503, 'postprocess': 0.7070999999996275},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2146000008215196, 'inference': 11.288399997283705, 'postprocess': 0.6900000007590279},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2225000027683564, 'inference': 11.59899999765912, 'postprocess': 1.2933999969391152},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2281999952392653, 'inference': 16.3479000038933, 'postprocess': 0.8172999951057136},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1532999997143634, 'inference': 11.553999996976927, 'postprocess': 0.9758999949553981},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1113000000477768, 'inference': 17.62330000201473, 'postprocess': 0.6990000038058497},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8152999982703477, 'inference': 13.854400000127498, 'postprocess': 2.1157000010134652},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.574999994772952, 'inference': 25.706599997647572, 'postprocess': 2.391000001807697},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6459000034956262, 'inference': 38.30949999974109, 'postprocess': 2.4174999998649582},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.9015999971306883, 'inference': 28.99020000040764, 'postprocess': 1.0494000016478822},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4172000010148622, 'inference': 13.904100000218023, 'postprocess': 0.7683000003453344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.056000000971835, 'inference': 22.231599999940954, 'postprocess': 1.6432999982498586},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6116999977384694, 'inference': 18.518299999414012, 'postprocess': 1.0804999983520247},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9333000018377788, 'inference': 22.397400003683288, 'postprocess': 0.7725000032223761},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1979000046267174, 'inference': 11.48490000196034, 'postprocess': 0.814300001366064},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5639999983250163, 'inference': 15.537200000835583, 'postprocess': 0.9059000003617257},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.378399996610824, 'inference': 12.779000004229601, 'postprocess': 0.8574000021326356},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1870000016642734, 'inference': 16.487299995787907, 'postprocess': 0.9839000049396418},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2746000031474978, 'inference': 39.12359999958426, 'postprocess': 1.8591999978525564},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2516999995568767, 'inference': 12.189900000521448, 'postprocess': 2.1829000033903867},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4400000000023283, 'inference': 41.41499999968801, 'postprocess': 0.7617999945068732},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4864000040688552, 'inference': 23.258299996086862, 'postprocess': 1.6247000021394342},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2046999981976114, 'inference': 15.048399996885564, 'postprocess': 3.708000003825873},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.274099999340251, 'inference': 37.61269999813521, 'postprocess': 2.139899996109307},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3799000007566065, 'inference': 32.72260000085225, 'postprocess': 2.5614999976824038},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4968000032240525, 'inference': 24.22179999848595, 'postprocess': 1.0007000018958934},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8113000041921623, 'inference': 21.07139999861829, 'postprocess': 0.869200004672166},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0839999997406267, 'inference': 21.28229999652831, 'postprocess': 1.2187999964226037},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9826999996439554, 'inference': 21.69560000038473, 'postprocess': 0.872600001457613},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6298000045935623, 'inference': 21.07590000377968, 'postprocess': 1.1293999996269122},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5056000047479756, 'inference': 20.792000002984423, 'postprocess': 1.3988999999128282},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9299999985378236, 'inference': 20.7079000028898, 'postprocess': 2.034299999650102},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6446000008727424, 'inference': 20.740600004501175, 'postprocess': 0.9995000000344589},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4731999981449917, 'inference': 21.258000000671018, 'postprocess': 1.2231000000610948},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7915999997057952, 'inference': 20.64519999839831, 'postprocess': 0.9368000028189272},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2159999969298951, 'inference': 20.607200000085868, 'postprocess': 0.8066000009421259},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2707999994745478, 'inference': 21.1051000005682, 'postprocess': 0.9315999996033497},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.335799999651499, 'inference': 20.805899999686517, 'postprocess': 0.9111999970627949},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3659000032930635, 'inference': 20.106700001633726, 'postprocess': 1.1128000041935593},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2417000034474768, 'inference': 20.135999999183696, 'postprocess': 0.9939000010490417},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5141000039875507, 'inference': 19.93670000229031, 'postprocess': 1.454699995520059},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6967999981716275, 'inference': 28.294800002186093, 'postprocess': 2.65650000073947},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.4540999947930686, 'inference': 30.653800000436604, 'postprocess': 2.502499999536667},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4821000004303642, 'inference': 20.04049999959534, 'postprocess': 1.2528000006568618},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6003999990061857, 'inference': 20.298299998103175, 'postprocess': 1.390700002957601},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7025999986799434, 'inference': 19.97250000567874, 'postprocess': 0.894299999345094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7541999986860901, 'inference': 20.20959999936167, 'postprocess': 0.7916999966255389},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3724999953410588, 'inference': 19.995399998151697, 'postprocess': 1.0915999955614097},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5838000035728328, 'inference': 20.168299997749273, 'postprocess': 0.8639000006951392},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1696999936248176, 'inference': 11.379700001270976, 'postprocess': 1.5916999982437119},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1882999970111996, 'inference': 11.24839999829419, 'postprocess': 1.0314000028301962},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2340999965090305, 'inference': 11.757500004023314, 'postprocess': 0.7110999940778129},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2123999986215495, 'inference': 11.487099996884353, 'postprocess': 1.0945000030915253},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.470399998652283, 'inference': 12.551099993288517, 'postprocess': 1.0591999962343834},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3269000046420842, 'inference': 11.525900001288392, 'postprocess': 0.7256999961100519},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.181799998448696, 'inference': 16.89970000006724, 'postprocess': 0.8469999957014807},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 0.995999995211605, 'inference': 11.224499998206738, 'postprocess': 0.6782999989809468},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2333999984548427, 'inference': 11.654499998257961, 'postprocess': 0.8937000020523556},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2805000005755574, 'inference': 15.110400003322866, 'postprocess': 0.7125999982235953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1728999961633235, 'inference': 12.116900004912168, 'postprocess': 1.4561999996658415},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2491000015870668, 'inference': 11.292100003629457, 'postprocess': 1.6388000003644265},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1359999989508651, 'inference': 11.466500000096858, 'postprocess': 1.0408000016468577},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1947999955737032, 'inference': 15.429299994139, 'postprocess': 0.9911000015563332},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.146599999628961, 'inference': 11.914599999727216, 'postprocess': 0.7247000030474737},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2489999935496598, 'inference': 12.401899999531452, 'postprocess': 0.8391000010306016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1219000007258728, 'inference': 12.006299999484327, 'postprocess': 0.7046000027912669},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.268800006073434, 'inference': 11.332399997627363, 'postprocess': 0.7016000017756596},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4059000022825785, 'inference': 11.79989999945974, 'postprocess': 0.8716000011190772},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2633000005735084, 'inference': 24.198400002205744, 'postprocess': 1.7036999997799285},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.974099999642931, 'inference': 19.78930000041146, 'postprocess': 0.7715000028838404},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4938000022084452, 'inference': 17.642200000409503, 'postprocess': 1.04010000359267},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0851000042748637, 'inference': 15.924200000881683, 'postprocess': 0.7488999981433153},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5504999973927625, 'inference': 19.0943999987212, 'postprocess': 1.1607999986154027},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3128999999025837, 'inference': 16.87830000446411, 'postprocess': 2.052299998467788},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0507999977562577, 'inference': 31.04650000022957, 'postprocess': 2.376900003582705},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3355000012088567, 'inference': 22.182799999427516, 'postprocess': 0.698499999998603},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.507299999706447, 'inference': 15.881100000115111, 'postprocess': 0.8834999971440993},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0750000001280569, 'inference': 11.657900002319366, 'postprocess': 1.4828999992460012},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0871000015176833, 'inference': 19.976399998995475, 'postprocess': 1.120599998102989},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5981999968062155, 'inference': 23.157800002081785, 'postprocess': 1.288700004806742},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7372000002069399, 'inference': 24.28860000509303, 'postprocess': 2.6397999972687103},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2860999961267225, 'inference': 24.70750000065891, 'postprocess': 1.1044999992009252},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.369899997371249, 'inference': 11.459800000011455, 'postprocess': 0.9314000053564087},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7150999992736615, 'inference': 21.728499996243045, 'postprocess': 2.5574999963282607},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.4452000070596114, 'inference': 32.47189999819966, 'postprocess': 1.7832000012276694},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2742999970214441, 'inference': 21.757399998023175, 'postprocess': 1.8315999986953102},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.618499998585321, 'inference': 22.139799999422394, 'postprocess': 1.42269999923883},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0577000032062642, 'inference': 21.0609000059776, 'postprocess': 1.7776000022422522},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1168000021134503, 'inference': 24.145700001099613, 'postprocess': 1.0695999953895807},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5362999984063208, 'inference': 21.063399995910004, 'postprocess': 1.3233999998192303},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4675999991595745, 'inference': 21.040999999968335, 'postprocess': 1.5768000012030825},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2055000042892061, 'inference': 21.023200002673548, 'postprocess': 1.4004999975441024},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1780000024591573, 'inference': 21.88459999888437, 'postprocess': 0.8621000015409663},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.100500001688488, 'inference': 22.61029999499442, 'postprocess': 2.125899998645764},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7368000044371001, 'inference': 23.264099996595178, 'postprocess': 1.5208999975584447},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.530499997898005, 'inference': 20.87050000409363, 'postprocess': 0.8941999985836446},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1239999987301417, 'inference': 39.838199998484924, 'postprocess': 2.5498000031802803},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3766999947838485, 'inference': 25.214499997673556, 'postprocess': 1.9855000064126216},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3132000060286373, 'inference': 23.2557999988785, 'postprocess': 1.190400005725678},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.857800001744181, 'inference': 25.840999995125458, 'postprocess': 1.8801999976858497},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.249800000048708, 'inference': 21.651399998518173, 'postprocess': 2.1891000069445},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5907999986666255, 'inference': 21.724900005210657, 'postprocess': 0.7954999964567833},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8026000034296885, 'inference': 36.70849999616621, 'postprocess': 1.4950000040698797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7172000007121824, 'inference': 26.4138999991701, 'postprocess': 1.6495000018039718},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8702000015764497, 'inference': 24.319700001797173, 'postprocess': 1.9229000026825815},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3010000004433095, 'inference': 25.072399999771733, 'postprocess': 2.758700000413228},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2430999961216003, 'inference': 23.92600000166567, 'postprocess': 1.8614000000525266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2877000010339543, 'inference': 21.89380000345409, 'postprocess': 2.7219999974477105},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.57789999502711, 'inference': 26.09459999803221, 'postprocess': 5.738399995607324},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0499999955063686, 'inference': 22.656900000583846, 'postprocess': 1.2124999993829988},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5080999946803786, 'inference': 31.403299995872658, 'postprocess': 1.1169999997946434},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8500999940442853, 'inference': 22.26360000349814, 'postprocess': 0.8283000061055645},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1452999935718253, 'inference': 29.427200002828613, 'postprocess': 3.2481999951414764},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.4961000017356128, 'inference': 39.38840000046184, 'postprocess': 2.953000002889894},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.56789999891771, 'inference': 22.76200000051176, 'postprocess': 1.767099995049648},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.781200000550598, 'inference': 31.766200001584366, 'postprocess': 1.1990999992121942},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6767000051913783, 'inference': 32.67229999619303, 'postprocess': 2.730100000917446},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.593400000478141, 'inference': 27.740800003812183, 'postprocess': 1.5730000013718382},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7176000037579797, 'inference': 29.18399999907706, 'postprocess': 2.28199999401113},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.165700003388338, 'inference': 23.128799999540206, 'postprocess': 3.0270999995991588},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7772999999579042, 'inference': 25.049900003068615, 'postprocess': 1.7393999951309524},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5812999990885146, 'inference': 21.514699998078868, 'postprocess': 2.899399994930718},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.085899999656249, 'inference': 24.71969999896828, 'postprocess': 1.6983999958029017},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.6475999984540977, 'inference': 28.021300000546034, 'postprocess': 0.8971999995992519},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.008799994655419, 'inference': 24.02849999634782, 'postprocess': 2.7896000028704293},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1969000008539297, 'inference': 23.84879999590339, 'postprocess': 2.7884999944944866},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.885099998617079, 'inference': 21.728899999288842, 'postprocess': 1.6876000008778647},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3255999985849485, 'inference': 28.452099999412894, 'postprocess': 1.6711999996914528},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3431000008713454, 'inference': 28.165800002170727, 'postprocess': 0.8470000029774383},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.491600000008475, 'inference': 23.232200001075398, 'postprocess': 0.825700000859797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.369599995086901, 'inference': 21.89879999787081, 'postprocess': 1.4885999989928678},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3939999989815988, 'inference': 21.936299999651965, 'postprocess': 1.460799998312723},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8209999980172142, 'inference': 27.708900001016445, 'postprocess': 1.4601999937440269},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.825699997425545, 'inference': 22.90769999672193, 'postprocess': 0.9072999964701012},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3923000005888753, 'inference': 21.77529999607941, 'postprocess': 1.9773999956669286},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.439299994672183, 'inference': 21.3590000057593, 'postprocess': 2.5342000008095056},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3055999952484854, 'inference': 21.055199998954777, 'postprocess': 0.7913000008556992},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6784999970695935, 'inference': 25.943499997083563, 'postprocess': 0.8567000040784478},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.782499995897524, 'inference': 24.395399996137712, 'postprocess': 0.7642999989911914},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4558999973814934, 'inference': 20.936200002324767, 'postprocess': 1.6123000023071654},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.530300000216812, 'inference': 54.90769999596523, 'postprocess': 3.2920000012381934},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6859999959706329, 'inference': 30.011400005605537, 'postprocess': 2.156700000341516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.312500004132744, 'inference': 23.26119999634102, 'postprocess': 1.0223999997833744},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105,  93, 113],\n",
       "         [106,  94, 114],\n",
       "         [104,  95, 113],\n",
       "         ...,\n",
       "         [ 52,  45,  51],\n",
       "         [ 71,  67,  70],\n",
       "         [102,  98, 101]],\n",
       " \n",
       "        [[105,  93, 113],\n",
       "         [106,  94, 114],\n",
       "         [104,  95, 113],\n",
       "         ...,\n",
       "         [ 56,  49,  55],\n",
       "         [ 68,  64,  67],\n",
       "         [ 89,  85,  88]],\n",
       " \n",
       "        [[105,  93, 113],\n",
       "         [106,  94, 114],\n",
       "         [104,  95, 113],\n",
       "         ...,\n",
       "         [ 59,  46,  55],\n",
       "         [ 64,  54,  61],\n",
       "         [ 73,  63,  70]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 43,  29,  48],\n",
       "         [ 44,  30,  49],\n",
       "         [ 44,  29,  50],\n",
       "         ...,\n",
       "         [ 90,  84, 142],\n",
       "         [ 92,  83, 142],\n",
       "         [ 93,  84, 143]],\n",
       " \n",
       "        [[ 45,  31,  50],\n",
       "         [ 46,  32,  51],\n",
       "         [ 46,  31,  52],\n",
       "         ...,\n",
       "         [ 90,  84, 142],\n",
       "         [ 92,  83, 142],\n",
       "         [ 93,  84, 143]],\n",
       " \n",
       "        [[ 47,  33,  52],\n",
       "         [ 49,  35,  54],\n",
       "         [ 49,  34,  55],\n",
       "         ...,\n",
       "         [ 89,  83, 141],\n",
       "         [ 91,  82, 141],\n",
       "         [ 93,  84, 143]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5447000041604042, 'inference': 20.989800003007986, 'postprocess': 1.2609000041265972},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105,  93, 113],\n",
       "         [106,  94, 114],\n",
       "         [104,  95, 113],\n",
       "         ...,\n",
       "         [ 65,  52,  61],\n",
       "         [ 58,  48,  55],\n",
       "         [ 63,  53,  60]],\n",
       " \n",
       "        [[105,  93, 113],\n",
       "         [106,  94, 114],\n",
       "         [104,  95, 113],\n",
       "         ...,\n",
       "         [ 67,  54,  63],\n",
       "         [ 59,  49,  56],\n",
       "         [ 60,  50,  57]],\n",
       " \n",
       "        [[105,  93, 113],\n",
       "         [106,  94, 114],\n",
       "         [104,  95, 113],\n",
       "         ...,\n",
       "         [ 68,  55,  64],\n",
       "         [ 58,  48,  55],\n",
       "         [ 57,  47,  54]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 40,  26,  45],\n",
       "         [ 42,  28,  47],\n",
       "         [ 42,  27,  48],\n",
       "         ...,\n",
       "         [ 90,  84, 142],\n",
       "         [ 92,  83, 142],\n",
       "         [ 93,  84, 143]],\n",
       " \n",
       "        [[ 43,  29,  48],\n",
       "         [ 44,  30,  49],\n",
       "         [ 44,  29,  50],\n",
       "         ...,\n",
       "         [ 90,  84, 142],\n",
       "         [ 92,  83, 142],\n",
       "         [ 93,  84, 143]],\n",
       " \n",
       "        [[ 45,  31,  50],\n",
       "         [ 46,  32,  51],\n",
       "         [ 46,  31,  52],\n",
       "         ...,\n",
       "         [ 89,  83, 141],\n",
       "         [ 91,  82, 141],\n",
       "         [ 93,  84, 143]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4239999945857562, 'inference': 22.95540000341134, 'postprocess': 2.077800003462471},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[107,  95, 115],\n",
       "         [107,  95, 115],\n",
       "         [105,  96, 114],\n",
       "         ...,\n",
       "         [ 79,  74,  75],\n",
       "         [ 76,  71,  72],\n",
       "         [ 71,  66,  67]],\n",
       " \n",
       "        [[107,  95, 115],\n",
       "         [107,  95, 115],\n",
       "         [105,  96, 114],\n",
       "         ...,\n",
       "         [ 78,  73,  74],\n",
       "         [ 75,  70,  71],\n",
       "         [ 71,  66,  67]],\n",
       " \n",
       "        [[107,  95, 115],\n",
       "         [107,  95, 115],\n",
       "         [105,  96, 114],\n",
       "         ...,\n",
       "         [ 76,  71,  72],\n",
       "         [ 73,  68,  69],\n",
       "         [ 71,  66,  67]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 52,  38,  57],\n",
       "         [ 52,  38,  57],\n",
       "         [ 52,  37,  58],\n",
       "         ...,\n",
       "         [ 88,  82, 140],\n",
       "         [ 90,  81, 140],\n",
       "         [ 91,  82, 141]],\n",
       " \n",
       "        [[ 53,  39,  58],\n",
       "         [ 53,  39,  58],\n",
       "         [ 53,  38,  59],\n",
       "         ...,\n",
       "         [ 88,  82, 140],\n",
       "         [ 90,  81, 140],\n",
       "         [ 91,  82, 141]],\n",
       " \n",
       "        [[ 53,  39,  58],\n",
       "         [ 53,  39,  58],\n",
       "         [ 53,  38,  59],\n",
       "         ...,\n",
       "         [ 88,  82, 140],\n",
       "         [ 90,  81, 140],\n",
       "         [ 91,  82, 141]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4043000046513043, 'inference': 21.100700003444217, 'postprocess': 1.8202999999630265},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[106,  94, 114],\n",
       "         [106,  94, 114],\n",
       "         [106,  94, 114],\n",
       "         ...,\n",
       "         [ 80,  69,  73],\n",
       "         [ 81,  72,  76],\n",
       "         [ 82,  73,  77]],\n",
       " \n",
       "        [[106,  94, 114],\n",
       "         [106,  94, 114],\n",
       "         [106,  94, 114],\n",
       "         ...,\n",
       "         [ 81,  70,  74],\n",
       "         [ 80,  71,  75],\n",
       "         [ 80,  71,  75]],\n",
       " \n",
       "        [[106,  94, 114],\n",
       "         [106,  94, 114],\n",
       "         [106,  94, 114],\n",
       "         ...,\n",
       "         [ 83,  72,  76],\n",
       "         [ 78,  69,  73],\n",
       "         [ 77,  68,  72]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  34,  55],\n",
       "         [ 50,  35,  56],\n",
       "         [ 50,  35,  56],\n",
       "         ...,\n",
       "         [ 90,  80, 142],\n",
       "         [ 91,  82, 141],\n",
       "         [ 92,  83, 142]],\n",
       " \n",
       "        [[ 52,  37,  58],\n",
       "         [ 51,  36,  57],\n",
       "         [ 51,  36,  57],\n",
       "         ...,\n",
       "         [ 90,  80, 142],\n",
       "         [ 90,  81, 140],\n",
       "         [ 91,  82, 141]],\n",
       " \n",
       "        [[ 53,  38,  59],\n",
       "         [ 52,  37,  58],\n",
       "         [ 52,  37,  58],\n",
       "         ...,\n",
       "         [ 90,  80, 142],\n",
       "         [ 90,  81, 140],\n",
       "         [ 91,  82, 141]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5413000000989996, 'inference': 20.934799998940434, 'postprocess': 1.1771999998018146},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105,  95, 115],\n",
       "         [105,  95, 115],\n",
       "         [102,  95, 114],\n",
       "         ...,\n",
       "         [101,  88,  92],\n",
       "         [ 99,  86,  90],\n",
       "         [ 95,  82,  86]],\n",
       " \n",
       "        [[105,  95, 115],\n",
       "         [105,  95, 115],\n",
       "         [103,  96, 115],\n",
       "         ...,\n",
       "         [104,  91,  95],\n",
       "         [100,  87,  91],\n",
       "         [ 97,  84,  88]],\n",
       " \n",
       "        [[106,  96, 116],\n",
       "         [105,  95, 115],\n",
       "         [103,  96, 115],\n",
       "         ...,\n",
       "         [108,  95,  99],\n",
       "         [105,  92,  96],\n",
       "         [101,  88,  92]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 53,  38,  59],\n",
       "         [ 53,  38,  59],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [ 91,  81, 145],\n",
       "         [ 91,  81, 143],\n",
       "         [ 90,  80, 142]],\n",
       " \n",
       "        [[ 53,  38,  59],\n",
       "         [ 53,  38,  59],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [ 96,  86, 150],\n",
       "         [ 91,  81, 143],\n",
       "         [ 90,  80, 142]],\n",
       " \n",
       "        [[ 53,  38,  59],\n",
       "         [ 53,  38,  59],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [ 98,  88, 152],\n",
       "         [ 92,  82, 144],\n",
       "         [ 89,  79, 141]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4017000066814944, 'inference': 21.41999999730615, 'postprocess': 0.9755999999470077},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[103,  96, 115],\n",
       "         [103,  96, 115],\n",
       "         [104,  94, 114],\n",
       "         ...,\n",
       "         [105,  92,  96],\n",
       "         [103,  90,  94],\n",
       "         [ 99,  86,  90]],\n",
       " \n",
       "        [[103,  96, 115],\n",
       "         [103,  96, 115],\n",
       "         [105,  95, 115],\n",
       "         ...,\n",
       "         [106,  93,  97],\n",
       "         [104,  91,  95],\n",
       "         [100,  87,  91]],\n",
       " \n",
       "        [[104,  97, 116],\n",
       "         [103,  96, 115],\n",
       "         [105,  95, 115],\n",
       "         ...,\n",
       "         [111,  98, 102],\n",
       "         [110,  97, 101],\n",
       "         [106,  93,  97]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [ 87,  77, 139],\n",
       "         [ 90,  80, 142],\n",
       "         [ 91,  81, 143]],\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [ 87,  77, 139],\n",
       "         [ 90,  80, 142],\n",
       "         [ 91,  81, 143]],\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [ 93,  83, 145],\n",
       "         [ 92,  82, 144],\n",
       "         [ 92,  82, 144]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2102000036975369, 'inference': 21.244799994747154, 'postprocess': 2.070599999569822},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[104,  97, 116],\n",
       "         [104,  97, 116],\n",
       "         [106,  96, 116],\n",
       "         ...,\n",
       "         [137, 119, 124],\n",
       "         [130, 112, 117],\n",
       "         [126, 108, 113]],\n",
       " \n",
       "        [[104,  97, 116],\n",
       "         [104,  97, 116],\n",
       "         [106,  96, 116],\n",
       "         ...,\n",
       "         [143, 125, 130],\n",
       "         [135, 117, 122],\n",
       "         [131, 113, 118]],\n",
       " \n",
       "        [[103,  96, 115],\n",
       "         [103,  96, 115],\n",
       "         [103,  96, 115],\n",
       "         ...,\n",
       "         [154, 136, 141],\n",
       "         [145, 127, 132],\n",
       "         [142, 124, 129]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [ 97,  87, 149],\n",
       "         [ 92,  82, 144],\n",
       "         [ 91,  81, 143]],\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [108,  98, 160],\n",
       "         [100,  90, 152],\n",
       "         [ 97,  87, 149]],\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [121, 111, 173],\n",
       "         [111, 101, 163],\n",
       "         [103,  93, 155]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.8942999997525476, 'inference': 29.7841999999946, 'postprocess': 1.4436999990721233},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[104,  97, 116],\n",
       "         [104,  97, 116],\n",
       "         [106,  96, 116],\n",
       "         ...,\n",
       "         [147, 128, 136],\n",
       "         [139, 121, 126],\n",
       "         [131, 113, 118]],\n",
       " \n",
       "        [[104,  97, 116],\n",
       "         [104,  97, 116],\n",
       "         [106,  96, 116],\n",
       "         ...,\n",
       "         [159, 140, 148],\n",
       "         [146, 128, 133],\n",
       "         [136, 118, 123]],\n",
       " \n",
       "        [[103,  96, 115],\n",
       "         [103,  96, 115],\n",
       "         [103,  96, 115],\n",
       "         ...,\n",
       "         [168, 149, 157],\n",
       "         [157, 139, 144],\n",
       "         [145, 127, 132]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [ 97,  87, 149],\n",
       "         [ 92,  82, 144],\n",
       "         [ 87,  77, 139]],\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [106,  96, 158],\n",
       "         [ 98,  88, 150],\n",
       "         [ 91,  81, 143]],\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         ...,\n",
       "         [115, 105, 167],\n",
       "         [104,  94, 156],\n",
       "         [ 94,  84, 146]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.376900003582705, 'inference': 26.73759999743197, 'postprocess': 1.6977000050246716},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[104,  94, 114],\n",
       "         [104,  94, 114],\n",
       "         [106,  94, 114],\n",
       "         ...,\n",
       "         [201, 178, 189],\n",
       "         [201, 181, 191],\n",
       "         [203, 183, 193]],\n",
       " \n",
       "        [[104,  94, 114],\n",
       "         [104,  94, 114],\n",
       "         [105,  93, 113],\n",
       "         ...,\n",
       "         [198, 175, 186],\n",
       "         [203, 183, 193],\n",
       "         [206, 186, 196]],\n",
       " \n",
       "        [[102,  90, 110],\n",
       "         [101,  89, 109],\n",
       "         [ 98,  88, 108],\n",
       "         ...,\n",
       "         [190, 167, 178],\n",
       "         [201, 181, 191],\n",
       "         [206, 186, 196]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [143, 132, 198],\n",
       "         [133, 122, 188],\n",
       "         [122, 111, 177]],\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [149, 138, 204],\n",
       "         [142, 131, 197],\n",
       "         [134, 123, 189]],\n",
       " \n",
       "        [[ 54,  39,  60],\n",
       "         [ 54,  39,  60],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [150, 139, 205],\n",
       "         [145, 134, 200],\n",
       "         [139, 128, 194]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6452000054414384, 'inference': 21.7491000003065, 'postprocess': 0.9827999965636991},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[102,  95, 114],\n",
       "         [102,  95, 114],\n",
       "         [105,  95, 115],\n",
       "         ...,\n",
       "         [192, 169, 180],\n",
       "         [196, 176, 186],\n",
       "         [202, 182, 192]],\n",
       " \n",
       "        [[101,  94, 113],\n",
       "         [101,  94, 113],\n",
       "         [103,  93, 113],\n",
       "         ...,\n",
       "         [181, 158, 169],\n",
       "         [192, 172, 182],\n",
       "         [203, 183, 193]],\n",
       " \n",
       "        [[ 99,  89, 109],\n",
       "         [ 98,  88, 108],\n",
       "         [ 96,  89, 108],\n",
       "         ...,\n",
       "         [165, 141, 155],\n",
       "         [184, 165, 173],\n",
       "         [200, 181, 189]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [145, 134, 200],\n",
       "         [133, 122, 188],\n",
       "         [120, 109, 175]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [148, 137, 203],\n",
       "         [139, 128, 194],\n",
       "         [131, 120, 186]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [150, 139, 205],\n",
       "         [148, 137, 203],\n",
       "         [142, 131, 197]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.385600000503473, 'inference': 20.97630000207573, 'postprocess': 2.5924000001396053},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 80,  68,  88],\n",
       "         [ 83,  71,  91],\n",
       "         [ 83,  71,  91],\n",
       "         ...,\n",
       "         [ 98,  69,  85],\n",
       "         [ 95,  67,  81],\n",
       "         [ 95,  67,  81]],\n",
       " \n",
       "        [[ 73,  61,  81],\n",
       "         [ 75,  63,  83],\n",
       "         [ 76,  64,  84],\n",
       "         ...,\n",
       "         [ 98,  69,  85],\n",
       "         [ 96,  68,  82],\n",
       "         [ 94,  66,  80]],\n",
       " \n",
       "        [[ 71,  56,  77],\n",
       "         [ 71,  56,  77],\n",
       "         [ 72,  57,  78],\n",
       "         ...,\n",
       "         [ 96,  67,  83],\n",
       "         [ 96,  68,  82],\n",
       "         [ 94,  66,  80]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [150, 138, 207],\n",
       "         [150, 138, 207],\n",
       "         [148, 136, 205]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [148, 136, 205],\n",
       "         [148, 136, 205],\n",
       "         [147, 135, 204]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [148, 136, 205],\n",
       "         [147, 135, 204],\n",
       "         [147, 135, 204]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6905999946175143, 'inference': 25.09709999867482, 'postprocess': 2.172900000005029},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 86,  70,  94],\n",
       "         [ 86,  70,  94],\n",
       "         [ 87,  72,  93],\n",
       "         ...,\n",
       "         [100,  72,  86],\n",
       "         [ 96,  70,  84],\n",
       "         [ 97,  71,  85]],\n",
       " \n",
       "        [[ 78,  62,  86],\n",
       "         [ 78,  62,  86],\n",
       "         [ 80,  65,  86],\n",
       "         ...,\n",
       "         [ 98,  70,  84],\n",
       "         [ 94,  68,  82],\n",
       "         [ 94,  68,  82]],\n",
       " \n",
       "        [[ 71,  56,  77],\n",
       "         [ 71,  56,  77],\n",
       "         [ 73,  57,  81],\n",
       "         ...,\n",
       "         [ 98,  69,  85],\n",
       "         [ 98,  70,  84],\n",
       "         [ 95,  67,  81]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [150, 139, 205],\n",
       "         [153, 142, 208],\n",
       "         [154, 143, 209]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [149, 138, 204],\n",
       "         [152, 141, 207],\n",
       "         [152, 141, 207]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [150, 139, 205],\n",
       "         [150, 139, 205],\n",
       "         [150, 139, 205]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6812000030768104, 'inference': 22.642999996605795, 'postprocess': 2.5938000035239384},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 70,  51,  77],\n",
       "         [ 63,  44,  70],\n",
       "         [ 60,  41,  67],\n",
       "         ...,\n",
       "         [102,  63,  81],\n",
       "         [100,  63,  81],\n",
       "         [100,  63,  81]],\n",
       " \n",
       "        [[ 70,  51,  77],\n",
       "         [ 63,  44,  70],\n",
       "         [ 59,  40,  66],\n",
       "         ...,\n",
       "         [102,  63,  81],\n",
       "         [100,  63,  81],\n",
       "         [100,  63,  81]],\n",
       " \n",
       "        [[ 72,  51,  77],\n",
       "         [ 64,  43,  69],\n",
       "         [ 56,  37,  63],\n",
       "         ...,\n",
       "         [102,  63,  81],\n",
       "         [100,  63,  81],\n",
       "         [100,  63,  81]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [153, 140, 211],\n",
       "         [150, 137, 208],\n",
       "         [149, 136, 207]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [152, 139, 210],\n",
       "         [152, 139, 210],\n",
       "         [150, 137, 208]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [152, 139, 210],\n",
       "         [152, 139, 210],\n",
       "         [150, 137, 208]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5375000002677552, 'inference': 21.266000003379304, 'postprocess': 1.1840000006486662},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 62,  43,  69],\n",
       "         [ 60,  41,  67],\n",
       "         [ 57,  40,  66],\n",
       "         ...,\n",
       "         [104,  63,  81],\n",
       "         [102,  63,  81],\n",
       "         [102,  63,  81]],\n",
       " \n",
       "        [[ 60,  41,  67],\n",
       "         [ 58,  39,  65],\n",
       "         [ 54,  37,  63],\n",
       "         ...,\n",
       "         [104,  63,  81],\n",
       "         [102,  63,  81],\n",
       "         [102,  63,  81]],\n",
       " \n",
       "        [[ 60,  39,  65],\n",
       "         [ 57,  36,  62],\n",
       "         [ 54,  35,  61],\n",
       "         ...,\n",
       "         [104,  63,  81],\n",
       "         [102,  63,  81],\n",
       "         [102,  63,  81]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [154, 141, 212],\n",
       "         [152, 139, 210],\n",
       "         [150, 137, 208]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [154, 141, 212],\n",
       "         [152, 139, 210]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [155, 142, 213],\n",
       "         [154, 141, 212],\n",
       "         [152, 139, 210]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.829699998779688, 'inference': 21.709000000555534, 'postprocess': 2.2180000014486723},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 51,  30,  56],\n",
       "         [ 51,  30,  56],\n",
       "         [ 49,  30,  56],\n",
       "         ...,\n",
       "         [109,  63,  82],\n",
       "         [109,  63,  82],\n",
       "         [109,  63,  82]],\n",
       " \n",
       "        [[ 50,  29,  55],\n",
       "         [ 50,  29,  55],\n",
       "         [ 48,  29,  55],\n",
       "         ...,\n",
       "         [109,  63,  82],\n",
       "         [109,  63,  82],\n",
       "         [109,  63,  82]],\n",
       " \n",
       "        [[ 49,  28,  54],\n",
       "         [ 50,  29,  55],\n",
       "         [ 50,  29,  55],\n",
       "         ...,\n",
       "         [109,  63,  82],\n",
       "         [109,  63,  82],\n",
       "         [109,  63,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [157, 145, 214],\n",
       "         [156, 144, 213],\n",
       "         [156, 144, 213]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [154, 142, 211],\n",
       "         [154, 142, 211],\n",
       "         [154, 142, 211]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [152, 140, 209],\n",
       "         [152, 140, 209],\n",
       "         [152, 140, 209]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2677999984589405, 'inference': 26.107400000910275, 'postprocess': 2.118800002790522},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 50,  29,  55],\n",
       "         [ 50,  29,  55],\n",
       "         [ 49,  30,  56],\n",
       "         ...,\n",
       "         [110,  64,  83],\n",
       "         [107,  64,  81],\n",
       "         [107,  64,  81]],\n",
       " \n",
       "        [[ 49,  28,  54],\n",
       "         [ 50,  29,  55],\n",
       "         [ 48,  29,  55],\n",
       "         ...,\n",
       "         [109,  63,  82],\n",
       "         [108,  65,  82],\n",
       "         [107,  64,  81]],\n",
       " \n",
       "        [[ 48,  27,  53],\n",
       "         [ 49,  28,  54],\n",
       "         [ 50,  29,  55],\n",
       "         ...,\n",
       "         [113,  62,  82],\n",
       "         [109,  63,  82],\n",
       "         [109,  63,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [159, 146, 217],\n",
       "         [159, 146, 217],\n",
       "         [157, 144, 215]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [157, 144, 215],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2608999968506396, 'inference': 21.275099999911617, 'postprocess': 2.8938999967067502},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 50,  29,  55],\n",
       "         [ 50,  29,  55],\n",
       "         [ 51,  30,  58],\n",
       "         ...,\n",
       "         [118,  66,  84],\n",
       "         [118,  67,  82],\n",
       "         [116,  65,  80]],\n",
       " \n",
       "        [[ 49,  28,  54],\n",
       "         [ 50,  29,  55],\n",
       "         [ 50,  29,  57],\n",
       "         ...,\n",
       "         [118,  66,  84],\n",
       "         [119,  68,  83],\n",
       "         [119,  68,  83]],\n",
       " \n",
       "        [[ 51,  27,  54],\n",
       "         [ 51,  27,  54],\n",
       "         [ 52,  28,  55],\n",
       "         ...,\n",
       "         [119,  67,  85],\n",
       "         [120,  66,  82],\n",
       "         [120,  66,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 57,  42,  63],\n",
       "         [ 57,  42,  63],\n",
       "         [ 57,  41,  65],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [156, 143, 214],\n",
       "         [155, 142, 213]],\n",
       " \n",
       "        [[ 57,  42,  63],\n",
       "         [ 57,  42,  63],\n",
       "         [ 57,  41,  65],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [155, 142, 213],\n",
       "         [153, 140, 211]],\n",
       " \n",
       "        [[ 57,  42,  63],\n",
       "         [ 57,  42,  63],\n",
       "         [ 57,  41,  65],\n",
       "         ...,\n",
       "         [157, 144, 215],\n",
       "         [155, 142, 213],\n",
       "         [153, 140, 211]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9742000004043803, 'inference': 23.939899998367764, 'postprocess': 1.8539000011514872},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 50,  29,  55],\n",
       "         [ 50,  29,  55],\n",
       "         [ 49,  30,  56],\n",
       "         ...,\n",
       "         [118,  66,  84],\n",
       "         [118,  67,  82],\n",
       "         [116,  65,  80]],\n",
       " \n",
       "        [[ 49,  28,  54],\n",
       "         [ 50,  29,  55],\n",
       "         [ 48,  29,  55],\n",
       "         ...,\n",
       "         [118,  66,  84],\n",
       "         [119,  68,  83],\n",
       "         [119,  68,  83]],\n",
       " \n",
       "        [[ 48,  27,  53],\n",
       "         [ 49,  28,  54],\n",
       "         [ 50,  29,  55],\n",
       "         ...,\n",
       "         [119,  67,  85],\n",
       "         [120,  66,  82],\n",
       "         [120,  66,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  40,  64],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  40,  64],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [155, 142, 213]],\n",
       " \n",
       "        [[ 56,  41,  62],\n",
       "         [ 56,  41,  62],\n",
       "         [ 56,  40,  64],\n",
       "         ...,\n",
       "         [157, 144, 215],\n",
       "         [157, 144, 215],\n",
       "         [155, 142, 213]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.400200002535712, 'inference': 21.820299996761605, 'postprocess': 1.4977999962866306},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 51,  27,  54],\n",
       "         [ 51,  27,  54],\n",
       "         [ 52,  28,  55],\n",
       "         ...,\n",
       "         [112,  63,  78],\n",
       "         [113,  64,  79],\n",
       "         [112,  63,  78]],\n",
       " \n",
       "        [[ 49,  25,  52],\n",
       "         [ 50,  26,  53],\n",
       "         [ 52,  28,  55],\n",
       "         ...,\n",
       "         [114,  65,  80],\n",
       "         [116,  67,  82],\n",
       "         [114,  65,  80]],\n",
       " \n",
       "        [[ 51,  25,  54],\n",
       "         [ 52,  26,  55],\n",
       "         [ 53,  27,  56],\n",
       "         ...,\n",
       "         [117,  67,  85],\n",
       "         [118,  68,  86],\n",
       "         [117,  67,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  43,  64],\n",
       "         [ 58,  43,  64],\n",
       "         [ 58,  42,  66],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]],\n",
       " \n",
       "        [[ 58,  43,  64],\n",
       "         [ 58,  43,  64],\n",
       "         [ 58,  42,  66],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]],\n",
       " \n",
       "        [[ 59,  44,  65],\n",
       "         [ 59,  44,  65],\n",
       "         [ 59,  43,  67],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5533999976469204, 'inference': 28.872200004116166, 'postprocess': 2.0880000010947697},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 53,  27,  56],\n",
       "         [ 54,  28,  57],\n",
       "         [ 52,  27,  59],\n",
       "         ...,\n",
       "         [112,  63,  78],\n",
       "         [113,  64,  79],\n",
       "         [112,  63,  78]],\n",
       " \n",
       "        [[ 53,  27,  56],\n",
       "         [ 53,  27,  56],\n",
       "         [ 52,  27,  59],\n",
       "         ...,\n",
       "         [114,  65,  80],\n",
       "         [116,  67,  82],\n",
       "         [114,  65,  80]],\n",
       " \n",
       "        [[ 52,  26,  55],\n",
       "         [ 53,  27,  56],\n",
       "         [ 54,  28,  57],\n",
       "         ...,\n",
       "         [117,  67,  85],\n",
       "         [118,  68,  86],\n",
       "         [117,  67,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 57,  42,  63],\n",
       "         [ 57,  42,  63],\n",
       "         [ 57,  41,  65],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]],\n",
       " \n",
       "        [[ 58,  43,  64],\n",
       "         [ 57,  42,  63],\n",
       "         [ 57,  41,  65],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]],\n",
       " \n",
       "        [[ 58,  43,  64],\n",
       "         [ 58,  43,  64],\n",
       "         [ 57,  41,  65],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6729999988456257, 'inference': 23.47810000355821, 'postprocess': 1.647700002649799},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 51,  25,  52],\n",
       "         [ 50,  24,  51],\n",
       "         [ 51,  25,  52],\n",
       "         ...,\n",
       "         [111,  64,  79],\n",
       "         [108,  64,  78],\n",
       "         [107,  63,  77]],\n",
       " \n",
       "        [[ 50,  24,  51],\n",
       "         [ 48,  22,  49],\n",
       "         [ 50,  24,  51],\n",
       "         ...,\n",
       "         [110,  63,  78],\n",
       "         [108,  64,  78],\n",
       "         [107,  63,  77]],\n",
       " \n",
       "        [[ 48,  23,  55],\n",
       "         [ 48,  23,  55],\n",
       "         [ 48,  23,  55],\n",
       "         ...,\n",
       "         [109,  62,  77],\n",
       "         [109,  65,  79],\n",
       "         [109,  65,  79]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         ...,\n",
       "         [154, 141, 212],\n",
       "         [154, 141, 212],\n",
       "         [154, 141, 212]],\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         ...,\n",
       "         [153, 140, 211],\n",
       "         [154, 141, 212],\n",
       "         [154, 141, 212]],\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         ...,\n",
       "         [152, 139, 210],\n",
       "         [154, 141, 212],\n",
       "         [154, 141, 212]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6883999996935017, 'inference': 22.045999998226762, 'postprocess': 1.3480999987223186},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 51,  25,  54],\n",
       "         [ 50,  24,  53],\n",
       "         [ 52,  26,  55],\n",
       "         ...,\n",
       "         [111,  64,  79],\n",
       "         [108,  64,  78],\n",
       "         [107,  63,  77]],\n",
       " \n",
       "        [[ 50,  24,  53],\n",
       "         [ 50,  24,  53],\n",
       "         [ 50,  24,  53],\n",
       "         ...,\n",
       "         [110,  63,  78],\n",
       "         [108,  64,  78],\n",
       "         [107,  63,  77]],\n",
       " \n",
       "        [[ 48,  23,  55],\n",
       "         [ 48,  23,  55],\n",
       "         [ 46,  21,  53],\n",
       "         ...,\n",
       "         [109,  62,  77],\n",
       "         [108,  64,  78],\n",
       "         [108,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 60,  43,  69],\n",
       "         [ 60,  43,  69],\n",
       "         [ 60,  43,  69],\n",
       "         ...,\n",
       "         [155, 142, 213],\n",
       "         [155, 142, 213],\n",
       "         [155, 142, 213]],\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         ...,\n",
       "         [154, 141, 212],\n",
       "         [154, 141, 212],\n",
       "         [154, 141, 212]],\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         ...,\n",
       "         [154, 141, 212],\n",
       "         [154, 141, 212],\n",
       "         [154, 141, 212]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1593000055872835, 'inference': 26.373900000180583, 'postprocess': 1.3405999998212792},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 55,  29,  70],\n",
       "         [ 54,  28,  69],\n",
       "         [ 53,  27,  68],\n",
       "         ...,\n",
       "         [113,  71,  85],\n",
       "         [115,  72,  84],\n",
       "         [115,  72,  84]],\n",
       " \n",
       "        [[ 60,  34,  75],\n",
       "         [ 58,  32,  73],\n",
       "         [ 58,  32,  73],\n",
       "         ...,\n",
       "         [114,  72,  86],\n",
       "         [115,  72,  84],\n",
       "         [116,  73,  85]],\n",
       " \n",
       "        [[ 62,  38,  81],\n",
       "         [ 63,  39,  82],\n",
       "         [ 63,  39,  82],\n",
       "         ...,\n",
       "         [115,  71,  85],\n",
       "         [114,  70,  84],\n",
       "         [115,  71,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         ...,\n",
       "         [156, 143, 214],\n",
       "         [155, 142, 213],\n",
       "         [154, 141, 212]],\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         ...,\n",
       "         [154, 141, 212],\n",
       "         [153, 140, 211],\n",
       "         [152, 139, 210]],\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         ...,\n",
       "         [154, 141, 212],\n",
       "         [153, 140, 211],\n",
       "         [152, 139, 210]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6144000037456863, 'inference': 30.55049999966286, 'postprocess': 1.7005000045173801},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 53,  28,  66],\n",
       "         [ 54,  29,  67],\n",
       "         [ 53,  28,  66],\n",
       "         ...,\n",
       "         [113,  71,  85],\n",
       "         [115,  72,  84],\n",
       "         [115,  72,  84]],\n",
       " \n",
       "        [[ 58,  33,  71],\n",
       "         [ 57,  32,  70],\n",
       "         [ 57,  32,  70],\n",
       "         ...,\n",
       "         [114,  72,  86],\n",
       "         [115,  72,  84],\n",
       "         [116,  73,  85]],\n",
       " \n",
       "        [[ 62,  38,  81],\n",
       "         [ 62,  38,  81],\n",
       "         [ 63,  39,  82],\n",
       "         ...,\n",
       "         [115,  71,  85],\n",
       "         [114,  70,  84],\n",
       "         [115,  71,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214],\n",
       "         [155, 142, 213]],\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214],\n",
       "         [155, 142, 213]],\n",
       " \n",
       "        [[ 61,  44,  70],\n",
       "         [ 61,  44,  70],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [157, 144, 215],\n",
       "         [156, 143, 214],\n",
       "         [155, 142, 213]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.901100000599399, 'inference': 25.682100000267383, 'postprocess': 0.9340000033262186},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 77,  56, 103],\n",
       "         [ 79,  58, 105],\n",
       "         [ 82,  61, 108],\n",
       "         ...,\n",
       "         [112,  70,  84],\n",
       "         [113,  72,  84],\n",
       "         [112,  71,  83]],\n",
       " \n",
       "        [[ 83,  62, 109],\n",
       "         [ 85,  64, 111],\n",
       "         [ 89,  68, 115],\n",
       "         ...,\n",
       "         [114,  72,  86],\n",
       "         [115,  74,  86],\n",
       "         [115,  74,  86]],\n",
       " \n",
       "        [[ 85,  65, 114],\n",
       "         [ 89,  69, 118],\n",
       "         [ 89,  71, 122],\n",
       "         ...,\n",
       "         [118,  76,  90],\n",
       "         [117,  75,  89],\n",
       "         [117,  75,  89]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [159, 145, 214],\n",
       "         [158, 144, 213],\n",
       "         [158, 144, 213]],\n",
       " \n",
       "        [[ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [158, 144, 213],\n",
       "         [158, 144, 213],\n",
       "         [157, 143, 212]],\n",
       " \n",
       "        [[ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [158, 144, 213],\n",
       "         [157, 143, 212],\n",
       "         [157, 143, 212]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.433299996482674, 'inference': 25.70230000128504, 'postprocess': 1.2572000050568022},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 81,  57, 105],\n",
       "         [ 84,  60, 108],\n",
       "         [ 86,  61, 111],\n",
       "         ...,\n",
       "         [112,  70,  84],\n",
       "         [112,  71,  83],\n",
       "         [111,  70,  82]],\n",
       " \n",
       "        [[ 86,  62, 110],\n",
       "         [ 89,  65, 113],\n",
       "         [ 92,  67, 117],\n",
       "         ...,\n",
       "         [114,  72,  86],\n",
       "         [114,  73,  85],\n",
       "         [114,  73,  85]],\n",
       " \n",
       "        [[ 90,  67, 119],\n",
       "         [ 93,  70, 122],\n",
       "         [ 95,  74, 126],\n",
       "         ...,\n",
       "         [118,  76,  90],\n",
       "         [118,  76,  90],\n",
       "         [117,  75,  89]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [157, 142, 213],\n",
       "         [156, 144, 213],\n",
       "         [156, 144, 213]],\n",
       " \n",
       "        [[ 64,  47,  73],\n",
       "         [ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [158, 143, 214],\n",
       "         [156, 144, 213],\n",
       "         [157, 145, 214]],\n",
       " \n",
       "        [[ 64,  47,  73],\n",
       "         [ 64,  47,  73],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [158, 143, 214],\n",
       "         [157, 145, 214],\n",
       "         [157, 145, 214]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5941999954520725, 'inference': 24.170099997718353, 'postprocess': 1.7961999983526766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105,  82, 141],\n",
       "         [107,  84, 143],\n",
       "         [109,  87, 150],\n",
       "         ...,\n",
       "         [111,  74,  87],\n",
       "         [113,  77,  88],\n",
       "         [113,  77,  88]],\n",
       " \n",
       "        [[107,  84, 143],\n",
       "         [111,  88, 147],\n",
       "         [112,  90, 153],\n",
       "         ...,\n",
       "         [111,  74,  87],\n",
       "         [113,  77,  88],\n",
       "         [113,  77,  88]],\n",
       " \n",
       "        [[107,  85, 148],\n",
       "         [110,  88, 151],\n",
       "         [112,  93, 156],\n",
       "         ...,\n",
       "         [113,  76,  89],\n",
       "         [111,  74,  87],\n",
       "         [113,  76,  89]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  44,  72],\n",
       "         [ 63,  46,  74],\n",
       "         [ 63,  46,  74],\n",
       "         ...,\n",
       "         [155, 141, 210],\n",
       "         [155, 141, 210],\n",
       "         [156, 142, 211]],\n",
       " \n",
       "        [[ 60,  43,  71],\n",
       "         [ 61,  44,  72],\n",
       "         [ 61,  44,  72],\n",
       "         ...,\n",
       "         [157, 142, 208],\n",
       "         [155, 141, 210],\n",
       "         [156, 142, 211]],\n",
       " \n",
       "        [[ 60,  43,  71],\n",
       "         [ 61,  44,  72],\n",
       "         [ 61,  44,  72],\n",
       "         ...,\n",
       "         [157, 142, 208],\n",
       "         [155, 141, 210],\n",
       "         [156, 142, 211]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6430000032414682, 'inference': 25.396899996849243, 'postprocess': 2.674700001080055},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[108,  88, 146],\n",
       "         [110,  90, 148],\n",
       "         [109,  91, 151],\n",
       "         ...,\n",
       "         [110,  73,  86],\n",
       "         [111,  75,  86],\n",
       "         [111,  75,  86]],\n",
       " \n",
       "        [[109,  89, 147],\n",
       "         [112,  92, 150],\n",
       "         [112,  94, 154],\n",
       "         ...,\n",
       "         [110,  73,  86],\n",
       "         [110,  74,  85],\n",
       "         [111,  75,  86]],\n",
       " \n",
       "        [[112,  90, 153],\n",
       "         [116,  94, 157],\n",
       "         [115,  96, 159],\n",
       "         ...,\n",
       "         [113,  76,  89],\n",
       "         [111,  74,  87],\n",
       "         [110,  73,  86]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 64,  47,  73],\n",
       "         [ 64,  47,  73],\n",
       "         [ 64,  47,  73],\n",
       "         ...,\n",
       "         [155, 141, 210],\n",
       "         [155, 141, 210],\n",
       "         [156, 142, 211]],\n",
       " \n",
       "        [[ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [155, 141, 210],\n",
       "         [155, 141, 210],\n",
       "         [156, 142, 211]],\n",
       " \n",
       "        [[ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         [ 63,  46,  72],\n",
       "         ...,\n",
       "         [155, 141, 210],\n",
       "         [155, 141, 210],\n",
       "         [156, 142, 211]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2233999950694852, 'inference': 21.881199994822964, 'postprocess': 0.9274999974877574},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[116,  98, 165],\n",
       "         [118, 100, 167],\n",
       "         [119, 100, 170],\n",
       "         ...,\n",
       "         [ 99,  62,  75],\n",
       "         [ 95,  59,  70],\n",
       "         [ 95,  59,  70]],\n",
       " \n",
       "        [[117,  99, 166],\n",
       "         [118, 100, 167],\n",
       "         [119, 100, 170],\n",
       "         ...,\n",
       "         [ 97,  60,  73],\n",
       "         [ 94,  58,  69],\n",
       "         [ 94,  58,  69]],\n",
       " \n",
       "        [[118, 100, 167],\n",
       "         [119, 101, 168],\n",
       "         [120, 101, 171],\n",
       "         ...,\n",
       "         [ 96,  59,  72],\n",
       "         [ 94,  58,  69],\n",
       "         [ 94,  58,  69]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  42,  70],\n",
       "         [ 60,  43,  71],\n",
       "         [ 60,  43,  71],\n",
       "         ...,\n",
       "         [158, 139, 209],\n",
       "         [158, 139, 209],\n",
       "         [158, 139, 209]],\n",
       " \n",
       "        [[ 59,  42,  70],\n",
       "         [ 60,  43,  71],\n",
       "         [ 60,  43,  71],\n",
       "         ...,\n",
       "         [158, 139, 209],\n",
       "         [156, 137, 207],\n",
       "         [158, 139, 209]],\n",
       " \n",
       "        [[ 58,  41,  69],\n",
       "         [ 59,  42,  70],\n",
       "         [ 59,  42,  70],\n",
       "         ...,\n",
       "         [160, 141, 211],\n",
       "         [160, 141, 211],\n",
       "         [161, 142, 212]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.751699994201772, 'inference': 27.685299995937385, 'postprocess': 1.9696000017574988},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[118,  99, 169],\n",
       "         [119, 100, 170],\n",
       "         [119, 100, 170],\n",
       "         ...,\n",
       "         [106,  69,  82],\n",
       "         [100,  64,  75],\n",
       "         [ 96,  60,  71]],\n",
       " \n",
       "        [[119, 100, 170],\n",
       "         [119, 100, 170],\n",
       "         [119, 100, 170],\n",
       "         ...,\n",
       "         [102,  65,  78],\n",
       "         [ 97,  61,  72],\n",
       "         [ 94,  58,  69]],\n",
       " \n",
       "        [[120, 101, 171],\n",
       "         [120, 101, 171],\n",
       "         [120, 101, 171],\n",
       "         ...,\n",
       "         [102,  65,  78],\n",
       "         [ 99,  63,  74],\n",
       "         [ 96,  60,  71]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  46,  74],\n",
       "         [ 61,  44,  72],\n",
       "         [ 63,  46,  74],\n",
       "         ...,\n",
       "         [156, 140, 209],\n",
       "         [156, 141, 207],\n",
       "         [154, 139, 205]],\n",
       " \n",
       "        [[ 61,  44,  72],\n",
       "         [ 61,  44,  72],\n",
       "         [ 63,  46,  74],\n",
       "         ...,\n",
       "         [158, 139, 209],\n",
       "         [156, 138, 205],\n",
       "         [156, 138, 205]],\n",
       " \n",
       "        [[ 60,  43,  71],\n",
       "         [ 61,  44,  72],\n",
       "         [ 61,  44,  72],\n",
       "         ...,\n",
       "         [156, 137, 207],\n",
       "         [156, 138, 205],\n",
       "         [156, 138, 205]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.434599999105558, 'inference': 28.098399998270907, 'postprocess': 1.0994999975082465},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[117, 101, 170],\n",
       "         [118, 102, 171],\n",
       "         [117, 101, 170],\n",
       "         ...,\n",
       "         [115,  78,  91],\n",
       "         [114,  80,  91],\n",
       "         [114,  80,  91]],\n",
       " \n",
       "        [[116, 100, 169],\n",
       "         [117, 101, 170],\n",
       "         [117, 101, 170],\n",
       "         ...,\n",
       "         [116,  79,  92],\n",
       "         [113,  79,  90],\n",
       "         [113,  79,  90]],\n",
       " \n",
       "        [[116, 101, 167],\n",
       "         [117, 102, 168],\n",
       "         [118, 102, 171],\n",
       "         ...,\n",
       "         [114,  79,  92],\n",
       "         [113,  78,  91],\n",
       "         [112,  77,  90]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  39,  65],\n",
       "         [ 57,  40,  66],\n",
       "         [ 57,  40,  68],\n",
       "         ...,\n",
       "         [162, 143, 213],\n",
       "         [161, 143, 210],\n",
       "         [159, 141, 208]],\n",
       " \n",
       "        [[ 56,  39,  65],\n",
       "         [ 56,  39,  65],\n",
       "         [ 56,  39,  67],\n",
       "         ...,\n",
       "         [163, 144, 214],\n",
       "         [167, 147, 214],\n",
       "         [165, 145, 212]],\n",
       " \n",
       "        [[ 57,  40,  66],\n",
       "         [ 57,  40,  66],\n",
       "         [ 57,  40,  68],\n",
       "         ...,\n",
       "         [165, 146, 216],\n",
       "         [168, 148, 215],\n",
       "         [168, 148, 215]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6080999994301237, 'inference': 25.988300003518816, 'postprocess': 3.279099997598678},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[121, 102, 172],\n",
       "         [120, 101, 171],\n",
       "         [121, 102, 172],\n",
       "         ...,\n",
       "         [115,  78,  91],\n",
       "         [114,  80,  91],\n",
       "         [114,  80,  91]],\n",
       " \n",
       "        [[120, 101, 171],\n",
       "         [120, 101, 171],\n",
       "         [121, 102, 172],\n",
       "         ...,\n",
       "         [115,  78,  91],\n",
       "         [113,  79,  90],\n",
       "         [114,  80,  91]],\n",
       " \n",
       "        [[118, 101, 172],\n",
       "         [118, 101, 172],\n",
       "         [119, 103, 172],\n",
       "         ...,\n",
       "         [114,  79,  92],\n",
       "         [113,  78,  91],\n",
       "         [112,  77,  90]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 57,  40,  68],\n",
       "         [ 57,  40,  68],\n",
       "         [ 57,  41,  65],\n",
       "         ...,\n",
       "         [162, 143, 213],\n",
       "         [162, 144, 211],\n",
       "         [161, 143, 210]],\n",
       " \n",
       "        [[ 56,  39,  65],\n",
       "         [ 57,  40,  66],\n",
       "         [ 57,  40,  68],\n",
       "         ...,\n",
       "         [162, 143, 213],\n",
       "         [162, 144, 211],\n",
       "         [161, 143, 210]],\n",
       " \n",
       "        [[ 56,  39,  65],\n",
       "         [ 56,  39,  65],\n",
       "         [ 56,  39,  67],\n",
       "         ...,\n",
       "         [162, 143, 213],\n",
       "         [162, 144, 211],\n",
       "         [161, 143, 210]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9912000061594881, 'inference': 29.31939999689348, 'postprocess': 2.442400000290945},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[123, 100, 167],\n",
       "         [124, 101, 168],\n",
       "         [122, 103, 168],\n",
       "         ...,\n",
       "         [123,  88, 101],\n",
       "         [120,  85,  98],\n",
       "         [116,  81,  94]],\n",
       " \n",
       "        [[123, 100, 167],\n",
       "         [123, 100, 167],\n",
       "         [122, 103, 168],\n",
       "         ...,\n",
       "         [121,  86,  99],\n",
       "         [117,  82,  95],\n",
       "         [114,  79,  92]],\n",
       " \n",
       "        [[122,  99, 166],\n",
       "         [123, 100, 167],\n",
       "         [120, 101, 166],\n",
       "         ...,\n",
       "         [119,  84,  97],\n",
       "         [115,  80,  93],\n",
       "         [113,  78,  91]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 66,  49,  77],\n",
       "         [ 65,  48,  76],\n",
       "         [ 64,  47,  75],\n",
       "         ...,\n",
       "         [167, 145, 210],\n",
       "         [164, 145, 210],\n",
       "         [164, 145, 210]],\n",
       " \n",
       "        [[ 67,  50,  78],\n",
       "         [ 66,  49,  77],\n",
       "         [ 65,  48,  76],\n",
       "         ...,\n",
       "         [163, 141, 206],\n",
       "         [164, 142, 207],\n",
       "         [165, 143, 208]],\n",
       " \n",
       "        [[ 67,  50,  78],\n",
       "         [ 67,  50,  78],\n",
       "         [ 67,  50,  78],\n",
       "         ...,\n",
       "         [159, 137, 202],\n",
       "         [161, 139, 204],\n",
       "         [163, 141, 206]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.968299999134615, 'inference': 28.41630000330042, 'postprocess': 1.9298999977763742},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[124, 101, 168],\n",
       "         [125, 102, 169],\n",
       "         [123, 104, 169],\n",
       "         ...,\n",
       "         [127,  92, 105],\n",
       "         [124,  89, 102],\n",
       "         [121,  86,  99]],\n",
       " \n",
       "        [[124, 101, 168],\n",
       "         [124, 101, 168],\n",
       "         [123, 104, 169],\n",
       "         ...,\n",
       "         [124,  89, 102],\n",
       "         [123,  88, 101],\n",
       "         [119,  84,  97]],\n",
       " \n",
       "        [[123, 100, 167],\n",
       "         [123, 100, 167],\n",
       "         [121, 102, 167],\n",
       "         ...,\n",
       "         [123,  88, 101],\n",
       "         [121,  86,  99],\n",
       "         [117,  82,  95]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  46,  74],\n",
       "         [ 60,  43,  71],\n",
       "         [ 59,  42,  70],\n",
       "         ...,\n",
       "         [164, 144, 211],\n",
       "         [162, 144, 211],\n",
       "         [163, 145, 212]],\n",
       " \n",
       "        [[ 63,  46,  74],\n",
       "         [ 63,  46,  74],\n",
       "         [ 63,  46,  74],\n",
       "         ...,\n",
       "         [167, 147, 214],\n",
       "         [167, 147, 214],\n",
       "         [168, 148, 215]],\n",
       " \n",
       "        [[ 66,  49,  77],\n",
       "         [ 65,  48,  76],\n",
       "         [ 64,  47,  75],\n",
       "         ...,\n",
       "         [162, 142, 209],\n",
       "         [163, 143, 210],\n",
       "         [164, 144, 211]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5273999961209483, 'inference': 21.799900001497008, 'postprocess': 1.7411000007996336},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[123, 101, 166],\n",
       "         [123, 101, 166],\n",
       "         [121, 102, 167],\n",
       "         ...,\n",
       "         [113,  77,  93],\n",
       "         [114,  76,  92],\n",
       "         [110,  72,  88]],\n",
       " \n",
       "        [[124, 102, 167],\n",
       "         [124, 102, 167],\n",
       "         [122, 103, 168],\n",
       "         ...,\n",
       "         [112,  76,  92],\n",
       "         [113,  75,  91],\n",
       "         [110,  72,  88]],\n",
       " \n",
       "        [[126, 101, 165],\n",
       "         [127, 102, 166],\n",
       "         [130, 105, 171],\n",
       "         ...,\n",
       "         [110,  77,  92],\n",
       "         [109,  76,  91],\n",
       "         [106,  73,  88]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         ...,\n",
       "         [133, 108, 174],\n",
       "         [139, 114, 180],\n",
       "         [145, 120, 186]],\n",
       " \n",
       "        [[ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         ...,\n",
       "         [121,  96, 160],\n",
       "         [127, 102, 166],\n",
       "         [133, 108, 172]],\n",
       " \n",
       "        [[ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         ...,\n",
       "         [109,  84, 148],\n",
       "         [114,  89, 153],\n",
       "         [120,  95, 159]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.9426999972201884, 'inference': 26.55929999309592, 'postprocess': 1.0670999981812201},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[124, 101, 168],\n",
       "         [124, 101, 168],\n",
       "         [123, 104, 169],\n",
       "         ...,\n",
       "         [118,  80,  96],\n",
       "         [119,  80,  93],\n",
       "         [116,  77,  90]],\n",
       " \n",
       "        [[125, 102, 169],\n",
       "         [126, 103, 170],\n",
       "         [125, 106, 171],\n",
       "         ...,\n",
       "         [116,  78,  94],\n",
       "         [117,  78,  91],\n",
       "         [113,  74,  87]],\n",
       " \n",
       "        [[128, 103, 169],\n",
       "         [130, 105, 171],\n",
       "         [133, 108, 174],\n",
       "         ...,\n",
       "         [114,  78,  94],\n",
       "         [115,  78,  91],\n",
       "         [113,  76,  89]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  51,  79],\n",
       "         [ 67,  50,  78],\n",
       "         [ 67,  50,  78],\n",
       "         ...,\n",
       "         [141, 122, 187],\n",
       "         [149, 127, 192],\n",
       "         [152, 130, 195]],\n",
       " \n",
       "        [[ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         ...,\n",
       "         [131, 109, 174],\n",
       "         [137, 115, 180],\n",
       "         [143, 121, 186]],\n",
       " \n",
       "        [[ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         ...,\n",
       "         [119,  97, 162],\n",
       "         [126, 104, 169],\n",
       "         [131, 109, 174]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.520500001788605, 'inference': 24.48990000266349, 'postprocess': 0.9957000002032146},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  74, 137],\n",
       "         [ 97,  75, 138],\n",
       "         [100,  79, 139],\n",
       "         ...,\n",
       "         [109,  74,  87],\n",
       "         [113,  78,  91],\n",
       "         [116,  81,  94]],\n",
       " \n",
       "        [[ 90,  68, 131],\n",
       "         [ 93,  71, 134],\n",
       "         [ 94,  73, 133],\n",
       "         ...,\n",
       "         [112,  77,  90],\n",
       "         [115,  80,  93],\n",
       "         [119,  84,  97]],\n",
       " \n",
       "        [[ 87,  62, 126],\n",
       "         [ 89,  64, 128],\n",
       "         [ 89,  65, 126],\n",
       "         ...,\n",
       "         [114,  79,  92],\n",
       "         [119,  84,  97],\n",
       "         [121,  86,  99]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 66,  49,  77],\n",
       "         [ 66,  49,  77],\n",
       "         [ 66,  49,  77],\n",
       "         ...,\n",
       "         [ 81,  56, 120],\n",
       "         [ 84,  60, 121],\n",
       "         [ 90,  66, 127]],\n",
       " \n",
       "        [[ 65,  48,  76],\n",
       "         [ 65,  48,  76],\n",
       "         [ 64,  47,  75],\n",
       "         ...,\n",
       "         [ 80,  56, 117],\n",
       "         [ 86,  60, 121],\n",
       "         [ 92,  66, 127]],\n",
       " \n",
       "        [[ 65,  48,  76],\n",
       "         [ 64,  47,  75],\n",
       "         [ 63,  46,  74],\n",
       "         ...,\n",
       "         [ 81,  57, 118],\n",
       "         [ 89,  63, 124],\n",
       "         [ 94,  68, 129]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.504600000975188, 'inference': 32.96090000367258, 'postprocess': 2.0326000012573786},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[101,  79, 142],\n",
       "         [102,  80, 143],\n",
       "         [104,  83, 143],\n",
       "         ...,\n",
       "         [106,  71,  84],\n",
       "         [109,  74,  87],\n",
       "         [113,  78,  91]],\n",
       " \n",
       "        [[ 93,  71, 134],\n",
       "         [ 95,  73, 136],\n",
       "         [ 96,  75, 135],\n",
       "         ...,\n",
       "         [107,  72,  85],\n",
       "         [111,  76,  89],\n",
       "         [114,  79,  92]],\n",
       " \n",
       "        [[ 88,  63, 127],\n",
       "         [ 90,  65, 129],\n",
       "         [ 90,  66, 127],\n",
       "         ...,\n",
       "         [111,  76,  89],\n",
       "         [114,  79,  92],\n",
       "         [117,  82,  95]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         [ 68,  51,  79],\n",
       "         ...,\n",
       "         [ 89,  67, 132],\n",
       "         [ 91,  69, 134],\n",
       "         [ 97,  75, 140]],\n",
       " \n",
       "        [[ 67,  50,  78],\n",
       "         [ 67,  50,  78],\n",
       "         [ 67,  50,  78],\n",
       "         ...,\n",
       "         [ 82,  57, 121],\n",
       "         [ 84,  59, 123],\n",
       "         [ 90,  65, 129]],\n",
       " \n",
       "        [[ 66,  49,  77],\n",
       "         [ 66,  49,  77],\n",
       "         [ 65,  48,  76],\n",
       "         ...,\n",
       "         [ 74,  49, 113],\n",
       "         [ 76,  51, 115],\n",
       "         [ 81,  56, 120]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.067599998554215, 'inference': 21.359800004574936, 'postprocess': 4.436699993675575},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  73, 132],\n",
       "         [ 91,  68, 127],\n",
       "         [ 86,  65, 125],\n",
       "         ...,\n",
       "         [119,  86, 101],\n",
       "         [116,  85, 100],\n",
       "         [117,  86, 101]],\n",
       " \n",
       "        [[ 90,  67, 126],\n",
       "         [ 85,  62, 121],\n",
       "         [ 80,  59, 119],\n",
       "         ...,\n",
       "         [119,  86, 101],\n",
       "         [117,  86, 101],\n",
       "         [115,  84,  99]],\n",
       " \n",
       "        [[ 80,  57, 116],\n",
       "         [ 78,  55, 114],\n",
       "         [ 72,  52, 110],\n",
       "         ...,\n",
       "         [116,  85, 100],\n",
       "         [117,  84,  99],\n",
       "         [115,  82,  97]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  44,  71],\n",
       "         [ 58,  44,  71],\n",
       "         [ 57,  43,  70],\n",
       "         ...,\n",
       "         [ 75,  50, 114],\n",
       "         [ 75,  50, 114],\n",
       "         [ 75,  50, 114]],\n",
       " \n",
       "        [[ 55,  43,  68],\n",
       "         [ 55,  43,  68],\n",
       "         [ 55,  43,  68],\n",
       "         ...,\n",
       "         [ 77,  53, 114],\n",
       "         [ 76,  53, 112],\n",
       "         [ 76,  53, 112]],\n",
       " \n",
       "        [[ 56,  44,  69],\n",
       "         [ 56,  44,  69],\n",
       "         [ 56,  44,  69],\n",
       "         ...,\n",
       "         [ 77,  53, 114],\n",
       "         [ 76,  53, 112],\n",
       "         [ 76,  53, 112]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8654000014066696, 'inference': 21.461300006194506, 'postprocess': 1.7772999999579042},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  69, 127],\n",
       "         [ 85,  65, 123],\n",
       "         [ 82,  61, 121],\n",
       "         ...,\n",
       "         [120,  87, 102],\n",
       "         [117,  86, 101],\n",
       "         [116,  85, 100]],\n",
       " \n",
       "        [[ 83,  63, 121],\n",
       "         [ 80,  60, 118],\n",
       "         [ 78,  57, 117],\n",
       "         ...,\n",
       "         [120,  87, 102],\n",
       "         [117,  86, 101],\n",
       "         [116,  85, 100]],\n",
       " \n",
       "        [[ 74,  54, 112],\n",
       "         [ 73,  53, 111],\n",
       "         [ 69,  49, 107],\n",
       "         ...,\n",
       "         [120,  87, 102],\n",
       "         [117,  86, 101],\n",
       "         [116,  85, 100]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 57,  43,  70],\n",
       "         [ 57,  43,  70],\n",
       "         [ 57,  43,  70],\n",
       "         ...,\n",
       "         [ 71,  49, 112],\n",
       "         [ 71,  49, 114],\n",
       "         [ 71,  49, 114]],\n",
       " \n",
       "        [[ 58,  44,  71],\n",
       "         [ 58,  44,  71],\n",
       "         [ 57,  43,  70],\n",
       "         ...,\n",
       "         [ 75,  50, 114],\n",
       "         [ 74,  49, 113],\n",
       "         [ 74,  49, 113]],\n",
       " \n",
       "        [[ 57,  43,  70],\n",
       "         [ 57,  43,  70],\n",
       "         [ 57,  43,  70],\n",
       "         ...,\n",
       "         [ 77,  52, 116],\n",
       "         [ 75,  50, 114],\n",
       "         [ 74,  49, 113]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.003000001423061, 'inference': 25.785599995288067, 'postprocess': 2.112699999997858},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 81,  57, 118],\n",
       "         [ 83,  59, 120],\n",
       "         [ 87,  63, 124],\n",
       "         ...,\n",
       "         [111,  80,  95],\n",
       "         [112,  79,  94],\n",
       "         [112,  79,  94]],\n",
       " \n",
       "        [[ 88,  64, 125],\n",
       "         [ 89,  65, 126],\n",
       "         [ 92,  68, 129],\n",
       "         ...,\n",
       "         [110,  79,  94],\n",
       "         [111,  78,  93],\n",
       "         [111,  78,  93]],\n",
       " \n",
       "        [[ 94,  73, 133],\n",
       "         [ 96,  75, 135],\n",
       "         [ 98,  77, 137],\n",
       "         ...,\n",
       "         [109,  78,  93],\n",
       "         [111,  78,  93],\n",
       "         [111,  78,  93]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  51,  76],\n",
       "         [ 62,  50,  75],\n",
       "         [ 61,  49,  74],\n",
       "         ...,\n",
       "         [ 78,  54, 115],\n",
       "         [ 78,  54, 115],\n",
       "         [ 78,  54, 115]],\n",
       " \n",
       "        [[ 63,  51,  76],\n",
       "         [ 63,  51,  76],\n",
       "         [ 62,  50,  75],\n",
       "         ...,\n",
       "         [ 78,  54, 115],\n",
       "         [ 78,  54, 115],\n",
       "         [ 78,  54, 115]],\n",
       " \n",
       "        [[ 63,  51,  76],\n",
       "         [ 63,  51,  76],\n",
       "         [ 62,  50,  75],\n",
       "         ...,\n",
       "         [ 77,  53, 114],\n",
       "         [ 77,  53, 114],\n",
       "         [ 77,  53, 114]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6038000030675903, 'inference': 26.04970000538742, 'postprocess': 0.8911000040825456},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84,  60, 121],\n",
       "         [ 85,  61, 122],\n",
       "         [ 89,  65, 126],\n",
       "         ...,\n",
       "         [111,  80,  95],\n",
       "         [112,  79,  94],\n",
       "         [112,  79,  94]],\n",
       " \n",
       "        [[ 91,  67, 128],\n",
       "         [ 92,  68, 129],\n",
       "         [ 95,  71, 132],\n",
       "         ...,\n",
       "         [110,  79,  94],\n",
       "         [111,  78,  93],\n",
       "         [111,  78,  93]],\n",
       " \n",
       "        [[ 95,  74, 134],\n",
       "         [ 97,  76, 136],\n",
       "         [ 98,  77, 137],\n",
       "         ...,\n",
       "         [109,  78,  93],\n",
       "         [111,  78,  93],\n",
       "         [111,  78,  93]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 60,  48,  73],\n",
       "         [ 61,  49,  74],\n",
       "         [ 60,  48,  73],\n",
       "         ...,\n",
       "         [ 78,  53, 117],\n",
       "         [ 78,  53, 117],\n",
       "         [ 78,  53, 117]],\n",
       " \n",
       "        [[ 62,  50,  75],\n",
       "         [ 61,  49,  74],\n",
       "         [ 60,  48,  73],\n",
       "         ...,\n",
       "         [ 78,  53, 117],\n",
       "         [ 78,  53, 117],\n",
       "         [ 78,  53, 117]],\n",
       " \n",
       "        [[ 62,  50,  75],\n",
       "         [ 61,  49,  74],\n",
       "         [ 61,  49,  74],\n",
       "         ...,\n",
       "         [ 78,  53, 117],\n",
       "         [ 78,  53, 117],\n",
       "         [ 78,  53, 117]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5596000012010336, 'inference': 21.193200002016965, 'postprocess': 0.9986000004573725},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[129, 109, 167],\n",
       "         [129, 109, 167],\n",
       "         [132, 111, 171],\n",
       "         ...,\n",
       "         [112,  81,  96],\n",
       "         [112,  79,  94],\n",
       "         [110,  77,  92]],\n",
       " \n",
       "        [[129, 109, 167],\n",
       "         [131, 111, 169],\n",
       "         [132, 111, 171],\n",
       "         ...,\n",
       "         [112,  81,  96],\n",
       "         [111,  78,  93],\n",
       "         [109,  76,  91]],\n",
       " \n",
       "        [[126, 108, 168],\n",
       "         [128, 110, 170],\n",
       "         [132, 113, 176],\n",
       "         ...,\n",
       "         [110,  79,  94],\n",
       "         [110,  77,  92],\n",
       "         [107,  74,  89]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  49,  75],\n",
       "         [ 57,  48,  74],\n",
       "         [ 57,  45,  72],\n",
       "         ...,\n",
       "         [ 77,  52, 116],\n",
       "         [ 77,  52, 116],\n",
       "         [ 77,  52, 116]],\n",
       " \n",
       "        [[ 57,  45,  72],\n",
       "         [ 59,  47,  74],\n",
       "         [ 57,  45,  72],\n",
       "         ...,\n",
       "         [ 78,  53, 117],\n",
       "         [ 78,  53, 117],\n",
       "         [ 78,  53, 117]],\n",
       " \n",
       "        [[ 57,  45,  72],\n",
       "         [ 57,  45,  72],\n",
       "         [ 57,  45,  72],\n",
       "         ...,\n",
       "         [ 84,  59, 123],\n",
       "         [ 83,  58, 122],\n",
       "         [ 83,  58, 122]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5419000046676956, 'inference': 25.216900001396425, 'postprocess': 1.7915999997057952},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[125, 106, 171],\n",
       "         [127, 108, 173],\n",
       "         [130, 111, 176],\n",
       "         ...,\n",
       "         [116,  85, 100],\n",
       "         [115,  82,  97],\n",
       "         [113,  80,  95]],\n",
       " \n",
       "        [[128, 109, 174],\n",
       "         [130, 111, 176],\n",
       "         [133, 114, 179],\n",
       "         ...,\n",
       "         [115,  84,  99],\n",
       "         [114,  81,  96],\n",
       "         [112,  79,  94]],\n",
       " \n",
       "        [[127, 110, 173],\n",
       "         [131, 114, 177],\n",
       "         [133, 116, 181],\n",
       "         ...,\n",
       "         [112,  81,  96],\n",
       "         [112,  79,  94],\n",
       "         [110,  77,  92]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  49,  73],\n",
       "         [ 57,  48,  72],\n",
       "         [ 57,  45,  70],\n",
       "         ...,\n",
       "         [ 71,  46, 110],\n",
       "         [ 74,  49, 113],\n",
       "         [ 75,  50, 114]],\n",
       " \n",
       "        [[ 59,  47,  72],\n",
       "         [ 59,  47,  72],\n",
       "         [ 57,  45,  70],\n",
       "         ...,\n",
       "         [ 74,  49, 113],\n",
       "         [ 75,  50, 114],\n",
       "         [ 76,  51, 115]],\n",
       " \n",
       "        [[ 57,  45,  70],\n",
       "         [ 57,  45,  70],\n",
       "         [ 57,  45,  70],\n",
       "         ...,\n",
       "         [ 77,  52, 116],\n",
       "         [ 77,  52, 116],\n",
       "         [ 78,  53, 117]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5448999984073453, 'inference': 20.79329999833135, 'postprocess': 1.3063000005786307},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 102, 162],\n",
       "         [125, 107, 167],\n",
       "         [129, 111, 171],\n",
       "         ...,\n",
       "         [101,  73,  87],\n",
       "         [101,  73,  87],\n",
       "         [101,  73,  87]],\n",
       " \n",
       "        [[119, 101, 161],\n",
       "         [123, 105, 165],\n",
       "         [129, 111, 171],\n",
       "         ...,\n",
       "         [101,  73,  87],\n",
       "         [ 99,  71,  85],\n",
       "         [100,  72,  86]],\n",
       " \n",
       "        [[118, 100, 160],\n",
       "         [123, 105, 165],\n",
       "         [128, 110, 170],\n",
       "         ...,\n",
       "         [100,  72,  86],\n",
       "         [ 99,  71,  85],\n",
       "         [100,  72,  86]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 60,  48,  75],\n",
       "         [ 60,  48,  75],\n",
       "         [ 60,  48,  75],\n",
       "         ...,\n",
       "         [120,  95, 161],\n",
       "         [106,  80, 148],\n",
       "         [103,  77, 145]],\n",
       " \n",
       "        [[ 61,  49,  76],\n",
       "         [ 61,  49,  76],\n",
       "         [ 61,  49,  76],\n",
       "         ...,\n",
       "         [124,  99, 165],\n",
       "         [110,  84, 152],\n",
       "         [105,  79, 147]],\n",
       " \n",
       "        [[ 61,  49,  76],\n",
       "         [ 61,  49,  76],\n",
       "         [ 61,  49,  76],\n",
       "         ...,\n",
       "         [125, 100, 166],\n",
       "         [111,  85, 153],\n",
       "         [107,  81, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4423000029637478, 'inference': 22.581600002013147, 'postprocess': 0.916600001801271},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[127, 109, 169],\n",
       "         [130, 112, 172],\n",
       "         [136, 118, 178],\n",
       "         ...,\n",
       "         [101,  73,  87],\n",
       "         [101,  73,  87],\n",
       "         [101,  73,  87]],\n",
       " \n",
       "        [[126, 108, 168],\n",
       "         [130, 112, 172],\n",
       "         [135, 117, 177],\n",
       "         ...,\n",
       "         [101,  73,  87],\n",
       "         [100,  72,  86],\n",
       "         [100,  72,  86]],\n",
       " \n",
       "        [[126, 108, 168],\n",
       "         [129, 111, 171],\n",
       "         [135, 117, 177],\n",
       "         ...,\n",
       "         [100,  72,  86],\n",
       "         [100,  72,  86],\n",
       "         [100,  72,  86]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 60,  48,  75],\n",
       "         [ 60,  48,  75],\n",
       "         [ 60,  48,  75],\n",
       "         ...,\n",
       "         [141, 115, 183],\n",
       "         [124,  99, 165],\n",
       "         [106,  81, 147]],\n",
       " \n",
       "        [[ 61,  49,  76],\n",
       "         [ 61,  49,  76],\n",
       "         [ 61,  49,  76],\n",
       "         ...,\n",
       "         [142, 116, 184],\n",
       "         [126, 101, 167],\n",
       "         [109,  84, 150]],\n",
       " \n",
       "        [[ 61,  49,  76],\n",
       "         [ 61,  49,  76],\n",
       "         [ 61,  49,  76],\n",
       "         ...,\n",
       "         [144, 118, 186],\n",
       "         [127, 102, 168],\n",
       "         [109,  84, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6641999973217025, 'inference': 20.903099997667596, 'postprocess': 1.0401999970781617},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[102,  80, 145],\n",
       "         [108,  86, 151],\n",
       "         [109,  90, 155],\n",
       "         ...,\n",
       "         [ 99,  73,  87],\n",
       "         [ 99,  73,  87],\n",
       "         [ 99,  73,  87]],\n",
       " \n",
       "        [[101,  79, 144],\n",
       "         [105,  83, 148],\n",
       "         [108,  89, 154],\n",
       "         ...,\n",
       "         [ 99,  73,  87],\n",
       "         [ 98,  72,  86],\n",
       "         [ 98,  72,  86]],\n",
       " \n",
       "        [[ 98,  76, 139],\n",
       "         [102,  80, 143],\n",
       "         [106,  86, 153],\n",
       "         ...,\n",
       "         [ 98,  72,  86],\n",
       "         [ 98,  72,  86],\n",
       "         [ 98,  72,  86]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 64,  52,  79],\n",
       "         [ 63,  51,  78],\n",
       "         [ 63,  51,  78],\n",
       "         ...,\n",
       "         [161, 137, 207],\n",
       "         [163, 139, 209],\n",
       "         [165, 141, 211]],\n",
       " \n",
       "        [[ 64,  52,  79],\n",
       "         [ 64,  52,  79],\n",
       "         [ 63,  51,  78],\n",
       "         ...,\n",
       "         [160, 136, 206],\n",
       "         [163, 139, 209],\n",
       "         [166, 142, 212]],\n",
       " \n",
       "        [[ 64,  52,  79],\n",
       "         [ 66,  54,  81],\n",
       "         [ 63,  51,  78],\n",
       "         ...,\n",
       "         [161, 137, 207],\n",
       "         [163, 139, 209],\n",
       "         [165, 141, 211]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0950999969500117, 'inference': 21.205799996096175, 'postprocess': 1.325000004726462},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105,  88, 153],\n",
       "         [110,  93, 158],\n",
       "         [113,  95, 162],\n",
       "         ...,\n",
       "         [ 99,  73,  87],\n",
       "         [ 99,  73,  87],\n",
       "         [ 99,  73,  87]],\n",
       " \n",
       "        [[103,  86, 151],\n",
       "         [109,  92, 157],\n",
       "         [112,  94, 161],\n",
       "         ...,\n",
       "         [ 99,  73,  87],\n",
       "         [ 98,  72,  86],\n",
       "         [ 98,  72,  86]],\n",
       " \n",
       "        [[100,  83, 148],\n",
       "         [105,  88, 153],\n",
       "         [109,  91, 158],\n",
       "         ...,\n",
       "         [ 98,  72,  86],\n",
       "         [ 98,  72,  86],\n",
       "         [ 98,  72,  86]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  51,  78],\n",
       "         [ 62,  50,  77],\n",
       "         [ 62,  50,  77],\n",
       "         ...,\n",
       "         [161, 137, 207],\n",
       "         [164, 140, 210],\n",
       "         [165, 141, 211]],\n",
       " \n",
       "        [[ 63,  51,  78],\n",
       "         [ 63,  51,  78],\n",
       "         [ 62,  50,  77],\n",
       "         ...,\n",
       "         [159, 135, 205],\n",
       "         [161, 137, 207],\n",
       "         [164, 140, 210]],\n",
       " \n",
       "        [[ 63,  51,  78],\n",
       "         [ 64,  52,  79],\n",
       "         [ 62,  50,  77],\n",
       "         ...,\n",
       "         [160, 136, 206],\n",
       "         [160, 136, 206],\n",
       "         [161, 137, 207]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2186000021756627, 'inference': 20.82710000104271, 'postprocess': 0.9250999937648885},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 97,  77, 149],\n",
       "         [ 98,  78, 150],\n",
       "         [100,  79, 154],\n",
       "         ...,\n",
       "         [ 96,  70,  84],\n",
       "         [ 97,  71,  85],\n",
       "         [ 97,  71,  85]],\n",
       " \n",
       "        [[ 99,  79, 151],\n",
       "         [100,  80, 152],\n",
       "         [102,  81, 156],\n",
       "         ...,\n",
       "         [ 96,  70,  84],\n",
       "         [ 97,  71,  85],\n",
       "         [ 96,  70,  84]],\n",
       " \n",
       "        [[104,  84, 156],\n",
       "         [103,  83, 155],\n",
       "         [104,  83, 158],\n",
       "         ...,\n",
       "         [ 96,  70,  84],\n",
       "         [ 97,  71,  85],\n",
       "         [ 96,  70,  84]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  50,  80],\n",
       "         [ 64,  51,  81],\n",
       "         [ 64,  51,  81],\n",
       "         ...,\n",
       "         [155, 136, 206],\n",
       "         [156, 137, 207],\n",
       "         [159, 140, 210]],\n",
       " \n",
       "        [[ 66,  53,  83],\n",
       "         [ 66,  53,  83],\n",
       "         [ 66,  53,  83],\n",
       "         ...,\n",
       "         [155, 136, 206],\n",
       "         [158, 139, 209],\n",
       "         [160, 141, 211]],\n",
       " \n",
       "        [[ 66,  53,  83],\n",
       "         [ 66,  53,  83],\n",
       "         [ 66,  53,  83],\n",
       "         ...,\n",
       "         [156, 137, 207],\n",
       "         [158, 139, 209],\n",
       "         [160, 141, 211]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.150400003301911, 'inference': 21.070399998279754, 'postprocess': 0.970299995969981},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 99,  78, 153],\n",
       "         [102,  81, 156],\n",
       "         [104,  83, 158],\n",
       "         ...,\n",
       "         [ 94,  68,  82],\n",
       "         [ 96,  70,  84],\n",
       "         [ 96,  70,  84]],\n",
       " \n",
       "        [[ 99,  78, 153],\n",
       "         [102,  81, 156],\n",
       "         [104,  83, 158],\n",
       "         ...,\n",
       "         [ 94,  68,  82],\n",
       "         [ 96,  70,  84],\n",
       "         [ 94,  68,  82]],\n",
       " \n",
       "        [[102,  81, 156],\n",
       "         [104,  83, 158],\n",
       "         [105,  84, 159],\n",
       "         ...,\n",
       "         [ 94,  68,  82],\n",
       "         [ 96,  70,  84],\n",
       "         [ 94,  68,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  50,  80],\n",
       "         [ 64,  51,  81],\n",
       "         [ 64,  51,  81],\n",
       "         ...,\n",
       "         [154, 135, 205],\n",
       "         [155, 136, 206],\n",
       "         [156, 137, 207]],\n",
       " \n",
       "        [[ 66,  53,  83],\n",
       "         [ 66,  53,  83],\n",
       "         [ 66,  53,  83],\n",
       "         ...,\n",
       "         [154, 135, 205],\n",
       "         [156, 137, 207],\n",
       "         [158, 139, 209]],\n",
       " \n",
       "        [[ 66,  53,  83],\n",
       "         [ 66,  53,  83],\n",
       "         [ 66,  53,  83],\n",
       "         ...,\n",
       "         [155, 136, 206],\n",
       "         [156, 137, 207],\n",
       "         [158, 139, 209]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7993000001297332, 'inference': 20.951499995135237, 'postprocess': 1.123000001825858},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 95,  71, 150],\n",
       "         [102,  78, 157],\n",
       "         [104,  79, 166],\n",
       "         ...,\n",
       "         [ 94,  70,  84],\n",
       "         [ 92,  68,  82],\n",
       "         [ 90,  66,  80]],\n",
       " \n",
       "        [[ 91,  67, 146],\n",
       "         [ 97,  73, 152],\n",
       "         [100,  75, 162],\n",
       "         ...,\n",
       "         [ 92,  68,  82],\n",
       "         [ 91,  67,  81],\n",
       "         [ 89,  65,  79]],\n",
       " \n",
       "        [[ 86,  60, 144],\n",
       "         [ 92,  66, 150],\n",
       "         [ 96,  70, 160],\n",
       "         ...,\n",
       "         [ 93,  67,  81],\n",
       "         [ 92,  66,  80],\n",
       "         [ 91,  65,  79]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  50,  84],\n",
       "         [ 65,  53,  87],\n",
       "         [ 69,  55,  87],\n",
       "         ...,\n",
       "         [160, 143, 214],\n",
       "         [159, 142, 213],\n",
       "         [157, 140, 211]],\n",
       " \n",
       "        [[ 64,  52,  86],\n",
       "         [ 66,  54,  88],\n",
       "         [ 70,  56,  88],\n",
       "         ...,\n",
       "         [160, 143, 214],\n",
       "         [159, 142, 213],\n",
       "         [157, 140, 211]],\n",
       " \n",
       "        [[ 65,  53,  87],\n",
       "         [ 68,  56,  90],\n",
       "         [ 73,  59,  91],\n",
       "         ...,\n",
       "         [160, 143, 214],\n",
       "         [159, 142, 213],\n",
       "         [157, 140, 211]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5311999959521927, 'inference': 20.250100002158433, 'postprocess': 1.6977999985101633},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[102,  77, 159],\n",
       "         [109,  84, 166],\n",
       "         [110,  84, 174],\n",
       "         ...,\n",
       "         [ 96,  72,  86],\n",
       "         [ 94,  70,  84],\n",
       "         [ 91,  67,  81]],\n",
       " \n",
       "        [[100,  75, 157],\n",
       "         [105,  80, 162],\n",
       "         [109,  83, 173],\n",
       "         ...,\n",
       "         [ 95,  71,  85],\n",
       "         [ 94,  70,  84],\n",
       "         [ 90,  66,  80]],\n",
       " \n",
       "        [[ 95,  69, 153],\n",
       "         [100,  74, 158],\n",
       "         [105,  79, 170],\n",
       "         ...,\n",
       "         [ 95,  71,  85],\n",
       "         [ 92,  68,  82],\n",
       "         [ 89,  65,  79]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  53,  87],\n",
       "         [ 67,  55,  89],\n",
       "         [ 71,  57,  89],\n",
       "         ...,\n",
       "         [158, 143, 214],\n",
       "         [158, 143, 214],\n",
       "         [157, 142, 213]],\n",
       " \n",
       "        [[ 66,  54,  88],\n",
       "         [ 67,  55,  89],\n",
       "         [ 71,  57,  89],\n",
       "         ...,\n",
       "         [158, 143, 214],\n",
       "         [158, 143, 214],\n",
       "         [157, 142, 213]],\n",
       " \n",
       "        [[ 66,  54,  88],\n",
       "         [ 68,  56,  90],\n",
       "         [ 73,  59,  91],\n",
       "         ...,\n",
       "         [158, 143, 214],\n",
       "         [158, 143, 214],\n",
       "         [157, 142, 213]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5725999983260408, 'inference': 21.31309999822406, 'postprocess': 0.916600001801271},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 81,  48, 159],\n",
       "         [ 81,  48, 159],\n",
       "         [ 81,  47, 161],\n",
       "         ...,\n",
       "         [ 95,  71,  85],\n",
       "         [ 95,  71,  85],\n",
       "         [ 94,  70,  84]],\n",
       " \n",
       "        [[ 78,  45, 156],\n",
       "         [ 77,  44, 155],\n",
       "         [ 80,  46, 160],\n",
       "         ...,\n",
       "         [ 92,  68,  82],\n",
       "         [ 92,  68,  82],\n",
       "         [ 92,  68,  82]],\n",
       " \n",
       "        [[ 75,  40, 156],\n",
       "         [ 77,  42, 158],\n",
       "         [ 80,  45, 163],\n",
       "         ...,\n",
       "         [ 92,  68,  82],\n",
       "         [ 92,  68,  82],\n",
       "         [ 91,  67,  81]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 67,  55,  89],\n",
       "         [ 68,  56,  90],\n",
       "         [ 73,  59,  91],\n",
       "         ...,\n",
       "         [160, 143, 214],\n",
       "         [160, 143, 214],\n",
       "         [160, 143, 214]],\n",
       " \n",
       "        [[ 67,  55,  89],\n",
       "         [ 68,  56,  90],\n",
       "         [ 73,  59,  91],\n",
       "         ...,\n",
       "         [160, 143, 214],\n",
       "         [160, 143, 214],\n",
       "         [160, 143, 214]],\n",
       " \n",
       "        [[ 67,  55,  89],\n",
       "         [ 68,  56,  90],\n",
       "         [ 73,  59,  91],\n",
       "         ...,\n",
       "         [160, 143, 214],\n",
       "         [160, 143, 214],\n",
       "         [160, 143, 214]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0614000022760592, 'inference': 20.422299996425863, 'postprocess': 1.031799998600036},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 82,  49, 160],\n",
       "         [ 80,  47, 158],\n",
       "         [ 80,  46, 160],\n",
       "         ...,\n",
       "         [ 94,  68,  82],\n",
       "         [ 94,  70,  84],\n",
       "         [ 94,  70,  84]],\n",
       " \n",
       "        [[ 80,  47, 158],\n",
       "         [ 81,  48, 159],\n",
       "         [ 82,  48, 162],\n",
       "         ...,\n",
       "         [ 94,  68,  82],\n",
       "         [ 94,  70,  84],\n",
       "         [ 94,  70,  84]],\n",
       " \n",
       "        [[ 76,  42, 156],\n",
       "         [ 78,  44, 158],\n",
       "         [ 81,  46, 162],\n",
       "         ...,\n",
       "         [ 94,  68,  82],\n",
       "         [ 94,  70,  84],\n",
       "         [ 94,  70,  84]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 67,  55,  89],\n",
       "         [ 68,  56,  90],\n",
       "         [ 73,  59,  91],\n",
       "         ...,\n",
       "         [161, 144, 215],\n",
       "         [161, 144, 215],\n",
       "         [161, 144, 215]],\n",
       " \n",
       "        [[ 68,  56,  90],\n",
       "         [ 69,  57,  91],\n",
       "         [ 74,  60,  92],\n",
       "         ...,\n",
       "         [161, 144, 215],\n",
       "         [161, 144, 215],\n",
       "         [161, 144, 215]],\n",
       " \n",
       "        [[ 68,  56,  90],\n",
       "         [ 69,  57,  91],\n",
       "         [ 74,  60,  92],\n",
       "         ...,\n",
       "         [161, 144, 215],\n",
       "         [161, 144, 215],\n",
       "         [161, 144, 215]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8927999990410171, 'inference': 24.503300002834294, 'postprocess': 1.559399999678135},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 73,  34, 164],\n",
       "         [ 73,  34, 164],\n",
       "         [ 75,  34, 162],\n",
       "         ...,\n",
       "         [ 94,  66,  80],\n",
       "         [ 95,  67,  81],\n",
       "         [ 95,  67,  81]],\n",
       " \n",
       "        [[ 75,  36, 166],\n",
       "         [ 74,  35, 165],\n",
       "         [ 76,  35, 163],\n",
       "         ...,\n",
       "         [ 94,  66,  80],\n",
       "         [ 95,  67,  81],\n",
       "         [ 96,  68,  82]],\n",
       " \n",
       "        [[ 76,  37, 167],\n",
       "         [ 76,  37, 167],\n",
       "         [ 75,  36, 164],\n",
       "         ...,\n",
       "         [ 94,  66,  80],\n",
       "         [ 95,  67,  81],\n",
       "         [ 96,  68,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 64,  55,  89],\n",
       "         [ 59,  50,  84],\n",
       "         [ 65,  53,  87],\n",
       "         ...,\n",
       "         [163, 142, 217],\n",
       "         [167, 144, 219],\n",
       "         [165, 142, 217]],\n",
       " \n",
       "        [[ 64,  55,  89],\n",
       "         [ 59,  50,  84],\n",
       "         [ 65,  53,  87],\n",
       "         ...,\n",
       "         [165, 142, 217],\n",
       "         [167, 144, 219],\n",
       "         [167, 144, 219]],\n",
       " \n",
       "        [[ 63,  54,  88],\n",
       "         [ 59,  50,  84],\n",
       "         [ 65,  53,  87],\n",
       "         ...,\n",
       "         [165, 142, 217],\n",
       "         [167, 144, 219],\n",
       "         [167, 144, 219]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.586699996551033, 'inference': 20.30440000089584, 'postprocess': 0.9252000018022954},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 71,  32, 160],\n",
       "         [ 73,  34, 162],\n",
       "         [ 75,  34, 162],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 93,  65,  79],\n",
       "         [ 93,  65,  79]],\n",
       " \n",
       "        [[ 74,  35, 163],\n",
       "         [ 75,  36, 164],\n",
       "         [ 77,  36, 164],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 93,  65,  79],\n",
       "         [ 94,  66,  80]],\n",
       " \n",
       "        [[ 75,  36, 164],\n",
       "         [ 76,  37, 165],\n",
       "         [ 75,  36, 164],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 93,  65,  79],\n",
       "         [ 94,  66,  80]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  50,  84],\n",
       "         [ 62,  53,  87],\n",
       "         [ 68,  56,  90],\n",
       "         ...,\n",
       "         [163, 142, 217],\n",
       "         [167, 144, 219],\n",
       "         [167, 144, 219]],\n",
       " \n",
       "        [[ 59,  50,  84],\n",
       "         [ 62,  53,  87],\n",
       "         [ 68,  56,  90],\n",
       "         ...,\n",
       "         [164, 141, 216],\n",
       "         [165, 142, 217],\n",
       "         [164, 141, 216]],\n",
       " \n",
       "        [[ 59,  50,  84],\n",
       "         [ 62,  53,  87],\n",
       "         [ 68,  56,  90],\n",
       "         ...,\n",
       "         [164, 141, 216],\n",
       "         [165, 142, 217],\n",
       "         [165, 142, 217]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.365099993767217, 'inference': 23.029699994367547, 'postprocess': 1.9214000058127567},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84,  57, 158],\n",
       "         [ 86,  59, 160],\n",
       "         [ 88,  61, 163],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 93,  65,  79],\n",
       "         [ 93,  65,  79]],\n",
       " \n",
       "        [[ 91,  64, 165],\n",
       "         [ 91,  64, 165],\n",
       "         [ 95,  68, 170],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 93,  65,  79],\n",
       "         [ 93,  65,  79]],\n",
       " \n",
       "        [[ 96,  75, 165],\n",
       "         [ 98,  77, 167],\n",
       "         [101,  79, 172],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 93,  65,  79],\n",
       "         [ 93,  65,  79]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  59,  93],\n",
       "         [ 62,  53,  87],\n",
       "         [ 62,  50,  84],\n",
       "         ...,\n",
       "         [168, 147, 217],\n",
       "         [168, 147, 217],\n",
       "         [167, 146, 216]],\n",
       " \n",
       "        [[ 68,  59,  93],\n",
       "         [ 62,  53,  87],\n",
       "         [ 62,  50,  84],\n",
       "         ...,\n",
       "         [167, 146, 216],\n",
       "         [168, 147, 217],\n",
       "         [168, 147, 217]],\n",
       " \n",
       "        [[ 66,  57,  91],\n",
       "         [ 62,  53,  87],\n",
       "         [ 62,  50,  84],\n",
       "         ...,\n",
       "         [165, 144, 214],\n",
       "         [168, 147, 217],\n",
       "         [168, 147, 217]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6357999993488193, 'inference': 25.00069999950938, 'postprocess': 0.9941000025719404},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 86,  59, 160],\n",
       "         [ 87,  60, 161],\n",
       "         [ 90,  63, 165],\n",
       "         ...,\n",
       "         [ 89,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 94,  67, 168],\n",
       "         [ 94,  67, 168],\n",
       "         [ 98,  71, 173],\n",
       "         ...,\n",
       "         [ 89,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 98,  77, 167],\n",
       "         [ 99,  78, 168],\n",
       "         [103,  81, 174],\n",
       "         ...,\n",
       "         [ 89,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  50,  84],\n",
       "         [ 61,  52,  86],\n",
       "         [ 65,  53,  87],\n",
       "         ...,\n",
       "         [166, 146, 218],\n",
       "         [166, 146, 218],\n",
       "         [165, 145, 217]],\n",
       " \n",
       "        [[ 59,  50,  84],\n",
       "         [ 61,  52,  86],\n",
       "         [ 65,  53,  87],\n",
       "         ...,\n",
       "         [166, 146, 218],\n",
       "         [166, 146, 218],\n",
       "         [166, 146, 218]],\n",
       " \n",
       "        [[ 59,  50,  84],\n",
       "         [ 61,  52,  86],\n",
       "         [ 65,  53,  87],\n",
       "         ...,\n",
       "         [165, 145, 217],\n",
       "         [166, 146, 218],\n",
       "         [166, 146, 218]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9656000004033558, 'inference': 20.70860000094399, 'postprocess': 1.1694999993778765},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[132, 122, 186],\n",
       "         [132, 122, 186],\n",
       "         [130, 123, 186],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[134, 124, 188],\n",
       "         [134, 124, 188],\n",
       "         [132, 125, 188],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[132, 126, 184],\n",
       "         [133, 127, 185],\n",
       "         [132, 126, 184],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  67, 103],\n",
       "         [ 68,  60,  96],\n",
       "         [ 63,  55,  91],\n",
       "         ...,\n",
       "         [102,  80, 145],\n",
       "         [103,  81, 146],\n",
       "         [107,  85, 150]],\n",
       " \n",
       "        [[ 74,  66, 102],\n",
       "         [ 67,  59,  95],\n",
       "         [ 62,  54,  90],\n",
       "         ...,\n",
       "         [103,  81, 146],\n",
       "         [103,  81, 146],\n",
       "         [104,  82, 147]],\n",
       " \n",
       "        [[ 73,  65, 101],\n",
       "         [ 67,  59,  95],\n",
       "         [ 61,  53,  89],\n",
       "         ...,\n",
       "         [103,  81, 146],\n",
       "         [103,  81, 146],\n",
       "         [104,  82, 147]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3660999975400046, 'inference': 20.260099998267833, 'postprocess': 3.162599998177029},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[133, 124, 183],\n",
       "         [133, 124, 183],\n",
       "         [131, 125, 183],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[133, 124, 183],\n",
       "         [134, 125, 184],\n",
       "         [131, 125, 183],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[134, 126, 183],\n",
       "         [135, 127, 184],\n",
       "         [134, 126, 183],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  60,  96],\n",
       "         [ 63,  55,  91],\n",
       "         [ 62,  52,  88],\n",
       "         ...,\n",
       "         [100,  78, 143],\n",
       "         [103,  81, 146],\n",
       "         [107,  85, 150]],\n",
       " \n",
       "        [[ 68,  60,  96],\n",
       "         [ 62,  54,  90],\n",
       "         [ 61,  51,  87],\n",
       "         ...,\n",
       "         [101,  79, 144],\n",
       "         [103,  81, 146],\n",
       "         [104,  82, 147]],\n",
       " \n",
       "        [[ 67,  59,  95],\n",
       "         [ 62,  54,  90],\n",
       "         [ 61,  51,  87],\n",
       "         ...,\n",
       "         [101,  79, 144],\n",
       "         [103,  81, 146],\n",
       "         [103,  81, 146]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.1996999965049326, 'inference': 20.11530000163475, 'postprocess': 0.9226999973179772},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[110, 102, 172],\n",
       "         [108, 100, 170],\n",
       "         [103,  97, 162],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[106,  98, 168],\n",
       "         [104,  96, 166],\n",
       "         [100,  94, 159],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[102,  91, 171],\n",
       "         [101,  90, 170],\n",
       "         [ 99,  91, 161],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  68, 104],\n",
       "         [ 70,  62,  98],\n",
       "         [ 66,  58,  94],\n",
       "         ...,\n",
       "         [109,  84, 150],\n",
       "         [109,  84, 148],\n",
       "         [109,  84, 148]],\n",
       " \n",
       "        [[ 75,  67, 103],\n",
       "         [ 70,  62,  98],\n",
       "         [ 66,  58,  94],\n",
       "         ...,\n",
       "         [109,  84, 150],\n",
       "         [109,  84, 148],\n",
       "         [109,  84, 148]],\n",
       " \n",
       "        [[ 74,  66, 102],\n",
       "         [ 69,  61,  97],\n",
       "         [ 66,  58,  94],\n",
       "         ...,\n",
       "         [109,  84, 150],\n",
       "         [109,  84, 148],\n",
       "         [109,  84, 148]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5872000003582798, 'inference': 20.356300003186334, 'postprocess': 1.2073999969288707},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[107, 101, 166],\n",
       "         [102,  96, 161],\n",
       "         [101,  94, 155],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[102,  96, 161],\n",
       "         [100,  94, 159],\n",
       "         [ 98,  91, 152],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[100,  91, 164],\n",
       "         [ 97,  88, 161],\n",
       "         [ 96,  89, 157],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 70,  62,  98],\n",
       "         [ 66,  58,  94],\n",
       "         [ 61,  53,  89],\n",
       "         ...,\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]],\n",
       " \n",
       "        [[ 70,  62,  98],\n",
       "         [ 66,  58,  94],\n",
       "         [ 61,  53,  89],\n",
       "         ...,\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]],\n",
       " \n",
       "        [[ 69,  61,  97],\n",
       "         [ 64,  56,  92],\n",
       "         [ 60,  52,  88],\n",
       "         ...,\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.226700005645398, 'inference': 20.161199994618073, 'postprocess': 0.8845000047585927},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 82,  80, 194],\n",
       "         [ 81,  79, 193],\n",
       "         [ 77,  76, 188],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 83,  81, 195],\n",
       "         [ 82,  80, 194],\n",
       "         [ 81,  80, 192],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 80,  84, 207],\n",
       "         [ 78,  82, 205],\n",
       "         [ 77,  81, 202],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  71, 106],\n",
       "         [ 72,  67, 102],\n",
       "         [ 69,  61,  97],\n",
       "         ...,\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]],\n",
       " \n",
       "        [[ 75,  70, 105],\n",
       "         [ 71,  66, 101],\n",
       "         [ 68,  60,  96],\n",
       "         ...,\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]],\n",
       " \n",
       "        [[ 74,  69, 104],\n",
       "         [ 69,  64,  99],\n",
       "         [ 67,  59,  95],\n",
       "         ...,\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5133999986574054, 'inference': 22.377499997674022, 'postprocess': 1.356500004476402},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 80,  76, 189],\n",
       "         [ 79,  75, 188],\n",
       "         [ 76,  72, 183],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 83,  79, 192],\n",
       "         [ 81,  77, 190],\n",
       "         [ 79,  75, 186],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 78,  80, 203],\n",
       "         [ 77,  79, 202],\n",
       "         [ 76,  78, 199],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 72,  67, 102],\n",
       "         [ 67,  62,  97],\n",
       "         [ 64,  59,  94],\n",
       "         ...,\n",
       "         [106,  81, 145],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]],\n",
       " \n",
       "        [[ 71,  66, 101],\n",
       "         [ 66,  61,  96],\n",
       "         [ 62,  57,  92],\n",
       "         ...,\n",
       "         [106,  81, 145],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]],\n",
       " \n",
       "        [[ 69,  64,  99],\n",
       "         [ 65,  60,  95],\n",
       "         [ 61,  56,  91],\n",
       "         ...,\n",
       "         [106,  81, 145],\n",
       "         [107,  82, 146],\n",
       "         [107,  82, 146]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0552999994833954, 'inference': 19.94879999983823, 'postprocess': 1.1952999993809499},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 66,  78, 211],\n",
       "         [ 64,  76, 209],\n",
       "         [ 66,  75, 210],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 61,  73, 206],\n",
       "         [ 60,  72, 205],\n",
       "         [ 62,  71, 206],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 59,  69, 200],\n",
       "         [ 56,  66, 197],\n",
       "         [ 56,  65, 200],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  70, 105],\n",
       "         [ 74,  69, 104],\n",
       "         [ 72,  67, 102],\n",
       "         ...,\n",
       "         [105,  83, 146],\n",
       "         [107,  82, 148],\n",
       "         [107,  82, 148]],\n",
       " \n",
       "        [[ 75,  70, 105],\n",
       "         [ 74,  69, 104],\n",
       "         [ 72,  67, 102],\n",
       "         ...,\n",
       "         [105,  83, 146],\n",
       "         [106,  81, 147],\n",
       "         [106,  81, 147]],\n",
       " \n",
       "        [[ 75,  70, 105],\n",
       "         [ 74,  69, 104],\n",
       "         [ 72,  67, 102],\n",
       "         ...,\n",
       "         [105,  83, 146],\n",
       "         [107,  82, 148],\n",
       "         [107,  82, 148]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0116000014240853, 'inference': 20.290500004193746, 'postprocess': 0.9924000041792169},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 65,  76, 211],\n",
       "         [ 64,  75, 210],\n",
       "         [ 66,  75, 210],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 60,  71, 206],\n",
       "         [ 60,  71, 206],\n",
       "         [ 62,  71, 206],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 58,  68, 201],\n",
       "         [ 56,  66, 199],\n",
       "         [ 56,  65, 200],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75,  70, 105],\n",
       "         [ 73,  68, 103],\n",
       "         [ 69,  64,  99],\n",
       "         ...,\n",
       "         [109,  84, 150],\n",
       "         [109,  84, 150],\n",
       "         [107,  82, 148]],\n",
       " \n",
       "        [[ 75,  70, 105],\n",
       "         [ 73,  68, 103],\n",
       "         [ 69,  64,  99],\n",
       "         ...,\n",
       "         [109,  84, 150],\n",
       "         [109,  84, 150],\n",
       "         [107,  82, 148]],\n",
       " \n",
       "        [[ 75,  70, 105],\n",
       "         [ 72,  67, 102],\n",
       "         [ 69,  64,  99],\n",
       "         ...,\n",
       "         [109,  84, 150],\n",
       "         [109,  84, 150],\n",
       "         [107,  82, 148]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7566999958944507, 'inference': 12.933799996972084, 'postprocess': 1.317300004302524},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 59,  59, 173],\n",
       "         [ 59,  59, 173],\n",
       "         [ 63,  58, 173],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 59,  59, 173],\n",
       "         [ 59,  59, 173],\n",
       "         [ 65,  60, 175],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 65,  62, 171],\n",
       "         [ 65,  62, 171],\n",
       "         [ 67,  62, 171],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84,  76, 112],\n",
       "         [ 83,  75, 111],\n",
       "         [ 83,  76, 110],\n",
       "         ...,\n",
       "         [104,  79, 143],\n",
       "         [104,  79, 143],\n",
       "         [104,  79, 143]],\n",
       " \n",
       "        [[ 86,  78, 114],\n",
       "         [ 85,  77, 113],\n",
       "         [ 84,  77, 111],\n",
       "         ...,\n",
       "         [103,  78, 144],\n",
       "         [102,  77, 143],\n",
       "         [102,  77, 143]],\n",
       " \n",
       "        [[ 86,  78, 114],\n",
       "         [ 85,  77, 113],\n",
       "         [ 84,  77, 111],\n",
       "         ...,\n",
       "         [103,  78, 144],\n",
       "         [102,  77, 143],\n",
       "         [102,  77, 143]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.258500004245434, 'inference': 12.404200002492871, 'postprocess': 1.1203999965800904},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 62,  60, 174],\n",
       "         [ 62,  60, 174],\n",
       "         [ 64,  59, 174],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 62,  60, 174],\n",
       "         [ 62,  60, 174],\n",
       "         [ 65,  60, 175],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 67,  62, 171],\n",
       "         [ 67,  62, 171],\n",
       "         [ 68,  63, 172],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  74, 113],\n",
       "         [ 82,  73, 112],\n",
       "         [ 82,  74, 110],\n",
       "         ...,\n",
       "         [104,  80, 141],\n",
       "         [104,  80, 141],\n",
       "         [104,  80, 141]],\n",
       " \n",
       "        [[ 83,  74, 113],\n",
       "         [ 83,  74, 113],\n",
       "         [ 82,  74, 110],\n",
       "         ...,\n",
       "         [104,  80, 141],\n",
       "         [104,  80, 141],\n",
       "         [104,  80, 141]],\n",
       " \n",
       "        [[ 83,  74, 113],\n",
       "         [ 82,  73, 112],\n",
       "         [ 82,  74, 110],\n",
       "         ...,\n",
       "         [104,  80, 141],\n",
       "         [104,  80, 141],\n",
       "         [104,  80, 141]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2134999997215346, 'inference': 12.486000006902032, 'postprocess': 1.365000003715977},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84,  73, 160],\n",
       "         [ 84,  73, 160],\n",
       "         [ 86,  73, 158],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 84,  73, 160],\n",
       "         [ 84,  73, 160],\n",
       "         [ 86,  73, 158],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 86,  75, 155],\n",
       "         [ 86,  75, 155],\n",
       "         [ 88,  75, 155],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[102,  89, 125],\n",
       "         [103,  90, 126],\n",
       "         [103,  90, 126],\n",
       "         ...,\n",
       "         [112,  89, 148],\n",
       "         [112,  88, 149],\n",
       "         [111,  87, 148]],\n",
       " \n",
       "        [[103,  90, 126],\n",
       "         [104,  91, 127],\n",
       "         [104,  91, 127],\n",
       "         ...,\n",
       "         [112,  89, 148],\n",
       "         [112,  87, 151],\n",
       "         [111,  86, 150]],\n",
       " \n",
       "        [[103,  90, 126],\n",
       "         [104,  91, 127],\n",
       "         [104,  91, 127],\n",
       "         ...,\n",
       "         [112,  89, 148],\n",
       "         [112,  87, 151],\n",
       "         [111,  86, 150]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7664000042714179, 'inference': 19.32420000230195, 'postprocess': 1.7694999987725168},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 84,  73, 160],\n",
       "         [ 84,  73, 160],\n",
       "         [ 86,  73, 158],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 84,  73, 160],\n",
       "         [ 84,  73, 160],\n",
       "         [ 86,  73, 158],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 86,  76, 153],\n",
       "         [ 86,  76, 153],\n",
       "         [ 88,  76, 153],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 98,  88, 124],\n",
       "         [ 99,  89, 125],\n",
       "         [ 99,  90, 124],\n",
       "         ...,\n",
       "         [113,  90, 149],\n",
       "         [113,  90, 149],\n",
       "         [112,  89, 148]],\n",
       " \n",
       "        [[ 99,  89, 125],\n",
       "         [100,  90, 126],\n",
       "         [100,  91, 125],\n",
       "         ...,\n",
       "         [113,  90, 149],\n",
       "         [113,  89, 150],\n",
       "         [112,  88, 149]],\n",
       " \n",
       "        [[100,  90, 126],\n",
       "         [100,  90, 126],\n",
       "         [101,  92, 126],\n",
       "         ...,\n",
       "         [113,  90, 149],\n",
       "         [113,  89, 150],\n",
       "         [112,  88, 149]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7538000029162504, 'inference': 14.911999998730607, 'postprocess': 1.1782000001403503},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 93,  77, 146],\n",
       "         [ 93,  77, 146],\n",
       "         [ 94,  79, 145],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 93,  77, 146],\n",
       "         [ 94,  78, 147],\n",
       "         [ 94,  79, 145],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 97,  79, 146],\n",
       "         [ 98,  80, 147],\n",
       "         [ 98,  80, 147],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[102,  93, 134],\n",
       "         [102,  93, 134],\n",
       "         [104,  93, 134],\n",
       "         ...,\n",
       "         [ 69,  49,  80],\n",
       "         [ 73,  53,  89],\n",
       "         [ 79,  59,  95]],\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [105,  94, 133],\n",
       "         [104,  95, 134],\n",
       "         ...,\n",
       "         [ 72,  52,  83],\n",
       "         [ 75,  55,  91],\n",
       "         [ 82,  62,  98]],\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [105,  94, 133],\n",
       "         [104,  95, 134],\n",
       "         ...,\n",
       "         [ 73,  53,  84],\n",
       "         [ 78,  58,  94],\n",
       "         [ 85,  65, 101]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5679000061936677, 'inference': 20.80299999943236, 'postprocess': 0.7452999998349696},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94,  78, 147],\n",
       "         [ 94,  78, 147],\n",
       "         [ 97,  79, 146],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 94,  78, 147],\n",
       "         [ 95,  79, 148],\n",
       "         [ 97,  79, 146],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 98,  80, 147],\n",
       "         [ 99,  81, 148],\n",
       "         [101,  81, 148],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[102,  93, 134],\n",
       "         [100,  91, 132],\n",
       "         [104,  93, 134],\n",
       "         ...,\n",
       "         [ 60,  41,  69],\n",
       "         [ 63,  44,  77],\n",
       "         [ 68,  49,  82]],\n",
       " \n",
       "        [[100,  91, 130],\n",
       "         [102,  93, 132],\n",
       "         [102,  93, 132],\n",
       "         ...,\n",
       "         [ 61,  42,  70],\n",
       "         [ 64,  45,  78],\n",
       "         [ 70,  51,  84]],\n",
       " \n",
       "        [[102,  93, 132],\n",
       "         [103,  94, 133],\n",
       "         [104,  95, 134],\n",
       "         ...,\n",
       "         [ 62,  43,  71],\n",
       "         [ 65,  46,  79],\n",
       "         [ 71,  52,  85]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8106999996234663, 'inference': 25.86959999462124, 'postprocess': 1.0345999980927445},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[102,  81, 156],\n",
       "         [103,  82, 157],\n",
       "         [109,  85, 155],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[102,  81, 156],\n",
       "         [103,  82, 157],\n",
       "         [109,  85, 155],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[100,  78, 156],\n",
       "         [103,  81, 159],\n",
       "         [108,  83, 155],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[107,  93, 132],\n",
       "         [108,  94, 133],\n",
       "         [105,  94, 133],\n",
       "         ...,\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54]],\n",
       " \n",
       "        [[107,  93, 132],\n",
       "         [108,  94, 133],\n",
       "         [105,  94, 133],\n",
       "         ...,\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54]],\n",
       " \n",
       "        [[107,  93, 132],\n",
       "         [108,  94, 133],\n",
       "         [105,  94, 133],\n",
       "         ...,\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4009000005898997, 'inference': 19.5666999934474, 'postprocess': 0.9416000029887073},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[108,  84, 154],\n",
       "         [109,  85, 155],\n",
       "         [109,  86, 153],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[108,  84, 154],\n",
       "         [109,  85, 155],\n",
       "         [109,  86, 153],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[105,  83, 155],\n",
       "         [106,  84, 156],\n",
       "         [109,  85, 155],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [105,  94, 133],\n",
       "         [106,  95, 134],\n",
       "         ...,\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54]],\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [105,  94, 133],\n",
       "         [106,  95, 134],\n",
       "         ...,\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54]],\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [105,  94, 133],\n",
       "         [106,  95, 134],\n",
       "         ...,\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54],\n",
       "         [ 61,  39,  54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4367999974638224, 'inference': 23.392800001602154, 'postprocess': 0.8298000029753894},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  69, 148],\n",
       "         [ 97,  70, 149],\n",
       "         [100,  72, 145],\n",
       "         ...,\n",
       "         [ 89,  61,  75],\n",
       "         [ 89,  61,  75],\n",
       "         [ 89,  61,  75]],\n",
       " \n",
       "        [[ 96,  69, 148],\n",
       "         [ 97,  70, 149],\n",
       "         [100,  72, 145],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 96,  69, 148],\n",
       "         [ 97,  70, 149],\n",
       "         [100,  73, 144],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[101,  91, 127],\n",
       "         [101,  91, 127],\n",
       "         [101,  91, 127],\n",
       "         ...,\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56]],\n",
       " \n",
       "        [[101,  91, 127],\n",
       "         [101,  91, 127],\n",
       "         [101,  91, 127],\n",
       "         ...,\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56]],\n",
       " \n",
       "        [[101,  91, 127],\n",
       "         [101,  91, 127],\n",
       "         [101,  91, 127],\n",
       "         ...,\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3222999987192452, 'inference': 20.250300003681332, 'postprocess': 1.568500003486406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 97,  71, 146],\n",
       "         [ 98,  72, 147],\n",
       "         [100,  74, 142],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 97,  71, 146],\n",
       "         [ 98,  72, 147],\n",
       "         [100,  74, 142],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 99,  70, 146],\n",
       "         [100,  71, 147],\n",
       "         [102,  74, 142],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[104,  91, 127],\n",
       "         [105,  92, 128],\n",
       "         [102,  92, 128],\n",
       "         ...,\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56]],\n",
       " \n",
       "        [[104,  91, 127],\n",
       "         [105,  92, 128],\n",
       "         [102,  92, 128],\n",
       "         ...,\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56]],\n",
       " \n",
       "        [[104,  91, 127],\n",
       "         [105,  92, 128],\n",
       "         [102,  92, 128],\n",
       "         ...,\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56],\n",
       "         [ 59,  39,  56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5082999962032773, 'inference': 17.690199994831346, 'postprocess': 2.4870000052032992},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[100,  67, 150],\n",
       "         [102,  69, 152],\n",
       "         [106,  76, 149],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[100,  67, 150],\n",
       "         [101,  68, 151],\n",
       "         [106,  76, 149],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 99,  66, 149],\n",
       "         [101,  68, 151],\n",
       "         [105,  75, 148],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 99,  91, 127],\n",
       "         [ 99,  91, 127],\n",
       "         [100,  92, 128],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[ 99,  91, 127],\n",
       "         [ 99,  91, 127],\n",
       "         [100,  92, 128],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[ 99,  91, 127],\n",
       "         [ 99,  91, 127],\n",
       "         [100,  92, 128],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3445999938994646, 'inference': 23.528400000941474, 'postprocess': 4.90669999999227},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[104,  73, 149],\n",
       "         [106,  75, 151],\n",
       "         [107,  79, 147],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[104,  73, 149],\n",
       "         [106,  75, 151],\n",
       "         [107,  79, 147],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[102,  71, 147],\n",
       "         [106,  75, 151],\n",
       "         [107,  79, 147],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[100,  92, 128],\n",
       "         [102,  94, 130],\n",
       "         [103,  95, 131],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[100,  92, 128],\n",
       "         [102,  94, 130],\n",
       "         [103,  95, 131],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[100,  92, 128],\n",
       "         [102,  94, 130],\n",
       "         [103,  95, 131],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2247000049683265, 'inference': 11.691400002746377, 'postprocess': 1.67679999867687},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 99,  65, 156],\n",
       "         [100,  66, 157],\n",
       "         [106,  74, 159],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 97,  63, 154],\n",
       "         [ 98,  64, 155],\n",
       "         [103,  71, 156],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 95,  60, 155],\n",
       "         [ 96,  61, 156],\n",
       "         [100,  66, 157],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.741500003845431, 'inference': 15.498299995670095, 'postprocess': 5.678199995600153},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[103,  70, 158],\n",
       "         [107,  74, 162],\n",
       "         [113,  82, 158],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[100,  67, 155],\n",
       "         [104,  71, 159],\n",
       "         [109,  78, 154],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        [[ 98,  64, 156],\n",
       "         [100,  66, 158],\n",
       "         [105,  73, 152],\n",
       "         ...,\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78],\n",
       "         [ 92,  64,  78]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         [ 99,  90, 129],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.910600003611762, 'inference': 20.23439999902621, 'postprocess': 3.5573000059230253},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 90,  52, 149],\n",
       "         [ 90,  52, 149],\n",
       "         [ 93,  56, 151],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 90,  52, 149],\n",
       "         [ 90,  52, 149],\n",
       "         [ 92,  55, 150],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 89,  51, 148],\n",
       "         [ 89,  51, 148],\n",
       "         [ 92,  55, 150],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         ...,\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56],\n",
       "         [ 60,  41,  54]],\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         ...,\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56]],\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         ...,\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4894999985699542, 'inference': 11.924600003112573, 'postprocess': 2.5506000019959174},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 92,  54, 151],\n",
       "         [ 94,  56, 153],\n",
       "         [ 95,  61, 146],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 92,  54, 151],\n",
       "         [ 93,  55, 152],\n",
       "         [ 98,  64, 149],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        [[ 91,  53, 150],\n",
       "         [ 93,  55, 152],\n",
       "         [ 95,  60, 148],\n",
       "         ...,\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77],\n",
       "         [ 91,  63,  77]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         ...,\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56],\n",
       "         [ 60,  41,  54]],\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         ...,\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56]],\n",
       " \n",
       "        [[104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         [104,  93, 132],\n",
       "         ...,\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56],\n",
       "         [ 62,  43,  56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.189600006910041, 'inference': 14.297900001110975, 'postprocess': 2.4471000069752336},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 86,  51, 131],\n",
       "         [ 86,  51, 131],\n",
       "         [ 89,  55, 127],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        [[ 85,  50, 130],\n",
       "         [ 85,  50, 130],\n",
       "         [ 87,  53, 125],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        [[ 85,  54, 123],\n",
       "         [ 85,  54, 123],\n",
       "         [ 87,  55, 120],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[101,  88, 124],\n",
       "         [ 98,  85, 121],\n",
       "         [ 96,  83, 119],\n",
       "         ...,\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54]],\n",
       " \n",
       "        [[ 96,  83, 119],\n",
       "         [ 94,  81, 117],\n",
       "         [ 91,  78, 114],\n",
       "         ...,\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54]],\n",
       " \n",
       "        [[ 93,  80, 116],\n",
       "         [ 90,  77, 113],\n",
       "         [ 88,  75, 111],\n",
       "         ...,\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 0.9810999981709756, 'inference': 12.4703999972553, 'postprocess': 5.409099998360034},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  53, 130],\n",
       "         [ 89,  53, 130],\n",
       "         [ 91,  56, 125],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        [[ 87,  51, 128],\n",
       "         [ 87,  51, 128],\n",
       "         [ 89,  54, 123],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        [[ 87,  55, 122],\n",
       "         [ 88,  56, 123],\n",
       "         [ 90,  57, 119],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[102,  89, 125],\n",
       "         [100,  87, 123],\n",
       "         [ 98,  85, 121],\n",
       "         ...,\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54]],\n",
       " \n",
       "        [[ 98,  85, 121],\n",
       "         [ 96,  83, 119],\n",
       "         [ 95,  82, 118],\n",
       "         ...,\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54]],\n",
       " \n",
       "        [[ 94,  81, 117],\n",
       "         [ 91,  78, 114],\n",
       "         [ 90,  77, 113],\n",
       "         ...,\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2423000007402152, 'inference': 21.624000000883825, 'postprocess': 2.7784999983850867},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  55, 127],\n",
       "         [ 89,  55, 127],\n",
       "         [ 91,  57, 122],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        [[ 87,  53, 125],\n",
       "         [ 87,  53, 125],\n",
       "         [ 89,  55, 120],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        [[ 87,  55, 120],\n",
       "         [ 88,  56, 121],\n",
       "         [ 90,  59, 116],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[103,  90, 126],\n",
       "         [101,  88, 124],\n",
       "         [ 98,  85, 121],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[102,  89, 125],\n",
       "         [100,  87, 123],\n",
       "         [ 96,  83, 119],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[100,  87, 123],\n",
       "         [ 96,  83, 119],\n",
       "         [ 93,  80, 116],\n",
       "         ...,\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54],\n",
       "         [ 60,  41,  54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 0.9863999948720448, 'inference': 12.622299997019581, 'postprocess': 2.228800003649667},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  56, 125],\n",
       "         [ 89,  56, 125],\n",
       "         [ 91,  58, 120],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        [[ 87,  54, 123],\n",
       "         [ 87,  54, 123],\n",
       "         [ 89,  56, 118],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        [[ 87,  56, 118],\n",
       "         [ 88,  57, 119],\n",
       "         [ 90,  60, 115],\n",
       "         ...,\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74],\n",
       "         [ 90,  59,  74]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[104,  91, 127],\n",
       "         [103,  90, 126],\n",
       "         [102,  89, 125],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[ 99,  89, 125],\n",
       "         [ 97,  87, 123],\n",
       "         [ 98,  85, 121],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]],\n",
       " \n",
       "        [[ 98,  88, 124],\n",
       "         [ 95,  85, 121],\n",
       "         [ 96,  83, 119],\n",
       "         ...,\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53],\n",
       "         [ 59,  40,  53]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.0567999997874722, 'inference': 11.793199999374337, 'postprocess': 4.215900000417605},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[81, 55, 96],\n",
       "         [81, 55, 96],\n",
       "         [84, 57, 94],\n",
       "         ...,\n",
       "         [90, 57, 72],\n",
       "         [90, 57, 72],\n",
       "         [90, 57, 72]],\n",
       " \n",
       "        [[83, 57, 98],\n",
       "         [82, 56, 97],\n",
       "         [85, 58, 95],\n",
       "         ...,\n",
       "         [90, 57, 72],\n",
       "         [90, 57, 72],\n",
       "         [90, 57, 72]],\n",
       " \n",
       "        [[85, 58, 95],\n",
       "         [86, 59, 96],\n",
       "         [87, 59, 93],\n",
       "         ...,\n",
       "         [89, 56, 71],\n",
       "         [89, 56, 71],\n",
       "         [89, 56, 71]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[67, 54, 90],\n",
       "         [67, 54, 90],\n",
       "         [67, 54, 90],\n",
       "         ...,\n",
       "         [60, 41, 54],\n",
       "         [62, 41, 54],\n",
       "         [62, 41, 54]],\n",
       " \n",
       "        [[66, 53, 89],\n",
       "         [66, 53, 89],\n",
       "         [66, 53, 89],\n",
       "         ...,\n",
       "         [60, 41, 54],\n",
       "         [62, 41, 54],\n",
       "         [62, 41, 54]],\n",
       " \n",
       "        [[66, 53, 89],\n",
       "         [66, 53, 89],\n",
       "         [66, 53, 89],\n",
       "         ...,\n",
       "         [60, 41, 54],\n",
       "         [62, 41, 54],\n",
       "         [62, 41, 54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3550000003306195, 'inference': 25.816200002736878, 'postprocess': 1.8723999965004623},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[83, 55, 94],\n",
       "         [84, 56, 95],\n",
       "         [85, 56, 93],\n",
       "         ...,\n",
       "         [90, 57, 72],\n",
       "         [90, 57, 72],\n",
       "         [90, 57, 72]],\n",
       " \n",
       "        [[84, 56, 95],\n",
       "         [85, 57, 96],\n",
       "         [86, 57, 94],\n",
       "         ...,\n",
       "         [90, 57, 72],\n",
       "         [90, 57, 72],\n",
       "         [90, 57, 72]],\n",
       " \n",
       "        [[88, 59, 96],\n",
       "         [87, 58, 95],\n",
       "         [87, 59, 93],\n",
       "         ...,\n",
       "         [89, 56, 71],\n",
       "         [89, 56, 71],\n",
       "         [89, 56, 71]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[69, 56, 92],\n",
       "         [69, 56, 92],\n",
       "         [69, 56, 92],\n",
       "         ...,\n",
       "         [60, 41, 54],\n",
       "         [62, 41, 54],\n",
       "         [62, 41, 54]],\n",
       " \n",
       "        [[68, 55, 91],\n",
       "         [68, 55, 91],\n",
       "         [68, 55, 91],\n",
       "         ...,\n",
       "         [60, 41, 54],\n",
       "         [62, 41, 54],\n",
       "         [62, 41, 54]],\n",
       " \n",
       "        [[67, 54, 90],\n",
       "         [67, 54, 90],\n",
       "         [67, 54, 90],\n",
       "         ...,\n",
       "         [60, 41, 54],\n",
       "         [62, 41, 54],\n",
       "         [62, 41, 54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8123999980161898, 'inference': 22.94469999469584, 'postprocess': 1.8471000003046356},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[96, 71, 96],\n",
       "         [95, 70, 95],\n",
       "         [95, 71, 93],\n",
       "         ...,\n",
       "         [85, 52, 67],\n",
       "         [88, 52, 68],\n",
       "         [88, 52, 68]],\n",
       " \n",
       "        [[97, 72, 97],\n",
       "         [97, 72, 97],\n",
       "         [95, 71, 93],\n",
       "         ...,\n",
       "         [86, 53, 68],\n",
       "         [88, 52, 68],\n",
       "         [88, 52, 68]],\n",
       " \n",
       "        [[99, 75, 97],\n",
       "         [97, 73, 95],\n",
       "         [97, 73, 95],\n",
       "         ...,\n",
       "         [86, 53, 68],\n",
       "         [88, 52, 68],\n",
       "         [90, 54, 70]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[61, 53, 84],\n",
       "         [61, 53, 84],\n",
       "         [61, 53, 84],\n",
       "         ...,\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55]],\n",
       " \n",
       "        [[61, 53, 84],\n",
       "         [61, 53, 84],\n",
       "         [61, 53, 84],\n",
       "         ...,\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55]],\n",
       " \n",
       "        [[61, 53, 84],\n",
       "         [61, 53, 84],\n",
       "         [61, 53, 84],\n",
       "         ...,\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3158000001567416, 'inference': 24.055800000496674, 'postprocess': 0.7126000054995529},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[95, 70, 95],\n",
       "         [95, 70, 95],\n",
       "         [94, 70, 92],\n",
       "         ...,\n",
       "         [85, 52, 67],\n",
       "         [85, 52, 67],\n",
       "         [86, 53, 68]],\n",
       " \n",
       "        [[97, 72, 97],\n",
       "         [95, 70, 95],\n",
       "         [94, 70, 92],\n",
       "         ...,\n",
       "         [85, 52, 67],\n",
       "         [85, 52, 67],\n",
       "         [86, 53, 68]],\n",
       " \n",
       "        [[97, 73, 95],\n",
       "         [97, 73, 95],\n",
       "         [96, 72, 94],\n",
       "         ...,\n",
       "         [85, 52, 67],\n",
       "         [86, 53, 68],\n",
       "         [86, 53, 68]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[60, 52, 88],\n",
       "         [60, 52, 88],\n",
       "         [60, 52, 88],\n",
       "         ...,\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55]],\n",
       " \n",
       "        [[59, 52, 86],\n",
       "         [59, 52, 86],\n",
       "         [59, 52, 86],\n",
       "         ...,\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55]],\n",
       " \n",
       "        [[59, 52, 86],\n",
       "         [59, 52, 86],\n",
       "         [59, 52, 86],\n",
       "         ...,\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55],\n",
       "         [58, 41, 55]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2893000020994805, 'inference': 16.49080000061076, 'postprocess': 0.7761999950162135},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[117,  96, 124],\n",
       "         [115,  94, 122],\n",
       "         [117,  93, 122],\n",
       "         ...,\n",
       "         [ 78,  50,  64],\n",
       "         [ 78,  50,  64],\n",
       "         [ 78,  50,  64]],\n",
       " \n",
       "        [[119,  98, 126],\n",
       "         [119,  98, 126],\n",
       "         [121,  97, 126],\n",
       "         ...,\n",
       "         [ 78,  50,  64],\n",
       "         [ 78,  50,  64],\n",
       "         [ 78,  50,  64]],\n",
       " \n",
       "        [[121, 100, 128],\n",
       "         [121, 100, 128],\n",
       "         [120,  99, 127],\n",
       "         ...,\n",
       "         [ 80,  49,  64],\n",
       "         [ 80,  49,  64],\n",
       "         [ 80,  49,  64]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         ...,\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54]],\n",
       " \n",
       "        [[ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         ...,\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54]],\n",
       " \n",
       "        [[ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         ...,\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8082999959005974, 'inference': 14.990499999839813, 'postprocess': 1.395599996612873},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[115,  94, 122],\n",
       "         [115,  94, 122],\n",
       "         [115,  94, 122],\n",
       "         ...,\n",
       "         [ 78,  50,  64],\n",
       "         [ 78,  50,  64],\n",
       "         [ 78,  50,  64]],\n",
       " \n",
       "        [[117,  96, 124],\n",
       "         [117,  96, 124],\n",
       "         [117,  96, 124],\n",
       "         ...,\n",
       "         [ 78,  50,  64],\n",
       "         [ 78,  50,  64],\n",
       "         [ 78,  50,  64]],\n",
       " \n",
       "        [[119,  98, 126],\n",
       "         [119,  98, 126],\n",
       "         [119,  98, 126],\n",
       "         ...,\n",
       "         [ 80,  49,  64],\n",
       "         [ 80,  49,  64],\n",
       "         [ 80,  49,  64]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         ...,\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54]],\n",
       " \n",
       "        [[ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         ...,\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54]],\n",
       " \n",
       "        [[ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         [ 61,  53,  84],\n",
       "         ...,\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54],\n",
       "         [ 57,  40,  54]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2092999968444929, 'inference': 17.25280000391649, 'postprocess': 1.1738000030163676},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         ...,\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        [[136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         ...,\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        [[136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         ...,\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 59,  50,  84],\n",
       "         [ 59,  50,  84],\n",
       "         [ 59,  50,  84],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.065199998265598, 'inference': 14.381399996636901, 'postprocess': 1.1876999997184612},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         ...,\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        [[136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         ...,\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        [[136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         [136, 116, 147],\n",
       "         ...,\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         [ 61,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3429999962681904, 'inference': 14.80940000328701, 'postprocess': 0.9634000016376376},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[143, 125, 156],\n",
       "         [143, 125, 156],\n",
       "         [143, 125, 156],\n",
       "         ...,\n",
       "         [ 81,  50,  65],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        [[143, 125, 156],\n",
       "         [143, 125, 156],\n",
       "         [143, 125, 156],\n",
       "         ...,\n",
       "         [ 80,  49,  64],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        [[146, 125, 158],\n",
       "         [146, 125, 158],\n",
       "         [146, 125, 158],\n",
       "         ...,\n",
       "         [ 82,  48,  65],\n",
       "         [ 80,  49,  64],\n",
       "         [ 80,  49,  64]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         [ 64,  53,  84],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 64,  53,  84],\n",
       "         [ 64,  53,  84],\n",
       "         [ 64,  53,  84],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.065500000549946, 'inference': 22.85729999857722, 'postprocess': 2.6240000006509945},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[143, 125, 156],\n",
       "         [143, 125, 156],\n",
       "         [143, 125, 156],\n",
       "         ...,\n",
       "         [ 79,  48,  63],\n",
       "         [ 79,  51,  65],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        [[143, 125, 156],\n",
       "         [143, 125, 156],\n",
       "         [143, 125, 156],\n",
       "         ...,\n",
       "         [ 79,  48,  63],\n",
       "         [ 78,  50,  64],\n",
       "         [ 79,  51,  65]],\n",
       " \n",
       "        [[146, 125, 158],\n",
       "         [146, 125, 158],\n",
       "         [146, 125, 158],\n",
       "         ...,\n",
       "         [ 81,  47,  64],\n",
       "         [ 80,  49,  64],\n",
       "         [ 80,  49,  64]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         ...,\n",
       "         [ 58,  41,  57],\n",
       "         [ 58,  41,  57],\n",
       "         [ 58,  41,  57]],\n",
       " \n",
       "        [[ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         [ 62,  51,  82],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.605100002256222, 'inference': 25.30560000013793, 'postprocess': 0.9968000013031997},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[146, 123, 156],\n",
       "         [146, 123, 156],\n",
       "         [146, 123, 156],\n",
       "         ...,\n",
       "         [ 64,  35,  51],\n",
       "         [ 64,  35,  51],\n",
       "         [ 64,  35,  51]],\n",
       " \n",
       "        [[146, 123, 156],\n",
       "         [146, 123, 156],\n",
       "         [146, 123, 156],\n",
       "         ...,\n",
       "         [ 64,  35,  51],\n",
       "         [ 64,  35,  51],\n",
       "         [ 64,  35,  51]],\n",
       " \n",
       "        [[146, 123, 156],\n",
       "         [146, 123, 156],\n",
       "         [146, 123, 156],\n",
       "         ...,\n",
       "         [ 65,  36,  52],\n",
       "         [ 65,  36,  52],\n",
       "         [ 65,  36,  52]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         ...,\n",
       "         [ 58,  43,  59],\n",
       "         [ 58,  43,  59],\n",
       "         [ 58,  43,  59]],\n",
       " \n",
       "        [[ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8454000019119121, 'inference': 24.089999998977873, 'postprocess': 0.967800006037578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[144, 123, 156],\n",
       "         [144, 123, 156],\n",
       "         [142, 123, 156],\n",
       "         ...,\n",
       "         [ 60,  31,  47],\n",
       "         [ 63,  34,  50],\n",
       "         [ 64,  35,  51]],\n",
       " \n",
       "        [[144, 123, 156],\n",
       "         [144, 123, 156],\n",
       "         [142, 123, 156],\n",
       "         ...,\n",
       "         [ 60,  31,  47],\n",
       "         [ 63,  34,  50],\n",
       "         [ 64,  35,  51]],\n",
       " \n",
       "        [[144, 123, 156],\n",
       "         [144, 123, 156],\n",
       "         [142, 123, 156],\n",
       "         ...,\n",
       "         [ 61,  32,  48],\n",
       "         [ 64,  35,  51],\n",
       "         [ 65,  36,  52]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         ...,\n",
       "         [ 58,  43,  59],\n",
       "         [ 58,  43,  59],\n",
       "         [ 58,  43,  59]],\n",
       " \n",
       "        [[ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]],\n",
       " \n",
       "        [[ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         [ 64,  52,  86],\n",
       "         ...,\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57],\n",
       "         [ 56,  41,  57]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.592300002812408, 'inference': 21.36370000516763, 'postprocess': 1.3288000045577064},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[131, 109, 140],\n",
       "         [131, 109, 140],\n",
       "         [131, 109, 140],\n",
       "         ...,\n",
       "         [ 63,  36,  52],\n",
       "         [ 64,  37,  53],\n",
       "         [ 64,  37,  53]],\n",
       " \n",
       "        [[127, 105, 136],\n",
       "         [127, 105, 136],\n",
       "         [127, 105, 136],\n",
       "         ...,\n",
       "         [ 64,  37,  53],\n",
       "         [ 64,  37,  53],\n",
       "         [ 64,  37,  53]],\n",
       " \n",
       "        [[124, 102, 133],\n",
       "         [124, 102, 133],\n",
       "         [124, 102, 133],\n",
       "         ...,\n",
       "         [ 66,  37,  53],\n",
       "         [ 66,  37,  53],\n",
       "         [ 66,  37,  53]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 69,  53,  90],\n",
       "         [ 69,  53,  90],\n",
       "         [ 69,  53,  90],\n",
       "         ...,\n",
       "         [ 59,  44,  60],\n",
       "         [ 59,  44,  60],\n",
       "         [ 59,  44,  60]],\n",
       " \n",
       "        [[ 70,  54,  91],\n",
       "         [ 70,  54,  91],\n",
       "         [ 69,  53,  90],\n",
       "         ...,\n",
       "         [ 58,  43,  59],\n",
       "         [ 58,  43,  59],\n",
       "         [ 58,  43,  59]],\n",
       " \n",
       "        [[ 70,  54,  91],\n",
       "         [ 70,  54,  91],\n",
       "         [ 69,  53,  90],\n",
       "         ...,\n",
       "         [ 58,  43,  59],\n",
       "         [ 58,  43,  59],\n",
       "         [ 58,  43,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7285000067204237, 'inference': 22.414800005208235, 'postprocess': 1.3040000048931688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[131, 109, 140],\n",
       "         [131, 109, 140],\n",
       "         [129, 107, 138],\n",
       "         ...,\n",
       "         [ 63,  36,  52],\n",
       "         [ 63,  36,  52],\n",
       "         [ 64,  37,  53]],\n",
       " \n",
       "        [[127, 105, 136],\n",
       "         [127, 105, 136],\n",
       "         [125, 103, 134],\n",
       "         ...,\n",
       "         [ 63,  36,  52],\n",
       "         [ 64,  37,  53],\n",
       "         [ 64,  37,  53]],\n",
       " \n",
       "        [[125, 103, 134],\n",
       "         [124, 102, 133],\n",
       "         [124, 102, 133],\n",
       "         ...,\n",
       "         [ 64,  37,  53],\n",
       "         [ 66,  37,  53],\n",
       "         [ 66,  37,  53]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  52,  89],\n",
       "         [ 68,  52,  89],\n",
       "         [ 68,  52,  89],\n",
       "         ...,\n",
       "         [ 57,  44,  60],\n",
       "         [ 57,  44,  60],\n",
       "         [ 57,  44,  60]],\n",
       " \n",
       "        [[ 68,  52,  89],\n",
       "         [ 68,  52,  89],\n",
       "         [ 68,  52,  89],\n",
       "         ...,\n",
       "         [ 57,  44,  60],\n",
       "         [ 57,  44,  60],\n",
       "         [ 57,  44,  60]],\n",
       " \n",
       "        [[ 69,  53,  90],\n",
       "         [ 68,  52,  89],\n",
       "         [ 68,  52,  89],\n",
       "         ...,\n",
       "         [ 57,  44,  60],\n",
       "         [ 57,  44,  60],\n",
       "         [ 57,  44,  60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6309999991790392, 'inference': 21.708799999032635, 'postprocess': 1.087999997253064},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[112,  88, 117],\n",
       "         [112,  88, 117],\n",
       "         [112,  88, 117],\n",
       "         ...,\n",
       "         [ 47,  39,  52],\n",
       "         [ 47,  40,  51],\n",
       "         [ 47,  40,  51]],\n",
       " \n",
       "        [[108,  84, 113],\n",
       "         [108,  84, 113],\n",
       "         [109,  85, 114],\n",
       "         ...,\n",
       "         [ 47,  39,  52],\n",
       "         [ 47,  40,  51],\n",
       "         [ 47,  40,  51]],\n",
       " \n",
       "        [[106,  82, 111],\n",
       "         [106,  82, 111],\n",
       "         [107,  83, 112],\n",
       "         ...,\n",
       "         [ 51,  38,  52],\n",
       "         [ 51,  38,  52],\n",
       "         [ 51,  38,  52]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 92,  77, 112],\n",
       "         [ 93,  78, 113],\n",
       "         [ 95,  80, 115],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[ 97,  82, 117],\n",
       "         [ 98,  83, 118],\n",
       "         [ 99,  84, 119],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[102,  87, 122],\n",
       "         [103,  88, 123],\n",
       "         [104,  89, 124],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.126699997461401, 'inference': 21.474000001035165, 'postprocess': 3.096999993431382},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[110,  89, 117],\n",
       "         [111,  90, 118],\n",
       "         [112,  91, 119],\n",
       "         ...,\n",
       "         [ 47,  39,  52],\n",
       "         [ 47,  40,  51],\n",
       "         [ 47,  40,  51]],\n",
       " \n",
       "        [[107,  86, 114],\n",
       "         [107,  86, 114],\n",
       "         [110,  89, 117],\n",
       "         ...,\n",
       "         [ 47,  39,  52],\n",
       "         [ 47,  40,  51],\n",
       "         [ 47,  40,  51]],\n",
       " \n",
       "        [[104,  83, 111],\n",
       "         [106,  85, 113],\n",
       "         [107,  86, 114],\n",
       "         ...,\n",
       "         [ 51,  38,  52],\n",
       "         [ 51,  38,  52],\n",
       "         [ 51,  38,  52]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 87,  71, 108],\n",
       "         [ 89,  73, 110],\n",
       "         [ 91,  75, 112],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[ 91,  75, 112],\n",
       "         [ 93,  77, 114],\n",
       "         [ 95,  79, 116],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[ 97,  81, 118],\n",
       "         [ 98,  82, 119],\n",
       "         [ 99,  83, 120],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1716999981435947, 'inference': 21.917299993219785, 'postprocess': 3.3178000012412667},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 51,  34,  62],\n",
       "         [ 51,  34,  62],\n",
       "         [ 52,  35,  63],\n",
       "         ...,\n",
       "         [ 57,  32,  48],\n",
       "         [ 55,  33,  48],\n",
       "         [ 55,  33,  48]],\n",
       " \n",
       "        [[ 50,  33,  61],\n",
       "         [ 50,  33,  61],\n",
       "         [ 52,  35,  63],\n",
       "         ...,\n",
       "         [ 59,  34,  50],\n",
       "         [ 57,  35,  50],\n",
       "         [ 57,  35,  50]],\n",
       " \n",
       "        [[ 52,  35,  63],\n",
       "         [ 52,  35,  63],\n",
       "         [ 52,  35,  63],\n",
       "         ...,\n",
       "         [ 59,  34,  50],\n",
       "         [ 57,  35,  50],\n",
       "         [ 57,  35,  50]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9590000010794029, 'inference': 21.64920000359416, 'postprocess': 5.7014999983948655},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 51,  34,  62],\n",
       "         [ 51,  34,  62],\n",
       "         [ 52,  35,  63],\n",
       "         ...,\n",
       "         [ 57,  32,  48],\n",
       "         [ 55,  33,  48],\n",
       "         [ 55,  33,  48]],\n",
       " \n",
       "        [[ 50,  33,  61],\n",
       "         [ 52,  35,  63],\n",
       "         [ 52,  35,  63],\n",
       "         ...,\n",
       "         [ 59,  34,  50],\n",
       "         [ 57,  35,  50],\n",
       "         [ 57,  35,  50]],\n",
       " \n",
       "        [[ 50,  33,  61],\n",
       "         [ 52,  35,  63],\n",
       "         [ 52,  35,  63],\n",
       "         ...,\n",
       "         [ 59,  34,  50],\n",
       "         [ 57,  35,  50],\n",
       "         [ 57,  35,  50]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[110,  96, 135],\n",
       "         [110,  96, 135],\n",
       "         [110,  96, 135],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[109,  95, 134],\n",
       "         [109,  95, 134],\n",
       "         [109,  95, 134],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         [109,  95, 134],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4594999956898391, 'inference': 22.587399995245505, 'postprocess': 2.8684999997494742},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 56,  43,  73],\n",
       "         [ 56,  43,  73],\n",
       "         [ 56,  43,  73],\n",
       "         ...,\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44]],\n",
       " \n",
       "        [[ 59,  46,  76],\n",
       "         [ 59,  46,  76],\n",
       "         [ 59,  46,  76],\n",
       "         ...,\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44]],\n",
       " \n",
       "        [[ 57,  48,  74],\n",
       "         [ 57,  48,  74],\n",
       "         [ 55,  46,  72],\n",
       "         ...,\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[107,  93, 132],\n",
       "         [107,  93, 132],\n",
       "         [107,  93, 132],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.322699994489085, 'inference': 21.783700001833495, 'postprocess': 1.9148999999742955},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 56,  43,  73],\n",
       "         [ 56,  43,  73],\n",
       "         [ 55,  42,  72],\n",
       "         ...,\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44]],\n",
       " \n",
       "        [[ 59,  46,  76],\n",
       "         [ 57,  44,  74],\n",
       "         [ 57,  44,  74],\n",
       "         ...,\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44]],\n",
       " \n",
       "        [[ 57,  48,  74],\n",
       "         [ 55,  46,  72],\n",
       "         [ 57,  48,  74],\n",
       "         ...,\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44],\n",
       "         [ 55,  28,  44]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]],\n",
       " \n",
       "        [[105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         [105,  91, 130],\n",
       "         ...,\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61],\n",
       "         [ 58,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.21770000300603, 'inference': 31.04870000242954, 'postprocess': 5.250900001556147},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         ...,\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43]],\n",
       " \n",
       "        [[ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         ...,\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43]],\n",
       " \n",
       "        [[ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         ...,\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[110,  96, 137],\n",
       "         [110,  96, 137],\n",
       "         [110,  96, 137],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]],\n",
       " \n",
       "        [[110,  96, 137],\n",
       "         [110,  96, 137],\n",
       "         [110,  96, 137],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]],\n",
       " \n",
       "        [[110,  96, 137],\n",
       "         [110,  96, 137],\n",
       "         [110,  96, 137],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7256999999517575, 'inference': 21.680300000298303, 'postprocess': 5.016000002797227},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         [ 75,  66,  92],\n",
       "         ...,\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43]],\n",
       " \n",
       "        [[ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         [ 75,  66,  92],\n",
       "         ...,\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43]],\n",
       " \n",
       "        [[ 75,  66,  90],\n",
       "         [ 75,  66,  90],\n",
       "         [ 75,  66,  92],\n",
       "         ...,\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43],\n",
       "         [ 56,  27,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[110,  96, 135],\n",
       "         [110,  96, 135],\n",
       "         [110,  96, 135],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]],\n",
       " \n",
       "        [[110,  96, 135],\n",
       "         [110,  96, 135],\n",
       "         [110,  96, 135],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]],\n",
       " \n",
       "        [[110,  96, 135],\n",
       "         [110,  96, 135],\n",
       "         [110,  96, 135],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.078900004562456, 'inference': 21.74650000233669, 'postprocess': 2.039499995589722},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 70,  65,  94],\n",
       "         [ 70,  65,  94],\n",
       "         [ 70,  65,  94],\n",
       "         ...,\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43]],\n",
       " \n",
       "        [[ 70,  65,  94],\n",
       "         [ 70,  65,  94],\n",
       "         [ 69,  64,  93],\n",
       "         ...,\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43]],\n",
       " \n",
       "        [[ 70,  65,  94],\n",
       "         [ 70,  65,  94],\n",
       "         [ 69,  64,  93],\n",
       "         ...,\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]],\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]],\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.826199993956834, 'inference': 21.7147000003024, 'postprocess': 1.9589000003179535},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 69,  64,  93],\n",
       "         [ 68,  63,  92],\n",
       "         [ 68,  63,  92],\n",
       "         ...,\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43]],\n",
       " \n",
       "        [[ 69,  64,  93],\n",
       "         [ 67,  62,  91],\n",
       "         [ 69,  64,  93],\n",
       "         ...,\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43]],\n",
       " \n",
       "        [[ 69,  64,  93],\n",
       "         [ 68,  63,  92],\n",
       "         [ 69,  64,  93],\n",
       "         ...,\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43],\n",
       "         [ 58,  26,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]],\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]],\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61],\n",
       "         [ 60,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7041999963112175, 'inference': 22.032900000340305, 'postprocess': 0.9142999988398515},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 81,  76, 105],\n",
       "         [ 81,  76, 105],\n",
       "         [ 80,  75, 104],\n",
       "         ...,\n",
       "         [ 64,  27,  47],\n",
       "         [ 64,  27,  47],\n",
       "         [ 64,  27,  47]],\n",
       " \n",
       "        [[ 81,  76, 105],\n",
       "         [ 81,  76, 105],\n",
       "         [ 81,  76, 105],\n",
       "         ...,\n",
       "         [ 64,  27,  47],\n",
       "         [ 64,  27,  47],\n",
       "         [ 64,  27,  47]],\n",
       " \n",
       "        [[ 79,  77, 105],\n",
       "         [ 79,  77, 105],\n",
       "         [ 79,  77, 105],\n",
       "         ...,\n",
       "         [ 60,  28,  47],\n",
       "         [ 60,  28,  47],\n",
       "         [ 60,  28,  47]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61]],\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61]],\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.161199998226948, 'inference': 22.05130000220379, 'postprocess': 3.188199996657204},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 81,  76, 105],\n",
       "         [ 78,  73, 102],\n",
       "         [ 77,  72, 101],\n",
       "         ...,\n",
       "         [ 64,  27,  47],\n",
       "         [ 64,  27,  47],\n",
       "         [ 64,  27,  47]],\n",
       " \n",
       "        [[ 81,  76, 105],\n",
       "         [ 80,  75, 104],\n",
       "         [ 78,  73, 102],\n",
       "         ...,\n",
       "         [ 64,  27,  47],\n",
       "         [ 64,  27,  47],\n",
       "         [ 64,  27,  47]],\n",
       " \n",
       "        [[ 79,  77, 105],\n",
       "         [ 78,  76, 104],\n",
       "         [ 75,  73, 101],\n",
       "         ...,\n",
       "         [ 60,  28,  47],\n",
       "         [ 60,  28,  47],\n",
       "         [ 60,  28,  47]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61]],\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61]],\n",
       " \n",
       "        [[106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         [106,  95, 136],\n",
       "         ...,\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61],\n",
       "         [ 62,  45,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.564199999847915, 'inference': 23.747500003082678, 'postprocess': 1.7317999954684637},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 78,  76, 104],\n",
       "         [ 76,  74, 102],\n",
       "         [ 76,  74, 102],\n",
       "         ...,\n",
       "         [ 64,  30,  47],\n",
       "         [ 64,  30,  47],\n",
       "         [ 64,  30,  47]],\n",
       " \n",
       "        [[ 78,  76, 104],\n",
       "         [ 78,  76, 104],\n",
       "         [ 76,  74, 102],\n",
       "         ...,\n",
       "         [ 63,  29,  46],\n",
       "         [ 63,  29,  46],\n",
       "         [ 63,  29,  46]],\n",
       " \n",
       "        [[ 78,  76, 104],\n",
       "         [ 78,  76, 104],\n",
       "         [ 76,  74, 102],\n",
       "         ...,\n",
       "         [ 63,  29,  46],\n",
       "         [ 63,  29,  46],\n",
       "         [ 63,  29,  46]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         ...,\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59]],\n",
       " \n",
       "        [[108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         [109,  95, 136],\n",
       "         ...,\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59]],\n",
       " \n",
       "        [[108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         [109,  95, 136],\n",
       "         ...,\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.665000003820751, 'inference': 25.205499994626734, 'postprocess': 1.0349000003770925},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 76,  74, 102],\n",
       "         [ 76,  74, 102],\n",
       "         [ 75,  73, 101],\n",
       "         ...,\n",
       "         [ 66,  29,  47],\n",
       "         [ 64,  30,  47],\n",
       "         [ 64,  30,  47]],\n",
       " \n",
       "        [[ 78,  76, 104],\n",
       "         [ 75,  73, 101],\n",
       "         [ 75,  73, 101],\n",
       "         ...,\n",
       "         [ 65,  28,  46],\n",
       "         [ 63,  29,  46],\n",
       "         [ 63,  29,  46]],\n",
       " \n",
       "        [[ 78,  76, 104],\n",
       "         [ 76,  74, 102],\n",
       "         [ 74,  72, 100],\n",
       "         ...,\n",
       "         [ 65,  28,  46],\n",
       "         [ 63,  29,  46],\n",
       "         [ 63,  29,  46]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         [109,  95, 136],\n",
       "         ...,\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59]],\n",
       " \n",
       "        [[108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         [109,  95, 136],\n",
       "         ...,\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59]],\n",
       " \n",
       "        [[108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         [109,  95, 136],\n",
       "         ...,\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59],\n",
       "         [ 64,  44,  59]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1471000000019558, 'inference': 24.529200003598817, 'postprocess': 1.2788999956683256},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 71,  64,  93],\n",
       "         [ 70,  63,  92],\n",
       "         [ 70,  63,  92],\n",
       "         ...,\n",
       "         [ 57,  24,  39],\n",
       "         [ 57,  24,  39],\n",
       "         [ 57,  24,  39]],\n",
       " \n",
       "        [[ 72,  65,  94],\n",
       "         [ 71,  64,  93],\n",
       "         [ 71,  64,  93],\n",
       "         ...,\n",
       "         [ 57,  24,  39],\n",
       "         [ 57,  24,  39],\n",
       "         [ 57,  24,  39]],\n",
       " \n",
       "        [[ 73,  67,  93],\n",
       "         [ 72,  66,  92],\n",
       "         [ 72,  66,  92],\n",
       "         ...,\n",
       "         [ 55,  24,  39],\n",
       "         [ 55,  24,  39],\n",
       "         [ 55,  24,  39]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         [108,  94, 135],\n",
       "         ...,\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62]],\n",
       " \n",
       "        [[104,  93, 134],\n",
       "         [104,  93, 134],\n",
       "         [104,  93, 134],\n",
       "         ...,\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62]],\n",
       " \n",
       "        [[104,  93, 134],\n",
       "         [104,  93, 134],\n",
       "         [104,  93, 134],\n",
       "         ...,\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.319100000022445, 'inference': 22.1631999957026, 'postprocess': 1.8819999968400225},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 70,  63,  92],\n",
       "         [ 69,  62,  91],\n",
       "         [ 69,  62,  91],\n",
       "         ...,\n",
       "         [ 57,  24,  39],\n",
       "         [ 57,  24,  39],\n",
       "         [ 57,  24,  39]],\n",
       " \n",
       "        [[ 71,  64,  93],\n",
       "         [ 70,  63,  92],\n",
       "         [ 70,  63,  92],\n",
       "         ...,\n",
       "         [ 57,  24,  39],\n",
       "         [ 57,  24,  39],\n",
       "         [ 57,  24,  39]],\n",
       " \n",
       "        [[ 72,  66,  92],\n",
       "         [ 71,  65,  91],\n",
       "         [ 71,  64,  93],\n",
       "         ...,\n",
       "         [ 55,  24,  39],\n",
       "         [ 55,  24,  39],\n",
       "         [ 55,  24,  39]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         ...,\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61]],\n",
       " \n",
       "        [[108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         ...,\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62]],\n",
       " \n",
       "        [[108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         [108,  94, 133],\n",
       "         ...,\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.939699999638833, 'inference': 24.683099996764213, 'postprocess': 1.727099996060133},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         ...,\n",
       "         [ 47,  19,  33],\n",
       "         [ 47,  19,  33],\n",
       "         [ 47,  19,  33]],\n",
       " \n",
       "        [[ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         ...,\n",
       "         [ 49,  21,  35],\n",
       "         [ 49,  21,  35],\n",
       "         [ 49,  21,  35]],\n",
       " \n",
       "        [[ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         ...,\n",
       "         [ 50,  22,  36],\n",
       "         [ 50,  22,  36],\n",
       "         [ 50,  22,  36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 96,  82, 121],\n",
       "         [ 96,  82, 121],\n",
       "         [ 98,  84, 123],\n",
       "         ...,\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61]],\n",
       " \n",
       "        [[100,  86, 125],\n",
       "         [100,  86, 125],\n",
       "         [102,  88, 127],\n",
       "         ...,\n",
       "         [ 68,  46,  63],\n",
       "         [ 68,  46,  63],\n",
       "         [ 68,  46,  63]],\n",
       " \n",
       "        [[100,  86, 125],\n",
       "         [100,  86, 125],\n",
       "         [102,  88, 127],\n",
       "         ...,\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62],\n",
       "         [ 67,  45,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9052999996347353, 'inference': 26.80529999634018, 'postprocess': 1.981499997782521},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         [ 86,  77, 103],\n",
       "         ...,\n",
       "         [ 46,  18,  32],\n",
       "         [ 47,  19,  33],\n",
       "         [ 47,  19,  33]],\n",
       " \n",
       "        [[ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         [ 85,  76, 102],\n",
       "         ...,\n",
       "         [ 46,  18,  32],\n",
       "         [ 49,  21,  35],\n",
       "         [ 49,  21,  35]],\n",
       " \n",
       "        [[ 83,  74,  98],\n",
       "         [ 83,  74,  98],\n",
       "         [ 85,  76, 100],\n",
       "         ...,\n",
       "         [ 47,  19,  33],\n",
       "         [ 50,  22,  36],\n",
       "         [ 50,  22,  36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 94,  80, 119],\n",
       "         [ 95,  81, 120],\n",
       "         [ 98,  84, 123],\n",
       "         ...,\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61]],\n",
       " \n",
       "        [[ 96,  82, 121],\n",
       "         [ 98,  84, 123],\n",
       "         [101,  87, 126],\n",
       "         ...,\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61]],\n",
       " \n",
       "        [[ 98,  84, 123],\n",
       "         [100,  86, 125],\n",
       "         [101,  87, 126],\n",
       "         ...,\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61],\n",
       "         [ 68,  46,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.319400002306793, 'inference': 31.92020000278717, 'postprocess': 0.9160999979940243},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  80, 104],\n",
       "         [ 89,  80, 104],\n",
       "         [ 89,  80, 104],\n",
       "         ...,\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36]],\n",
       " \n",
       "        [[ 89,  80, 104],\n",
       "         [ 89,  80, 104],\n",
       "         [ 89,  80, 104],\n",
       "         ...,\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36]],\n",
       " \n",
       "        [[ 90,  81, 105],\n",
       "         [ 90,  81, 105],\n",
       "         [ 90,  81, 105],\n",
       "         ...,\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         ...,\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60]],\n",
       " \n",
       "        [[109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         ...,\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60]],\n",
       " \n",
       "        [[109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         ...,\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.661099995544646, 'inference': 22.601199998462107, 'postprocess': 1.6170000017154962},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  80, 104],\n",
       "         [ 89,  80, 104],\n",
       "         [ 89,  80, 104],\n",
       "         ...,\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36]],\n",
       " \n",
       "        [[ 89,  80, 104],\n",
       "         [ 89,  80, 104],\n",
       "         [ 90,  81, 105],\n",
       "         ...,\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36]],\n",
       " \n",
       "        [[ 89,  80, 104],\n",
       "         [ 90,  81, 105],\n",
       "         [ 91,  82, 106],\n",
       "         ...,\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36],\n",
       "         [ 56,  20,  36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         ...,\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61]],\n",
       " \n",
       "        [[109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         ...,\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60]],\n",
       " \n",
       "        [[109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         [109,  92, 132],\n",
       "         ...,\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60],\n",
       "         [ 68,  47,  60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.067500005068723, 'inference': 33.16869999980554, 'postprocess': 3.0035999952815473},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         ...,\n",
       "         [ 77,  28,  43],\n",
       "         [ 75,  28,  43],\n",
       "         [ 75,  28,  43]],\n",
       " \n",
       "        [[ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         ...,\n",
       "         [ 77,  28,  43],\n",
       "         [ 75,  28,  43],\n",
       "         [ 75,  28,  43]],\n",
       " \n",
       "        [[ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         ...,\n",
       "         [ 75,  28,  43],\n",
       "         [ 75,  28,  43],\n",
       "         [ 75,  28,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         ...,\n",
       "         [ 70,  45,  61],\n",
       "         [ 70,  45,  61],\n",
       "         [ 70,  45,  61]],\n",
       " \n",
       "        [[109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         ...,\n",
       "         [ 69,  44,  60],\n",
       "         [ 69,  44,  60],\n",
       "         [ 69,  44,  60]],\n",
       " \n",
       "        [[109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         ...,\n",
       "         [ 69,  44,  60],\n",
       "         [ 69,  44,  60],\n",
       "         [ 69,  44,  60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.4960000009741634, 'inference': 31.064599999808706, 'postprocess': 0.8818999995128252},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         [100,  93, 112],\n",
       "         ...,\n",
       "         [ 77,  28,  43],\n",
       "         [ 77,  28,  43],\n",
       "         [ 77,  28,  43]],\n",
       " \n",
       "        [[ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         [100,  93, 112],\n",
       "         ...,\n",
       "         [ 77,  28,  43],\n",
       "         [ 77,  28,  43],\n",
       "         [ 77,  28,  43]],\n",
       " \n",
       "        [[ 98,  91, 110],\n",
       "         [ 98,  91, 110],\n",
       "         [100,  93, 112],\n",
       "         ...,\n",
       "         [ 77,  28,  43],\n",
       "         [ 75,  28,  43],\n",
       "         [ 75,  28,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         [110,  93, 135],\n",
       "         ...,\n",
       "         [ 70,  45,  61],\n",
       "         [ 70,  45,  61],\n",
       "         [ 70,  45,  61]],\n",
       " \n",
       "        [[109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         [110,  93, 135],\n",
       "         ...,\n",
       "         [ 70,  45,  61],\n",
       "         [ 70,  45,  61],\n",
       "         [ 70,  45,  61]],\n",
       " \n",
       "        [[109,  92, 134],\n",
       "         [109,  92, 134],\n",
       "         [110,  93, 135],\n",
       "         ...,\n",
       "         [ 70,  45,  61],\n",
       "         [ 69,  44,  60],\n",
       "         [ 69,  44,  60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.711900000576861, 'inference': 30.542000000423286, 'postprocess': 1.033200001984369},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[105,  96, 120],\n",
       "         [107,  98, 122],\n",
       "         [108,  99, 123],\n",
       "         ...,\n",
       "         [ 71,  20,  35],\n",
       "         [ 72,  21,  36],\n",
       "         [ 72,  21,  36]],\n",
       " \n",
       "        [[105,  96, 120],\n",
       "         [108,  99, 123],\n",
       "         [108,  99, 123],\n",
       "         ...,\n",
       "         [ 71,  20,  35],\n",
       "         [ 71,  20,  35],\n",
       "         [ 72,  21,  36]],\n",
       " \n",
       "        [[107,  98, 124],\n",
       "         [108,  99, 125],\n",
       "         [108,  99, 125],\n",
       "         ...,\n",
       "         [ 71,  20,  35],\n",
       "         [ 71,  20,  35],\n",
       "         [ 71,  20,  35]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         ...,\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60]],\n",
       " \n",
       "        [[106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         ...,\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60]],\n",
       " \n",
       "        [[106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         ...,\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.876100002846215, 'inference': 25.52760000253329, 'postprocess': 1.2742000035359524},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[108,  99, 123],\n",
       "         [108,  99, 123],\n",
       "         [109, 100, 124],\n",
       "         ...,\n",
       "         [ 71,  20,  35],\n",
       "         [ 71,  20,  35],\n",
       "         [ 72,  21,  36]],\n",
       " \n",
       "        [[108,  99, 123],\n",
       "         [109, 100, 124],\n",
       "         [110, 101, 125],\n",
       "         ...,\n",
       "         [ 71,  20,  35],\n",
       "         [ 71,  20,  35],\n",
       "         [ 71,  20,  35]],\n",
       " \n",
       "        [[108,  99, 125],\n",
       "         [110, 101, 127],\n",
       "         [111, 102, 128],\n",
       "         ...,\n",
       "         [ 70,  19,  34],\n",
       "         [ 71,  20,  35],\n",
       "         [ 71,  20,  35]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[107,  90, 132],\n",
       "         [107,  90, 132],\n",
       "         [107,  90, 132],\n",
       "         ...,\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60]],\n",
       " \n",
       "        [[106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         ...,\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60]],\n",
       " \n",
       "        [[106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         [106,  89, 131],\n",
       "         ...,\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60],\n",
       "         [ 65,  45,  60]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6424000059487298, 'inference': 22.998599997663405, 'postprocess': 1.5802999987499788},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[112, 103, 129],\n",
       "         [112, 103, 129],\n",
       "         [114, 105, 131],\n",
       "         ...,\n",
       "         [ 71,  17,  28],\n",
       "         [ 69,  17,  28],\n",
       "         [ 69,  17,  28]],\n",
       " \n",
       "        [[112, 103, 129],\n",
       "         [112, 103, 129],\n",
       "         [114, 105, 131],\n",
       "         ...,\n",
       "         [ 71,  17,  28],\n",
       "         [ 69,  17,  28],\n",
       "         [ 71,  19,  30]],\n",
       " \n",
       "        [[114, 105, 131],\n",
       "         [114, 105, 131],\n",
       "         [114, 105, 131],\n",
       "         ...,\n",
       "         [ 71,  17,  28],\n",
       "         [ 69,  17,  28],\n",
       "         [ 71,  19,  30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         ...,\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61]],\n",
       " \n",
       "        [[109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         ...,\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61],\n",
       "         [ 71,  50,  63]],\n",
       " \n",
       "        [[109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         ...,\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5578999955323525, 'inference': 22.994099999777973, 'postprocess': 1.7920000027515925},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[112, 103, 129],\n",
       "         [112, 103, 129],\n",
       "         [114, 105, 131],\n",
       "         ...,\n",
       "         [ 71,  17,  28],\n",
       "         [ 69,  17,  28],\n",
       "         [ 69,  17,  28]],\n",
       " \n",
       "        [[112, 103, 129],\n",
       "         [112, 103, 129],\n",
       "         [114, 105, 131],\n",
       "         ...,\n",
       "         [ 71,  17,  28],\n",
       "         [ 69,  17,  28],\n",
       "         [ 71,  19,  30]],\n",
       " \n",
       "        [[114, 105, 131],\n",
       "         [114, 105, 131],\n",
       "         [114, 105, 131],\n",
       "         ...,\n",
       "         [ 73,  19,  30],\n",
       "         [ 69,  17,  28],\n",
       "         [ 71,  19,  30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109,  90, 132],\n",
       "         [109,  90, 132],\n",
       "         [109,  90, 132],\n",
       "         ...,\n",
       "         [ 71,  50,  63],\n",
       "         [ 71,  50,  63],\n",
       "         [ 71,  50,  63]],\n",
       " \n",
       "        [[109,  90, 132],\n",
       "         [109,  90, 132],\n",
       "         [109,  90, 132],\n",
       "         ...,\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61]],\n",
       " \n",
       "        [[109,  90, 132],\n",
       "         [109,  90, 132],\n",
       "         [109,  90, 132],\n",
       "         ...,\n",
       "         [ 69,  48,  61],\n",
       "         [ 69,  48,  61],\n",
       "         [ 71,  50,  63]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3646000006701797, 'inference': 22.76249999704305, 'postprocess': 1.6823999976622872},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[129, 120, 146],\n",
       "         [129, 120, 146],\n",
       "         [130, 121, 147],\n",
       "         ...,\n",
       "         [ 64,  10,  26],\n",
       "         [ 64,  10,  26],\n",
       "         [ 64,  10,  26]],\n",
       " \n",
       "        [[130, 121, 147],\n",
       "         [130, 121, 147],\n",
       "         [130, 121, 147],\n",
       "         ...,\n",
       "         [ 65,  11,  27],\n",
       "         [ 65,  11,  27],\n",
       "         [ 65,  11,  27]],\n",
       " \n",
       "        [[131, 122, 148],\n",
       "         [132, 123, 149],\n",
       "         [131, 122, 148],\n",
       "         ...,\n",
       "         [ 65,  10,  29],\n",
       "         [ 65,  10,  29],\n",
       "         [ 65,  10,  29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[111,  91, 135],\n",
       "         [111,  91, 135],\n",
       "         [111,  91, 135],\n",
       "         ...,\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64]],\n",
       " \n",
       "        [[109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         ...,\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64]],\n",
       " \n",
       "        [[109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         [109,  89, 133],\n",
       "         ...,\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.490199996624142, 'inference': 23.085799999535084, 'postprocess': 1.2659999993047677},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[129, 120, 146],\n",
       "         [130, 121, 147],\n",
       "         [129, 120, 146],\n",
       "         ...,\n",
       "         [ 62,  11,  26],\n",
       "         [ 64,  10,  26],\n",
       "         [ 64,  10,  26]],\n",
       " \n",
       "        [[130, 121, 147],\n",
       "         [130, 121, 147],\n",
       "         [130, 121, 147],\n",
       "         ...,\n",
       "         [ 63,  12,  27],\n",
       "         [ 65,  11,  27],\n",
       "         [ 65,  11,  27]],\n",
       " \n",
       "        [[132, 123, 149],\n",
       "         [131, 122, 148],\n",
       "         [131, 122, 148],\n",
       "         ...,\n",
       "         [ 64,  12,  30],\n",
       "         [ 65,  10,  29],\n",
       "         [ 65,  10,  29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[111,  91, 135],\n",
       "         [111,  91, 135],\n",
       "         [111,  91, 135],\n",
       "         ...,\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64]],\n",
       " \n",
       "        [[111,  91, 135],\n",
       "         [111,  91, 135],\n",
       "         [111,  91, 135],\n",
       "         ...,\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64]],\n",
       " \n",
       "        [[111,  91, 135],\n",
       "         [111,  91, 135],\n",
       "         [111,  91, 135],\n",
       "         ...,\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64],\n",
       "         [ 72,  51,  64]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4503999991575256, 'inference': 22.817500001110602, 'postprocess': 1.1990999992121942},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[137, 123, 150],\n",
       "         [139, 125, 152],\n",
       "         [139, 125, 152],\n",
       "         ...,\n",
       "         [ 99,  49, 106],\n",
       "         [100,  51, 105],\n",
       "         [101,  52, 106]],\n",
       " \n",
       "        [[140, 126, 153],\n",
       "         [141, 127, 154],\n",
       "         [141, 127, 154],\n",
       "         ...,\n",
       "         [ 99,  49, 106],\n",
       "         [100,  51, 105],\n",
       "         [101,  52, 106]],\n",
       " \n",
       "        [[141, 127, 154],\n",
       "         [142, 128, 155],\n",
       "         [143, 129, 156],\n",
       "         ...,\n",
       "         [ 97,  48, 111],\n",
       "         [ 98,  50, 110],\n",
       "         [ 99,  51, 111]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[111,  87, 130],\n",
       "         [112,  88, 131],\n",
       "         [111,  87, 130],\n",
       "         ...,\n",
       "         [ 75,  51,  65],\n",
       "         [ 76,  52,  66],\n",
       "         [ 76,  52,  66]],\n",
       " \n",
       "        [[111,  87, 130],\n",
       "         [111,  87, 130],\n",
       "         [111,  87, 130],\n",
       "         ...,\n",
       "         [ 74,  50,  64],\n",
       "         [ 75,  51,  65],\n",
       "         [ 75,  51,  65]],\n",
       " \n",
       "        [[110,  86, 129],\n",
       "         [111,  87, 130],\n",
       "         [111,  87, 130],\n",
       "         ...,\n",
       "         [ 71,  47,  61],\n",
       "         [ 73,  49,  63],\n",
       "         [ 73,  49,  63]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6901000053621829, 'inference': 22.96129999740515, 'postprocess': 1.1723999996320345},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[136, 121, 151],\n",
       "         [139, 124, 154],\n",
       "         [137, 125, 152],\n",
       "         ...,\n",
       "         [ 93,  46, 109],\n",
       "         [ 96,  49, 107],\n",
       "         [ 98,  51, 109]],\n",
       " \n",
       "        [[139, 124, 154],\n",
       "         [140, 125, 155],\n",
       "         [138, 126, 153],\n",
       "         ...,\n",
       "         [ 93,  46, 109],\n",
       "         [ 96,  49, 107],\n",
       "         [ 98,  51, 109]],\n",
       " \n",
       "        [[141, 126, 156],\n",
       "         [142, 127, 157],\n",
       "         [140, 128, 155],\n",
       "         ...,\n",
       "         [ 96,  47, 110],\n",
       "         [ 95,  49, 109],\n",
       "         [ 97,  51, 111]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[112,  88, 131],\n",
       "         [112,  88, 131],\n",
       "         [112,  88, 131],\n",
       "         ...,\n",
       "         [ 78,  52,  66],\n",
       "         [ 77,  54,  65],\n",
       "         [ 77,  54,  65]],\n",
       " \n",
       "        [[112,  88, 131],\n",
       "         [112,  88, 131],\n",
       "         [112,  88, 131],\n",
       "         ...,\n",
       "         [ 78,  52,  66],\n",
       "         [ 77,  54,  65],\n",
       "         [ 77,  54,  65]],\n",
       " \n",
       "        [[111,  87, 130],\n",
       "         [111,  87, 130],\n",
       "         [111,  87, 130],\n",
       "         ...,\n",
       "         [ 77,  51,  65],\n",
       "         [ 76,  53,  64],\n",
       "         [ 76,  53,  64]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8935000043711625, 'inference': 21.728799998527393, 'postprocess': 0.9232999946107157},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[158, 144, 171],\n",
       "         [158, 144, 171],\n",
       "         [155, 143, 168],\n",
       "         ...,\n",
       "         [ 54,   4, 103],\n",
       "         [ 56,   3, 103],\n",
       "         [ 56,   3, 103]],\n",
       " \n",
       "        [[160, 146, 173],\n",
       "         [160, 146, 173],\n",
       "         [158, 146, 171],\n",
       "         ...,\n",
       "         [ 54,   4, 103],\n",
       "         [ 56,   3, 103],\n",
       "         [ 56,   3, 103]],\n",
       " \n",
       "        [[162, 148, 175],\n",
       "         [162, 148, 175],\n",
       "         [160, 148, 173],\n",
       "         ...,\n",
       "         [ 54,   3, 105],\n",
       "         [ 56,   2, 105],\n",
       "         [ 56,   2, 105]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[111,  86, 124],\n",
       "         [111,  86, 124],\n",
       "         [109,  86, 124],\n",
       "         ...,\n",
       "         [ 74,  46,  60],\n",
       "         [ 72,  47,  58],\n",
       "         [ 72,  47,  58]],\n",
       " \n",
       "        [[111,  86, 124],\n",
       "         [111,  86, 124],\n",
       "         [109,  86, 124],\n",
       "         ...,\n",
       "         [ 74,  46,  60],\n",
       "         [ 72,  47,  58],\n",
       "         [ 72,  47,  58]],\n",
       " \n",
       "        [[111,  86, 124],\n",
       "         [111,  86, 124],\n",
       "         [109,  86, 124],\n",
       "         ...,\n",
       "         [ 74,  46,  60],\n",
       "         [ 72,  47,  58],\n",
       "         [ 72,  47,  58]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 5.336299996997695, 'inference': 36.3260000012815, 'postprocess': 1.204100000904873},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[157, 143, 170],\n",
       "         [157, 143, 170],\n",
       "         [153, 141, 166],\n",
       "         ...,\n",
       "         [ 54,   3, 105],\n",
       "         [ 56,   3, 103],\n",
       "         [ 56,   3, 103]],\n",
       " \n",
       "        [[160, 146, 173],\n",
       "         [160, 146, 173],\n",
       "         [158, 146, 171],\n",
       "         ...,\n",
       "         [ 54,   3, 105],\n",
       "         [ 56,   3, 103],\n",
       "         [ 56,   3, 103]],\n",
       " \n",
       "        [[162, 148, 175],\n",
       "         [162, 148, 175],\n",
       "         [160, 148, 173],\n",
       "         ...,\n",
       "         [ 54,   2, 107],\n",
       "         [ 56,   2, 105],\n",
       "         [ 56,   2, 105]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[111,  86, 124],\n",
       "         [111,  86, 124],\n",
       "         [109,  86, 124],\n",
       "         ...,\n",
       "         [ 73,  45,  59],\n",
       "         [ 72,  47,  58],\n",
       "         [ 72,  47,  58]],\n",
       " \n",
       "        [[111,  86, 124],\n",
       "         [111,  86, 124],\n",
       "         [109,  86, 124],\n",
       "         ...,\n",
       "         [ 73,  45,  59],\n",
       "         [ 72,  47,  58],\n",
       "         [ 72,  47,  58]],\n",
       " \n",
       "        [[111,  86, 124],\n",
       "         [111,  86, 124],\n",
       "         [109,  86, 124],\n",
       "         ...,\n",
       "         [ 73,  45,  59],\n",
       "         [ 72,  47,  58],\n",
       "         [ 72,  47,  58]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.832900001318194, 'inference': 23.43509999627713, 'postprocess': 1.6925999952945858},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[158, 144, 176],\n",
       "         [158, 144, 176],\n",
       "         [158, 145, 175],\n",
       "         ...,\n",
       "         [ 51,  17,  34],\n",
       "         [ 49,  17,  34],\n",
       "         [ 49,  17,  34]],\n",
       " \n",
       "        [[158, 144, 176],\n",
       "         [158, 144, 176],\n",
       "         [158, 145, 175],\n",
       "         ...,\n",
       "         [ 51,  17,  34],\n",
       "         [ 49,  17,  34],\n",
       "         [ 49,  17,  34]],\n",
       " \n",
       "        [[158, 144, 176],\n",
       "         [158, 144, 176],\n",
       "         [158, 145, 175],\n",
       "         ...,\n",
       "         [ 51,  17,  34],\n",
       "         [ 49,  17,  34],\n",
       "         [ 49,  17,  34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 48,  22,  51],\n",
       "         [ 48,  22,  51],\n",
       "         ...,\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228]],\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 48,  22,  51],\n",
       "         [ 48,  22,  51],\n",
       "         ...,\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228]],\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 48,  22,  51],\n",
       "         [ 48,  22,  51],\n",
       "         ...,\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.21350000356324, 'inference': 26.279399993654806, 'postprocess': 4.540499998256564},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[158, 144, 176],\n",
       "         [158, 144, 176],\n",
       "         [158, 145, 175],\n",
       "         ...,\n",
       "         [ 49,  20,  38],\n",
       "         [ 51,  19,  38],\n",
       "         [ 49,  17,  36]],\n",
       " \n",
       "        [[158, 144, 176],\n",
       "         [158, 144, 176],\n",
       "         [158, 145, 175],\n",
       "         ...,\n",
       "         [ 49,  20,  38],\n",
       "         [ 51,  19,  38],\n",
       "         [ 49,  17,  36]],\n",
       " \n",
       "        [[158, 144, 176],\n",
       "         [158, 144, 176],\n",
       "         [158, 145, 175],\n",
       "         ...,\n",
       "         [ 49,  20,  38],\n",
       "         [ 51,  19,  38],\n",
       "         [ 49,  17,  36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228]],\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228]],\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228],\n",
       "         [185, 151, 228]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.457899998058565, 'inference': 27.46330000081798, 'postprocess': 5.790700000943616},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[139, 128, 159],\n",
       "         [139, 128, 159],\n",
       "         [139, 128, 159],\n",
       "         ...,\n",
       "         [ 43,  23,  40],\n",
       "         [ 43,  22,  42],\n",
       "         [ 42,  21,  41]],\n",
       " \n",
       "        [[138, 127, 158],\n",
       "         [139, 128, 159],\n",
       "         [139, 128, 159],\n",
       "         ...,\n",
       "         [ 43,  23,  40],\n",
       "         [ 43,  22,  42],\n",
       "         [ 42,  21,  41]],\n",
       " \n",
       "        [[136, 128, 159],\n",
       "         [137, 129, 160],\n",
       "         [140, 129, 160],\n",
       "         ...,\n",
       "         [ 43,  23,  40],\n",
       "         [ 43,  22,  42],\n",
       "         [ 42,  21,  41]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 152, 229],\n",
       "         [186, 152, 229],\n",
       "         [186, 152, 229]],\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 152, 229],\n",
       "         [186, 152, 229],\n",
       "         [186, 152, 229]],\n",
       " \n",
       "        [[ 48,  22,  51],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 152, 229],\n",
       "         [186, 152, 229],\n",
       "         [186, 152, 229]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4021000024513341, 'inference': 26.581099999020807, 'postprocess': 8.067000002483837},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[142, 131, 162],\n",
       "         [142, 131, 162],\n",
       "         [143, 132, 163],\n",
       "         ...,\n",
       "         [ 42,  24,  43],\n",
       "         [ 42,  23,  44],\n",
       "         [ 42,  23,  44]],\n",
       " \n",
       "        [[140, 129, 160],\n",
       "         [140, 129, 160],\n",
       "         [142, 131, 162],\n",
       "         ...,\n",
       "         [ 42,  24,  43],\n",
       "         [ 42,  23,  44],\n",
       "         [ 42,  23,  44]],\n",
       " \n",
       "        [[140, 129, 160],\n",
       "         [140, 129, 160],\n",
       "         [142, 131, 162],\n",
       "         ...,\n",
       "         [ 42,  24,  43],\n",
       "         [ 42,  23,  44],\n",
       "         [ 42,  23,  44]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 153, 227],\n",
       "         [188, 153, 227],\n",
       "         [188, 153, 227]],\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 153, 227],\n",
       "         [188, 153, 227],\n",
       "         [188, 153, 227]],\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 153, 227],\n",
       "         [188, 153, 227],\n",
       "         [188, 153, 227]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9038000027649105, 'inference': 24.868399996194057, 'postprocess': 3.3578000002307817},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[146, 135, 166],\n",
       "         [146, 135, 166],\n",
       "         [145, 135, 164],\n",
       "         ...,\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45]],\n",
       " \n",
       "        [[145, 134, 165],\n",
       "         [143, 132, 163],\n",
       "         [144, 134, 163],\n",
       "         ...,\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45]],\n",
       " \n",
       "        [[144, 133, 164],\n",
       "         [143, 132, 163],\n",
       "         [143, 133, 162],\n",
       "         ...,\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 151, 225],\n",
       "         [184, 149, 223],\n",
       "         [186, 151, 225]],\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 151, 225],\n",
       "         [184, 149, 223],\n",
       "         [186, 151, 225]],\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 151, 225],\n",
       "         [184, 149, 223],\n",
       "         [186, 151, 225]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3928999978816137, 'inference': 21.836899999470916, 'postprocess': 2.213100000517443},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[147, 133, 165],\n",
       "         [146, 132, 164],\n",
       "         [145, 131, 163],\n",
       "         ...,\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45]],\n",
       " \n",
       "        [[145, 131, 163],\n",
       "         [145, 131, 163],\n",
       "         [142, 128, 160],\n",
       "         ...,\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45]],\n",
       " \n",
       "        [[142, 128, 160],\n",
       "         [142, 128, 160],\n",
       "         [140, 126, 158],\n",
       "         ...,\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45],\n",
       "         [ 46,  25,  45]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 154, 221],\n",
       "         [184, 154, 221],\n",
       "         [184, 154, 221]],\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 153, 222],\n",
       "         [184, 153, 222],\n",
       "         [184, 153, 222]],\n",
       " \n",
       "        [[ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         [ 47,  21,  50],\n",
       "         ...,\n",
       "         [186, 153, 222],\n",
       "         [184, 153, 222],\n",
       "         [184, 153, 222]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4805999962845817, 'inference': 29.448600005707704, 'postprocess': 2.9929000011179596},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[139, 125, 157],\n",
       "         [139, 125, 157],\n",
       "         [138, 123, 158],\n",
       "         ...,\n",
       "         [ 57,  23,  34],\n",
       "         [ 57,  23,  34],\n",
       "         [ 58,  24,  35]],\n",
       " \n",
       "        [[139, 125, 157],\n",
       "         [139, 125, 157],\n",
       "         [138, 123, 158],\n",
       "         ...,\n",
       "         [ 57,  23,  34],\n",
       "         [ 57,  23,  34],\n",
       "         [ 58,  24,  35]],\n",
       " \n",
       "        [[140, 125, 160],\n",
       "         [140, 125, 160],\n",
       "         [139, 124, 159],\n",
       "         ...,\n",
       "         [ 57,  23,  34],\n",
       "         [ 57,  23,  34],\n",
       "         [ 58,  24,  35]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [127, 100, 150],\n",
       "         [138, 110, 165],\n",
       "         [147, 119, 174]],\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [144, 116, 169],\n",
       "         [154, 125, 182],\n",
       "         [161, 132, 189]],\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [154, 126, 179],\n",
       "         [164, 135, 192],\n",
       "         [169, 140, 197]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.2880999929620884, 'inference': 24.881299999833573, 'postprocess': 2.447700004267972},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[137, 123, 155],\n",
       "         [137, 123, 155],\n",
       "         [135, 120, 155],\n",
       "         ...,\n",
       "         [ 57,  23,  34],\n",
       "         [ 59,  23,  34],\n",
       "         [ 60,  24,  35]],\n",
       " \n",
       "        [[137, 123, 155],\n",
       "         [137, 123, 155],\n",
       "         [135, 120, 155],\n",
       "         ...,\n",
       "         [ 57,  23,  34],\n",
       "         [ 59,  23,  34],\n",
       "         [ 60,  24,  35]],\n",
       " \n",
       "        [[138, 124, 156],\n",
       "         [138, 124, 156],\n",
       "         [137, 122, 157],\n",
       "         ...,\n",
       "         [ 57,  23,  34],\n",
       "         [ 59,  23,  34],\n",
       "         [ 60,  24,  35]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 66,  44,  85],\n",
       "         [ 73,  49,  92],\n",
       "         [ 79,  55,  98]],\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 68,  46,  89],\n",
       "         [ 76,  51,  96],\n",
       "         [ 82,  57, 102]],\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 71,  49,  92],\n",
       "         [ 79,  54,  99],\n",
       "         [ 84,  59, 104]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.284700003452599, 'inference': 23.940099999890663, 'postprocess': 5.5412000001524575},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[140, 123, 163],\n",
       "         [140, 123, 163],\n",
       "         [142, 126, 163],\n",
       "         ...,\n",
       "         [ 62,  10,  28],\n",
       "         [ 63,  11,  29],\n",
       "         [ 63,  11,  29]],\n",
       " \n",
       "        [[142, 125, 165],\n",
       "         [144, 127, 167],\n",
       "         [146, 130, 167],\n",
       "         ...,\n",
       "         [ 62,  10,  28],\n",
       "         [ 63,  11,  29],\n",
       "         [ 63,  11,  29]],\n",
       " \n",
       "        [[152, 135, 175],\n",
       "         [152, 135, 175],\n",
       "         [155, 139, 176],\n",
       "         ...,\n",
       "         [ 62,  10,  28],\n",
       "         [ 63,  11,  29],\n",
       "         [ 63,  11,  29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 41,  14,  46],\n",
       "         [ 41,  14,  46],\n",
       "         [ 41,  14,  46],\n",
       "         ...,\n",
       "         [ 60,  43,  69],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70]],\n",
       " \n",
       "        [[ 41,  14,  46],\n",
       "         [ 41,  14,  46],\n",
       "         [ 41,  14,  46],\n",
       "         ...,\n",
       "         [ 60,  43,  69],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70]],\n",
       " \n",
       "        [[ 41,  14,  46],\n",
       "         [ 41,  14,  46],\n",
       "         [ 41,  14,  46],\n",
       "         ...,\n",
       "         [ 60,  43,  69],\n",
       "         [ 61,  44,  70],\n",
       "         [ 61,  44,  70]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4972999997553416, 'inference': 21.843999995326158, 'postprocess': 0.8959000042523257},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[144, 127, 167],\n",
       "         [145, 128, 168],\n",
       "         [147, 131, 168],\n",
       "         ...,\n",
       "         [ 58,   7,  27],\n",
       "         [ 60,   9,  29],\n",
       "         [ 60,   9,  29]],\n",
       " \n",
       "        [[148, 131, 171],\n",
       "         [148, 131, 171],\n",
       "         [152, 136, 173],\n",
       "         ...,\n",
       "         [ 58,   7,  27],\n",
       "         [ 60,   9,  29],\n",
       "         [ 60,   9,  29]],\n",
       " \n",
       "        [[155, 138, 178],\n",
       "         [156, 139, 179],\n",
       "         [160, 144, 181],\n",
       "         ...,\n",
       "         [ 60,   7,  27],\n",
       "         [ 62,   9,  29],\n",
       "         [ 62,   9,  29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 44,  17,  49],\n",
       "         [ 44,  17,  49],\n",
       "         [ 44,  17,  49],\n",
       "         ...,\n",
       "         [ 59,  43,  67],\n",
       "         [ 61,  43,  67],\n",
       "         [ 61,  43,  67]],\n",
       " \n",
       "        [[ 43,  16,  48],\n",
       "         [ 43,  16,  48],\n",
       "         [ 43,  16,  48],\n",
       "         ...,\n",
       "         [ 60,  44,  68],\n",
       "         [ 62,  44,  68],\n",
       "         [ 62,  44,  68]],\n",
       " \n",
       "        [[ 43,  16,  48],\n",
       "         [ 43,  16,  48],\n",
       "         [ 43,  16,  48],\n",
       "         ...,\n",
       "         [ 60,  44,  68],\n",
       "         [ 62,  44,  68],\n",
       "         [ 62,  44,  68]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5468999990844168, 'inference': 22.49149999988731, 'postprocess': 1.2750000023515895},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[190, 173, 215],\n",
       "         [190, 173, 215],\n",
       "         [191, 174, 214],\n",
       "         ...,\n",
       "         [ 57,   6,  21],\n",
       "         [ 57,   6,  21],\n",
       "         [ 57,   6,  21]],\n",
       " \n",
       "        [[190, 173, 215],\n",
       "         [190, 173, 215],\n",
       "         [190, 173, 213],\n",
       "         ...,\n",
       "         [ 57,   6,  21],\n",
       "         [ 57,   6,  21],\n",
       "         [ 57,   6,  21]],\n",
       " \n",
       "        [[190, 173, 215],\n",
       "         [190, 173, 215],\n",
       "         [190, 173, 213],\n",
       "         ...,\n",
       "         [ 57,   6,  21],\n",
       "         [ 57,   6,  21],\n",
       "         [ 57,   6,  21]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 40,  14,  43],\n",
       "         [ 40,  14,  43],\n",
       "         [ 41,  15,  44],\n",
       "         ...,\n",
       "         [ 57,  43,  62],\n",
       "         [ 59,  43,  62],\n",
       "         [ 59,  43,  62]],\n",
       " \n",
       "        [[ 40,  14,  43],\n",
       "         [ 40,  14,  43],\n",
       "         [ 41,  15,  44],\n",
       "         ...,\n",
       "         [ 57,  43,  62],\n",
       "         [ 59,  43,  62],\n",
       "         [ 59,  43,  62]],\n",
       " \n",
       "        [[ 40,  14,  43],\n",
       "         [ 40,  14,  43],\n",
       "         [ 41,  15,  44],\n",
       "         ...,\n",
       "         [ 57,  43,  62],\n",
       "         [ 59,  43,  62],\n",
       "         [ 59,  43,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5210999990813434, 'inference': 22.69990000058897, 'postprocess': 2.196699999331031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[190, 173, 215],\n",
       "         [190, 173, 215],\n",
       "         [191, 174, 214],\n",
       "         ...,\n",
       "         [ 59,   5,  21],\n",
       "         [ 59,   5,  21],\n",
       "         [ 59,   5,  21]],\n",
       " \n",
       "        [[190, 173, 215],\n",
       "         [190, 173, 215],\n",
       "         [190, 173, 213],\n",
       "         ...,\n",
       "         [ 59,   5,  21],\n",
       "         [ 59,   5,  21],\n",
       "         [ 59,   5,  21]],\n",
       " \n",
       "        [[190, 173, 215],\n",
       "         [190, 173, 215],\n",
       "         [190, 173, 213],\n",
       "         ...,\n",
       "         [ 59,   5,  21],\n",
       "         [ 59,   5,  21],\n",
       "         [ 59,   5,  21]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 43,  14,  44],\n",
       "         [ 43,  14,  44],\n",
       "         [ 43,  17,  46],\n",
       "         ...,\n",
       "         [ 57,  43,  62],\n",
       "         [ 59,  43,  62],\n",
       "         [ 59,  43,  62]],\n",
       " \n",
       "        [[ 43,  14,  44],\n",
       "         [ 43,  14,  44],\n",
       "         [ 43,  17,  46],\n",
       "         ...,\n",
       "         [ 57,  43,  62],\n",
       "         [ 59,  43,  62],\n",
       "         [ 59,  43,  62]],\n",
       " \n",
       "        [[ 43,  14,  44],\n",
       "         [ 43,  14,  44],\n",
       "         [ 43,  17,  46],\n",
       "         ...,\n",
       "         [ 57,  43,  62],\n",
       "         [ 59,  43,  62],\n",
       "         [ 59,  43,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0813000010093674, 'inference': 24.787300004391, 'postprocess': 1.7463999975007027},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[180, 171, 212],\n",
       "         [180, 171, 212],\n",
       "         [182, 171, 212],\n",
       "         ...,\n",
       "         [ 55,   6,  21],\n",
       "         [ 54,   5,  20],\n",
       "         [ 54,   5,  20]],\n",
       " \n",
       "        [[180, 171, 212],\n",
       "         [180, 171, 212],\n",
       "         [182, 171, 212],\n",
       "         ...,\n",
       "         [ 55,   6,  21],\n",
       "         [ 54,   5,  20],\n",
       "         [ 54,   5,  20]],\n",
       " \n",
       "        [[180, 169, 210],\n",
       "         [180, 169, 210],\n",
       "         [180, 171, 212],\n",
       "         ...,\n",
       "         [ 55,   6,  21],\n",
       "         [ 55,   6,  21],\n",
       "         [ 55,   6,  21]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 63,  41,  63],\n",
       "         [ 63,  41,  63],\n",
       "         [ 63,  41,  63]],\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 63,  41,  63],\n",
       "         [ 63,  41,  63],\n",
       "         [ 63,  41,  63]],\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 63,  41,  63],\n",
       "         [ 63,  41,  63],\n",
       "         [ 63,  41,  63]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.376700002059806, 'inference': 23.34539999719709, 'postprocess': 1.8644000010681339},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[183, 171, 214],\n",
       "         [183, 171, 214],\n",
       "         [181, 172, 213],\n",
       "         ...,\n",
       "         [ 55,   6,  21],\n",
       "         [ 54,   5,  20],\n",
       "         [ 54,   5,  20]],\n",
       " \n",
       "        [[183, 171, 214],\n",
       "         [183, 171, 214],\n",
       "         [182, 173, 214],\n",
       "         ...,\n",
       "         [ 55,   6,  21],\n",
       "         [ 54,   5,  20],\n",
       "         [ 54,   5,  20]],\n",
       " \n",
       "        [[183, 171, 214],\n",
       "         [184, 172, 215],\n",
       "         [182, 173, 214],\n",
       "         ...,\n",
       "         [ 55,   6,  21],\n",
       "         [ 55,   6,  21],\n",
       "         [ 55,   6,  21]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 63,  42,  62],\n",
       "         [ 63,  42,  62],\n",
       "         [ 63,  42,  62]],\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 63,  42,  62],\n",
       "         [ 63,  42,  62],\n",
       "         [ 63,  42,  62]],\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 63,  42,  62],\n",
       "         [ 63,  42,  62],\n",
       "         [ 63,  42,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.619700004288461, 'inference': 27.200699994864408, 'postprocess': 1.6892999992705882},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[176, 172, 217],\n",
       "         [176, 172, 217],\n",
       "         [176, 173, 215],\n",
       "         ...,\n",
       "         [ 53,   6,  21],\n",
       "         [ 54,   7,  22],\n",
       "         [ 54,   7,  22]],\n",
       " \n",
       "        [[176, 172, 217],\n",
       "         [176, 172, 217],\n",
       "         [176, 173, 215],\n",
       "         ...,\n",
       "         [ 54,   7,  22],\n",
       "         [ 54,   7,  22],\n",
       "         [ 54,   7,  22]],\n",
       " \n",
       "        [[176, 172, 217],\n",
       "         [176, 172, 217],\n",
       "         [174, 174, 215],\n",
       "         ...,\n",
       "         [ 52,   8,  22],\n",
       "         [ 55,   8,  23],\n",
       "         [ 54,   7,  22]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 71,  46,  62],\n",
       "         [ 71,  46,  62],\n",
       "         [ 71,  46,  62]],\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 71,  46,  62],\n",
       "         [ 71,  46,  62],\n",
       "         [ 71,  46,  62]],\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 47,  16,  46],\n",
       "         ...,\n",
       "         [ 71,  46,  62],\n",
       "         [ 71,  46,  62],\n",
       "         [ 71,  46,  62]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6681999986758456, 'inference': 28.176699997857213, 'postprocess': 1.9245000003138557},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[175, 171, 216],\n",
       "         [175, 171, 216],\n",
       "         [175, 172, 214],\n",
       "         ...,\n",
       "         [ 51,   7,  21],\n",
       "         [ 52,   8,  22],\n",
       "         [ 52,   8,  22]],\n",
       " \n",
       "        [[175, 171, 216],\n",
       "         [175, 171, 216],\n",
       "         [175, 172, 214],\n",
       "         ...,\n",
       "         [ 51,   7,  21],\n",
       "         [ 52,   8,  22],\n",
       "         [ 52,   8,  22]],\n",
       " \n",
       "        [[175, 171, 216],\n",
       "         [175, 171, 216],\n",
       "         [173, 173, 214],\n",
       "         ...,\n",
       "         [ 51,   7,  21],\n",
       "         [ 52,   8,  22],\n",
       "         [ 52,   8,  22]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 71,  47,  61],\n",
       "         [ 71,  47,  61],\n",
       "         [ 71,  47,  61]],\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 71,  47,  61],\n",
       "         [ 71,  47,  61],\n",
       "         [ 71,  47,  61]],\n",
       " \n",
       "        [[ 49,  16,  46],\n",
       "         [ 49,  16,  46],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 71,  47,  61],\n",
       "         [ 71,  47,  61],\n",
       "         [ 71,  47,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6517999974894337, 'inference': 26.291099995432887, 'postprocess': 2.299799998581875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[173, 172, 216],\n",
       "         [172, 171, 215],\n",
       "         [172, 172, 213],\n",
       "         ...,\n",
       "         [ 52,  15,  28],\n",
       "         [ 54,  16,  27],\n",
       "         [ 54,  16,  27]],\n",
       " \n",
       "        [[172, 171, 215],\n",
       "         [172, 171, 215],\n",
       "         [170, 170, 211],\n",
       "         ...,\n",
       "         [ 52,  15,  28],\n",
       "         [ 54,  16,  27],\n",
       "         [ 54,  16,  27]],\n",
       " \n",
       "        [[169, 169, 210],\n",
       "         [169, 169, 210],\n",
       "         [172, 169, 211],\n",
       "         ...,\n",
       "         [ 53,  16,  29],\n",
       "         [ 53,  17,  28],\n",
       "         [ 52,  16,  27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  17,  47],\n",
       "         [ 50,  17,  47],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 74,  50,  64],\n",
       "         [ 75,  50,  66],\n",
       "         [ 75,  50,  66]],\n",
       " \n",
       "        [[ 50,  17,  47],\n",
       "         [ 50,  17,  47],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 74,  50,  64],\n",
       "         [ 75,  50,  66],\n",
       "         [ 75,  50,  66]],\n",
       " \n",
       "        [[ 50,  17,  47],\n",
       "         [ 50,  17,  47],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 74,  50,  64],\n",
       "         [ 75,  50,  66],\n",
       "         [ 75,  50,  66]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3638000018545426, 'inference': 20.915500004775822, 'postprocess': 1.2820999982068315},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[170, 170, 211],\n",
       "         [169, 169, 210],\n",
       "         [169, 170, 209],\n",
       "         ...,\n",
       "         [ 54,  18,  29],\n",
       "         [ 53,  17,  28],\n",
       "         [ 53,  17,  28]],\n",
       " \n",
       "        [[169, 169, 210],\n",
       "         [169, 169, 210],\n",
       "         [169, 170, 209],\n",
       "         ...,\n",
       "         [ 54,  18,  29],\n",
       "         [ 53,  17,  28],\n",
       "         [ 53,  17,  28]],\n",
       " \n",
       "        [[168, 168, 209],\n",
       "         [167, 167, 208],\n",
       "         [167, 168, 207],\n",
       "         ...,\n",
       "         [ 54,  18,  29],\n",
       "         [ 54,  18,  29],\n",
       "         [ 54,  18,  29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  17,  47],\n",
       "         [ 50,  17,  47],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 73,  49,  63],\n",
       "         [ 73,  49,  63],\n",
       "         [ 73,  49,  63]],\n",
       " \n",
       "        [[ 50,  17,  47],\n",
       "         [ 50,  17,  47],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 73,  49,  63],\n",
       "         [ 73,  49,  63],\n",
       "         [ 73,  49,  63]],\n",
       " \n",
       "        [[ 50,  17,  47],\n",
       "         [ 50,  17,  47],\n",
       "         [ 48,  17,  47],\n",
       "         ...,\n",
       "         [ 74,  50,  64],\n",
       "         [ 74,  50,  64],\n",
       "         [ 74,  50,  64]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.297299997531809, 'inference': 21.251599995594006, 'postprocess': 0.9200999993481673},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[143, 145, 186],\n",
       "         [144, 146, 187],\n",
       "         [144, 147, 186],\n",
       "         ...,\n",
       "         [ 67,  31,  55],\n",
       "         [ 67,  31,  55],\n",
       "         [ 65,  29,  53]],\n",
       " \n",
       "        [[137, 139, 180],\n",
       "         [138, 140, 181],\n",
       "         [138, 141, 180],\n",
       "         ...,\n",
       "         [ 67,  31,  55],\n",
       "         [ 67,  31,  55],\n",
       "         [ 65,  29,  53]],\n",
       " \n",
       "        [[134, 137, 176],\n",
       "         [135, 138, 177],\n",
       "         [134, 137, 174],\n",
       "         ...,\n",
       "         [ 68,  33,  55],\n",
       "         [ 69,  31,  54],\n",
       "         [ 67,  29,  52]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 74,  50,  64],\n",
       "         [ 74,  50,  64],\n",
       "         [ 73,  49,  63]],\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 74,  50,  64],\n",
       "         [ 74,  50,  64],\n",
       "         [ 73,  49,  63]],\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 74,  50,  64],\n",
       "         [ 74,  50,  64],\n",
       "         [ 73,  49,  63]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4573999942513183, 'inference': 23.470899999665562, 'postprocess': 1.4091999983065762},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[144, 146, 187],\n",
       "         [146, 148, 189],\n",
       "         [146, 149, 188],\n",
       "         ...,\n",
       "         [ 69,  34,  56],\n",
       "         [ 70,  33,  53],\n",
       "         [ 69,  32,  52]],\n",
       " \n",
       "        [[141, 143, 184],\n",
       "         [141, 143, 184],\n",
       "         [141, 144, 183],\n",
       "         ...,\n",
       "         [ 70,  35,  57],\n",
       "         [ 71,  34,  54],\n",
       "         [ 70,  33,  53]],\n",
       " \n",
       "        [[135, 138, 177],\n",
       "         [136, 139, 178],\n",
       "         [137, 140, 177],\n",
       "         ...,\n",
       "         [ 69,  34,  56],\n",
       "         [ 71,  34,  54],\n",
       "         [ 70,  33,  53]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 73,  49,  63],\n",
       "         [ 73,  49,  63],\n",
       "         [ 71,  47,  61]],\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 73,  49,  63],\n",
       "         [ 73,  49,  63],\n",
       "         [ 71,  47,  61]],\n",
       " \n",
       "        [[ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         [ 47,  17,  50],\n",
       "         ...,\n",
       "         [ 73,  49,  63],\n",
       "         [ 73,  49,  63],\n",
       "         [ 71,  47,  61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7396000039298087, 'inference': 22.204699998837896, 'postprocess': 0.857999999425374},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 122, 156],\n",
       "         [120, 122, 156],\n",
       "         [120, 121, 158],\n",
       "         ...,\n",
       "         [139,  88, 110],\n",
       "         [138,  87, 107],\n",
       "         [136,  85, 105]],\n",
       " \n",
       "        [[119, 121, 155],\n",
       "         [119, 121, 155],\n",
       "         [119, 120, 157],\n",
       "         ...,\n",
       "         [138,  87, 109],\n",
       "         [136,  85, 105],\n",
       "         [136,  85, 105]],\n",
       " \n",
       "        [[118, 120, 154],\n",
       "         [118, 120, 154],\n",
       "         [118, 119, 156],\n",
       "         ...,\n",
       "         [135,  84, 106],\n",
       "         [136,  85, 105],\n",
       "         [136,  85, 105]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  18,  51],\n",
       "         [ 48,  18,  51],\n",
       "         [ 46,  19,  51],\n",
       "         ...,\n",
       "         [ 79,  53,  67],\n",
       "         [ 79,  53,  67],\n",
       "         [ 79,  53,  67]],\n",
       " \n",
       "        [[ 48,  18,  51],\n",
       "         [ 48,  18,  51],\n",
       "         [ 46,  19,  51],\n",
       "         ...,\n",
       "         [ 80,  54,  68],\n",
       "         [ 80,  54,  68],\n",
       "         [ 80,  54,  68]],\n",
       " \n",
       "        [[ 48,  18,  51],\n",
       "         [ 48,  18,  51],\n",
       "         [ 46,  19,  51],\n",
       "         ...,\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8966999996337108, 'inference': 25.991599999542814, 'postprocess': 2.463800003170036},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[118, 122, 156],\n",
       "         [120, 124, 158],\n",
       "         [120, 124, 158],\n",
       "         ...,\n",
       "         [139,  87, 112],\n",
       "         [139,  88, 110],\n",
       "         [138,  87, 109]],\n",
       " \n",
       "        [[118, 122, 156],\n",
       "         [118, 122, 156],\n",
       "         [120, 124, 158],\n",
       "         ...,\n",
       "         [139,  87, 112],\n",
       "         [139,  88, 110],\n",
       "         [138,  87, 109]],\n",
       " \n",
       "        [[117, 121, 155],\n",
       "         [118, 122, 156],\n",
       "         [120, 124, 158],\n",
       "         ...,\n",
       "         [139,  87, 112],\n",
       "         [139,  88, 110],\n",
       "         [138,  87, 109]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 46,  19,  51],\n",
       "         [ 47,  20,  52],\n",
       "         [ 45,  20,  52],\n",
       "         ...,\n",
       "         [ 75,  51,  65],\n",
       "         [ 75,  51,  65],\n",
       "         [ 75,  51,  65]],\n",
       " \n",
       "        [[ 46,  19,  51],\n",
       "         [ 47,  20,  52],\n",
       "         [ 45,  20,  52],\n",
       "         ...,\n",
       "         [ 75,  51,  65],\n",
       "         [ 75,  51,  65],\n",
       "         [ 75,  51,  65]],\n",
       " \n",
       "        [[ 46,  19,  51],\n",
       "         [ 47,  20,  52],\n",
       "         [ 45,  20,  52],\n",
       "         ...,\n",
       "         [ 75,  51,  65],\n",
       "         [ 75,  51,  65],\n",
       "         [ 75,  51,  65]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7066000000340864, 'inference': 23.996800002350938, 'postprocess': 3.002199999173172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[118, 122, 151],\n",
       "         [118, 122, 151],\n",
       "         [117, 120, 152],\n",
       "         ...,\n",
       "         [117,  76,  94],\n",
       "         [118,  77,  95],\n",
       "         [118,  77,  95]],\n",
       " \n",
       "        [[118, 122, 151],\n",
       "         [118, 122, 151],\n",
       "         [117, 120, 152],\n",
       "         ...,\n",
       "         [117,  76,  94],\n",
       "         [118,  77,  95],\n",
       "         [117,  76,  94]],\n",
       " \n",
       "        [[118, 122, 151],\n",
       "         [118, 122, 151],\n",
       "         [118, 122, 151],\n",
       "         ...,\n",
       "         [117,  76,  94],\n",
       "         [118,  77,  95],\n",
       "         [117,  76,  94]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 46,  19,  51],\n",
       "         [ 46,  19,  51],\n",
       "         [ 44,  19,  51],\n",
       "         ...,\n",
       "         [ 81,  57,  71],\n",
       "         [ 81,  57,  71],\n",
       "         [ 81,  57,  71]],\n",
       " \n",
       "        [[ 46,  19,  51],\n",
       "         [ 46,  19,  51],\n",
       "         [ 44,  19,  51],\n",
       "         ...,\n",
       "         [ 82,  58,  72],\n",
       "         [ 82,  58,  72],\n",
       "         [ 82,  58,  72]],\n",
       " \n",
       "        [[ 46,  19,  51],\n",
       "         [ 46,  19,  51],\n",
       "         [ 44,  19,  51],\n",
       "         ...,\n",
       "         [ 83,  59,  73],\n",
       "         [ 83,  59,  73],\n",
       "         [ 83,  59,  73]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5540000022156164, 'inference': 24.942900003225077, 'postprocess': 1.7749999969964847},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[117, 121, 150],\n",
       "         [117, 121, 150],\n",
       "         [116, 119, 151],\n",
       "         ...,\n",
       "         [116,  75,  93],\n",
       "         [117,  76,  94],\n",
       "         [117,  76,  94]],\n",
       " \n",
       "        [[118, 122, 151],\n",
       "         [118, 122, 151],\n",
       "         [117, 120, 152],\n",
       "         ...,\n",
       "         [116,  75,  93],\n",
       "         [117,  76,  94],\n",
       "         [116,  75,  93]],\n",
       " \n",
       "        [[118, 122, 151],\n",
       "         [118, 122, 151],\n",
       "         [117, 121, 150],\n",
       "         ...,\n",
       "         [116,  75,  93],\n",
       "         [117,  76,  94],\n",
       "         [116,  75,  93]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 77,  53,  67],\n",
       "         [ 77,  53,  67],\n",
       "         [ 77,  53,  67]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 78,  54,  68],\n",
       "         [ 78,  54,  68],\n",
       "         [ 78,  54,  68]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 78,  54,  68],\n",
       "         [ 78,  54,  68],\n",
       "         [ 78,  54,  68]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7521999980090186, 'inference': 22.31690000189701, 'postprocess': 2.7031999998143874},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 122, 150],\n",
       "         [119, 121, 149],\n",
       "         [117, 121, 150],\n",
       "         ...,\n",
       "         [106,  74,  86],\n",
       "         [106,  75,  85],\n",
       "         [106,  75,  85]],\n",
       " \n",
       "        [[120, 122, 150],\n",
       "         [119, 121, 149],\n",
       "         [117, 121, 150],\n",
       "         ...,\n",
       "         [106,  74,  86],\n",
       "         [106,  75,  85],\n",
       "         [106,  75,  85]],\n",
       " \n",
       "        [[121, 121, 149],\n",
       "         [121, 121, 149],\n",
       "         [120, 120, 148],\n",
       "         ...,\n",
       "         [106,  73,  88],\n",
       "         [105,  73,  85],\n",
       "         [105,  73,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 94,  68,  82],\n",
       "         [ 94,  68,  82],\n",
       "         [ 97,  71,  85]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 97,  71,  85],\n",
       "         [ 97,  71,  85],\n",
       "         [ 97,  71,  85]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 97,  71,  85],\n",
       "         [ 97,  71,  85],\n",
       "         [ 98,  72,  86]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.7618000021902844, 'inference': 24.879800002963748, 'postprocess': 2.210800004831981},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[117, 122, 149],\n",
       "         [116, 121, 148],\n",
       "         [114, 120, 149],\n",
       "         ...,\n",
       "         [107,  75,  87],\n",
       "         [107,  76,  86],\n",
       "         [107,  76,  86]],\n",
       " \n",
       "        [[117, 122, 149],\n",
       "         [116, 121, 148],\n",
       "         [113, 119, 148],\n",
       "         ...,\n",
       "         [107,  75,  87],\n",
       "         [106,  75,  85],\n",
       "         [106,  75,  85]],\n",
       " \n",
       "        [[117, 119, 147],\n",
       "         [117, 119, 147],\n",
       "         [115, 117, 145],\n",
       "         ...,\n",
       "         [106,  74,  86],\n",
       "         [106,  75,  85],\n",
       "         [106,  75,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 91,  65,  79],\n",
       "         [ 91,  65,  79],\n",
       "         [ 90,  64,  78]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 92,  66,  80],\n",
       "         [ 91,  65,  79],\n",
       "         [ 91,  65,  79]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 92,  66,  80],\n",
       "         [ 93,  67,  81],\n",
       "         [ 92,  66,  80]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7437999995308928, 'inference': 23.443000005499925, 'postprocess': 1.6997999991872348},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98,  98, 126],\n",
       "         [ 98,  98, 126],\n",
       "         [ 94,  96, 124],\n",
       "         ...,\n",
       "         [101,  77,  91],\n",
       "         [101,  78,  89],\n",
       "         [101,  78,  89]],\n",
       " \n",
       "        [[ 95,  95, 123],\n",
       "         [ 95,  95, 123],\n",
       "         [ 94,  96, 124],\n",
       "         ...,\n",
       "         [102,  78,  92],\n",
       "         [102,  79,  90],\n",
       "         [101,  78,  89]],\n",
       " \n",
       "        [[ 95,  95, 123],\n",
       "         [ 95,  95, 123],\n",
       "         [ 94,  96, 124],\n",
       "         ...,\n",
       "         [102,  78,  92],\n",
       "         [102,  79,  90],\n",
       "         [101,  78,  89]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 46,  18,  52],\n",
       "         [ 46,  18,  52],\n",
       "         [ 44,  18,  52],\n",
       "         ...,\n",
       "         [ 82,  56,  70],\n",
       "         [ 84,  56,  70],\n",
       "         [ 84,  56,  70]],\n",
       " \n",
       "        [[ 46,  18,  52],\n",
       "         [ 46,  18,  52],\n",
       "         [ 44,  18,  52],\n",
       "         ...,\n",
       "         [ 82,  56,  70],\n",
       "         [ 84,  56,  70],\n",
       "         [ 84,  56,  70]],\n",
       " \n",
       "        [[ 46,  18,  52],\n",
       "         [ 46,  18,  52],\n",
       "         [ 44,  18,  52],\n",
       "         ...,\n",
       "         [ 82,  56,  70],\n",
       "         [ 84,  56,  70],\n",
       "         [ 82,  54,  68]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 4.0576000028522685, 'inference': 30.218699997931253, 'postprocess': 1.7915999997057952},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 99,  99, 127],\n",
       "         [ 99,  99, 127],\n",
       "         [ 96,  98, 126],\n",
       "         ...,\n",
       "         [102,  78,  92],\n",
       "         [102,  79,  90],\n",
       "         [102,  79,  90]],\n",
       " \n",
       "        [[ 96,  96, 124],\n",
       "         [ 96,  96, 124],\n",
       "         [ 96,  98, 126],\n",
       "         ...,\n",
       "         [103,  79,  93],\n",
       "         [103,  80,  91],\n",
       "         [102,  79,  90]],\n",
       " \n",
       "        [[ 96,  96, 124],\n",
       "         [ 96,  96, 124],\n",
       "         [ 96,  98, 126],\n",
       "         ...,\n",
       "         [103,  79,  93],\n",
       "         [103,  80,  91],\n",
       "         [102,  79,  90]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 90,  64,  78],\n",
       "         [ 91,  63,  77],\n",
       "         [ 89,  61,  75]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 86,  60,  74],\n",
       "         [ 88,  60,  74],\n",
       "         [ 88,  60,  74]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 84,  58,  72],\n",
       "         [ 86,  58,  72],\n",
       "         [ 86,  58,  72]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6680999979143962, 'inference': 23.2659999965108, 'postprocess': 0.84709999646293},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 58,  59,  84],\n",
       "         [ 57,  58,  83],\n",
       "         [ 57,  57,  85],\n",
       "         ...,\n",
       "         [152, 147, 159],\n",
       "         [150, 145, 159],\n",
       "         [150, 145, 159]],\n",
       " \n",
       "        [[ 48,  49,  74],\n",
       "         [ 48,  49,  74],\n",
       "         [ 45,  45,  73],\n",
       "         ...,\n",
       "         [152, 147, 159],\n",
       "         [150, 145, 159],\n",
       "         [150, 145, 159]],\n",
       " \n",
       "        [[ 37,  38,  63],\n",
       "         [ 36,  37,  62],\n",
       "         [ 36,  36,  64],\n",
       "         ...,\n",
       "         [151, 146, 158],\n",
       "         [151, 146, 160],\n",
       "         [150, 145, 159]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 83,  57,  71],\n",
       "         [ 83,  57,  71],\n",
       "         [ 83,  57,  71]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 83,  57,  71],\n",
       "         [ 84,  58,  72],\n",
       "         [ 84,  58,  72]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.227800003311131, 'inference': 30.84530000342056, 'postprocess': 2.0938000016030855},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 57,  59,  87],\n",
       "         [ 56,  58,  86],\n",
       "         [ 56,  57,  87],\n",
       "         ...,\n",
       "         [153, 148, 160],\n",
       "         [152, 147, 161],\n",
       "         [152, 147, 161]],\n",
       " \n",
       "        [[ 47,  49,  77],\n",
       "         [ 47,  49,  77],\n",
       "         [ 44,  45,  75],\n",
       "         ...,\n",
       "         [153, 148, 160],\n",
       "         [152, 147, 161],\n",
       "         [152, 147, 161]],\n",
       " \n",
       "        [[ 36,  38,  66],\n",
       "         [ 36,  38,  66],\n",
       "         [ 35,  36,  66],\n",
       "         ...,\n",
       "         [153, 148, 160],\n",
       "         [152, 147, 161],\n",
       "         [152, 147, 161]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 46,  18,  52],\n",
       "         [ 47,  19,  53],\n",
       "         [ 44,  18,  52],\n",
       "         ...,\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 44,  18,  52],\n",
       "         ...,\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70],\n",
       "         [ 82,  56,  70]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7402000012225471, 'inference': 20.87529999698745, 'postprocess': 2.011999997193925},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[  0,   4,  35],\n",
       "         [  0,   4,  35],\n",
       "         [  0,   8,  39],\n",
       "         ...,\n",
       "         [139, 116, 127],\n",
       "         [144, 119, 130],\n",
       "         [146, 121, 132]],\n",
       " \n",
       "        [[  0,   3,  34],\n",
       "         [  0,   4,  35],\n",
       "         [  0,   6,  37],\n",
       "         ...,\n",
       "         [139, 116, 127],\n",
       "         [144, 119, 130],\n",
       "         [146, 121, 132]],\n",
       " \n",
       "        [[  0,   3,  35],\n",
       "         [  0,   5,  37],\n",
       "         [  0,   7,  38],\n",
       "         ...,\n",
       "         [137, 114, 125],\n",
       "         [141, 116, 127],\n",
       "         [142, 117, 128]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [103,  72,  87],\n",
       "         [100,  72,  86],\n",
       "         [101,  73,  87]],\n",
       " \n",
       "        [[ 46,  18,  52],\n",
       "         [ 46,  18,  52],\n",
       "         [ 44,  18,  52],\n",
       "         ...,\n",
       "         [105,  72,  87],\n",
       "         [101,  73,  87],\n",
       "         [101,  73,  87]],\n",
       " \n",
       "        [[ 46,  18,  52],\n",
       "         [ 46,  18,  52],\n",
       "         [ 44,  18,  52],\n",
       "         ...,\n",
       "         [104,  71,  86],\n",
       "         [101,  73,  87],\n",
       "         [100,  72,  86]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6372000027331524, 'inference': 23.85830000275746, 'postprocess': 1.3649000029545277},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[  3,   8,  40],\n",
       "         [  7,  12,  44],\n",
       "         [  8,  16,  47],\n",
       "         ...,\n",
       "         [135, 112, 123],\n",
       "         [140, 115, 126],\n",
       "         [141, 116, 127]],\n",
       " \n",
       "        [[  3,   8,  40],\n",
       "         [  7,  12,  44],\n",
       "         [  8,  16,  47],\n",
       "         ...,\n",
       "         [133, 110, 121],\n",
       "         [136, 111, 122],\n",
       "         [137, 112, 123]],\n",
       " \n",
       "        [[  1,   9,  40],\n",
       "         [  3,  11,  42],\n",
       "         [  8,  16,  47],\n",
       "         ...,\n",
       "         [132, 109, 120],\n",
       "         [135, 110, 121],\n",
       "         [136, 111, 122]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [ 95,  67,  81],\n",
       "         [ 95,  67,  81],\n",
       "         [ 95,  67,  81]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [101,  70,  85],\n",
       "         [ 98,  70,  84],\n",
       "         [ 98,  70,  84]],\n",
       " \n",
       "        [[ 47,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         ...,\n",
       "         [102,  71,  86],\n",
       "         [100,  72,  86],\n",
       "         [100,  72,  86]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.774299998942297, 'inference': 23.49030000186758, 'postprocess': 0.9242999949492514},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[  2,   8,  44],\n",
       "         [  3,   9,  45],\n",
       "         [  4,  13,  46],\n",
       "         ...,\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        [[  1,   7,  43],\n",
       "         [  1,   7,  43],\n",
       "         [  1,  10,  43],\n",
       "         ...,\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        [[  3,   7,  41],\n",
       "         [  2,   6,  40],\n",
       "         [  4,   8,  42],\n",
       "         ...,\n",
       "         [100,  84,  82],\n",
       "         [100,  84,  82],\n",
       "         [100,  84,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 45,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         ...,\n",
       "         [ 82,  55,  66],\n",
       "         [ 82,  55,  66],\n",
       "         [ 82,  55,  66]],\n",
       " \n",
       "        [[ 45,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         ...,\n",
       "         [ 84,  54,  66],\n",
       "         [ 84,  54,  66],\n",
       "         [ 84,  54,  66]],\n",
       " \n",
       "        [[ 45,  19,  53],\n",
       "         [ 45,  19,  53],\n",
       "         [ 47,  19,  53],\n",
       "         ...,\n",
       "         [ 84,  54,  66],\n",
       "         [ 84,  54,  66],\n",
       "         [ 84,  54,  66]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6150000010384247, 'inference': 24.70080000057351, 'postprocess': 2.008600000408478},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 10,  16,  52],\n",
       "         [ 15,  21,  57],\n",
       "         [ 17,  27,  63],\n",
       "         ...,\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        [[  8,  14,  50],\n",
       "         [ 13,  19,  55],\n",
       "         [ 13,  23,  59],\n",
       "         ...,\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        [[  6,  12,  48],\n",
       "         [  9,  15,  51],\n",
       "         [ 10,  21,  54],\n",
       "         ...,\n",
       "         [100,  84,  82],\n",
       "         [100,  84,  82],\n",
       "         [100,  84,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 45,  18,  55],\n",
       "         [ 45,  18,  55],\n",
       "         [ 44,  17,  54],\n",
       "         ...,\n",
       "         [ 85,  59,  73],\n",
       "         [ 85,  59,  73],\n",
       "         [ 85,  59,  73]],\n",
       " \n",
       "        [[ 45,  18,  55],\n",
       "         [ 45,  18,  55],\n",
       "         [ 44,  17,  54],\n",
       "         ...,\n",
       "         [ 86,  55,  70],\n",
       "         [ 87,  56,  71],\n",
       "         [ 87,  56,  71]],\n",
       " \n",
       "        [[ 45,  18,  55],\n",
       "         [ 45,  18,  55],\n",
       "         [ 44,  17,  54],\n",
       "         ...,\n",
       "         [ 86,  55,  70],\n",
       "         [ 86,  55,  70],\n",
       "         [ 86,  55,  70]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.654499996220693, 'inference': 22.329199993691873, 'postprocess': 1.2839999981224537},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[  8,  12,  46],\n",
       "         [ 10,  14,  48],\n",
       "         [ 14,  19,  51],\n",
       "         ...,\n",
       "         [100,  85,  81],\n",
       "         [103,  85,  82],\n",
       "         [102,  84,  81]],\n",
       " \n",
       "        [[  5,   9,  43],\n",
       "         [  8,  12,  46],\n",
       "         [ 11,  16,  48],\n",
       "         ...,\n",
       "         [100,  85,  81],\n",
       "         [103,  85,  82],\n",
       "         [102,  84,  81]],\n",
       " \n",
       "        [[  6,   9,  41],\n",
       "         [ 10,  13,  45],\n",
       "         [ 10,  16,  45],\n",
       "         ...,\n",
       "         [100,  85,  81],\n",
       "         [100,  85,  81],\n",
       "         [101,  86,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 44,  18,  52],\n",
       "         [ 44,  18,  52],\n",
       "         [ 43,  17,  51],\n",
       "         ...,\n",
       "         [ 89,  68,  81],\n",
       "         [ 91,  67,  81],\n",
       "         [ 92,  68,  82]],\n",
       " \n",
       "        [[ 44,  18,  52],\n",
       "         [ 44,  18,  52],\n",
       "         [ 43,  17,  51],\n",
       "         ...,\n",
       "         [ 94,  70,  84],\n",
       "         [ 92,  68,  82],\n",
       "         [ 94,  70,  84]],\n",
       " \n",
       "        [[ 44,  18,  52],\n",
       "         [ 44,  18,  52],\n",
       "         [ 43,  17,  51],\n",
       "         ...,\n",
       "         [ 95,  71,  85],\n",
       "         [ 95,  71,  85],\n",
       "         [ 95,  71,  85]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.821100002620369, 'inference': 24.108800003887154, 'postprocess': 1.9618999940576032},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 18,  28,  59],\n",
       "         [ 25,  35,  66],\n",
       "         [ 32,  41,  74],\n",
       "         ...,\n",
       "         [100,  85,  81],\n",
       "         [103,  85,  82],\n",
       "         [102,  84,  81]],\n",
       " \n",
       "        [[ 15,  25,  56],\n",
       "         [ 21,  31,  62],\n",
       "         [ 28,  37,  70],\n",
       "         ...,\n",
       "         [100,  85,  81],\n",
       "         [103,  85,  82],\n",
       "         [102,  84,  81]],\n",
       " \n",
       "        [[ 15,  23,  54],\n",
       "         [ 21,  29,  60],\n",
       "         [ 25,  34,  67],\n",
       "         ...,\n",
       "         [100,  85,  81],\n",
       "         [100,  85,  81],\n",
       "         [101,  86,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 43,  17,  51],\n",
       "         [ 43,  17,  51],\n",
       "         [ 43,  17,  51],\n",
       "         ...,\n",
       "         [ 84,  60,  74],\n",
       "         [ 84,  60,  74],\n",
       "         [ 84,  60,  74]],\n",
       " \n",
       "        [[ 43,  17,  51],\n",
       "         [ 43,  17,  51],\n",
       "         [ 43,  17,  51],\n",
       "         ...,\n",
       "         [ 87,  63,  77],\n",
       "         [ 87,  63,  77],\n",
       "         [ 87,  63,  77]],\n",
       " \n",
       "        [[ 43,  17,  51],\n",
       "         [ 43,  17,  51],\n",
       "         [ 43,  17,  51],\n",
       "         ...,\n",
       "         [ 88,  64,  78],\n",
       "         [ 88,  64,  78],\n",
       "         [ 88,  64,  78]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8572999979369342, 'inference': 20.972600003005937, 'postprocess': 1.8768000009004027},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 15,  14,  44],\n",
       "         [ 17,  16,  46],\n",
       "         [ 21,  20,  50],\n",
       "         ...,\n",
       "         [ 99,  86,  82],\n",
       "         [101,  86,  82],\n",
       "         [100,  85,  81]],\n",
       " \n",
       "        [[ 14,  13,  43],\n",
       "         [ 16,  15,  45],\n",
       "         [ 20,  19,  49],\n",
       "         ...,\n",
       "         [ 99,  86,  82],\n",
       "         [101,  86,  82],\n",
       "         [100,  85,  81]],\n",
       " \n",
       "        [[ 15,  10,  39],\n",
       "         [ 18,  13,  42],\n",
       "         [ 19,  17,  45],\n",
       "         ...,\n",
       "         [ 99,  86,  82],\n",
       "         [ 98,  85,  81],\n",
       "         [ 99,  86,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  16,  50],\n",
       "         [ 42,  16,  50],\n",
       "         [ 44,  16,  50],\n",
       "         ...,\n",
       "         [ 85,  57,  71],\n",
       "         [ 83,  57,  71],\n",
       "         [ 83,  57,  71]],\n",
       " \n",
       "        [[ 42,  16,  50],\n",
       "         [ 42,  16,  50],\n",
       "         [ 44,  16,  50],\n",
       "         ...,\n",
       "         [ 85,  57,  71],\n",
       "         [ 83,  57,  71],\n",
       "         [ 84,  58,  72]],\n",
       " \n",
       "        [[ 42,  16,  50],\n",
       "         [ 42,  16,  50],\n",
       "         [ 44,  16,  50],\n",
       "         ...,\n",
       "         [ 85,  57,  71],\n",
       "         [ 83,  57,  71],\n",
       "         [ 84,  58,  72]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.337599998805672, 'inference': 28.10950000275625, 'postprocess': 1.748299997416325},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[27, 29, 57],\n",
       "         [34, 36, 64],\n",
       "         [40, 42, 70],\n",
       "         ...,\n",
       "         [96, 86, 81],\n",
       "         [98, 85, 81],\n",
       "         [99, 86, 82]],\n",
       " \n",
       "        [[26, 28, 56],\n",
       "         [30, 32, 60],\n",
       "         [36, 38, 66],\n",
       "         ...,\n",
       "         [96, 86, 81],\n",
       "         [98, 85, 81],\n",
       "         [99, 86, 82]],\n",
       " \n",
       "        [[27, 25, 53],\n",
       "         [33, 31, 59],\n",
       "         [36, 36, 64],\n",
       "         ...,\n",
       "         [96, 86, 81],\n",
       "         [98, 85, 81],\n",
       "         [99, 86, 82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[45, 14, 49],\n",
       "         [45, 14, 49],\n",
       "         [45, 14, 49],\n",
       "         ...,\n",
       "         [84, 58, 72],\n",
       "         [85, 59, 73],\n",
       "         [85, 59, 73]],\n",
       " \n",
       "        [[46, 15, 50],\n",
       "         [46, 15, 50],\n",
       "         [46, 15, 50],\n",
       "         ...,\n",
       "         [85, 57, 71],\n",
       "         [84, 58, 72],\n",
       "         [85, 59, 73]],\n",
       " \n",
       "        [[46, 15, 50],\n",
       "         [46, 15, 50],\n",
       "         [46, 15, 50],\n",
       "         ...,\n",
       "         [85, 57, 71],\n",
       "         [83, 57, 71],\n",
       "         [83, 57, 71]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.6278000043239444, 'inference': 25.071500000194646, 'postprocess': 1.0679000042728148},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 23,  14,  38],\n",
       "         [ 26,  17,  41],\n",
       "         [ 29,  20,  46],\n",
       "         ...,\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82]],\n",
       " \n",
       "        [[ 20,  11,  35],\n",
       "         [ 23,  14,  38],\n",
       "         [ 25,  16,  42],\n",
       "         ...,\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82]],\n",
       " \n",
       "        [[ 21,   9,  36],\n",
       "         [ 22,  10,  37],\n",
       "         [ 20,  13,  42],\n",
       "         ...,\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 45,  16,  53],\n",
       "         [ 45,  16,  53],\n",
       "         [ 46,  17,  54],\n",
       "         ...,\n",
       "         [107,  77,  89],\n",
       "         [105,  75,  87],\n",
       "         [105,  75,  87]],\n",
       " \n",
       "        [[ 46,  17,  54],\n",
       "         [ 46,  17,  54],\n",
       "         [ 47,  18,  55],\n",
       "         ...,\n",
       "         [108,  78,  90],\n",
       "         [107,  77,  89],\n",
       "         [107,  77,  89]],\n",
       " \n",
       "        [[ 46,  17,  54],\n",
       "         [ 46,  17,  54],\n",
       "         [ 47,  18,  55],\n",
       "         ...,\n",
       "         [108,  78,  90],\n",
       "         [107,  77,  89],\n",
       "         [107,  77,  89]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7341999991913326, 'inference': 28.137599998444784, 'postprocess': 1.9447000013315119},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 34,  25,  51],\n",
       "         [ 39,  30,  56],\n",
       "         [ 45,  36,  62],\n",
       "         ...,\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82]],\n",
       " \n",
       "        [[ 32,  23,  49],\n",
       "         [ 36,  27,  53],\n",
       "         [ 41,  32,  58],\n",
       "         ...,\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82]],\n",
       " \n",
       "        [[ 29,  17,  42],\n",
       "         [ 33,  21,  46],\n",
       "         [ 36,  27,  51],\n",
       "         ...,\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82],\n",
       "         [ 97,  87,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  15,  53],\n",
       "         [ 47,  15,  53],\n",
       "         [ 47,  15,  53],\n",
       "         ...,\n",
       "         [ 95,  60,  73],\n",
       "         [ 96,  64,  76],\n",
       "         [ 95,  63,  75]],\n",
       " \n",
       "        [[ 48,  16,  54],\n",
       "         [ 48,  16,  54],\n",
       "         [ 48,  16,  54],\n",
       "         ...,\n",
       "         [ 98,  66,  78],\n",
       "         [ 94,  67,  78],\n",
       "         [ 94,  67,  78]],\n",
       " \n",
       "        [[ 48,  16,  54],\n",
       "         [ 48,  16,  54],\n",
       "         [ 48,  16,  54],\n",
       "         ...,\n",
       "         [100,  68,  80],\n",
       "         [ 98,  71,  82],\n",
       "         [ 98,  71,  82]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.3201999972807243, 'inference': 32.69710000313353, 'postprocess': 1.1255999997956678},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[24, 11, 34],\n",
       "         [28, 15, 38],\n",
       "         [29, 17, 42],\n",
       "         ...,\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82]],\n",
       " \n",
       "        [[23, 10, 33],\n",
       "         [26, 13, 36],\n",
       "         [27, 15, 40],\n",
       "         ...,\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82]],\n",
       " \n",
       "        [[22,  9, 32],\n",
       "         [22,  9, 32],\n",
       "         [24, 12, 37],\n",
       "         ...,\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[46, 19, 56],\n",
       "         [46, 19, 56],\n",
       "         [46, 19, 56],\n",
       "         ...,\n",
       "         [83, 46, 59],\n",
       "         [85, 48, 61],\n",
       "         [85, 48, 61]],\n",
       " \n",
       "        [[46, 19, 56],\n",
       "         [46, 19, 56],\n",
       "         [46, 19, 56],\n",
       "         ...,\n",
       "         [83, 46, 59],\n",
       "         [85, 48, 61],\n",
       "         [85, 48, 61]],\n",
       " \n",
       "        [[46, 19, 56],\n",
       "         [46, 19, 56],\n",
       "         [46, 19, 56],\n",
       "         ...,\n",
       "         [83, 46, 59],\n",
       "         [85, 48, 61],\n",
       "         [85, 48, 61]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7312999989371747, 'inference': 21.309899995685555, 'postprocess': 1.7941999976756051},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[41, 28, 51],\n",
       "         [47, 34, 57],\n",
       "         [54, 38, 62],\n",
       "         ...,\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82]],\n",
       " \n",
       "        [[38, 25, 48],\n",
       "         [43, 30, 53],\n",
       "         [51, 35, 59],\n",
       "         ...,\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82],\n",
       "         [97, 87, 82]],\n",
       " \n",
       "        [[37, 22, 43],\n",
       "         [40, 25, 46],\n",
       "         [44, 32, 52],\n",
       "         ...,\n",
       "         [96, 86, 81],\n",
       "         [96, 86, 81],\n",
       "         [96, 86, 81]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [83, 47, 58],\n",
       "         [83, 47, 58],\n",
       "         [83, 47, 58]],\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [83, 47, 58],\n",
       "         [83, 47, 58],\n",
       "         [83, 47, 58]],\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [83, 47, 58],\n",
       "         [83, 47, 58],\n",
       "         [83, 47, 58]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.011500000662636, 'inference': 22.748300005332567, 'postprocess': 1.9604999979492277},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[28, 11, 32],\n",
       "         [31, 14, 35],\n",
       "         [33, 17, 41],\n",
       "         ...,\n",
       "         [97, 84, 80],\n",
       "         [97, 83, 81],\n",
       "         [97, 83, 81]],\n",
       " \n",
       "        [[27, 10, 31],\n",
       "         [27, 10, 31],\n",
       "         [30, 14, 38],\n",
       "         ...,\n",
       "         [97, 84, 80],\n",
       "         [97, 83, 81],\n",
       "         [97, 83, 81]],\n",
       " \n",
       "        [[22,  7, 28],\n",
       "         [23,  8, 29],\n",
       "         [26, 11, 32],\n",
       "         ...,\n",
       "         [97, 84, 80],\n",
       "         [97, 83, 81],\n",
       "         [97, 83, 81]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [83, 43, 52],\n",
       "         [83, 42, 54],\n",
       "         [83, 42, 54]],\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [80, 40, 49],\n",
       "         [80, 39, 51],\n",
       "         [80, 39, 51]],\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [80, 40, 49],\n",
       "         [80, 39, 51],\n",
       "         [80, 39, 51]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6023999996832572, 'inference': 22.886999999172986, 'postprocess': 1.7682999969110824},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 25, 48],\n",
       "         [44, 31, 54],\n",
       "         [54, 36, 60],\n",
       "         ...,\n",
       "         [97, 84, 80],\n",
       "         [97, 83, 81],\n",
       "         [97, 83, 81]],\n",
       " \n",
       "        [[36, 23, 46],\n",
       "         [40, 27, 50],\n",
       "         [49, 31, 55],\n",
       "         ...,\n",
       "         [97, 84, 80],\n",
       "         [97, 83, 81],\n",
       "         [97, 83, 81]],\n",
       " \n",
       "        [[33, 21, 41],\n",
       "         [36, 24, 44],\n",
       "         [46, 29, 50],\n",
       "         ...,\n",
       "         [97, 84, 80],\n",
       "         [97, 83, 81],\n",
       "         [97, 83, 81]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [95, 49, 62],\n",
       "         [94, 51, 63],\n",
       "         [94, 51, 63]],\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [91, 45, 58],\n",
       "         [89, 46, 58],\n",
       "         [89, 46, 58]],\n",
       " \n",
       "        [[48, 21, 58],\n",
       "         [48, 21, 58],\n",
       "         [50, 21, 58],\n",
       "         ...,\n",
       "         [89, 43, 56],\n",
       "         [87, 44, 56],\n",
       "         [87, 44, 56]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6064000010374002, 'inference': 26.420000001962762, 'postprocess': 2.1643000000040047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 22,  13,  31],\n",
       "         [ 27,  18,  36],\n",
       "         [ 37,  23,  42],\n",
       "         ...,\n",
       "         [101,  86,  82],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        [[ 21,  12,  30],\n",
       "         [ 27,  18,  36],\n",
       "         [ 35,  21,  40],\n",
       "         ...,\n",
       "         [101,  86,  82],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        [[ 24,  13,  31],\n",
       "         [ 28,  17,  35],\n",
       "         [ 36,  22,  41],\n",
       "         ...,\n",
       "         [101,  86,  82],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         [ 51,  22,  59],\n",
       "         ...,\n",
       "         [ 91,  49,  58],\n",
       "         [ 94,  49,  59],\n",
       "         [ 94,  49,  59]],\n",
       " \n",
       "        [[ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         [ 51,  22,  59],\n",
       "         ...,\n",
       "         [ 96,  51,  61],\n",
       "         [ 97,  52,  62],\n",
       "         [ 97,  52,  62]],\n",
       " \n",
       "        [[ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         [ 51,  22,  59],\n",
       "         ...,\n",
       "         [100,  55,  65],\n",
       "         [100,  55,  65],\n",
       "         [101,  56,  66]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.679199998965487, 'inference': 31.059900000400376, 'postprocess': 1.621399998839479},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 44,  32,  52],\n",
       "         [ 51,  39,  59],\n",
       "         [ 59,  44,  65],\n",
       "         ...,\n",
       "         [101,  86,  82],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        [[ 43,  31,  51],\n",
       "         [ 51,  39,  59],\n",
       "         [ 59,  44,  65],\n",
       "         ...,\n",
       "         [101,  86,  82],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        [[ 43,  31,  51],\n",
       "         [ 50,  38,  58],\n",
       "         [ 59,  44,  65],\n",
       "         ...,\n",
       "         [101,  86,  82],\n",
       "         [101,  85,  83],\n",
       "         [101,  85,  83]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         ...,\n",
       "         [ 84,  40,  48],\n",
       "         [ 84,  39,  49],\n",
       "         [ 83,  38,  48]],\n",
       " \n",
       "        [[ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         ...,\n",
       "         [ 87,  43,  51],\n",
       "         [ 87,  42,  52],\n",
       "         [ 86,  41,  51]],\n",
       " \n",
       "        [[ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         ...,\n",
       "         [ 88,  44,  52],\n",
       "         [ 88,  43,  53],\n",
       "         [ 87,  42,  52]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7976999952225015, 'inference': 24.271000002045184, 'postprocess': 1.8144999994547106},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 47,  35,  55],\n",
       "         [ 51,  39,  59],\n",
       "         [ 57,  45,  65],\n",
       "         ...,\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82]],\n",
       " \n",
       "        [[ 45,  33,  53],\n",
       "         [ 51,  39,  59],\n",
       "         [ 56,  44,  64],\n",
       "         ...,\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82]],\n",
       " \n",
       "        [[ 45,  33,  53],\n",
       "         [ 51,  39,  59],\n",
       "         [ 56,  44,  64],\n",
       "         ...,\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         ...,\n",
       "         [ 79,  31,  37],\n",
       "         [ 79,  31,  37],\n",
       "         [ 80,  32,  38]],\n",
       " \n",
       "        [[ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         ...,\n",
       "         [ 79,  31,  37],\n",
       "         [ 79,  31,  37],\n",
       "         [ 79,  31,  37]],\n",
       " \n",
       "        [[ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         [ 49,  22,  59],\n",
       "         ...,\n",
       "         [ 78,  30,  36],\n",
       "         [ 78,  30,  36],\n",
       "         [ 78,  30,  36]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1922999949310906, 'inference': 23.421099998813588, 'postprocess': 1.9832999969366938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 63,  51,  71],\n",
       "         [ 69,  57,  77],\n",
       "         [ 73,  61,  81],\n",
       "         ...,\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82]],\n",
       " \n",
       "        [[ 63,  51,  71],\n",
       "         [ 69,  57,  77],\n",
       "         [ 73,  61,  81],\n",
       "         ...,\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82]],\n",
       " \n",
       "        [[ 63,  51,  71],\n",
       "         [ 68,  56,  76],\n",
       "         [ 72,  60,  80],\n",
       "         ...,\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82],\n",
       "         [105,  85,  82]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         ...,\n",
       "         [ 80,  32,  38],\n",
       "         [ 82,  31,  38],\n",
       "         [ 83,  32,  39]],\n",
       " \n",
       "        [[ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         ...,\n",
       "         [ 80,  32,  38],\n",
       "         [ 82,  31,  38],\n",
       "         [ 82,  31,  38]],\n",
       " \n",
       "        [[ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         [ 50,  23,  60],\n",
       "         ...,\n",
       "         [ 79,  31,  37],\n",
       "         [ 81,  30,  37],\n",
       "         [ 82,  31,  38]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6216000003623776, 'inference': 29.70889999414794, 'postprocess': 1.764300002832897},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 61,  51,  71],\n",
       "         [ 61,  51,  71],\n",
       "         [ 65,  53,  73],\n",
       "         ...,\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83]],\n",
       " \n",
       "        [[ 60,  50,  70],\n",
       "         [ 62,  52,  72],\n",
       "         [ 65,  53,  73],\n",
       "         ...,\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83]],\n",
       " \n",
       "        [[ 61,  51,  71],\n",
       "         [ 61,  51,  71],\n",
       "         [ 64,  52,  72],\n",
       "         ...,\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         ...,\n",
       "         [ 75,  30,  40],\n",
       "         [ 77,  31,  39],\n",
       "         [ 78,  32,  40]],\n",
       " \n",
       "        [[ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         ...,\n",
       "         [ 75,  30,  40],\n",
       "         [ 77,  31,  39],\n",
       "         [ 78,  32,  40]],\n",
       " \n",
       "        [[ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         ...,\n",
       "         [ 75,  30,  40],\n",
       "         [ 77,  31,  39],\n",
       "         [ 78,  32,  40]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 4.3671000021276996, 'inference': 23.1084999977611, 'postprocess': 1.6290000057779253},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[ 68,  56,  76],\n",
       "         [ 71,  59,  79],\n",
       "         [ 74,  59,  80],\n",
       "         ...,\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83]],\n",
       " \n",
       "        [[ 66,  54,  74],\n",
       "         [ 71,  59,  79],\n",
       "         [ 74,  59,  80],\n",
       "         ...,\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83]],\n",
       " \n",
       "        [[ 66,  54,  74],\n",
       "         [ 69,  57,  77],\n",
       "         [ 72,  57,  78],\n",
       "         ...,\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83],\n",
       "         [109,  83,  83]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         ...,\n",
       "         [ 74,  29,  39],\n",
       "         [ 76,  30,  38],\n",
       "         [ 77,  31,  39]],\n",
       " \n",
       "        [[ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         ...,\n",
       "         [ 74,  29,  39],\n",
       "         [ 76,  30,  38],\n",
       "         [ 77,  31,  39]],\n",
       " \n",
       "        [[ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         [ 49,  25,  61],\n",
       "         ...,\n",
       "         [ 74,  29,  39],\n",
       "         [ 76,  30,  38],\n",
       "         [ 77,  31,  39]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.962200000183657, 'inference': 24.48520000325516, 'postprocess': 1.859399999375455},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.890000003390014, 'inference': 24.569399996835273, 'postprocess': 1.5175000007729977},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9489000042085536, 'inference': 22.833200004242826, 'postprocess': 1.8348999947193079},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.589299994520843, 'inference': 37.0762000020477, 'postprocess': 19.49360000435263},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.3464999942225404, 'inference': 22.234500000195112, 'postprocess': 1.6930999991018325},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 5.105800002638716, 'inference': 32.821100001456216, 'postprocess': 3.0292999945231713},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.800300000468269, 'inference': 22.318900002574082, 'postprocess': 1.1702999981935136},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.7370999960112385, 'inference': 22.797699995862786, 'postprocess': 3.314799992949702},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1173999994061887, 'inference': 26.437100001203362, 'postprocess': 2.8319999983068556},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.4164999995264225, 'inference': 28.456599997298326, 'postprocess': 2.524000003177207},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.43940000270959, 'inference': 25.993000002927147, 'postprocess': 1.8273999958182685},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7905999993672594, 'inference': 29.852300001948606, 'postprocess': 4.651700000977144},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 3.3452999996370636, 'inference': 27.91540000180248, 'postprocess': 2.045200002612546},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5062999955262057, 'inference': 22.02899999974761, 'postprocess': 2.19170000491431},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8427000031806529, 'inference': 22.391499995137565, 'postprocess': 1.8389999968349002},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5794999999343418, 'inference': 26.234099997964222, 'postprocess': 2.1627000023727305},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.832599999033846, 'inference': 24.109099998895545, 'postprocess': 1.8204000007244758},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.9790999979013577, 'inference': 23.654099997656886, 'postprocess': 2.0223000028636307},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6230000037467107, 'inference': 25.236599998606835, 'postprocess': 1.5615000011166558},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.0617000045604073, 'inference': 23.80550000088988, 'postprocess': 1.2503000034485012},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7296000005444512, 'inference': 27.246500001638196, 'postprocess': 1.8887999976868741},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.7312999989371747, 'inference': 26.489900003070943, 'postprocess': 1.997800005483441},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6375000050175004, 'inference': 24.597000003268477, 'postprocess': 1.3604000050690956},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.3719999953755178, 'inference': 24.723300004552584, 'postprocess': 1.9410000022617169},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.4770000052521937, 'inference': 22.149700002046302, 'postprocess': 1.247799998964183},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.768300000752788, 'inference': 21.8137999981991, 'postprocess': 1.9338999991305172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5882000006968156, 'inference': 27.394299999286886, 'postprocess': 1.0700999991968274},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.711100001761224, 'inference': 23.647100002563093, 'postprocess': 2.1498999994946644},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8379999964963645, 'inference': 22.03379999991739, 'postprocess': 1.8891999934567139},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.645100004679989, 'inference': 21.80890000454383, 'postprocess': 1.9672999987960793},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.8073000028380193, 'inference': 25.918599996657576, 'postprocess': 2.2290999986580573},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.482700001564808, 'inference': 23.537100001703948, 'postprocess': 1.9840000022668391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.175300003727898, 'inference': 25.478499999735504, 'postprocess': 1.934400002937764},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6187000001082197, 'inference': 25.532800005748868, 'postprocess': 1.752900003339164},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.837700001487974, 'inference': 27.14179999748012, 'postprocess': 1.9577000057324767},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6381000023102388, 'inference': 22.81539999967208, 'postprocess': 1.8962000031024218},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.5843000001041219, 'inference': 24.491399999533314, 'postprocess': 2.47799999488052},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2152000019559637, 'inference': 25.517699999909382, 'postprocess': 1.8163999993703328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6446000008727424, 'inference': 24.515000004612375, 'postprocess': 1.893499997095205},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.6087000039988197, 'inference': 27.399699996749405, 'postprocess': 1.644500000111293},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.2025999933248386, 'inference': 34.109199994418304, 'postprocess': 1.6948999982560053},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 2.1007999966968782, 'inference': 29.09170000202721, 'postprocess': 1.2160999976913445},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ai\\\\AI-Development\\\\Yolo v8\\\\3. Keypoint Detection in YOLOv8 - Pose or YOLOv8 pose estimation\\\\video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\predict'\n",
       " speed: {'preprocess': 1.9513000006554648, 'inference': 22.407600001315586, 'postprocess': 2.1785999997518957},\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting on video\n",
    "source='video.mp4'\n",
    "\n",
    "model.predict(source, save=True, imgsz=320, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee25726-5664-4fc5-a157-eb9529eff1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: 0... Success  (inf frames of shape 640x480 at 30.00 FPS)\n",
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 256x320 1 person, 539.7ms\n",
      "0: 256x320 1 person, 13.0ms\n",
      "0: 256x320 1 person, 11.8ms\n",
      "0: 256x320 1 person, 20.3ms\n",
      "0: 256x320 1 person, 20.0ms\n",
      "0: 256x320 1 person, 15.9ms\n",
      "0: 256x320 1 person, 10.8ms\n",
      "0: 256x320 1 person, 13.3ms\n",
      "0: 256x320 1 person, 13.9ms\n",
      "0: 256x320 1 person, 13.0ms\n",
      "0: 256x320 1 person, 17.2ms\n",
      "0: 256x320 1 person, 15.0ms\n",
      "0: 256x320 1 person, 30.0ms\n",
      "0: 256x320 1 person, 28.2ms\n",
      "0: 256x320 1 person, 12.1ms\n",
      "0: 256x320 1 person, 21.0ms\n",
      "0: 256x320 1 person, 20.8ms\n",
      "0: 256x320 1 person, 34.0ms\n",
      "0: 256x320 1 person, 21.1ms\n",
      "0: 256x320 1 person, 9.5ms\n",
      "0: 256x320 1 person, 15.6ms\n",
      "0: 256x320 1 person, 15.5ms\n",
      "0: 256x320 1 person, 17.5ms\n",
      "0: 256x320 1 person, 13.9ms\n",
      "0: 256x320 1 person, 9.2ms\n",
      "0: 256x320 1 person, 14.4ms\n",
      "0: 256x320 1 person, 11.0ms\n",
      "0: 256x320 1 person, 24.5ms\n",
      "0: 256x320 1 person, 12.4ms\n",
      "0: 256x320 1 person, 15.2ms\n",
      "0: 256x320 1 person, 11.6ms\n",
      "0: 256x320 1 person, 9.8ms\n",
      "0: 256x320 1 person, 13.1ms\n",
      "0: 256x320 1 person, 14.6ms\n",
      "0: 256x320 1 person, 11.2ms\n",
      "0: 256x320 1 person, 19.6ms\n",
      "0: 256x320 1 person, 21.5ms\n",
      "0: 256x320 1 person, 13.3ms\n",
      "0: 256x320 1 person, 13.1ms\n",
      "0: 256x320 1 person, 10.8ms\n",
      "0: 256x320 1 person, 11.9ms\n",
      "0: 256x320 1 person, 37.5ms\n",
      "0: 256x320 1 person, 19.6ms\n",
      "0: 256x320 1 person, 14.8ms\n",
      "0: 256x320 1 person, 16.4ms\n",
      "0: 256x320 1 person, 10.0ms\n",
      "0: 256x320 1 person, 14.9ms\n",
      "0: 256x320 1 person, 22.2ms\n",
      "0: 256x320 1 person, 24.2ms\n",
      "0: 256x320 1 person, 25.0ms\n",
      "0: 256x320 1 person, 10.8ms\n",
      "0: 256x320 1 person, 18.2ms\n",
      "0: 256x320 1 person, 11.4ms\n",
      "0: 256x320 1 person, 9.9ms\n",
      "0: 256x320 1 person, 22.3ms\n",
      "0: 256x320 1 person, 10.6ms\n",
      "0: 256x320 1 person, 35.0ms\n",
      "0: 256x320 1 person, 15.4ms\n",
      "0: 256x320 1 person, 11.2ms\n",
      "0: 256x320 1 person, 11.5ms\n",
      "0: 256x320 1 person, 9.5ms\n",
      "0: 256x320 1 person, 11.9ms\n",
      "0: 256x320 1 person, 10.1ms\n",
      "0: 256x320 1 person, 10.6ms\n",
      "0: 256x320 1 person, 10.2ms\n",
      "0: 256x320 1 person, 25.3ms\n",
      "0: 256x320 1 person, 25.1ms\n",
      "0: 256x320 1 person, 23.6ms\n",
      "0: 256x320 1 person, 13.4ms\n",
      "0: 256x320 1 person, 14.3ms\n",
      "0: 256x320 1 person, 13.9ms\n",
      "0: 256x320 1 person, 24.1ms\n",
      "0: 256x320 1 person, 27.9ms\n",
      "0: 256x320 1 person, 11.3ms\n",
      "0: 256x320 1 person, 13.8ms\n",
      "0: 256x320 1 person, 16.9ms\n",
      "0: 256x320 1 person, 14.1ms\n",
      "0: 256x320 1 person, 10.4ms\n",
      "0: 256x320 1 person, 20.8ms\n",
      "0: 256x320 1 person, 11.2ms\n",
      "0: 256x320 1 person, 21.5ms\n",
      "0: 256x320 1 person, 17.5ms\n",
      "0: 256x320 1 person, 9.0ms\n",
      "0: 256x320 1 person, 30.2ms\n",
      "0: 256x320 1 person, 7.9ms\n",
      "0: 256x320 1 person, 19.1ms\n",
      "0: 256x320 1 person, 11.5ms\n",
      "0: 256x320 1 person, 32.1ms\n",
      "0: 256x320 1 person, 11.8ms\n",
      "0: 256x320 1 person, 13.6ms\n",
      "0: 256x320 1 person, 21.2ms\n",
      "0: 256x320 1 person, 11.3ms\n",
      "0: 256x320 1 person, 28.5ms\n",
      "0: 256x320 1 person, 12.0ms\n",
      "0: 256x320 1 person, 15.5ms\n",
      "0: 256x320 1 person, 12.3ms\n",
      "0: 256x320 1 person, 12.4ms\n",
      "0: 256x320 1 person, 11.7ms\n",
      "0: 256x320 1 person, 11.8ms\n",
      "0: 256x320 1 person, 16.1ms\n",
      "0: 256x320 1 person, 21.2ms\n",
      "0: 256x320 1 person, 16.8ms\n",
      "0: 256x320 1 person, 15.7ms\n",
      "0: 256x320 1 person, 11.2ms\n",
      "0: 256x320 1 person, 41.2ms\n",
      "0: 256x320 1 person, 12.6ms\n",
      "0: 256x320 1 person, 12.9ms\n",
      "0: 256x320 1 person, 12.3ms\n",
      "0: 256x320 1 person, 24.2ms\n",
      "0: 256x320 1 person, 20.4ms\n",
      "0: 256x320 1 person, 11.0ms\n",
      "0: 256x320 1 person, 27.4ms\n",
      "0: 256x320 1 person, 10.8ms\n",
      "0: 256x320 1 person, 33.8ms\n",
      "0: 256x320 1 person, 44.1ms\n",
      "0: 256x320 1 person, 10.8ms\n",
      "0: 256x320 1 person, 13.7ms\n",
      "0: 256x320 1 person, 10.7ms\n",
      "0: 256x320 1 person, 25.7ms\n",
      "0: 256x320 1 person, 14.7ms\n",
      "0: 256x320 1 person, 18.8ms\n",
      "0: 256x320 1 person, 26.3ms\n",
      "0: 256x320 1 person, 13.1ms\n",
      "0: 256x320 1 person, 23.8ms\n",
      "0: 256x320 1 person, 15.1ms\n",
      "0: 256x320 1 person, 13.3ms\n",
      "0: 256x320 1 person, 24.2ms\n",
      "0: 256x320 1 person, 13.4ms\n",
      "0: 256x320 1 person, 19.7ms\n",
      "0: 256x320 1 person, 16.3ms\n",
      "0: 256x320 1 person, 11.1ms\n",
      "0: 256x320 1 person, 12.0ms\n",
      "0: 256x320 1 person, 18.0ms\n",
      "0: 256x320 1 person, 18.1ms\n",
      "0: 256x320 1 person, 31.6ms\n",
      "0: 256x320 1 person, 11.2ms\n",
      "0: 256x320 1 person, 12.8ms\n",
      "0: 256x320 1 person, 19.5ms\n",
      "0: 256x320 1 person, 43.5ms\n",
      "0: 256x320 1 person, 19.9ms\n",
      "0: 256x320 1 person, 26.9ms\n",
      "0: 256x320 1 person, 27.9ms\n",
      "0: 256x320 1 person, 33.6ms\n",
      "0: 256x320 1 person, 28.8ms\n",
      "0: 256x320 1 person, 29.9ms\n",
      "0: 256x320 1 person, 12.7ms\n",
      "0: 256x320 1 person, 41.0ms\n",
      "0: 256x320 1 person, 20.8ms\n",
      "0: 256x320 1 person, 19.9ms\n",
      "0: 256x320 1 person, 34.0ms\n",
      "0: 256x320 1 person, 19.8ms\n",
      "0: 256x320 1 person, 26.6ms\n",
      "0: 256x320 1 person, 14.4ms\n",
      "0: 256x320 1 person, 20.8ms\n",
      "0: 256x320 1 person, 36.7ms\n",
      "0: 256x320 1 person, 11.1ms\n",
      "0: 256x320 1 person, 10.8ms\n",
      "0: 256x320 1 person, 14.8ms\n",
      "0: 256x320 1 person, 25.6ms\n",
      "0: 256x320 1 person, 12.3ms\n",
      "0: 256x320 1 person, 14.5ms\n",
      "0: 256x320 1 person, 10.5ms\n",
      "0: 256x320 1 person, 17.6ms\n",
      "0: 256x320 1 person, 13.0ms\n",
      "0: 256x320 1 person, 14.0ms\n",
      "0: 256x320 1 person, 20.9ms\n",
      "0: 256x320 1 person, 10.8ms\n",
      "0: 256x320 1 person, 10.8ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To use web cam for this use source as 0\n",
    "source = 0\n",
    "model.predict(source, save=True, imgsz=320, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6219128-1d75-4ef1-854a-9493b06b88cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 14.5ms\n",
      "Speed: 2.7ms preprocess, 14.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 13.9ms\n",
      "Speed: 1.7ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 26.4ms\n",
      "Speed: 2.3ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.9ms\n",
      "Speed: 1.9ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 15.2ms\n",
      "Speed: 2.9ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 14.3ms\n",
      "Speed: 1.6ms preprocess, 14.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 20.1ms\n",
      "Speed: 1.6ms preprocess, 20.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 24.1ms\n",
      "Speed: 3.1ms preprocess, 24.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.9ms\n",
      "Speed: 2.3ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 21.0ms\n",
      "Speed: 1.3ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 39.2ms\n",
      "Speed: 3.3ms preprocess, 39.2ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 2.7ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 14.9ms\n",
      "Speed: 3.3ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 2.2ms preprocess, 12.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 1.8ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 3.5ms preprocess, 16.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 14.1ms\n",
      "Speed: 3.4ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.9ms\n",
      "Speed: 2.3ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 14.7ms\n",
      "Speed: 2.6ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.7ms\n",
      "Speed: 6.5ms preprocess, 16.7ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 36.4ms\n",
      "Speed: 3.0ms preprocess, 36.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 12.9ms\n",
      "Speed: 1.6ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 33.8ms\n",
      "Speed: 3.4ms preprocess, 33.8ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 25.3ms\n",
      "Speed: 2.8ms preprocess, 25.3ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 29.8ms\n",
      "Speed: 3.7ms preprocess, 29.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 13.7ms\n",
      "Speed: 1.8ms preprocess, 13.7ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 2.8ms preprocess, 13.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 28.6ms\n",
      "Speed: 2.4ms preprocess, 28.6ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 29.4ms\n",
      "Speed: 2.9ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 36.7ms\n",
      "Speed: 3.0ms preprocess, 36.7ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 35.3ms\n",
      "Speed: 3.8ms preprocess, 35.3ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 42.8ms\n",
      "Speed: 3.8ms preprocess, 42.8ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.4ms\n",
      "Speed: 3.2ms preprocess, 18.4ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.6ms\n",
      "Speed: 3.0ms preprocess, 18.6ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 15.6ms\n",
      "Speed: 1.7ms preprocess, 15.6ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.6ms\n",
      "Speed: 1.8ms preprocess, 18.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 1.8ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.3ms\n",
      "Speed: 1.7ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.5ms\n",
      "Speed: 2.3ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.6ms\n",
      "Speed: 2.1ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.7ms\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.0ms\n",
      "Speed: 2.6ms preprocess, 17.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.5ms\n",
      "Speed: 2.6ms preprocess, 18.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.9ms\n",
      "Speed: 2.1ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 21.4ms\n",
      "Speed: 1.7ms preprocess, 21.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.8ms\n",
      "Speed: 2.8ms preprocess, 16.8ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 16.8ms\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 20.5ms\n",
      "Speed: 2.5ms preprocess, 20.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 1.9ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.9ms\n",
      "Speed: 1.7ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.4ms\n",
      "Speed: 2.9ms preprocess, 17.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 2.7ms preprocess, 17.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.5ms\n",
      "Speed: 1.6ms preprocess, 17.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.6ms\n",
      "Speed: 1.6ms preprocess, 17.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.6ms\n",
      "Speed: 1.9ms preprocess, 17.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.4ms\n",
      "Speed: 2.2ms preprocess, 17.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.4ms\n",
      "Speed: 1.9ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.8ms\n",
      "Speed: 2.3ms preprocess, 17.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 1.8ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 1.7ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.8ms\n",
      "Speed: 2.5ms preprocess, 17.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.1ms\n",
      "Speed: 2.2ms preprocess, 18.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.0ms\n",
      "Speed: 1.7ms preprocess, 18.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.5ms\n",
      "Speed: 2.6ms preprocess, 18.5ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.0ms\n",
      "Speed: 2.1ms preprocess, 18.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.8ms\n",
      "Speed: 1.7ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.7ms\n",
      "Speed: 1.8ms preprocess, 18.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.2ms\n",
      "Speed: 1.7ms preprocess, 18.2ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.0ms\n",
      "Speed: 1.7ms preprocess, 18.0ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.0ms\n",
      "Speed: 1.7ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.9ms\n",
      "Speed: 2.6ms preprocess, 17.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.1ms\n",
      "Speed: 1.8ms preprocess, 18.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.8ms\n",
      "Speed: 1.7ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.6ms\n",
      "Speed: 2.3ms preprocess, 18.6ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.4ms\n",
      "Speed: 1.9ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.5ms\n",
      "Speed: 2.4ms preprocess, 18.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.5ms\n",
      "Speed: 1.8ms preprocess, 18.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.5ms\n",
      "Speed: 1.7ms preprocess, 18.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.6ms\n",
      "Speed: 1.7ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.1ms\n",
      "Speed: 2.9ms preprocess, 19.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.6ms\n",
      "Speed: 2.4ms preprocess, 18.6ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.7ms\n",
      "Speed: 1.9ms preprocess, 18.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.6ms\n",
      "Speed: 2.5ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.3ms\n",
      "Speed: 1.7ms preprocess, 19.3ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.2ms\n",
      "Speed: 2.8ms preprocess, 19.2ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.2ms\n",
      "Speed: 1.8ms preprocess, 19.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.3ms\n",
      "Speed: 2.0ms preprocess, 19.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.4ms\n",
      "Speed: 2.2ms preprocess, 19.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.4ms\n",
      "Speed: 1.9ms preprocess, 19.4ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.1ms\n",
      "Speed: 2.2ms preprocess, 19.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.2ms\n",
      "Speed: 2.2ms preprocess, 19.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.3ms\n",
      "Speed: 1.9ms preprocess, 19.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 19.1ms\n",
      "Speed: 2.2ms preprocess, 19.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.9ms\n",
      "Speed: 2.0ms preprocess, 18.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 18.0ms\n",
      "Speed: 1.9ms preprocess, 18.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 17.9ms\n",
      "Speed: 1.8ms preprocess, 17.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# opening web cam interface\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# load the YOLOv8 model\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# open the video file\n",
    "# video_path = 'path/to/video.mp4'\n",
    "\n",
    "video_path = 0  # for web cam\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the cideo frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame, save=True)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # display the annotated frame\n",
    "        cv2.imshow('YOLOv8 Interference', annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        # break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# reload the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0fa48-bcbb-42d2-9f33-574ecf3a4e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0a9b5-fa3a-499e-b3b5-b497c2ac37aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08d8fc-3468-4f1f-b78a-d15b63837159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda1731-0b69-4729-bc00-3bc4726aa874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2eb99-4579-4d41-a751-7b48e1a090d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
