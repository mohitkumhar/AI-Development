{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc99a071-2d97-4563-bcfe-91d7ea664103",
   "metadata": {},
   "source": [
    "## Types of optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894c3b7d-2569-44e8-a241-7d174c5fc549",
   "metadata": {},
   "source": [
    "1. Batch Gradient Descent\n",
    "2. Stochastic Gradient Descent\n",
    "3. Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e0828-af83-4f52-b9b3-98db3df4cc96",
   "metadata": {},
   "source": [
    "# ğŸš€ Types of Gradient Descent: Advantages & Disadvantages  \n",
    "\n",
    "Gradient Descent is a method used to minimize the loss in machine learning. There are three main types:  \n",
    "\n",
    "## 1ï¸âƒ£ **Batch Gradient Descent**  \n",
    "**ğŸ“ How it works:** Uses the entire dataset to update weights after every step.  \n",
    "\n",
    "### âœ… **Advantages:**  \n",
    "- **Stable updates** â†’ Less noise, smooth convergence.  \n",
    "- **Efficient for convex problems** â†’ Works well when thereâ€™s only one minimum.  \n",
    "- **Uses matrix operations** â†’ Faster on small datasets.  \n",
    "\n",
    "### âŒ **Disadvantages:**  \n",
    "- **Slow for large datasets** â†’ Takes too long when data is huge.  \n",
    "- **High memory usage** â†’ Needs to store all data.  \n",
    "- **Can get stuck in local minima** â†’ Not great for complex problems.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ **Stochastic Gradient Descent (SGD)**  \n",
    "**ğŸ“ How it works:** Updates weights after every single data point.  \n",
    "\n",
    "### âœ… **Advantages:**  \n",
    "- **Fast updates** â†’ Learns quickly.  \n",
    "- **Works well for large datasets** â†’ Doesn't need all data at once.  \n",
    "- **Can escape local minima** â†’ Good for complex problems.  \n",
    "\n",
    "### âŒ **Disadvantages:**  \n",
    "- **Noisy updates** â†’ Can jump around instead of smoothly decreasing.  \n",
    "- **Harder to tune** â†’ Learning rate must be adjusted properly.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3ï¸âƒ£ **Mini-Batch Gradient Descent**  \n",
    "**ğŸ“ How it works:** Uses small groups (mini-batches) of data to update weights.  \n",
    "\n",
    "### âœ… **Advantages:**  \n",
    "- **Balances speed and stability** â†’ Faster than Batch GD, smoother than SGD.  \n",
    "- **Works well with GPUs** â†’ Efficient for deep learning.  \n",
    "- **Uses less memory** â†’ Handles big datasets better.  \n",
    "\n",
    "### âŒ **Disadvantages:**  \n",
    "- **Still needs tuning** â†’ Batch size affects performance.  \n",
    "- **Not as fast as pure SGD** â†’ But still better than Batch GD.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¥ **Which One Should You Use?**  \n",
    "\n",
    "| Scenario | Best Gradient Descent Type |\n",
    "|----------|--------------------------|\n",
    "| Small dataset | **Batch Gradient Descent** |\n",
    "| Large dataset | **Mini-Batch GD or SGD** |\n",
    "| Need fast updates | **Mini-Batch GD** |\n",
    "| Complex problem | **SGD (escapes local minima better)** |\n",
    "| Deep learning (GPU) | **Mini-Batch GD** |\n",
    "\n",
    "### **Conclusion:**  \n",
    "- **Batch GD** â†’ Best for small datasets, smooth convergence.  \n",
    "- **SGD** â†’ Best for large datasets and escaping bad local minima.  \n",
    "- **Mini-Batch GD** â†’ Best of both worlds, commonly used in deep learning.  \n",
    "\n",
    "ğŸš€ **Mini-Batch Gradient Descent is the most widely used method today!**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc28809-1e02-451f-aeae-afe6e6027d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
