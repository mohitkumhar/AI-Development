{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be164c18-d8cc-49b6-84f1-acebe901e6c4",
   "metadata": {},
   "source": [
    "## 1. Fine tuning NN hyper parameters\n",
    "1. Epochs\n",
    "2. Hidden Layers\n",
    "3. Neurons Per Layer\n",
    "4. Learning Rate - Gradient Descent\n",
    "5. Optimizer - Gradient Descent\n",
    "6. BatchSize\n",
    "7. Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d1802e-37e1-4d50-b67e-79ff761fdd54",
   "metadata": {},
   "source": [
    "## 2. By Solving Problems\n",
    "- Vanishing/ Exploding Gradient\n",
    "- Not Enough Data\n",
    "- Slow Training\n",
    "- Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7d367-9012-4bcd-8ed4-cd0adf7e5f90",
   "metadata": {},
   "source": [
    "# <center> Fine Tuning HyperParameter </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba6653-86a5-4cc4-9a97-654def7c3b61",
   "metadata": {},
   "source": [
    "#### 1. No. of hidden Layers:\n",
    "- increase the number of hiddne layers instead of increasing the number of neurons\n",
    "- Increasing the number of hidden layers helps in capturing complex patterns and hierarchical features more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e924c6-76c7-48ba-8808-fdd7bda0e0d3",
   "metadata": {},
   "source": [
    "#### 2. Number of Neurons per Layer\n",
    "- Choose the number of neurons per layer based on the complexity of the data; too many can lead to overfitting, while too few may underfit.\n",
    "- A good practice is to start with a higher number in initial layers and gradually decrease in deeper layers to extract high-level features efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c248c-40ea-4d8e-ba48-39ffbd9c196a",
   "metadata": {},
   "source": [
    "#### 3. Batch Size:\n",
    "- Smaller Batch Size gives good result but is slower\n",
    "- Bigger Batch Size are faster but not gives good result\n",
    "- Researches Gives a better Approach of this problem is that:\n",
    "- - give big batch size but keeps the learning rate dynamic\n",
    "  - learning rate should be low in beginning but later it should be increase gradually\n",
    "  - it maintain the speed of training and result will also be good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdcbad-252b-42e5-9dfe-ab30c9730f09",
   "metadata": {},
   "source": [
    "#### 4. Epochs:\n",
    "- use early stopping which has the ability to stop the training when the performance of the model becomes stable\n",
    "- it is implemented using a feature called callback in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50630e8-bf4b-49f8-9b43-a859f08be655",
   "metadata": {},
   "source": [
    "# Problems With Neural Network\n",
    "1. Vanishing and Exploding Gradients\n",
    "   - - Weight initialization\n",
    "     - Activation Function\n",
    "     - Batch Normalization\n",
    "     - Gradient Clipping (used for Exploding Gradients)\n",
    "       \n",
    "2. Not Enough Data\n",
    "    - - Transfer Learning (use another model)\n",
    "      - unsupervised pretraining\n",
    "           \n",
    "3. Slow Trakkining\n",
    "    - - Optimizers\n",
    "      - Learning Rate Scheduler\n",
    "   \n",
    "4. Overfitting\n",
    "    - - l1 and l2 regularization\n",
    "      - Dropouts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61dc0b-3d8f-4779-986c-d622b6cc476c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
