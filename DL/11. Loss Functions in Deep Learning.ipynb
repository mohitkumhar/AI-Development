{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e48e446-f6bd-474f-8882-cb10186b5b26",
   "metadata": {},
   "source": [
    "### What is Loss Function?\n",
    "- Loss Function is a method of evaluating how well you algorithm is modeling your dataset\n",
    "- - High Loss function means poor model performance\n",
    "  - Small Loss Function means Great model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c78220-a919-4203-8540-76a7300973ea",
   "metadata": {},
   "source": [
    "### Why is Loss Function important?\n",
    "- it acts as the guiding metric for the optimization process\n",
    "- it tells how well model is performing\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f6b7b-42a7-40ed-b432-c24ae9ba826e",
   "metadata": {},
   "source": [
    "### Types of Loss Function\n",
    "\n",
    "- 1. Regression\n",
    "- - MSE\n",
    "  - MAE\n",
    "  - Huber Loss\n",
    "<br>\n",
    "<br>\n",
    "- 2. Classification\n",
    "- - Binary Class Entropy\n",
    "  - Categorical cross Entropy\n",
    "  - Hinge Loss\n",
    "<br>\n",
    "<br>\n",
    "- 3. Autoencoder\n",
    "- - K L divergence\n",
    "<br>\n",
    "<br>\n",
    "- 4. GAN\n",
    "- - Discriminator Loss\n",
    "  - MinMax GAN Loss\n",
    "<br>\n",
    "<br>\n",
    "- 5. Object Detection\n",
    "- - Focal Loss\n",
    "<br>\n",
    "<br>\n",
    "- 6. Embedding\n",
    "- - Triplet Loss\n",
    "<br><br>\n",
    "\n",
    "#### We can also create our own loss function using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c461aa-1796-4ba0-ba7e-8f846d21332e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c65b9-cae0-4d5c-809d-28ddcbe99c8a",
   "metadata": {},
   "source": [
    "### 1. Mean Squared Error\n",
    "- formula = (true - predict) ^2\n",
    "\n",
    "#### Advantages: \n",
    "1. Punishes large errors more, improvig accuracy\n",
    "2. Smooth function, easy to optimize\n",
    "3. Standard & widely used in ML & regression\n",
    "\n",
    "#### Disadvantages: \n",
    "1. Very sensitive to outliers\n",
    "2. Hard to interpret due to squared units\n",
    "3. Prefers small errors over a few large ones\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a44197-660b-41b5-904a-5ce7a24d6ee2",
   "metadata": {},
   "source": [
    "### 2. Mean Absolute Error\n",
    "- MAE measures the average absolute difference between actual and predicted values.\n",
    "- Unlike MSE, it does not square errors, making it less sensitive to outliers.\n",
    "\n",
    "#### Advantages:\n",
    "1. Less sensitive to outliers compared to MSE.\n",
    "2. Easy to interpret (same unit as the target variable).\n",
    "3. Useful for real-world problems like stock price prediction.\n",
    "\n",
    "#### DisAdvantages:\n",
    "1. Not differentiable at zero, which can make optimization harder.\n",
    "2. Treats all errors equally, even when some should matter more.\n",
    "3. Can be harder to optimize compared to MSE in some cases.\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "daa78d9f-e2b0-4cfc-9a3d-5863c7c107fc.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "4038d7c3-df35-40d2-8471-10fec384a02b",
   "metadata": {},
   "source": [
    "### Huber Loss\n",
    "- Best and most useful when we have many outliers\n",
    "![image.png](attachment:daa78d9f-e2b0-4cfc-9a3d-5863c7c107fc.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8c83d-7f86-4d3e-8117-8f7b80e7956d",
   "metadata": {},
   "source": [
    "### 4. Binary Cross Entropy\n",
    "- Binary Classification\n",
    "- Two classes\n",
    "- Always use Sigmoid as a output Activation Function\n",
    "- - Formula:\n",
    "  - - (y * log(p) + (1 - y) * log(1 - p))\n",
    "    - Where:\n",
    "    - \"y\" represents the true label (0 or 1)\n",
    "    - \"p\" is the predicted probability of the positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c3ffeb-7ff9-4646-ad40-aa65f17f9a3a",
   "metadata": {},
   "source": [
    "### 5. Categorical Cross Entropy\n",
    "- Categorical Cross Entropy is a loss function used in classification problems where the output has multiple categories.\n",
    "- It measures how different the predicted probability distribution is from the actual (true) distribution.\n",
    "    - If the model predicts a High probability for the correct class, the loss is Low.\n",
    "    - If the model predicts a Low probability for the correct class, the loss is High.\n",
    "\n",
    "- It requires a One Hot Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3af64-d801-4cb2-8d23-a464c236c0dc",
   "metadata": {},
   "source": [
    "### 6. Sparse Categorical Cross Entropy\n",
    "- Sparse Categorical Cross Entropy is a loss function used for multi-class classification when labels are integer-encoded instead of one-hot encoded.\n",
    "- It works similarly to Categorical Cross Entropy (CCE) but is more memory-efficient because it doesn't require converting labels into one-hot vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266a06a1-1ec1-404b-93f6-2c459ceb1057",
   "metadata": {},
   "source": [
    "# Summary\n",
    "<pre>\n",
    "### Regression - 1. MSE\n",
    "                 2. MAE  (Used When Outliers in data)\n",
    "                 3. Huber loss (if data has many outliers)\n",
    "                 \n",
    "\n",
    "### Classification - 1. Binary Class Entropy (when problem is of binary classification)\n",
    "                     2. Sparse Class Entropy (when problem is of multi class classification)\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e4ecd-0c22-4d29-b4e1-dd85fffab615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
